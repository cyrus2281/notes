{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP9Y/aDssBhc9zPVDoxkLWV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cyrus2281/notes/blob/main/Math/Algebra.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">[Linear Algebra](#scrollTo=xEknEZHZbH8O&uniqifier=5)\n",
        "\n",
        ">>[Axioms](#scrollTo=jxwAHVOfvsj6&uniqifier=5)\n",
        "\n",
        ">>[Function](#scrollTo=a2ShAoylSoM_&uniqifier=5)\n",
        "\n",
        ">>>[Transformation](#scrollTo=KBuiX44AzCOi&uniqifier=5)\n",
        "\n",
        ">>[Vectors](#scrollTo=vT2WbMjAbSfc&uniqifier=5)\n",
        "\n",
        ">>>[Engineering notation](#scrollTo=MTbhFtZ_WG9s&uniqifier=5)\n",
        "\n",
        ">>>[Standard Form Notation](#scrollTo=i0U8W2ASXfgN&uniqifier=5)\n",
        "\n",
        ">>>[Norms](#scrollTo=kuihvriNM1iv&uniqifier=5)\n",
        "\n",
        ">>>>[Types of Norms](#scrollTo=GsYJtJqERs-L&uniqifier=5)\n",
        "\n",
        ">>>>[Unit Vectors](#scrollTo=t3GKNy1WgVv6&uniqifier=5)\n",
        "\n",
        ">>>>[Normalization](#scrollTo=3jUvN70Yk8hp&uniqifier=5)\n",
        "\n",
        ">>>[Vector Summation](#scrollTo=ErevL6nidtLX&uniqifier=5)\n",
        "\n",
        ">>>[Vector Multiplication (Scaling)](#scrollTo=c_Ty0QhXelvN&uniqifier=5)\n",
        "\n",
        ">>>>[Scaler Multiplication](#scrollTo=Jo36BozVtVY2&uniqifier=5)\n",
        "\n",
        ">>>>[Vector Dot Products](#scrollTo=KeLuek7ksooP&uniqifier=5)\n",
        "\n",
        ">>>>[Cross Product](#scrollTo=uaQCLUDCrO-L&uniqifier=5)\n",
        "\n",
        ">>>>>[Triple Cross Product Expansion](#scrollTo=kpudH0fWxaAq&uniqifier=5)\n",
        "\n",
        ">>>[Vector Properties](#scrollTo=UNaCljYcaW1y&uniqifier=5)\n",
        "\n",
        ">>>>[Vector Length](#scrollTo=p1y2qtSx_2R4&uniqifier=5)\n",
        "\n",
        ">>>>[Cauchy-Schwarz inequality](#scrollTo=DsClyT-1BrmA&uniqifier=5)\n",
        "\n",
        ">>>>[Vector Triangle Inequality](#scrollTo=n4QGvEesLkjl&uniqifier=5)\n",
        "\n",
        ">>>>[Angle Between Vectors & Dot Product](#scrollTo=5y4gZqYEamyR&uniqifier=5)\n",
        "\n",
        ">>>>>[Orthogonal Vectors](#scrollTo=gAXs8uPAcdIf&uniqifier=5)\n",
        "\n",
        ">>>>[Angle Between Vectors & Cross Product](#scrollTo=aWPFZOUFpuaU&uniqifier=5)\n",
        "\n",
        ">>>[Parametric Representations of lines](#scrollTo=3Zh3uUClSkza&uniqifier=5)\n",
        "\n",
        ">>>[Vector Transposition](#scrollTo=pQhPbgrXUPMh&uniqifier=5)\n",
        "\n",
        ">>>[Linear Combination](#scrollTo=Qdut1DFCiPWS&uniqifier=5)\n",
        "\n",
        ">>>>[Linearly Dependent](#scrollTo=z_6VtDCd6MEs&uniqifier=5)\n",
        "\n",
        ">>>>[Linearly independent](#scrollTo=WZfmHmfG6U80&uniqifier=5)\n",
        "\n",
        ">>>>[Linear Subspaces](#scrollTo=6OS55GPMeNsr&uniqifier=5)\n",
        "\n",
        ">>>[Linear Transformation](#scrollTo=1wkRY7nklziS&uniqifier=5)\n",
        "\n",
        ">>>>[Locally Linear Transformation](#scrollTo=Reyj1BDI-BA5&uniqifier=5)\n",
        "\n",
        ">>>[Point Distance to Plane](#scrollTo=rhXMf_ER0va3&uniqifier=5)\n",
        "\n",
        ">>>[Distance Between Parallel  Planes](#scrollTo=zDNMMYCT2n0T&uniqifier=5)\n",
        "\n",
        ">>[Matrices](#scrollTo=UzMIA2NFW5RI&uniqifier=5)\n",
        "\n",
        ">>>[Zero Matrix](#scrollTo=I4JwtScnhMIR&uniqifier=5)\n",
        "\n",
        ">>>[Matrix Addition properties](#scrollTo=9C03iFYkjLoj&uniqifier=5)\n",
        "\n",
        ">>>[Scalar Multiplication Properties](#scrollTo=76pGup2kf98P&uniqifier=5)\n",
        "\n",
        ">>>[Matrix tranformation](#scrollTo=J20yGJu3psPi&uniqifier=5)\n",
        "\n",
        ">>>>[Composition](#scrollTo=Mxvaf7bpsIgX&uniqifier=5)\n",
        "\n",
        ">>>[Reduced Row-Echelon Form (RREF)](#scrollTo=qM5ewkzXgxe0&uniqifier=5)\n",
        "\n",
        ">>>[Determinant](#scrollTo=SZpMS8NK1wzr&uniqifier=5)\n",
        "\n",
        ">>>>[$3\\times 3$ Determinant](#scrollTo=gG5AsXcF5Iqo&uniqifier=5)\n",
        "\n",
        ">>>>[$n\\times n$ determinant](#scrollTo=u3RYNCohlojl&uniqifier=5)\n",
        "\n",
        ">>>>[Rule of Sarrus of determinants](#scrollTo=U4P5jhX8vDjH&uniqifier=5)\n",
        "\n",
        ">>>>[Determinant multiplied by scalar](#scrollTo=cgtDzLwx0sdq&uniqifier=5)\n",
        "\n",
        ">>>>[Triangular Determinant](#scrollTo=dxuFFexQ6Z4P&uniqifier=5)\n",
        "\n",
        ">>>[Transpose](#scrollTo=gr3fEUVtw_QJ&uniqifier=5)\n",
        "\n",
        ">>>>[Determinant of Transpose](#scrollTo=a-atRXiGFzMO&uniqifier=5)\n",
        "\n",
        ">>>>[Properties of Transpose](#scrollTo=FWqUd9ce8HmK&uniqifier=5)\n",
        "\n",
        ">>>>[Transpose of a vector](#scrollTo=JyF4D-8D_rcX&uniqifier=5)\n",
        "\n",
        ">>>[Dot Product](#scrollTo=CSpK2ytvbNgg&uniqifier=5)\n",
        "\n",
        ">>>[Matrix Multiplication Properties](#scrollTo=fc5P7JNi3Xmy&uniqifier=5)\n",
        "\n",
        ">>>[Identity Matrix](#scrollTo=hFnazoZKc__K&uniqifier=5)\n",
        "\n",
        ">>>[Matrix Properties](#scrollTo=9dBL2Pi9sA1E&uniqifier=5)\n",
        "\n",
        ">>>>[Rank](#scrollTo=y7iq5uvU90dH&uniqifier=5)\n",
        "\n",
        ">>>>[Null Space](#scrollTo=F2qxt9eVvX2J&uniqifier=5)\n",
        "\n",
        ">>>>>[Kernel](#scrollTo=0jQNy3qkHINt&uniqifier=5)\n",
        "\n",
        ">>>>>[Nullity (Dimension of the null space)](#scrollTo=A96dj8PBF5Sg&uniqifier=5)\n",
        "\n",
        ">>>>[Column Space](#scrollTo=R_FN1MbX74qR&uniqifier=5)\n",
        "\n",
        ">>>>>>[Column Space Basis](#scrollTo=u0i6r-El6879&uniqifier=5)\n",
        "\n",
        ">>>>>[Dimension of the column space (Rank)](#scrollTo=lSWOaucrLpPJ&uniqifier=5)\n",
        "\n",
        ">>>[Orthogonal Complements](#scrollTo=rqlnu64_L3IB&uniqifier=5)\n",
        "\n",
        ">>>>[Orthogonal Complements  Properties](#scrollTo=T9EijUZdZLtu&uniqifier=5)\n",
        "\n",
        ">>>>>[$\\dim(v) +\\dim(v^\\perp) = n$](#scrollTo=MLZRm48EmP01&uniqifier=5)\n",
        "\n",
        ">>>>>[Representing vectors in $R^n$ using subspace members](#scrollTo=vJZCf7hhfVHc&uniqifier=5)\n",
        "\n",
        ">>>>>[Orthogonal complement of the orthogonal complement](#scrollTo=NfdtRGdPpe9M&uniqifier=5)\n",
        "\n",
        ">>>>>[Orthogonal complement of the nullspace](#scrollTo=6jKuMKL_rmo4&uniqifier=5)\n",
        "\n",
        ">>>>>[Unique rowspace solution to $A\\vec x = \\vec b$](#scrollTo=6_T2NB0IukzQ&uniqifier=5)\n",
        "\n",
        ">>>>[Orthogonal Projections](#scrollTo=4ffq8roTepOM&uniqifier=5)\n",
        "\n",
        ">>>>>[Subspace Projection Matrix](#scrollTo=D4QOaTbTnfUW&uniqifier=5)\n",
        "\n",
        ">>>>>[Least Squares Approximation](#scrollTo=qMam0U-svNRy&uniqifier=5)\n",
        "\n",
        ">>>[Coefficient Matrix Equations](#scrollTo=XWULL_FQ-Q-h&uniqifier=5)\n",
        "\n",
        ">>>[Cramer's Rule](#scrollTo=Hpujf5wwYyR4&uniqifier=5)\n",
        "\n",
        ">>>[Projections](#scrollTo=dK9c2SqnmCMx&uniqifier=5)\n",
        "\n",
        ">>>>[Matrix Projection](#scrollTo=HSo2p8Cewpqc&uniqifier=5)\n",
        "\n",
        ">>>[Invertible Functions](#scrollTo=F9FJEJZIKQ5p&uniqifier=5)\n",
        "\n",
        ">>>>[Surjective Functions](#scrollTo=XyqZSG_ZH1dd&uniqifier=5)\n",
        "\n",
        ">>>>[Injective  Functions](#scrollTo=Nw4ON0_zIKLQ&uniqifier=5)\n",
        "\n",
        ">>>[Inverse Transformation](#scrollTo=rUSkuk4E1ssH&uniqifier=5)\n",
        "\n",
        ">>>>[Inverses of $2\\times 2$ Matrices](#scrollTo=gpjXDSCCNJcC&uniqifier=5)\n",
        "\n",
        ">>>>[Inverse of $n\\times n$ Matrices](#scrollTo=0o1Ex74kOZrp&uniqifier=5)\n",
        "\n",
        ">>>>[Determine of inverse matrix](#scrollTo=sfjlE2GpD3W0&uniqifier=5)\n",
        "\n",
        ">>>>>[Invertible Matrices](#scrollTo=Rr2CMfPMESiT&uniqifier=5)\n",
        "\n",
        ">>>[Coordinates with Respect to Basis](#scrollTo=BSCVdCtceklu&uniqifier=5)\n",
        "\n",
        ">>>>[Change of Basis](#scrollTo=LiPYXEv97iNJ&uniqifier=5)\n",
        "\n",
        ">>>>[Inverting Change of Basis Matrix](#scrollTo=haKrbbfPmoD7&uniqifier=5)\n",
        "\n",
        ">>>>[Transformation Matrix with Respect to Basis](#scrollTo=dKgTq39soNui&uniqifier=5)\n",
        "\n",
        ">>>[Orthonormal Bases](#scrollTo=xa3UAOUErSxX&uniqifier=5)\n",
        "\n",
        ">>>>>[Coordinates with Respect to Orthonormal Bases](#scrollTo=UkzUfHvWu_0g&uniqifier=5)\n",
        "\n",
        ">>>>[Projections onto Subspaces with Orthonormal Bases](#scrollTo=IornFHEayi5w&uniqifier=5)\n",
        "\n",
        ">>>>[Orthogonal Matrices](#scrollTo=ayymun1w8Cnh&uniqifier=5)\n",
        "\n",
        ">>>>[Gram-Schmidt Process](#scrollTo=q1pv35i1AjgB&uniqifier=5)\n",
        "\n",
        ">>[Eigenvectors and Eigenvalues](#scrollTo=MiJFEx1DmdJY&uniqifier=5)\n",
        "\n",
        ">>>[Eigenspace](#scrollTo=9oB2xNaoznqA&uniqifier=5)\n",
        "\n",
        ">>>[Eigenbasis](#scrollTo=GSjkAC7GuLMz&uniqifier=5)\n",
        "\n",
        ">[Linear Alegbra in Machine Learning](#scrollTo=zYTbTlV1KPjo&uniqifier=5)\n",
        "\n",
        ">>[Components and terminologies](#scrollTo=n5ZltHajOEtm&uniqifier=5)\n",
        "\n",
        ">>>[Algebra Data Structures](#scrollTo=viQVRsfjOLeF&uniqifier=5)\n",
        "\n",
        ">>>>[Scalars](#scrollTo=jkuL_P83PMFF&uniqifier=5)\n",
        "\n",
        ">>>>[Vectors](#scrollTo=Bg_6oXy6S6Sd&uniqifier=5)\n",
        "\n",
        ">>>>[Matrices](#scrollTo=hUTiFYSxcor2&uniqifier=5)\n",
        "\n",
        ">>>>[Tensors](#scrollTo=uMUSQGUFg6Da&uniqifier=5)\n",
        "\n",
        ">[Linear Alegbra with Python](#scrollTo=xET4Mhr-KTt9&uniqifier=5)\n",
        "\n",
        ">>[Algebra Data Structures](#scrollTo=3qG3rsFJQ8Jm&uniqifier=5)\n",
        "\n",
        ">>>[Scalars](#scrollTo=2DEyMiqLREeX&uniqifier=5)\n",
        "\n",
        ">>>[Vectors](#scrollTo=7T56m3JyVWup&uniqifier=5)\n",
        "\n",
        ">>>>[Vector Norm](#scrollTo=aOToo72eNbdC&uniqifier=5)\n",
        "\n",
        ">>>[Matrices](#scrollTo=yh1tKxq2chmM&uniqifier=5)\n",
        "\n",
        ">>>[Tensors](#scrollTo=rPFjl60WiLgI&uniqifier=5)\n",
        "\n",
        ">>[Tensor Operations](#scrollTo=F7XyS8HNi26f&uniqifier=5)\n",
        "\n",
        ">[Resouces](#scrollTo=hO6aVIMt58u7&uniqifier=5)\n",
        "\n"
      ],
      "metadata": {
        "colab_type": "toc",
        "id": "iAIDmcGU1P68"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Algebra"
      ],
      "metadata": {
        "id": "xEknEZHZbH8O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Axioms**\n",
        "The rules and formulas of linear algebra applies to any vector space, as long as the following rulses, known as **Axioms**, are met.\n",
        "\n",
        "1. $\\vec{u} + (\\vec{v}+\\vec{w}) = (\\vec{u}+\\vec{v})+\\vec{w}$\n",
        "2. $\\vec{v}+\\vec{w} = \\vec{w} + \\vec{v}$\n",
        "3. There is a vector 0 such that $0+\\vec{v}=\\vec{v}$ for all $\\vec{v}$\n",
        "4. For every vector $\\vec{v}$ there is a vector $-\\vec{v}$ so that $\\vec{v}+(-\\vec{v})=0$\n",
        "5. $a(b\\vec{v}) = (ab)\\vec{v}$\n",
        "6. $1\\vec{v}=\\vec{v}$\n",
        "7. $a(\\vec{v} + \\vec{w}) = a\\vec{v} + a\\vec{w}$\n",
        "8. $(a+b)\\vec{v} = a\\vec{v} + b\\vec{v}$"
      ],
      "metadata": {
        "id": "jxwAHVOfvsj6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function\n",
        "\n",
        "Function take an input from the domain A and outputs a value in the codomain B.\n",
        "\n",
        "* domain and codomain can be the same thing: $f: R \\mapsto  R$\n",
        "* domain and codomain can be different: $f: R \\mapsto  R^2$\n",
        "\n",
        "\n",
        "Range is the subset of the codomain that includes the possible output values.\n",
        "* range $\\in$ codomain\n"
      ],
      "metadata": {
        "id": "a2ShAoylSoM_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformation\n",
        "\n",
        "A function on vectors."
      ],
      "metadata": {
        "id": "KBuiX44AzCOi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vectors\n",
        "\n",
        "**In physics:** Arrows pointing in space. It is defined by a length and a direction. It can be moved around and it's still the same vector. They can be in 2 or 3 dimentional world.\n",
        "\n",
        "**In Computer Science:** Ordered list of numbers. It can be of any dimention\n",
        "\n",
        "**In Mathematics:** Anything where there's a sensible notion of adding two vetors and multiplying a vector by a number.\n",
        "\n"
      ],
      "metadata": {
        "id": "vT2WbMjAbSfc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Engineering notation\n",
        "\n",
        "Cartesian Coordinates\n",
        "\n",
        "$$\n",
        "\\vec{u} = (a,b) = \\begin{bmatrix}a\\\\b\\end{bmatrix} = a\\hat{i} + b\\hat{j}\n",
        "$$\n",
        "\n",
        "> $R^2$ refers to the 2-dimensional real coordinate space"
      ],
      "metadata": {
        "id": "MTbhFtZ_WG9s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Standard Form Notation\n",
        "\n",
        "$$\n",
        "\\vec{v} = (a,b) = \\|\\vec{v}\\|, \\theta \\\\\n",
        "\\|\\vec{v}\\| = \\sqrt{a^2+b^2}\\\\\n",
        "\\theta = \\arctan(\\frac{a}{b})\n",
        "$$\n",
        "\n",
        "Note: Arctan returns the response for quadrant 1 and 4, additional calculating for quadrant 2 and 3 vectors would need an addition of 180 or 360 degress to the response.\n",
        "\n",
        "\n",
        "**Standard Form to Component Form:**\n",
        "\n",
        "$$\n",
        "\\vec{v} = \\|\\vec{v}\\|, \\theta = (\\|\\vec{v}\\| \\cos \\theta, \\|\\vec{v}\\| \\sin \\theta)\n",
        "$$"
      ],
      "metadata": {
        "id": "i0U8W2ASXfgN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Norms\n",
        "\n",
        "> Norms are functions that quantify vector magnitude.\n"
      ],
      "metadata": {
        "id": "kuihvriNM1iv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Types of Norms\n",
        "\n",
        "**L2 Norm**\n",
        "\n",
        "$$\n",
        "\\|x\\|_2 = \\sqrt{\\sum_i x_i^2}\n",
        "$$\n",
        "\n",
        "Measures simple (Euclidean) distance from origin.\n",
        "\n",
        "Most common is **L2** norm.\n",
        "\n",
        "\\\n",
        "\n",
        "**L1 Norm**\n",
        "\n",
        "$$\n",
        "\\|x\\|_1 = \\sqrt{\\sum_i |x_i|}\n",
        "$$\n",
        "\n",
        "- Varies linearly at all locations whether near or far from origin\n",
        "- Used whenever difference between zero and non-zero is key.\n",
        "\n",
        "\\\n",
        "\n",
        "**Squared L2 Norm**\n",
        "\n",
        "$$\n",
        "\\|x\\|_2^2 = \\sum_i x_i^2\n",
        "$$\n",
        "\n",
        "- Equals to $x^Tx$\n",
        "- Can't be used distinguish between zero and near zero.\n",
        "\n",
        "\\\n",
        "\n",
        "**Max Norm**\n",
        "\n",
        "$$\n",
        "\\|x\\|_\\infty = \\max_i |x_i|\n",
        "$$\n",
        "\n",
        "Returns the absolute value of the larget magnitude element.\n",
        "\n",
        "\\\n",
        "\n",
        "**Generalized $L^p$ Norm**\n",
        "\n",
        "$$\n",
        "\\|x\\|_p = \\left ( \\sum_i |x_i|^p \\right )^\\frac{1}{p}\n",
        "$$\n",
        "\n",
        "- p must be a real number and greater than zero\n",
        "- Other norms can be derived by substituting for p"
      ],
      "metadata": {
        "id": "GsYJtJqERs-L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Unit Vectors\n",
        "\n",
        "Vectors which their length (L2 norm) is one: $\\|\\vec u\\|=1$\n",
        "\n",
        "\n",
        "**$\\hat{i}$**: A vector pointing to right with length of one. $\\begin{bmatrix} 1 \\\\ 0 \\end {bmatrix}$\n",
        "\n",
        "**$\\hat{j}$**: A vector pointing to top with length of one $\\begin{bmatrix} 0 \\\\ 1 \\end {bmatrix}$\n",
        "\n",
        "Together these are the **basis vectors** of the xy coordiante system.\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "-5 \\\\\n",
        "2\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "-5 \\hat{i} \\\\\n",
        "2 \\hat{j}\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "\n",
        "**$\\hat{k}$**: A vector in Z dimnetion in a 3D space $\\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\end {bmatrix}$"
      ],
      "metadata": {
        "id": "t3GKNy1WgVv6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Normalization\n",
        "\n",
        "To convert any vector to a normal/unit vector (to normalize it), it should be devided by the magnitude of it's length\n",
        "\n",
        "$$\n",
        "\\vec u = \\frac{1}{\\|\\vec v\\|} \\vec v\n",
        "$$"
      ],
      "metadata": {
        "id": "3jUvN70Yk8hp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vector Summation\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "x_1 \\\\\n",
        "y_1\n",
        "\\end{bmatrix}\n",
        "+\n",
        "\\begin{bmatrix}\n",
        "x_2\\\\\n",
        "y_2\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "x_1 + x_2\\\\\n",
        "y_1 + y_2\n",
        "\\end{bmatrix}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "ErevL6nidtLX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vector Multiplication (Scaling)\n"
      ],
      "metadata": {
        "id": "c_Ty0QhXelvN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Scaler Multiplication\n",
        "Scaler is a number that scales a vector. $k$\n",
        "\n",
        "$$\n",
        "k\n",
        "\\cdot\n",
        "\\begin{bmatrix}\n",
        "x\\\\\n",
        "y\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "kx\\\\\n",
        "ky\n",
        "\\end{bmatrix}\n",
        "$$"
      ],
      "metadata": {
        "id": "Jo36BozVtVY2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Vector Dot Products\n",
        "\n",
        "$$\n",
        "\\vec{a} \\cdot \\vec{b} = \\|\\vec{a}\\| \\|\\vec{b}\\| \\cos(\\theta)\n",
        "$$\n",
        "\n",
        "Projecting the magnitude of vector a on the b, and multiplying it with vector b magnitude. The angle betweent the projection is $\\theta$"
      ],
      "metadata": {
        "id": "KeLuek7ksooP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two vectors of the same dimension\n",
        "$$\n",
        "\\begin{bmatrix}a \\\\ b \\\\ c \\\\ d \\end{bmatrix}\n",
        "\\cdot\n",
        "\\begin{bmatrix}e \\\\ f \\\\ g \\\\ h \\end{bmatrix}\n",
        "= a.e + b.f + c.g + d.h\n",
        "$$\n",
        "* The dot product of the vectors is positive if they're in the same direction\n",
        "* The dot product of the vectors is zero if they're in perpendicular\n",
        "* The dot product of the vectors is negative if they're in the opposite direction\n"
      ],
      "metadata": {
        "id": "FMZdri-zgSeQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cross Product\n",
        "Given the two vectors $\\vec{v}$ and $\\vec{w}$, there's parallelogram that they span out. If you copy the vector $\\vec{v}$ and move its tail to the tip of $\\vec{w}$, and copy the vector $\\vec{w}$ and move its tail to the tip of $\\vec{v}$, the four vectors enclose a certain parallelogram.\n",
        "$$\n",
        "\\vec{v} \\times \\vec{w} = \\vec{p} =  \\text{Area of parallelogram} = determinant\n",
        "$$\n",
        "\n",
        "If $\\vec{v}$ is on the right of $\\vec{w}$, their cross product is positive.\n",
        "If $\\vec{v}$ is on the left of $\\vec{w}$, their cross product is negative.\n",
        "$$\n",
        "\\vec{v} \\times \\vec{w} =  -\\vec{w} \\times \\vec{v}\n",
        "$$\n",
        "Also\n",
        "$$\n",
        "(3\\vec{v}) \\times \\vec{w} =  3(\\vec{v} \\times \\vec{w})\n",
        "$$\n",
        "\n",
        "To caculcate the area, you just need to compute their determenant.\n",
        "$$\n",
        "\\vec{v} \\times \\vec{w} = \\det(\\begin{bmatrix} \\vec{v} & \\vec{w} \\end{bmatrix})\n",
        "$$"
      ],
      "metadata": {
        "id": "uaQCLUDCrO-L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cross Product**\n",
        "> Cross Product is a vector with the length of determenant of vector $\\vec{v}$ and $\\vec{w}$ (the area of their parallelogram) which is perpendicular to their resulting parallelogram.\n",
        "\n",
        "For the direction, point the 4 figure of the right hand in the direction of $\\vec{v}$, stick out the middle fingure in the direction of $\\vec{w}$, then pointing up the thumb shows the direction for their cross product.\n",
        "\n",
        "The formula:\n",
        "\n",
        "2D\n",
        "$$\n",
        "\\begin{bmatrix} v_1 \\\\ v_2 \\end{bmatrix}\n",
        "\\times\n",
        "\\begin{bmatrix} w_1 \\\\ w_2 \\end{bmatrix}\n",
        "=  v_1 \\cdot w_2  - w_1 \\cdot v_2 \\\\\n",
        "$$\n",
        "\n",
        "3D\n",
        "$$\n",
        "\\begin{bmatrix} v_1 \\\\ v_2 \\\\ v_3 \\end{bmatrix}\n",
        "\\times\n",
        "\\begin{bmatrix} w_1 \\\\ w_2 \\\\ w_3 \\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "  v_2 \\cdot w_3  - w_2 \\cdot v_3 \\\\\n",
        "  v_3 \\cdot w_1  - w_3 \\cdot v_1 \\\\\n",
        "  v_1 \\cdot w_2  - w_1 \\cdot v_2 \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "OR\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix} v_1 \\\\ v_2 \\\\ v_3 \\end{bmatrix}\n",
        "\\times\n",
        "\\begin{bmatrix} w_1 \\\\ w_2 \\\\ w_3 \\end{bmatrix}\n",
        "=\n",
        "\\det \\left(\\begin{bmatrix}\n",
        "  \\hat{i} & v_1 & w_1 \\\\\n",
        "  \\hat{j} & v_2 & w_2 \\\\\n",
        "  \\hat{k} & v_3 & w_3\n",
        "\\end{bmatrix}\\right) =\n",
        "\\det \\left(\\begin{bmatrix}\n",
        "  \\hat{i} & \\hat{j} & \\hat{k}  \\\\\n",
        "  v_1 & v_2 & v_3 \\\\\n",
        "  w_1 & w_2 & w_3 \\\\\n",
        "\\end{bmatrix}\\right)\n",
        "\\\\ = \\\\\n",
        "\\hat{i}(v_2w_3-v_3w_2)+\\hat{j}(v_3w_1-v_1w_3)+\\hat{k}(v_1w_2-v_2w_1)\n",
        "$$"
      ],
      "metadata": {
        "id": "IF9SDHiyzqM6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\vec{a} \\times \\vec{b} = \\vec{c} \\\\\n",
        "\\|\\vec{c}\\|  = \\|\\vec{a}\\| \\|\\vec{b}\\| \\sin(\\theta) \\\\\n",
        "$$\n",
        "\n",
        "- First, it is perpendicular to both $\\vec{a}$ and $\\vec{b}$. Phrasing this in terms of the dot product, we could say that $\\vec{c} \\cdot \\vec{a} = \\vec{c} \\cdot \\vec{b}$. This property alone makes the cross product quite useful. This is also why the cross product only works in three dimensions. In 2D, there isn't always a vector perpendicular to any pair of other vectors. In four and more dimensions, there are infinitely many vectors perpendicular to a given pair of other vectors.\n",
        "\n",
        "\n",
        "- Second, the length of $\\vec{c}$ is a measure of how far apart $\\vec{a}$ and $\\vec{b}$ are pointing, augmented by their magnitudes.\n",
        "\n",
        "\n",
        "\n",
        "the dot product and the cross product complement each other.\n",
        "\n",
        "If you hold up your right hand, point your index finger in the direction of $\\vec{a}$ and point your middle finger in the direction of $\\vec{b}$, then your thumb will point in the direction of $\\vec{c}$."
      ],
      "metadata": {
        "id": "XIkYc8DSwnZF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Triple Cross Product Expansion\n",
        "\n",
        "$$\n",
        "\\vec a \\times (\\vec b \\times \\vec c) = \\vec b (\\vec a \\cdot \\vec c) - \\vec c (\\vec a \\cdot \\vec b)\n",
        "$$"
      ],
      "metadata": {
        "id": "kpudH0fWxaAq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vector Properties"
      ],
      "metadata": {
        "id": "UNaCljYcaW1y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Vector Length\n",
        "\n",
        "$$\n",
        "\\vec v = \\begin{bmatrix} v_1\\\\ v_2\\\\ \\vdots \\\\ v_n\\end{bmatrix} \\\\\n",
        "\\| \\vec v \\| = \\sqrt{v_1^2+v_2^2+\\cdots+v_n^2}\n",
        "$$"
      ],
      "metadata": {
        "id": "p1y2qtSx_2R4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  Cauchy-Schwarz inequality\n",
        "\n",
        "$$\n",
        "\\left ( \\sum^n_{k=1} a_kb_k \\right )^2 \\le\n",
        "\\left ( \\sum^n_{k=1} a_k^2 \\right )\n",
        "\\left ( \\sum^n_{k=1} b_k^2 \\right )\\\\\n",
        "$$\n",
        "\n",
        "Or in simpler terms:\n",
        "$$\n",
        "\\vec a, \\vec b \\in R^n \\quad \\&\\quad \\vec a \\ne \\vec 0\\quad \\&\\quad \\vec b \\ne \\vec 0 \\\\\n",
        "| \\vec a \\cdot \\vec b | \\ \\le \\ \\| \\vec a \\| \\ \\| \\vec b\\| \\\\\n",
        "$$\n",
        "\n",
        "If $\\vec a$ is some scalar multiple of $\\vec b$:\n",
        "$$\n",
        "\\vec a = c \\vec b \\\\\n",
        "| \\vec a \\cdot \\vec b | \\ = \\ \\| \\vec a \\| \\ \\| \\vec b\\| \\\\\n",
        "$$"
      ],
      "metadata": {
        "id": "DsClyT-1BrmA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Vector Triangle Inequality\n",
        "\n",
        "$$\n",
        "\\vec a, \\vec b \\in R^n \\quad \\&\\quad \\vec a \\ne \\vec 0\\quad \\&\\quad \\vec b \\ne \\vec 0 \\\\\n",
        "\\| \\vec a + \\vec b \\| \\ \\le \\ \\| \\vec a \\| \\ + \\| \\vec b\\| \\\\\n",
        "$$\n",
        "\n",
        "If $\\vec a$ is some scalar multiple of $\\vec b$:\n",
        "\n",
        "$$\n",
        "\\vec a = c \\vec b \\\\\n",
        "\\| \\vec a + \\vec b \\| \\ = \\ \\| \\vec a \\| \\ + \\| \\vec b\\| \\\\\n",
        "$$\n"
      ],
      "metadata": {
        "id": "n4QGvEesLkjl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Angle Between Vectors & Dot Product\n",
        "\n",
        "$$\n",
        "\\| \\vec a - \\vec b \\|^2 \\ = \\ \\| \\vec a \\| \\ + \\| \\vec b\\| -2 \\ \\|\\vec a\\| \\ \\|\\vec b\\|\\cos\\theta \\\\\n",
        "\\| \\vec a \\|^2 + \\|\\vec b\\|^2 - 2(\\vec a \\cdot \\vec b)= \\ \\| \\vec a \\| \\ + \\| \\vec b\\| -2 \\ \\|\\vec a\\| \\ \\|\\vec b\\|\\cos\\theta \\\\[1cm]\n",
        "\\vec a \\cdot \\vec b = \\|\\vec a\\| \\ \\|\\vec b\\|\\cos\\theta\n",
        "$$"
      ],
      "metadata": {
        "id": "5y4gZqYEamyR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Orthogonal Vectors\n",
        "\n",
        "If two vectors dot product is equal to 0, they're called orthogonal.\n",
        "$$\n",
        "\\vec a \\cdot \\vec b = 0\n",
        "$$\n",
        "\n",
        "Orthogonal Vectors are perpendicular vectors.\n",
        "\n",
        "The $\\vec 0$ is orthogonal to everything else, even to itself."
      ],
      "metadata": {
        "id": "gAXs8uPAcdIf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Angle Between Vectors & Cross Product\n",
        "\n",
        "$$\n",
        "\\vec a \\times \\vec b = \\|\\vec a\\| \\ \\|\\vec b\\|\\sin\\theta\n",
        "$$"
      ],
      "metadata": {
        "id": "aWPFZOUFpuaU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jQDrV3i3s9KU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parametric Representations of lines\n",
        "\n",
        "$$\n",
        "S = \\{ c \\vec v | c \\in R \\}\n",
        "$$\n",
        "\n",
        "A line that goes through a point and a vector\n",
        "\n",
        "$$\n",
        "L = \\{ \\vec x + t \\vec v | t \\in R \\}\n",
        "$$\n",
        "\n",
        "A line that goes through the 2 points $\\vec a$ and $\\vec b$\n",
        "\n",
        "$$\n",
        "L = \\{ \\vec a + t (\\vec b - \\vec a) | t \\in R \\}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "3Zh3uUClSkza"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vector Transposition\n",
        "\n",
        "> Transposition transforms a vector from a row vector to a column vector or vice versa.\n",
        "\n",
        "$$\n",
        "v = \\begin{bmatrix}v_1 \\\\ v_2\\\\ \\vdots \\\\ v_n\\end{bmatrix} \\\\\n",
        "v^T = \\begin{bmatrix}v_1 & v_2& \\cdots & v_n\\end{bmatrix} \\\\[0.5cm]\n",
        "v \\text{ shape}: (1,n) \\\\\n",
        "v^T \\text{ shape}: (n, 1) \\\\\n",
        "$$\n",
        "\n"
      ],
      "metadata": {
        "id": "pQhPbgrXUPMh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear Combination\n",
        "\n",
        "Linear Combination of $\\vec{v}$ and $\\vec{w}$\n",
        "\n",
        "$$\n",
        "a\\vec{v}+b\\vec{w}\n",
        "$$\n",
        "\n",
        "$a$ and $b$ are scalars\n",
        "\n",
        "With a combination of two scalars, you can reach every point on the xy plane. Unless the scalars are algined or are zero.\n",
        "\n",
        "**Span**\n",
        "> The **span** of $\\vec{v}$ and $\\vec{w}$ is the set of all their linear combinations.\n",
        "\n",
        "It's typical to think of a vector as a point that starts from origin and ends at the point.\n",
        "\n",
        "Linear Combination of $\\vec{v}$, $\\vec{w}$ and $\\vec{u}$ for 3 dimentions.\n",
        "\n",
        "$$\n",
        "a\\vec{v}+b\\vec{w}+c\\vec{u}\n",
        "$$\n",
        "\n"
      ],
      "metadata": {
        "id": "Qdut1DFCiPWS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Linearly Dependent\n",
        "\n",
        "> When a vector becomes redundant which you can remove without effecting the span, eg two vectors are algined, they are called **Linearly Dependent**.\n",
        "This means one of the vectors can be represented as a linear combination of others. $\\vec{w}=a\\vec{v}$\n",
        "\n",
        "eg: $\\vec{v}$ and $\\vec{w}$ are `\"Linearly depdendent\"`\n",
        "\n"
      ],
      "metadata": {
        "id": "z_6VtDCd6MEs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Linearly independent\n",
        "\n",
        "> On the other hand, if each vector does add a deminetion to the plane, it is called **Linearly independent**. $\\vec{w} \\neq a\\vec{v}$\n",
        "\n",
        "There's only one solution to $A\\vec x = 0$ that is $\\vec x = \\vec 0$\n",
        "\n",
        "\n",
        "Example: is S linearly independent and is span$(S) = R^3$?\n",
        "\n",
        "$\\displaystyle{\n",
        "S=\\left \\{\n",
        "  \\begin{bmatrix}1 \\\\ -1\\\\ 2\\end{bmatrix} ,\n",
        "  \\begin{bmatrix} -1\\\\ 1\\\\0 \\end{bmatrix} ,\n",
        "  \\begin{bmatrix} 2\\\\ 3\\\\ 2\\end{bmatrix} ,\n",
        "\\right \\} \\\\[0.5cm]\n",
        "  c_1\\begin{bmatrix}1 \\\\ -1\\\\ 2\\end{bmatrix} +\n",
        "  c_2\\begin{bmatrix} -1\\\\ 1\\\\0 \\end{bmatrix} +\n",
        "  c_3\\begin{bmatrix} 2\\\\ 3\\\\ 2\\end{bmatrix}  =\n",
        "  \\begin{bmatrix} a\\\\ b\\\\ c\\end{bmatrix}  \\\\\n",
        "  \\left . \\begin{align*}\n",
        "  c_1 + 2c_2 + -c_3 = a \\\\\n",
        "  -c_1 + c_2 = b \\\\\n",
        "  2c_1 + 3c_2 + 2c_3 = c \\\\\n",
        "   \\end{align*}\\right \\}\n",
        "  c_1 = \\frac{1}{11}(3c-5a+b) \\quad c_2= \\frac{1}{3}(b+a+c_3) \\quad c_3= a-2c_2+c_3 \\therefore \\text{ span}(S) = R^3 \\\\\n",
        "  \\text{linearly independent} = c_1=c_2=c_3=0 \\\\\n",
        "  \\therefore S \\text{ is linearly independent}\n",
        "}$"
      ],
      "metadata": {
        "id": "WZfmHmfG6U80"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Linear Subspaces\n",
        "\n",
        " a linear subspace or vector subspace is a vector space that is a subset of some larger vector space. A linear subspace is usually simply called a subspace when the context serves to distinguish it from other types of subspaces.\n",
        "\n",
        "$$\n",
        "\\text{Subspace of } R^n \\\\\n",
        "V \\leftarrow \\text{ subset of } R^n \\\\\n",
        "$$\n",
        "\n",
        "**Closure under scalar multiplication**\n",
        "> If some member of a set is multiplied by some scalar, it will still be in the set.\n",
        "$$\n",
        "\\vec x \\text{ in } V \\Rightarrow c\\vec x \\text{ in } V\n",
        "$$\n",
        "\n",
        "**Closure under addition**\n",
        "> If some member of a set is added by some other member of the set, their sum will still be in the set.\n",
        "$$\n",
        "\\left . \\begin{align*}\n",
        "\\vec a \\text{ in } V \\\\\n",
        "\\vec b \\text{ in } V \\\\\n",
        "\\end{align*}\n",
        "\\right \\}  \\Rightarrow \\vec a + \\vec b \\text{ in } V\n",
        "$$\n",
        "\n",
        "$\\displaystyle{\n",
        "}$"
      ],
      "metadata": {
        "id": "6OS55GPMeNsr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Basis**\n",
        "> The **Basis** of a vector space is a set of *linearly independent* vectors that *span* the full space.\n",
        "\n"
      ],
      "metadata": {
        "id": "La_o0urXeX8U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear Transformation\n",
        "A function that takes a vector and returns a transformed one. The word tranformation suggest movement.\n",
        "\n",
        "In Linear tranformation, all lines must stay a line, and origin remains the same.\n",
        "\n",
        "$$\n",
        "\\vec{v} = x\\hat{i} + y\\hat{j}\n",
        "\\\\\n",
        "\\text{Transformed }\\vec{v} = x (\\text{Transformed }\\hat{i}) + y (\\text{Transformed }\\hat{j}) \\\\[0.5cm]\n",
        "$$\n",
        "\n",
        "> Linear tranformatIons **preserve** addition and scalar multiplication.\n",
        "\n",
        "Meaning, in a linear tranformation, additivity and scaling remain the same:\n",
        "\n",
        "* Additivity: $L(\\vec{v}+\\vec{w})=L(\\vec{v})+L(\\vec{w})$\n",
        "* Scaling: $L(c\\vec{v})=cL(\\vec{v})$\n",
        "* Vector Base:  $L\\left(\\begin{bmatrix}x \\\\ y \\end{bmatrix}\\right) = L\\left(x\\begin{bmatrix}1 \\\\ 0 \\end{bmatrix}+y\\begin{bmatrix}0 \\\\ 1 \\end{bmatrix}\\right)$"
      ],
      "metadata": {
        "id": "1wkRY7nklziS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example: if $\\hat{i}$ is moved to $\\begin{bmatrix}1 \\\\ -2 \\end{bmatrix}$ and $\\hat{j}$ is moved to $\\begin{bmatrix} 3 \\\\ 0 \\end {bmatrix}$, the general tranformation rule would be:\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix} x \\\\ y \\end {bmatrix} \\rightarrow\n",
        "x \\begin{bmatrix} 1 \\\\ -2 \\end {bmatrix} +\n",
        "y \\begin{bmatrix} 3 \\\\ 0 \\end {bmatrix}\n",
        "= \\begin{bmatrix} 1x+3y \\\\ -2x + 0y \\end {bmatrix}\n",
        "$$\n",
        "\n",
        "Or in a **matrix** notation, it would be:\n",
        "$$\n",
        "\\begin{bmatrix} 1 & 3 \\\\ -2 & 0 \\end {bmatrix}\n",
        "$$"
      ],
      "metadata": {
        "id": "uyGH7N69oGt_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Locally Linear Transformation\n",
        "\n",
        "If zoomed in a small portion of the graph, the portion would *almost* stay linear after the tranformation.\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}x_0 \\\\ y_0 \\end{bmatrix} \\leftrightarrow \\begin{bmatrix} x_0 + c_0 \\\\ y_0 + c_1 \\end{bmatrix}\n",
        "$$\n",
        "\n",
        "- $c_0$ and $c_1$ represent tiny changes\n",
        "\n",
        "Example:\n",
        "\n",
        "For $\\begin{bmatrix}x + \\sin(y) \\\\ y + \\sin(x) \\end{bmatrix}$\n",
        "the local transformation at point $(-2,1)$ looks like:\n",
        "\n",
        "$\\begin{bmatrix}1 & 0.54 \\\\ -0.42 & 1 \\end{bmatrix}$\n",
        "\n",
        "(Checkout Jacobian Matrix for calculation steps)"
      ],
      "metadata": {
        "id": "Reyj1BDI-BA5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Point Distance to Plane\n",
        "\n",
        "$$\n",
        "\\text{Point } = (x_0, y_0, z_0) \\\\\n",
        "\\text{Plane } = Ax + By + Cz = D \\\\\n",
        "\\frac{Ax_0 + By_0 + Cz_0 - D}{\\sqrt{A^2+B^2+C^2}}\n",
        "$$"
      ],
      "metadata": {
        "id": "rhXMf_ER0va3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distance Between Parallel  Planes\n",
        "\n",
        "$$\n",
        "P_1 = A_1x + B_1y + C_1z = D_1 \\\\\n",
        "P_2 = A_2x + B_2y + C_2z = D_2 \\\\[1cm]\n",
        "\\text{Check they're parallel}: \\\\\n",
        "\\frac{A_1}{A_2}= \\frac{B_1}{B_2} = \\frac{C_1}{C_2} \\\\[1cm]\n",
        "\\text{Find a point on }P_1 : \\text{e.g. setting y and z to zero} \\\\\n",
        "A_1x + B_10+C_10 = D_1 \\Rightarrow (\\frac{D_1}{A_1}, 0, 0) \\\\[1cm]\n",
        "\\text{Find the distance between the point and the other plane:}\\\\\n",
        "\\frac{A_2(\\frac{D_1}{A_1}) - D_2}{\\sqrt{A_2^2+B_2^2+C_2^2}}\n",
        "\\\\[1cm]\n",
        "$$"
      ],
      "metadata": {
        "id": "zDNMMYCT2n0T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matrices"
      ],
      "metadata": {
        "id": "UzMIA2NFW5RI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "M = \\begin{bmatrix} a & b & c \\\\\n",
        "d & e & f \\\\\n",
        "g & h & i \\\\\n",
        "\\end{bmatrix}\n",
        "$$"
      ],
      "metadata": {
        "id": "BUQjo791gYa1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zero Matrix\n",
        "A zero matrix is a matrix in which all of the entries are 0 Some examples are given below.\n",
        "\n",
        "$$\n",
        "0_{2,3} = \\begin{bmatrix}0 & 0 & 0 \\\\\n",
        "0 & 0 & 0 \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "A zero matrix is indicated by O, and a subscript can be added to indicate the dimensions of the matrix if necessary.\n",
        "\n",
        "Zero matrices play a similar role in operations with matrices as the number zero plays in operations with real numbers. Let's take a look."
      ],
      "metadata": {
        "id": "I4JwtScnhMIR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Frobenius Norm\n",
        "\n",
        "A function that enables us to quantify the size of a matrix.\n",
        "\n",
        "$$\n",
        "\\|X\\|_F = \\sqrt{\\sum_{i,j} X^2{i,j}}\n",
        "$$"
      ],
      "metadata": {
        "id": "CljMc8Z8hNqL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matrix Addition properties\n",
        "\n",
        "$$\n",
        "A = \\begin{bmatrix}\n",
        "a_{11} & a_{12} & a_{13} \\\\\n",
        "a_{21} & a_{22} & a_{23} \\\\\n",
        "\\end{bmatrix} \\quad\n",
        " B = \\begin{bmatrix}\n",
        "b_{11} & b_{12} & b_{13} \\\\\n",
        "b_{21} & b_{22} & b_{23} \\\\\n",
        "\\end{bmatrix} \\\\\n",
        "A + B = \\begin{bmatrix}\n",
        "a_{11} + b_{11} & a_{12} + b_{12} & a_{13} + b_{13} \\\\\n",
        "a_{21} + b_{21} & a_{22} + b_{22} & a_{23} + b_{23} \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "\n",
        "Commutative property of addition:\n",
        "$$\n",
        "A + B = B + A\n",
        "$$\n",
        "\n",
        "Associative property of addition:\n",
        "$$\n",
        "(A+B)+C=A+(B+C)\n",
        "$$\n",
        "\n",
        "Additive identity property:\n",
        "$$\n",
        "A+O=A\n",
        "$$\n",
        "\n",
        "Additive inverse property:\n",
        "$$\n",
        "A+(-A)=O\n",
        "$$\n",
        "\n"
      ],
      "metadata": {
        "id": "9C03iFYkjLoj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scalar Multiplication Properties\n",
        "\n",
        "$$\n",
        "zM = z\\cdot\\begin{bmatrix} a & b & c \\\\\n",
        "d & e & f \\\\\n",
        "g & h & i \\\\\n",
        "\\end{bmatrix} = \\begin{bmatrix} za & zb & zc \\\\\n",
        "zd & ze & zf \\\\\n",
        "zg & zh & zi \\\\\n",
        "\\end{bmatrix}\\\\\n",
        "$$\n",
        "\n",
        "**Properties:**\n",
        "Associative property of multiplication\n",
        "$$\n",
        "(cd)A=c(dA)\n",
        "$$\n",
        "Distributive properties\n",
        "$$\n",
        "c(A+B)=cA+cBc\\\\\n",
        "(c+d)A=cA+dA\n",
        "$$\n",
        "Multiplicative identity property\n",
        "$$\n",
        "1A=A1\n",
        "$$\n",
        "Multiplicative properties of zero\n",
        "$$\n",
        "0⋅A=O\\\\\n",
        "c⋅O=O\n",
        "$$\n",
        "Closure property of multiplication\n",
        "$$\n",
        "cA \\text{ is a matrix of the same dimensions as A.}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "76pGup2kf98P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matrix tranformation\n",
        "\n",
        "\"2x2 Matrix\"\n",
        "$$\n",
        "\\begin{bmatrix} a & b \\\\ c & d \\end {bmatrix}\n",
        "\\begin{bmatrix} x \\\\ y \\end {bmatrix}\n",
        "\\\\\n",
        "x \\begin{bmatrix} a \\\\ c \\end {bmatrix} +\n",
        "y \\begin{bmatrix} b \\\\ d \\end {bmatrix}\n",
        "=\n",
        "\\begin{bmatrix} ax + by \\\\ cx + dy \\end {bmatrix}\n",
        "$$"
      ],
      "metadata": {
        "id": "J20yGJu3psPi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Composition\n",
        "> A combination of multiple tranformation is called **composition**\n",
        "\n",
        "$$\n",
        "T(\\vec x) = B \\vec X \\quad S(\\vec x) = A \\vec x \\\\\n",
        "T\\circ S(\\vec x)  = T(S(\\vec x)) = B( A \\vec x) = C \\vec x \\\\[1cm]\n",
        "\\begin{bmatrix} a & b \\\\ c & d \\end {bmatrix} \\left(\n",
        "\\begin{bmatrix} e & f \\\\ g & h \\end {bmatrix}\n",
        "\\begin{bmatrix} x \\\\ y \\end {bmatrix} \\right)\n",
        "= \\begin{bmatrix}ae+bg & af + bh \\\\ ce + dg & cf + dh \\end {bmatrix}\\begin{bmatrix} x \\\\ y \\end {bmatrix} \\\\\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Mxvaf7bpsIgX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reduced Row-Echelon Form (RREF)\n",
        "\n",
        "A matrix is in reduced row-echelon form if it satisfies the following:\n",
        "\n",
        "1. In each row, the left-most nonzero entry is 1 and the column that contains this 1 has all other entries equal to 0. This 1 is called a leading 1 or pivot 1. Other variables are called free variables,\n",
        "\n",
        "2. The leading 1 in the second row or beyond is to the right of the leading 1 in the row just above.\n",
        "\n",
        "3. Any row containing only 0's is at the bottom.\n",
        "\n",
        "\n",
        "\n",
        "Steps:\n",
        "\n",
        "writting the first row,\n",
        "writting the second row in a form that the first coefficient is zero (eg the first row - the second row)\n",
        "writting the third row in a form that the first coefficient is zero (eg the first row - 2 times the second row)\n",
        "\n",
        "Similar to Inverse of  n×n  Matrices.\n",
        "\n",
        "\n",
        "**Example**\n",
        "\n",
        "$\\displaystyle{\n",
        "x_1 + 2x_2 + x_3 + x_4 = 7\\\\\n",
        "x_1 + 2x_2 + 2x_3 - x_4 = 12\\\\\n",
        "2x_1 + 4x_2 - 6x_4 = 4\\\\[0.5cm]\n",
        "A =\n",
        "\\left [\\begin{matrix}\n",
        "1  & 2 & 1 & 1\\\\\n",
        "1  & 2 & 2 & -1\\\\\n",
        "2  & 4 & 0 & 6\\\\\n",
        "\\end{matrix}\\right | \\left .\\begin{matrix}\n",
        "7 \\\\ 12 \\\\ 4\n",
        "\\end {matrix} \\right ]\n",
        "\\begin{matrix}\n",
        "\\rightarrow R_1 \\quad \\quad \\ \\ \\\\ \\rightarrow R_1 - R_2 \\ \\\\ \\rightarrow R_3 - 2R_1\n",
        "\\end {matrix} \\\\\n",
        "\\quad = \\left [ \\begin{matrix}\n",
        "1  & 2 & 1 & 1\\\\\n",
        "0  & 0 & -1 & 2\\\\\n",
        "0  & 0 & -2 & 4\\\\\n",
        "\\end{matrix} \\right | \\left . \\begin{matrix}\n",
        "7 \\\\ -5 \\\\ -10\n",
        "\\end {matrix} \\right ] \\begin{matrix}\n",
        "\\rightarrow R_1 - R_2 \\ \\ \\\\ \\rightarrow  - R_2 \\quad \\quad \\ \\\\ \\rightarrow  R_3 - 2R_2 \\end {matrix} \\\\\n",
        "\\quad = \\left [ \\begin{matrix}\n",
        "1  & 2 & 0 & 3\\\\\n",
        "0  & 0 & 1 & -2\\\\\n",
        "0  & 0 & 0 & 0\\\\\n",
        "\\end{matrix} \\right | \\left . \\begin{matrix}\n",
        "2 \\\\ 5 \\\\ 0\n",
        "\\end {matrix} \\right ] = \\text{rref}(A) \\\\[1.5cm]\n",
        "x_1 + 2x_2 + 3x_4 = 2\\\\\n",
        "x_3 -2x_4 = 5 \\\\[0.5cm]\n",
        "x_1 = 2-2x_2 -3x_4 \\\\\n",
        "x_3 = 5 + 2x_4 \\\\[0.5cm]\n",
        "\\begin{bmatrix}\n",
        "x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4\n",
        "\\end{bmatrix} =\n",
        "\\begin{bmatrix}\n",
        "2 \\\\ 0 \\\\ 5 \\\\ 0\n",
        "\\end{bmatrix} + x_2\n",
        "\\begin{bmatrix}\n",
        "-2 \\\\ 1 \\\\ 0 \\\\ 0\n",
        "\\end{bmatrix} + x_4\n",
        "\\begin{bmatrix}\n",
        "-3 \\\\ 0 \\\\ 2 \\\\ 1\n",
        "\\end{bmatrix}\n",
        "\\\\\n",
        "}$"
      ],
      "metadata": {
        "id": "qM5ewkzXgxe0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Determinant\n",
        "\n",
        "**Determinant of that transformation**\n",
        "> The factor by which a linear tranformation changes any area is called the **determinant** of that transformation.\n",
        "\n",
        "\\\n",
        "\n",
        "- $\\det(X) = 0$, then $X$ collapses space completely in at least one dimesion, thereby elminiating all volume.\n",
        "- $0 < |\\det(X)| < 0$, then $X$ contracts volume to some extent.\n",
        "- $|\\det(X)| =1 0$, then $X$ preserves volume exactly.\n",
        "- $|\\det(X)| > 1 0$, then $X$ expands volume.\n",
        "\n",
        "Negative values have the same effect, they just flip the volume.\n",
        "\n",
        "\\\n",
        "\n",
        "A matrix with a **determinant of zero** can **not be inverted**"
      ],
      "metadata": {
        "id": "SZpMS8NK1wzr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### $2\\times 2$ Determinant\n",
        "\n",
        "\n",
        "$$\n",
        "\\text{det}\\left(\\begin{bmatrix} a & b \\\\ c & d \\end {bmatrix}\\right) = ad - bc\n",
        "$$\n",
        "\n",
        "Examples:\n",
        "$$\n",
        "\\text{det}\\left(\\begin{bmatrix} -1 & 1 \\\\ -1 & -1 \\end {bmatrix}\\right) = 2 \\\\[1cm]\n",
        "\\text{det}\\left(\\begin{bmatrix} 0.0 & 2.o \\\\ -1.5 & 1.o \\end {bmatrix}\\right) = 3 \\\\[1cm]\n",
        "\\text{det}\\left(\\begin{bmatrix} 4 & 2 \\\\ 2 & 1 \\end {bmatrix}\\right) = 0 \\\\[1cm]\n",
        "\\text{det}\\left(\\begin{bmatrix} 0 & 0 \\\\ 0 & 0 \\end {bmatrix}\\right) = 0 \\\\[1cm]\n",
        "$$\n"
      ],
      "metadata": {
        "id": "KONFgnN4FZxM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**invert of orientation of space**\n",
        "> A negative determinat flips the space and is called **invert of orientation of space**\n",
        "\n",
        "Normaly $L(\\hat{j})$ is to the *left* of $L(\\hat{i})$.\n",
        "If $L(\\hat{j})$ is to the *right* of $L(\\hat{i})$ the orientation of space has been inverted.\n",
        "\n",
        "The absoulte value of the determinant shows the scale by which the area was transformed.\n"
      ],
      "metadata": {
        "id": "QNNa-2xY323f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### $3\\times 3$ Determinant\n",
        "\n",
        "**Parallelepiped**\n",
        "> A cube in a 3 dimentional space that starts with a volume of 1, and has gone through a matric tranformation is called **parallelepiped**\n",
        "$$\n",
        "\\det\\left(\\begin{bmatrix} a & b & c \\\\ d & e & f \\\\ g & h & i \\end {bmatrix}\\right) = \\\\[1cm]\n",
        "a \\det\\left(\\begin{bmatrix} e & f \\\\ h & i \\end {bmatrix}\\right) -\n",
        "b \\det\\left(\\begin{bmatrix} d & f \\\\ g & i \\end {bmatrix}\\right) +\n",
        "c \\det\\left(\\begin{bmatrix} d & e \\\\ g & h \\end {bmatrix}\\right) \\\\[1cm]\n",
        "= a(ei-fh) - d(bi-ch) + g(bf-ec)  \\\\[0.5cm]\n",
        "= \\text{Volume of the parallelepiped}\n",
        "$$\n",
        "\n",
        "Exmple:\n",
        "$$\n",
        "\\det\\left(\\begin{bmatrix} 1.0 & 0.0 & 0.5 \\\\ 0.5 & 1.0 & 0.0 \\\\ 1.0 & 0.0 & 1.0\\end {bmatrix}\\right) = 0\n",
        "$$\n",
        "\n"
      ],
      "metadata": {
        "id": "gG5AsXcF5Iqo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### $n\\times n$ determinant\n",
        "\n",
        "$n\\times n$ determinant has a recursive definition:\n",
        "\n",
        "$$\n",
        "A_{(n\\times n)} = \\begin{bmatrix}\n",
        "a_{11} & a_{12} & \\cdots & a_{1n} \\\\\n",
        "a_{21} & \\ddots \\\\\n",
        "\\vdots  & & \\ddots \\\\\n",
        "a_{n1} & & & a_{nn}\n",
        "\\end{bmatrix} \\\\[2cm]\n",
        "\\text{ matrix you get if you \"ignore\" the }i^\\text{th}\\text{  row and }j^\\text{th} \\text{  column of } A \\\\[0.5cm]\n",
        "\\text{Define } A_{ij} = (n-1) \\times (n-1) \\\\[1cm]\n",
        "\\det(A) = a_{11} \\det(A_{11}) - a_{12} \\det(A_{12}) + \\cdots - a_{1n} \\det(A_{1n})\\\\[1cm]\n",
        "$$\n",
        "\n",
        "The sign can be calculated using:\n",
        "$$\n",
        "\\text{sign}(i,j) = -1 ^{(i+j)} \\\\\n",
        "$$\n",
        "\n",
        "Checkout $3\\times3$ determinant to understand $A_{ij}$ better"
      ],
      "metadata": {
        "id": "u3RYNCohlojl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Rule of Sarrus of determinants\n",
        "\n",
        "$$\n",
        "\\det\\left(\\begin{bmatrix} a & b & c \\\\ d & e & f \\\\ g & h & i \\end {bmatrix}\\right) = \\\\[1cm]\n",
        "a \\det\\left(\\begin{bmatrix} e & f \\\\ h & i \\end {bmatrix}\\right) -\n",
        "b \\det\\left(\\begin{bmatrix} d & f \\\\ g & i \\end {bmatrix}\\right) +\n",
        "c \\det\\left(\\begin{bmatrix} d & e \\\\ g & h \\end {bmatrix}\\right) \\\\[1cm]\n",
        "= a(ei-fh) - d(bi-ch) + g(bf-ec)  \\\\\n",
        "= aei-afh - dbi+dch + gbf-gec  \\\\\n",
        "= aei + bfg + cdh - afh - bdj - ceg  \\\\\n",
        "$$\n",
        "\n",
        "It would be the diagonals, first round positive, second round negative.\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix} a & b & c \\\\ d & e & f \\\\ g & h & i \\end {bmatrix}\n",
        "\\begin{matrix} a & b & c \\\\ d & e & f \\\\ g & h & i \\end {matrix} \\\\\n",
        "$$\n",
        "\n",
        "![Rule of Sarrus of determinants](https://i.stack.imgur.com/JD0KH.png)"
      ],
      "metadata": {
        "id": "U4P5jhX8vDjH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Determinant multiplied by scalar\n",
        "\n",
        "When a row in a determinant is multiplied by a scalar, the whole values is multiplied by that scalar.\n",
        "\n",
        "$$\n",
        "A' = A \\text{ but one row is multiplied by } k \\\\\n",
        "\\det(A') = k \\det(A) \\\\\n",
        "$$\n",
        "\n",
        "When $n$ rows in a determinant are multiplied by a scalar, the whole values is multiplied by that scalar to the power of $n$.\n",
        "\n",
        "\n",
        "$$\n",
        "A' = A \\text{ but n rows are multiplied by } k \\\\\n",
        "\\det(A') = k^n \\det(A)\n",
        "$$\n"
      ],
      "metadata": {
        "id": "cgtDzLwx0sdq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Triangular Determinant\n",
        "\n",
        "**Upper triangular determinant**\n",
        "If all the enteries blow the main diagonal  are zeros, the determinant is just the multiplication of the enteries in the diagonal .\n",
        "\n",
        "\n",
        "$$\n",
        "A = \\begin{bmatrix}\n",
        "a_{11} & a_{12} & \\cdots & a_{1n} \\\\\n",
        "0 & a_{22} & & a_{2n} \\\\\n",
        "\\vdots  & \\ddots & \\ddots  & \\vdots \\\\\n",
        "0 & \\cdots & 0& a_{nn}\n",
        "\\end{bmatrix} \\\\[2cm]\n",
        "\\det (A) = a_{11} a_{22} \\cdots a_{nn}\n",
        "$$\n",
        "\n",
        "**Lower triangular determinant**\n",
        "Similar to upper triangular determinant with the only difference being now the non-zero values are in the lower side of the diagonal  line."
      ],
      "metadata": {
        "id": "dxuFFexQ6Z4P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transpose\n",
        "\n",
        "The transpose of a matrix is that matrix with its rows and columns switched.\n",
        "That is, the entry $a_{i,j}$ becomes $a_{j,i}$. We write $A^T$ to refer to the transpose of A. The transpose also reverses the dimensions of a matrix.\n",
        "\n",
        "\n",
        "We flip the matrix base on it's diagonal line over the axis.\n",
        "\n",
        "$$\n",
        "A = \\begin{bmatrix} a & b & c \\\\\n",
        "d & e & f \\\\\n",
        "\\end{bmatrix} \\\\\n",
        "A^T = \\begin{bmatrix} a & d \\\\ b & e \\\\ c & f\n",
        "\\end{bmatrix} \\\\\n",
        "(A^T)^T = A \\\\\n",
        "(A^T)_{i,j} = A_{j,i}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "gr3fEUVtw_QJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Determinant of Transpose\n",
        "\n",
        "$$\n",
        "\\text{det}\\left(\\begin{bmatrix} a & b \\\\ c & d \\end {bmatrix}\\right) = ad - bc \\\\\n",
        "\\text{det}\\left(\\begin{bmatrix} a & c \\\\ b & d \\end {bmatrix}\\right) = ad - bc \\\\[1cm]\n",
        "\\det(A_{2\\times2}) = \\det(A_{2\\times2}^T)\n",
        "$$\n",
        "\n",
        "\n",
        "Also true of all matrixs.\n",
        "\n",
        "$$\n",
        "\\det(A_{n\\times n}) = \\det(A_{n\\times n}^T)\n",
        "$$"
      ],
      "metadata": {
        "id": "a-atRXiGFzMO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Properties of Transpose\n",
        "\n",
        "**Matrix Product**\n",
        "\n",
        "$$\n",
        "A_{m\\times n} \\quad\\quad B_{n\\times m} \\\\\n",
        "A^T_{n\\times m} \\quad\\quad B^T_{m\\times n} \\\\\n",
        "C_{m\\times m} = AB \\quad\\quad D_{m\\times m}  =B^TA^T   \\\\\n",
        "c_{ij} = d_{ji} \\\\[0.5cm]\n",
        "(AB)^T = B^T A^T\\\\\n",
        "$$\n",
        "\n",
        "**Matrix Sum**\n",
        "\n",
        "$$\n",
        "(A+B)^T = A^T + B^T \\\\\n",
        "$$\n",
        "\n",
        "**Matrix Inverses**\n",
        "\n",
        "$$\n",
        "(A^T)^{-1} = (A^{-1})^T\\\\\n",
        "$$\n",
        "\n",
        "**Column space of a matrix**\n",
        "\n",
        "$$\n",
        "C(A^T) = \\text{Row space of } A\\\\\n",
        "$$\n",
        "\n",
        "**Matrix Rank**\n",
        "\n",
        "$$\n",
        "\\text{Rank}(A) = \\text{Rank}(A^T)\\\\\n",
        "$$\n",
        "\n",
        "**$A^TA$ is Invertible**\n",
        "\n",
        "$$\n",
        "\\text{rref}(A^TA) = I \\rightarrow A^TA \\text{ is invertible}\\\\\n",
        "$$"
      ],
      "metadata": {
        "id": "FWqUd9ce8HmK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Transpose of a vector\n",
        "\n",
        "$$\n",
        "\\vec v_{n\\times 1} = \\begin{bmatrix} v_1 \\\\ v_2 \\\\ \\vdots \\\\ v_n \\end{bmatrix} \\\\\n",
        "\\vec v^T_{1 \\times n} = \\begin{bmatrix} v_1 & v_2 & \\cdots & v_n \\end{bmatrix} \\\\[1cm]\n",
        "\\vec v \\cdot \\vec w = \\vec v^T \\cdot \\vec w \\\\\n",
        "(A\\vec x) \\cdot \\vec y = \\vec x \\cdot (A^T \\vec y)\n",
        "$$\n",
        "\n"
      ],
      "metadata": {
        "id": "JyF4D-8D_rcX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dot Product\n",
        "https://www.mathsisfun.com/algebra/matrix-multiplying.\n"
      ],
      "metadata": {
        "id": "CSpK2ytvbNgg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\begin{bmatrix} a & b \\\\ c & d \\end {bmatrix}\n",
        "\\begin{bmatrix} e & f \\\\ g & h \\end {bmatrix} = \\\\\n",
        "\\begin{bmatrix} a & b \\\\ c & d \\end {bmatrix}\n",
        "\\begin{bmatrix} e \\\\ g \\end {bmatrix} +\n",
        "\\begin{bmatrix} a & b \\\\ c & d \\end {bmatrix}\n",
        "\\begin{bmatrix} f \\\\ h \\end {bmatrix} = \\\\\n",
        "e \\begin{bmatrix} a \\\\ c \\end {bmatrix} +\n",
        "g \\begin{bmatrix} b \\\\ d \\end {bmatrix} +\n",
        "f \\begin{bmatrix} a \\\\ c \\end {bmatrix} +\n",
        "h \\begin{bmatrix} b \\\\ d \\end {bmatrix} = \\\\\n",
        "\\begin{bmatrix}ae+bg & af + bh \\\\ ce + dg & cf + dh \\end{bmatrix}\n",
        "$$\n",
        "Shape:\n",
        "$$\n",
        "(m,n)\\times(n,p)=(m,p)\n",
        "$$"
      ],
      "metadata": {
        "id": "e1tEFQq3uagk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example:\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "1 & 2 & 3\\\\\n",
        "4 & 5 & 6\n",
        "\\end{bmatrix} \\times\n",
        "\\begin{bmatrix}\n",
        "7 & 8\\\\\n",
        "9 & 10\\\\\n",
        "11 & 12\n",
        "\\end{bmatrix} = \\begin{bmatrix}\n",
        "58 & 64\\\\\n",
        "139 & 154\n",
        "\\end{bmatrix}\n",
        "\\\\\n",
        "(2,3)\\times(3,2)=(2,2)\n",
        "$$"
      ],
      "metadata": {
        "id": "ngUYtg1zuXGA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example 2\n",
        "\n",
        "$$\\begin{bmatrix}\n",
        "0  & 1 & 2\\\\\n",
        "3  & 4 & 5\\\\\n",
        "6  & 7 & 8\\\\\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix} x \\\\ y \\\\ z \\end {bmatrix}\n",
        "=\n",
        "x \\begin{bmatrix}\n",
        "0\\\\\n",
        "3\\\\\n",
        "6\\\\\n",
        "\\end{bmatrix}+\n",
        "y \\begin{bmatrix}\n",
        "1\\\\\n",
        "4\\\\\n",
        "7\\\\\n",
        "\\end{bmatrix}+\n",
        "z \\begin{bmatrix}\n",
        "2\\\\\n",
        "5\\\\\n",
        "8\\\\\n",
        "\\end{bmatrix}\n",
        "$$"
      ],
      "metadata": {
        "id": "_jSDCx7zzUc_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example 3\n",
        "\n",
        "multiplying a 3×1 by a 1×3 gets a 3×3 result:\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "4 \\\\\n",
        "5 \\\\\n",
        "6\n",
        "\\end{bmatrix}\\begin{bmatrix}\n",
        "1 & 2 & 3\\\\\n",
        "\\end{bmatrix} = \\begin{bmatrix}\n",
        "4\\times1  & 4\\times2 & 4\\times3\\\\\n",
        "5\\times1  & 5\\times2 & 5\\times3\\\\\n",
        "6\\times1  & 6\\times2 & 6\\times3\\\\\n",
        "\\end{bmatrix} = \\begin{bmatrix}\n",
        "4 & 8 & 12\\\\\n",
        "5 & 10 & 15\\\\\n",
        "6 & 12 &  18\n",
        "\\end{bmatrix}\n",
        "$$"
      ],
      "metadata": {
        "id": "HskOcky-hBIH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matrix Multiplication Properties\n",
        "\n",
        "Matrix Multiplication is a linear transformation.\n",
        "\n",
        "The commutative property of multiplication.\n",
        "> When we change the order of multiplication, the answer is (usually) different.\n",
        "\n",
        "$$\n",
        "AB \\neq BA\n",
        "$$\n",
        "\n",
        "Associative property of matrix multiplication\n",
        "\n",
        "$$(A\\cdot B) \\cdot C = A \\cdot (B \\cdot C)$$\n",
        "\n",
        "Distributive properties\n",
        "$$\n",
        "A(B+C)=AB+AC\\\\\n",
        "(B+C)A=BA+CA\n",
        "$$\n",
        "\n",
        "Multiplicative identity property\n",
        "$$\n",
        "IA = A \\\\\n",
        "AI = A\n",
        "$$\n",
        "\n",
        "Multiplicative property of zero\n",
        "$$\n",
        "O\\cdot A=O\\\\\n",
        "A\\cdot O = O\n",
        "$$\n",
        "\n",
        "Dimension property\n",
        "$$\n",
        "\\text{The product of an } m\\times n \\text{ matrix and an } n\\times k \\text{ matreix is an } m \\times k \\text{ matrix.}\n",
        "$$"
      ],
      "metadata": {
        "id": "fc5P7JNi3Xmy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Symmetric Matrix\n",
        "\n",
        "A matrix that is symmetric over its diagonal line.\n",
        "\n",
        "$$\n",
        "M = \\begin{bmatrix}\n",
        "a & b & c\\\\\n",
        "b & d & e\\\\\n",
        "c & e & f\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "* It is \"square\" (has same number of rows as columns)\n",
        "* It can be large or small (2×2, 100×100, ... whatever)\n",
        "\n",
        "$$\n",
        "M^T = M\n",
        "$$\n"
      ],
      "metadata": {
        "id": "mtVxQQwWtIh_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Identity Matrix\n",
        "\n",
        "The \"Identity Matrix\" is the matrix equivalent of the number \"1\":\n",
        "$$\n",
        "I = \\begin{bmatrix}\n",
        "1 & 0 & 0\\\\\n",
        "0 & 1 & 0\\\\\n",
        "0 & 0 & 1\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "* It is \"square\" (has same number of rows as columns)\n",
        "* It can be large or small (2×2, 100×100, ... whatever)\n",
        "* It has 1s on the main diagonal and 0s everywhere else\n",
        "* Its symbol is the capital letter I\n",
        "* It's a symmetric matrix\n",
        "\n",
        "$$\n",
        "A \\times I = A\\\\\n",
        "I \\times A = A\n",
        "$$"
      ],
      "metadata": {
        "id": "hFnazoZKc__K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matrix Properties"
      ],
      "metadata": {
        "id": "9dBL2Pi9sA1E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Rank\n",
        "\n",
        "**Rank**\n",
        "> Number of dimensions in the outpt of a tranformation. Or more precisely, the number of dimensions in the column space.\n",
        "\n",
        "**Column Space**\n",
        "> Set of all possible outputs for $A\\vec{v}$ is called **column space** of $A$.\n",
        "\n",
        "The idea of column space helps us understand when a solution exists for an inverse tranforamtion\n",
        "\n",
        "**Rank 1**\n",
        "> When the ouput of a tranformation is a line (has a determine of 0) we say the tranformation has. a \"rank\" of one.\n",
        "\n",
        "**Rank 2**\n",
        "> When the ouput of a tranformation is on a 2D plane (has a determine of 0) we say the tranformation has. a \"rank\" of two.\n",
        "\n",
        "**Null Space (Kernel)**\n",
        "> The space of all vectors that become null in a\n",
        "transformation is called **\"Null space\"** or **\"Kernel\"**\n",
        "\n",
        "The idea of null space helps us understand what the set of all possible solutions could look like."
      ],
      "metadata": {
        "id": "y7iq5uvU90dH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Null Space\n",
        "\n",
        "> The space of all vectors that become null in a transformation is called \"Null space\" or \"Kernel\"\n",
        "\n",
        "The idea of null space helps us understand what the set of all possible solutions could look like.\n",
        "\n",
        "> If the column vectors of a matrix are linearly independent,then the null space of that matrix is only going to consist of the zero vector. Or the other way, if the null space of a matrix only contains the zero vector, that means that the columns of that matrix are linearly independent.\n",
        "\n",
        "$$\n",
        "\\vec 0 \\in S \\\\\n",
        "\\vec v_1 , \\vec v_2 \\in S \\Rightarrow  \\vec v_1 + \\vec v_2 \\in S \\\\\n",
        "c \\in R \\quad \\vec v_1 \\in S \\quad c\\vec v_1 \\in S \\\\[1cm]\n",
        "A: m\\times n \\\\\n",
        "A \\vec x = \\vec 0 \\quad (\\text{homogenous}) \\\\\n",
        "N = \\{ x \\in R^n | A\\vec X = \\vec 0 \\} \\\\\n",
        "A \\vec 0 = \\vec 0 \\\\\n",
        "\\vec 0 \\in N \\quad \\quad\n",
        "\\vec v_1 , \\vec v_2 \\in N \\\\\n",
        "\\Rightarrow A \\vec v_1 = \\vec 0 \\\\\n",
        "\\quad A \\vec v_2 = \\vec 0 \\\\[1cm]\n",
        "A(\\vec v_1 + \\vec v_2) = A \\vec v_1 + A \\vec v_2 = \\vec 0 + \\vec 0 = \\vec 0 \\\\\n",
        "\\vec v_1 + \\vec v_2 \\in N \\\\[1cm]\n",
        "c \\vec v_1 \\in N \\\\\n",
        "A(c\\vec v_1 ) = c A \\vec v_1 = c \\vec 0 = \\vec 0 \\\\[1cm]\n",
        "N = N(A) = \\text{ Nullspace of } A \\\\[1cm]\n",
        "$$"
      ],
      "metadata": {
        "id": "F2qxt9eVvX2J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Kernel\n",
        "\n",
        "Kernel is all of the vectors in our domain, $S$, such that the transformation of those vectors is equal to the zero vector.\n",
        "\n",
        "If the transformation is equal to some matrix times some vector, and we know that any linear transformation can be written as a matrix vector product, then the kernel of T is the same thing as the null space of A.\n",
        "\n",
        "$$\n",
        "\\{ x \\in S | T(\\vec x) = \\{ \\vec 0 \\}\\} \\\\\n",
        "T = A\\vec x \\\\\n",
        "\\ker(T) = N(A)\n",
        "$$"
      ],
      "metadata": {
        "id": "0jQNy3qkHINt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example:**\n",
        "\n",
        "$\\displaystyle{\n",
        "\\vec x \\in R^4 \\quad \\quad\n",
        "A = (3\\times 4) \\\\\n",
        "A = \\begin{bmatrix}\n",
        "1 & 1 & 1 & 1 \\\\\n",
        "1 & 2 & 3 & 4 \\\\\n",
        "4 & 3 & 2 & 1\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4\n",
        "\\end{bmatrix} =\n",
        "\\begin{bmatrix}\n",
        "0 \\\\ 0 \\\\ 0 \\\\ 0\n",
        "\\end{bmatrix} \\\\[2cm]\n",
        "N(a) = \\{ \\vec x \\in R^4 | A\\vec x = \\vec 0 \\} \\\\[1cm]\n",
        "x_1 + x_2 + x_3 + x_4 = 0 \\\\\n",
        "x_1 + 2x_2 + 3x_3 + 4x_4 = 0 \\\\\n",
        "4x_1 + 3x_2 + 2x_3 + x_4 = 0 \\\\[1cm]\n",
        "\\left [\\overbrace{\\begin{matrix}\n",
        "1 & 1 & 1 & 1 \\\\\n",
        "1 & 2 & 3 & 4 \\\\\n",
        "4 & 3 & 2 & 1\n",
        "\\end{matrix}}^A\\right | \\left . \\overbrace{\\begin{matrix}\n",
        "0 \\\\ 0 \\\\ 0\n",
        "\\end {matrix}}^{\\vec 0} \\right ] \\Rightarrow\n",
        "\\text{rref}(A) =  \n",
        "\\left [\\begin{matrix}\n",
        "1 & 0 & -1 & -2 \\\\\n",
        "0 & 1 & 2 & 3 \\\\\n",
        "0 & 0 & 0 & 0\n",
        "\\end{matrix}\\right | \\left . \\begin{matrix}\n",
        "0 \\\\ 0 \\\\ 0\n",
        "\\end {matrix} \\right ] \\\\[2cm]\n",
        "x_1 - x_3 - 2x_4 = 0 \\\\\n",
        "x_2 + 2x_3 + 3x_4 = 0 \\\\[1cm]\n",
        "x_1 = x_3 + 2x_4 \\\\\n",
        "x_2 = -2x_3 -3x_4\\\\[1cm]\n",
        "\\begin{bmatrix}\n",
        "x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4\n",
        "\\end{bmatrix} = x_3\n",
        "\\begin{bmatrix}\n",
        "1 \\\\ -2 \\\\ 1 \\\\ 0\n",
        "\\end{bmatrix} + x_4\n",
        "\\begin{bmatrix}\n",
        "2 \\\\ -3 \\\\ 0 \\\\ 1\n",
        "\\end{bmatrix} \\\\[2cm]\n",
        "N(A) = \\text{span}\\left (\n",
        "  \\begin{bmatrix}\n",
        "1 \\\\ -2 \\\\ 1 \\\\ 0\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "2 \\\\ -3 \\\\ 0 \\\\ 1\n",
        "\\end{bmatrix}\n",
        "  \\right )\n",
        "}$"
      ],
      "metadata": {
        "id": "Q1WgqXRszS2G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Nullity (Dimension of the null space)\n",
        "\n",
        "The nulitty of any matrix A is equal to number of the non-pivot columns in RREF$(A)$.\n",
        "\n",
        "i.e. number of the solutions to $N(A)$"
      ],
      "metadata": {
        "id": "A96dj8PBF5Sg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Column Space\n",
        "\n",
        "> Set of all possible outputs for $A\\vec{v}$ is called **column space** of $A$.\n",
        "\n",
        "$$\n",
        "A = (m\\times n) \\\\\n",
        "\\vec v_1 , \\vec v_2, \\cdots , \\vec v_n \\in R^n \\\\\n",
        "A = \\left [ \\vec v_1 \\ \\vec v_2 \\ \\cdots \\ \\vec v_n \\right ] \\\\\n",
        "C(A) = \\text{span}(\\vec v_1 , \\vec v_2, \\cdots , \\vec v_n) \\\\[1cm]\n",
        "\\vec a \\in C(A) \\quad \\quad \\vec b \\in C(A) \\\\\n",
        "\\vec a = c_1 \\vec v_1, c_2\\vec v_2 , \\cdots , c_n\\vec v_n \\\\\n",
        "\\vec b =  b_1 \\vec v_1, b_2\\vec v_2 , \\cdots , b_n\\vec v_n \\\\\n",
        "\\vec a + \\vec b \\in C(A) \\\\\n",
        "\\quad = (c_1 + b_1 ) \\vec v_1 + (c_2 +b_2) \\vec v_2 + \\cdots + (c_n + b_n) \\vec v_n \\\\[2cm]\n",
        "\\{ A \\vec x | \\vec x \\in R^n \\} \\\\\n",
        "A = x_1 \\vec v_1 + x_2 \\vec v_2 +  \\cdots + x_n \\vec v_n \\\\\n",
        "\\{ x_1 \\vec v_1 + x_2 \\vec v_2 +  \\cdots + x_n \\vec v_n \\big |\n",
        "x_1, x_2, \\cdots, x_n \\in R \\} \\\\\n",
        " = \\text{span}(\\vec v_1 , \\vec v_2, \\cdots , \\vec v_n) = C(A) \\\\[2cm]\n",
        "A \\vec x = \\vec b_1 \\\\\n",
        "\\vec b_1 \\text{ not } \\in C(A) \\Rightarrow A \\vec x = \\vec b_1 \\text{ has no solution} \\\\\n",
        "A \\vec x = \\vec b_2 \\text{ has at least 1 solution} \\Rightarrow \\vec b_2 \\in C(A)\n",
        "$$"
      ],
      "metadata": {
        "id": "R_FN1MbX74qR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Column Space Basis\n",
        "\n",
        "If a matrix is linearly independent the column space is the colum space basis.\n",
        "\n",
        "To find the basis we need to remove the linearly dependent columns, This can be done by finding the RREF of the matrix, the columns that have free variables can be dropped, the remaining columns are the column space basis."
      ],
      "metadata": {
        "id": "u0i6r-El6879"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Dimension of the column space (Rank)\n",
        "\n",
        "Dimension of the column space (Rank) is the number of columns in its column space basis."
      ],
      "metadata": {
        "id": "lSWOaucrLpPJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Orthogonal Complements\n",
        "\n",
        "V is some subspace of $R^n$, the orthogonal (perpendicular) complement of V is:\n",
        "\n",
        "$$\n",
        "V^{\\perp} = \\{ \\vec x \\in R^n | \\vec x \\cdot \\vec v = 0 \\text{ for every } \\vec v \\in V \\}\n",
        "$$\n",
        "\n",
        "$V^{\\perp}$ is a subspace.\n",
        "\n",
        "$N(A)$ is the orthogonal complement of the row space of A ($=C(A^T)$)\n",
        "\n",
        "$$\n",
        "N(A) = (C(A^T))^\\perp\n",
        "$$\n",
        "\n",
        "\\\n",
        "\n",
        "If $Q$ is an orthogonal matrix\n",
        "$$\n",
        "Q^TQ = QQ^T = I \\\\\n",
        "Q^T = Q^{-1}\n",
        "$$\n",
        "\n"
      ],
      "metadata": {
        "id": "rqlnu64_L3IB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Orthogonal Complements  Properties\n"
      ],
      "metadata": {
        "id": "T9EijUZdZLtu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### $\\dim(v) +\\dim(v^\\perp) = n$\n",
        "\n",
        "If v is some subspace of $R^n$\n",
        "\n",
        "$$\n",
        "\\{ \\vec v_1, \\vec v_2, \\cdots, \\vec v_k \\} \\text{ basis for } v \\\\\n",
        "\\dim(v) = k \\\\\n",
        "A_{(n\\times k)} = \\begin{bmatrix}\n",
        "\\cdots  \\\\\n",
        "\\vec v_1 \\ \\vec v_2 \\cdots \\vec v_k \\\\\n",
        "\\cdots\n",
        "\\end{bmatrix} \\\\\n",
        "A^T_{(k\\times n)} = \\begin{bmatrix}\n",
        "\\vdots  &\n",
        "\\begin{matrix}\\vec v_1 \\\\ \\vec v_2 \\\\ \\vdots \\\\ \\vec v_k\\end{matrix} &\n",
        "\\vdots\n",
        "\\end{bmatrix} \\\\[2cm]\n",
        "v = \\text{span}(\\vec v_1, \\vec v_2, \\cdots, \\vec v_k) = C(A) \\\\\n",
        "N(A) = (C(A^T))^\\perp = v^\\perp \\\\\n",
        "\\dim(v^\\perp) = \\dim(N(A^T)) = \\text{Nullity}(A^T)\\\\[1cm]\n",
        "\\text{Rank}(A^T) + \\text{Nullity}(A^T) = n \\\\\n",
        "\\text{Rank}(A) +\\dim(N(A^T)) = n \\\\\n",
        "\\dim(C(A^T)) +\\dim(N(A^T)) = n \\\\\n",
        "\\dim(v) +\\dim(v^\\perp) = n \\\\[2cm]\n",
        "v \\text{ subspace of } n \\\\\n",
        "\\dim(v) +\\dim(v^\\perp) = n \\\\\n",
        "$$"
      ],
      "metadata": {
        "id": "MLZRm48EmP01"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Representing vectors in $R^n$ using subspace members\n",
        "\n",
        "Any member of $R^n$ can be represented as a unique sum of a vector in subspace $V$ and a vector in the orthogonal complement of $V$.\n",
        "\n",
        "$$\n",
        "V \\subseteq R^N \\quad \\quad V^\\perp \\subseteq R^N \\\\\n",
        "\\dim(v) +\\dim(v^\\perp) = n \\\\\n",
        "V \\cap V^\\perp = \\{ \\vec 0 \\} \\\\\n",
        "\\dim(V) = k \\quad \\dim(V^\\perp) = n -k \\\\[1cm]\n",
        "\\{ \\vec v_1, \\vec v_2, \\cdots, \\vec v_k \\} \\text{ basis for } V \\\\\n",
        "\\{ \\vec w_1, \\vec w_2, \\cdots, \\vec w_{n-k} \\} \\text{ basis for } V^\\perp \\\\\n",
        "\\text{ for some scalar constant c and d} \\\\\n",
        "c_1\\vec v_1 + c_2\\vec v_2+  \\cdots+ c_k\\vec v_k + d_1\\vec w_1+ d_2 \\vec w_2 + \\cdots + d_{n-k} \\vec w_{n-k} = \\vec 0 \\\\\n",
        "\\underbrace{c_1\\vec v_1 + c_2\\vec v_2+  \\cdots+ c_k\\vec v_k}_{\\vec x \\\\ \\vec x \\in V}\n",
        "= \\underbrace{-( d_1\\vec w_1+ d_2 \\vec w_2 + \\cdots + d_{n-k} \\vec w_{n-k})}_{\\text{some linear combination of } V^\\perp  \\text{'s basis vector} \\\\ \\vec x \\in V^\\perp} \\\\\n",
        "\\therefore \\vec x = \\vec 0 \\Rightarrow\n",
        "c_1,c_2,\\cdots,c_k = 0 \\quad\n",
        "d_1,d_2,\\cdots,d_{n-k} = 0 \\\\[1cm]\n",
        "\\{ \\vec v_1, \\vec v_2, \\cdots, \\vec v_k , \\vec w_1, \\vec w_2, \\cdots, \\vec w_{n-k} \\} \\text{ is a linearly independent set, and a basis for }R^n \\\\[1cm]\n",
        "\\vec a \\in R^n \\quad \\vec v \\in V \\quad \\vec x \\in V^\\perp \\\\\n",
        "\\vec a = \\vec v + \\vec x \\leftarrow \\text{unique}\n",
        "$$\n",
        "\n",
        "* $\\subseteq$: subset\n",
        "* $\\cap$: intersection\n"
      ],
      "metadata": {
        "id": "vJZCf7hhfVHc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Orthogonal complement of the orthogonal complement\n",
        "\n",
        "The orthogonal complement of the orthogonal complement of V is V.\n",
        "\n",
        "$$\n",
        "V^\\perp = \\{ \\vec x \\in R^n | \\vec x \\cdot \\vec v = 0 \\text{ for every } \\vec v \\in V \\} \\\\\n",
        "(V^\\perp)^\\perp = \\{ \\vec x \\in R^n | \\vec x \\cdot \\vec w = 0 \\text{ for every } \\vec w \\in V^\\perp \\} \\\\[1cm]\n",
        "\\vec x \\in (V^\\perp)^\\perp \\\\\n",
        "vec x = \\vec v + \\vec w \\text{ where } \\vec v \\in V \\text{ and } \\vec w \\in V^\\perp \\\\\n",
        "\\vec x \\cdot \\vec w = 0 = (\\vec v + \\vec w) \\cdot \\vec w = \\vec v \\cdot \\vec w+ \\vec w \\cdot \\vec w = 0 + \\| \\vec w \\| ^2 \\\\\n",
        " \\| \\vec w \\| ^2 = 0 \\Rightarrow \\vec w = \\vec 0 \\\\\n",
        "\\Rightarrow \\vec x = \\vec v \\Rightarrow \\vec x \\in V \\\\[1cm]\n",
        "(V^\\perp)^\\perp = V\n",
        "$$"
      ],
      "metadata": {
        "id": "NfdtRGdPpe9M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Orthogonal complement of the nullspace\n",
        "\n",
        "$$\n",
        "C(A^T)^\\perp = N(A) \\quad \\quad C(A)^\\perp = N(A^T) \\quad \\quad (A^\\perp)^\\perp = A \\\\[0.5cm]\n",
        "N(A)^\\perp = (C(A^T)^\\perp)^\\perp = C(A^T) \\quad \\leftarrow \\text{Rowspace of } A \\\\[0.5cm]\n",
        "N(A^T)^\\perp = (C(A)^\\perp)^\\perp = C(A)\\\\\n",
        "$$"
      ],
      "metadata": {
        "id": "6jKuMKL_rmo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Unique rowspace solution to $A\\vec x = \\vec b$\n",
        "\n",
        "For any b that is in the column space of A, there is a unique member of the row space that is the \"smallest\" solution to Ax=b\n",
        "\n",
        "$$\n",
        "A_{m\\times n } = \\begin{bmatrix}\n",
        "\\vec a_1 \\ \\vec a_2 \\cdots \\vec a_n\n",
        "\\end{bmatrix} \\\\\n",
        "\\vec b \\in C(A) \\\\\n",
        "\\Rightarrow \\vec b = x_1\\vec a_1 + x_2\\vec a_2 +\\cdots + x_n\\vec a_n \\\\\n",
        " \\begin{bmatrix}\n",
        "\\vec a_1 \\ \\vec a_2 \\cdots \\vec a_n\n",
        "\\end{bmatrix} \\begin{bmatrix}\n",
        " x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n  \n",
        "\\end{bmatrix}= \\vec b \\\\\n",
        "\\Rightarrow  A\\vec x = \\vec b \\text{ has at least 1 solution } \\vec x \\in R^n \\\\[1cm]\n",
        "\\vec x \\text{ is a solution to } A\\vec x = \\vec b  \\\\\n",
        "\\vec x \\in R^n \\quad \\vec x = \\vec r_0 + \\vec n _0 \\text{ where } \\vec r_0 \\in C(A^T) \\text{ and } \\vec n_0 \\in N(A) \\\\[0.5cm]\n",
        "\\vec r_0 = \\vec x - \\vec n_0 \\\\\n",
        "A \\vec r_0 = A(\\vec x - \\vec n_0) = \\vec b - \\vec 0 = \\vec b \\\\\n",
        "\\Rightarrow \\vec r_0 \\text{ is the smallest solution to } A\\vec x = \\vec b\n",
        "$$"
      ],
      "metadata": {
        "id": "6_T2NB0IukzQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Orthogonal Projections\n",
        "\n",
        "The line $L = \\text{span}(\\vec v), L = \\{ c\\vec v | c \\in R \\}$, projection of $\\vec x$ on $L$ would be:\n",
        "\n",
        "$$\n",
        "\\text{Proj}_L(\\vec x) = \\frac{\\vec x \\cdot \\vec v}{\\vec v \\cdot \\vec v} \\vec v \\\\\n",
        "$$\n",
        "\n",
        "\n",
        "If $V$ is a subspace of $R^n$ and $V^\\perp$ also a subspace of $R^n$.\n",
        "\n",
        "$$\n",
        "\\vec x \\in R^n \\quad \\vec x = \\vec v + \\vec w \\text{ where } \\vec v \\in V , \\vec w \\in V^\\perp \\\\\n",
        "\\text{Proj}_V(\\vec x) = \\vec v\n",
        "$$"
      ],
      "metadata": {
        "id": "4ffq8roTepOM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Subspace Projection Matrix\n",
        "\n",
        "$$\n",
        "\\text{Proj}_V \\vec x = A(A^TA)^{-1}A^T \\vec x\n",
        "$$\n",
        "\n",
        "Example:\n",
        "\n",
        "$\\displaystyle{\n",
        "V = \\text{span}(\n",
        "  \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 1\\end{bmatrix}\n",
        "  \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\\\ 1\\end{bmatrix}\n",
        ") \\quad \\vec x \\in R^4 \\\\\n",
        "A =   \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\\\ 0 &0 \\\\ 1& 1\\end{bmatrix} \\\\\n",
        "\\text{Proj}_V \\vec x =  A(A^TA)^{-1}A^T \\vec x \\\\\n",
        "A^T =  \\begin{bmatrix} 1 & 0 & 0 & 1 \\\\ 0 & 1 & 0 & 1\\end{bmatrix} \\\\\n",
        "A^TA = \\begin{bmatrix} 2 & 1 \\\\ 1 & 2\\end{bmatrix} \\\\\n",
        "(A^TA)^{-1} = 1/3 \\begin{bmatrix} 2 & -1 \\\\ -1 & 2 \\end{bmatrix} \\\\\n",
        "(A^TA)^{-1}A^T =  1/3 \\begin{bmatrix} 2 & -1 & 0 & 1 \\\\ -1 & 2 & 0 & 1\\end{bmatrix} \\\\\n",
        "A(A^TA)^{-1}A^T = 1/3 \\begin{bmatrix} 2 & -1 & 0 & 1 \\\\ -1 & 2 & 0 & 1 \\\\ 0 & 0 & 0 &0 \\\\ 1 & 1 &0 &2\\end{bmatrix} \\\\\n",
        "\\text{Proj}_V \\vec x =  A(A^TA)^{-1}A^T \\vec x = 1/3 \\begin{bmatrix} 2 & -1 & 0 & 1 \\\\ -1 & 2 & 0 & 1 \\\\ 0 & 0 & 0 &0 \\\\ 1 & 1 &0 &2\\end{bmatrix} \\vec x\n",
        "}$"
      ],
      "metadata": {
        "id": "D4QOaTbTnfUW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Least Squares Approximation\n",
        "\n",
        "No solution to $A\\vec x = \\vec b$ i.e. $\\vec b$ is not in the $C(A)$.\n",
        "\n",
        "The closest approximation, $\\vec x^*$ where $A\\vec x^*$ is as close to $\\vec b $ as possible.\n",
        "\n",
        "The closet vector to $\\vec b$ in the column space $C(A)$, is the projection of vector $\\vec b$ in the column space $C(A)$.\n",
        "$$\n",
        "\\vec x^* = \\frac{A^T\\vec b}{A^TA} \\\\\n",
        "$$\n",
        "\n",
        "Proof:\n",
        "\n",
        "$$\n",
        "A_{n\\times k} \\vec x \\ne \\vec b \\quad \\vec x \\in R^k \\quad \\vec b \\in R^n \\\\\n",
        "\\begin{bmatrix} \\vec a_1 & \\vec a_2 & \\cdots & \\vec a_k\\end{bmatrix}\n",
        "\\begin{bmatrix} \\vec x_1 \\\\ \\vec a_2 \\\\ \\vdots \\\\ \\vec a_k\\end{bmatrix} \\ne \\vec b\\\\\n",
        "\\vec x_1\\vec a_1 + \\vec a_2\\vec a_2 + \\cdots + \\vec a_k\\vec a_k \\ne \\vec b \\\\[1cm]\n",
        "\\text{minimize } \\| \\vec b - A \\vec x \\| \\quad \\quad A \\vec x = \\vec v\\\\\n",
        "\\left \\|\\begin{bmatrix} b_1 - v_1 \\\\ b_2 - v_2 \\\\ \\vdots \\\\ b_k - v_k\\end{bmatrix}\\right\\|^2 \\\\[2cm]\n",
        "A\\vec x^* = \\text{Proj}_{C(A)}\\vec b\\\\\n",
        "A\\vec x^* - \\vec b = \\underbrace{\\text{Proj}_{C(A)}\\vec b - \\vec b}_{\\text{Orthogonal to }\\vec b}\\\\\n",
        "A\\vec x^* - \\vec b \\in C(A)^\\perp \\\\\n",
        "A\\vec x^* - \\vec b  \\in (N(A^T) \\\\\n",
        "A^T(A\\vec x^* - \\vec b) = \\vec 0 \\\\\n",
        "A^TA\\vec x^* - A^T\\vec b = \\vec 0 \\\\\n",
        "A^TA\\vec x^* = A^T\\vec b \\\\\n",
        "\\vec x^* = \\frac{A^T\\vec b}{A^TA} \\\\[2cm]\n",
        "$$\n"
      ],
      "metadata": {
        "id": "qMam0U-svNRy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Coefficient Matrix Equations\n",
        "\n",
        "Representing polynomial equations as an coefficeitn matrix multiplication by a polynomial vector\n",
        "\n",
        "$$\n",
        "ax + by + cz = d \\\\\n",
        "ex + fy + gz = h \\\\\n",
        "ix + jy + lz = k \\\\\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "a & b & c\\\\\n",
        "e & f & g\\\\\n",
        "i & j & l\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "x\\\\\n",
        "y\\\\\n",
        "z\n",
        "\\end{bmatrix} =\n",
        "\\begin{bmatrix}\n",
        "d\\\\\n",
        "h\\\\\n",
        "k\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Only if the determine of the matrix is none zero does this equation have an answer.\n"
      ],
      "metadata": {
        "id": "XWULL_FQ-Q-h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solving\n",
        "$$\n",
        "A \\vec{x} = \\vec{b} \\\\\n",
        "A^{-1}A\\vec{x} = A^{-1}\\vec{b} \\\\\n",
        "I\\vec{x} = A^{-1}\\vec{b} \\\\\n",
        "\\vec{x} = A^{-1}\\vec{b} \\\\[1cm]\n",
        "$$"
      ],
      "metadata": {
        "id": "SDX7m1ToKD-7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "2 & -5 \\\\\n",
        "-2 & 4\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "s\\\\\n",
        "t\n",
        "\\end{bmatrix} =\n",
        "\\begin{bmatrix}\n",
        "7 \\\\ -6\n",
        "\\end{bmatrix} \\\\\n",
        "A^{-1} = \\frac{1}{\\det(A)} \\cdot \\text{adjoint of } A = \\frac{1}{(2)(4) - (-5)(-2)} \\begin{bmatrix}\n",
        "4 & 5 \\\\\n",
        "2 & 2\n",
        "\\end{bmatrix} =\n",
        "\\begin{bmatrix}\n",
        "-2 & -2.5 \\\\\n",
        "-1 & -1\n",
        "\\end{bmatrix} \\\\\n",
        "\\vec{x} = A^{-1}\\vec{b} = \\begin{bmatrix}\n",
        "-2 & -2.5 \\\\\n",
        "-1 & -1\n",
        "\\end{bmatrix} \\begin{bmatrix}\n",
        "7 \\\\ -6\n",
        "\\end{bmatrix}  = \\begin{bmatrix}\n",
        "-14 + 15 \\\\ -7 + 6\n",
        "\\end{bmatrix} = \\begin{bmatrix}\n",
        "1 \\\\ -1\n",
        "\\end{bmatrix} \\\\\n",
        "\\begin{bmatrix}\n",
        "s\\\\\n",
        "t\n",
        "\\end{bmatrix} = \\begin{bmatrix}\n",
        "1 \\\\ -1\n",
        "\\end{bmatrix}\n",
        "$$"
      ],
      "metadata": {
        "id": "3hhykHVsKcGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cramer's Rule\n",
        "\n",
        "$$\n",
        " \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix}\n",
        " \\begin{bmatrix} x \\\\ y \\end{bmatrix} = \\begin{bmatrix} m \\\\ n \\end{bmatrix} \\\\[1cm]\n",
        " x = \\frac{\\text{Area}} {\\det(A)} =\n",
        " \\frac{\\det\\left(\\begin{bmatrix} m & b \\\\ n & d \\end{bmatrix} \\right)}\n",
        " {\\det\\left(\\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix} \\right)} \\\\[1.5cm]\n",
        "  y = \\frac{\\text{Area}} {\\det(A)} =\n",
        " \\frac{\\det\\left(\\begin{bmatrix} a & m \\\\ c & n  \\end{bmatrix} \\right)}\n",
        " {\\det\\left(\\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix} \\right)} \\\\[1cm]\n",
        "$$"
      ],
      "metadata": {
        "id": "Hpujf5wwYyR4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Projections\n",
        "\n",
        "Projection of the vector $\\vec x$ on the line $L$ can be viewed as the shadow of $\\vec x$ on the line $L$. In other words, how much of $\\vec x$ goes in the $L$ direction.\n",
        "\n",
        "$$\n",
        "L = \\{ c \\ \\vec v \\ | \\ c \\in R \\} \\\\\n",
        "\\text{Proj}_L(\\vec x) = c = \\frac{\\vec x \\cdot \\vec v }{\\vec v \\cdot \\vec v}\n",
        "$$\n",
        "\n",
        "If $\\vec v$ is a unit (normal) vector\n",
        "\n",
        "$$\n",
        "\\text{Proj}_L(\\vec x) =\\vec x \\cdot \\vec v\n",
        "$$\n",
        "\n",
        "Proof\n",
        "\n",
        "$\\displaystyle{\n",
        "\\text{From } \\vec x \\text{ we draw an orthogonal line to } L, \\text{ and we call it b} \\\\\n",
        "\\vec x = b + c \\vec v \\\\\n",
        "b \\cdot \\vec v = 0 \\because b \\text{ is orthogonal to } L \\\\\n",
        "b = \\vec x - c \\vec v \\Rightarrow (\\vec x - c \\vec v ) \\cdot  \\vec v = 0 \\\\\n",
        "\\vec x \\cdot \\vec v - c \\vec v \\cdot \\vec v = 0 \\\\\n",
        "\\vec x \\cdot \\vec v = c \\vec v \\cdot \\vec v  \\\\\n",
        "c = \\frac{\\vec x \\cdot \\vec v }{\\vec v \\cdot \\vec v}\n",
        "}$"
      ],
      "metadata": {
        "id": "dK9c2SqnmCMx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Matrix Projection\n",
        "\n",
        "A projection on to a line as a matrix vector prod.\n",
        "\n",
        "Matrix Projection is a linear transformation.\n",
        "\n",
        "$$\n",
        "L = \\{ c \\ \\vec v \\ | \\ c \\in R \\} \\\\\n",
        "\\text{Proj}_L(\\vec x) = \\frac{\\vec x \\cdot \\vec v }{\\| \\vec v \\|^2}\\ \\vec v = A \\vec x\n",
        "$$\n",
        "\n",
        "\n",
        "If $\\vec v$ is a unit (normal) vector\n",
        "\n",
        "$$\n",
        "\\text{Proj}_L(\\vec x) = (\\vec x \\cdot \\vec v)\\ \\vec v = A \\vec x\n",
        "$$\n",
        "\n",
        "\n",
        "The matrix transformation would be\n",
        "\n",
        "$$\n",
        "A = (I \\cdot \\vec u) \\vec u \\\\\n",
        "\\vec u = \\begin{bmatrix}u_1 \\\\ u_2 \\end{bmatrix} \\quad\n",
        "I = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}  \\\\\n",
        "A = \\begin{bmatrix}\n",
        "\\left (\\begin{bmatrix}1 \\\\ 0 \\end{bmatrix} \\cdot \\begin{bmatrix}u_1 \\\\ u_2 \\end{bmatrix} \\right )\\begin{bmatrix}u_1 \\\\ u_2 \\end{bmatrix}\n",
        "&\n",
        "\\left (\\begin{bmatrix}0 \\\\ 1 \\end{bmatrix} \\cdot \\begin{bmatrix}u_1 \\\\ u_2 \\end{bmatrix} \\right )\\begin{bmatrix}u_1 \\\\ u_2 \\end{bmatrix}\n",
        "\\end{bmatrix} \\\\\n",
        "A = \\begin{bmatrix}\n",
        "u_1 \\begin{bmatrix}u_1 \\\\ u_2 \\end{bmatrix} &\n",
        "u_2 \\begin{bmatrix}u_1 \\\\ u_2 \\end{bmatrix}\n",
        "\\end{bmatrix} \\\\\n",
        "A = \\begin{bmatrix}u_1^2 & u_2u_1 \\\\ u_1u_2 & u_2^2 \\end{bmatrix} \\\\[1.5cm]\n",
        "\\text{Proj}_L(\\vec x) = \\begin{bmatrix}u_1^2 & u_2u_1 \\\\ u_1u_2 & u_2^2 \\end{bmatrix} \\vec x\n",
        "$$"
      ],
      "metadata": {
        "id": "HSo2p8Cewpqc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Invertible Functions\n",
        "\n",
        "A function is invertible that is injective meaning there's a unique solution to the function $f(x) = y$"
      ],
      "metadata": {
        "id": "F9FJEJZIKQ5p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Surjective Functions\n",
        "\n",
        "Function that every point in the codomain is mapped to. Also known as onto function.\n",
        "$$\n",
        "\\text{range}(f) = Y = \\text{codomain}\n",
        "$$"
      ],
      "metadata": {
        "id": "XyqZSG_ZH1dd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Injective  Functions\n",
        "\n",
        "for any $y \\in Y$ there's at most one $x$ such that $f(x)=y$. In other word there exists unique $x \\in X$ such that $f(x)=y$. Also known as one-to-one function.\n"
      ],
      "metadata": {
        "id": "Nw4ON0_zIKLQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inverse Transformation\n",
        "if $A\\vec{x}=\\vec{y}$, the transformation that converts $\\vec{y}$ to $A\\vec{x}$ is called the **inverse transformation**. It's deomstracted as $A^{-1}$\n",
        "\n",
        "applying inverse transformation Of a tranformation to it, causes it to go back to the origin.\n",
        "$$\n",
        "A^{-1}A = AA^{-1}=I\n",
        "$$\n",
        "\n",
        "- The resulted tranformation does nothing and is called an **identity matrix**.\n",
        "\n",
        "- The inverse transformation of a transformation, is also linear.\n",
        "\n",
        "- Can only be calculated if matrix is square: $n_\\text{row} = n_\\text{col}$ (i.e., **\"vector span\" = \"matrix range\"**)\n",
        "  - Avoids overdetermination: $n_\\text{row} > n_\\text{col}$ (i.e., $n_\\text{equations} > n_\\text{dimensions}$)\n",
        "  - Avoids undersdetermination: $n_\\text{row} < n_\\text{col}$ (i.e., $n_\\text{equations} < n_\\text{dimensions}$)\n"
      ],
      "metadata": {
        "id": "rUSkuk4E1ssH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Inverses of $2\\times 2$ Matrices\n",
        "\n",
        "$$\n",
        "A =\\begin{bmatrix}\n",
        "a & b\\\\ c & d\n",
        "\\end{bmatrix} \\\\\n",
        "A^{-1} = \\frac{1}{\\det(A)} \\cdot \\text{adj}(A) \\\\\n",
        "A^{-1} = \\frac{1}{ad-bc}\\begin{bmatrix}\n",
        "d & -b\\\\ -c & a\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "- $\\text{adj}$ is adjoint"
      ],
      "metadata": {
        "id": "gpjXDSCCNJcC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Inverse of $n\\times n$ Matrices\n",
        "\n",
        "Finding the reduced row-echelon form (rref)\n",
        "\n",
        "Steps:\n",
        "1. Write a $n\\times 2n$ matrix with the original on left half and the identity matrix on the right half.\n",
        "2. Convert the left matrix to the identity matrix\n",
        "3. The new matrix on the right is the inverse matrix.\n",
        "\n",
        "$$\n",
        "\\left [ \\begin{matrix}\n",
        "a & b & c\\\\\n",
        "d & e & f\\\\\n",
        "g & h & i\n",
        "\\end{matrix}\\right | \\left.\\begin{matrix}\n",
        "1 & 0 & 0\\\\\n",
        "0 & 1 & 0\\\\\n",
        "0 & 0 & 1\n",
        "\\end{matrix}\\right]\n",
        "$$"
      ],
      "metadata": {
        "id": "0o1Ex74kOZrp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example\n",
        "$$\n",
        "\\begin{align*}\n",
        "A &= \\begin{bmatrix}\n",
        "1 & -2 & -4\\\\\n",
        "2 & -3 & -6\\\\\n",
        "-3 & 6 & 15\n",
        "\\end{bmatrix} \\\\\n",
        "A^{-1} &=\n",
        "\\left [ \\begin{matrix}\n",
        "1 & -2 & -4\\\\\n",
        "2 & -3 & -6\\\\\n",
        "-3 & 6 & 15\n",
        "\\end{matrix}\\right | \\left.\\begin{matrix}\n",
        "1 & 0 & 0\\\\\n",
        "0 & 1 & 0\\\\\n",
        "0 & 0 & 1\n",
        "\\end{matrix}\\right] \\begin{matrix}\\\\ \\rightarrow -2R_1 + R_2  \\\\ \\rightarrow +3R_1 + R_3 \\end{matrix} \\\\\n",
        "&=\n",
        "\\left [ \\begin{matrix}\n",
        "1 & -2 & -4\\\\\n",
        "0 & 1 & 2\\\\\n",
        "0 & 0 & 3\n",
        "\\end{matrix}\\right | \\left.\\begin{matrix}\n",
        "1 & 0 & 0\\\\\n",
        "-2 & 1 & 0\\\\\n",
        "3 & 0 & 1\n",
        "\\end{matrix}\\right] \\begin{matrix}\\\\  \\\\ \\rightarrow \\frac{1}{3} R_3  \\end{matrix} \\\\\n",
        "&=\n",
        "\\left [ \\begin{matrix}\n",
        "1 & -2 & -4\\\\\n",
        "0 & 1 & 2\\\\\n",
        "0 & 0 & 1\n",
        "\\end{matrix}\\right | \\left.\\begin{matrix}\n",
        "1 & 0 & 0\\\\\n",
        "-2 & 1 & 0\\\\\n",
        "1 & 0 & \\frac{1}{3}\n",
        "\\end{matrix}\\right] \\begin{matrix}\\\\ \\rightarrow -2R_3 + R_2 \\\\ \\; \\end{matrix} \\\\\n",
        "&=\n",
        "\\left [ \\begin{matrix}\n",
        "1 & -2 & -4\\\\\n",
        "0 & 1 & 0\\\\\n",
        "0 & 0 & 1\n",
        "\\end{matrix}\\right | \\left.\\begin{matrix}\n",
        "1 & 0 & 0\\\\\n",
        "-4 & 1 & -\\frac{2}{3}\\\\\n",
        "1 & 0 & \\frac{1}{3}\n",
        "\\end{matrix}\\right] \\begin{matrix} \\rightarrow 4 R_3 + R_1 \\\\ \\; \\\\ \\; \\end{matrix} \\\\\n",
        "&=\n",
        "\\left [ \\begin{matrix}\n",
        "1 & -2 & 0\\\\\n",
        "0 & 1 & 0\\\\\n",
        "0 & 0 & 1\n",
        "\\end{matrix}\\right | \\left.\\begin{matrix}\n",
        "5 & 0 & \\frac{4}{3}\\\\\n",
        "-4 & 1 & -\\frac{2}{3}\\\\\n",
        "1 & 0 & \\frac{1}{3}\n",
        "\\end{matrix}\\right] \\begin{matrix} \\rightarrow 2 R_2 + R_1 \\\\ \\; \\\\ \\; \\end{matrix} \\\\\n",
        "&=\n",
        "\\left [ \\begin{matrix}\n",
        "1 & 0 & 0\\\\\n",
        "0 & 1 & 0\\\\\n",
        "0 & 0 & 1\n",
        "\\end{matrix}\\right | \\left.\\begin{matrix}\n",
        "-3 & 2 & 0\\\\\n",
        "-4 & 1 & -\\frac{2}{3}\\\\\n",
        "1 & 0 & \\frac{1}{3}\n",
        "\\end{matrix}\\right] \\\\\n",
        "A^{-1} &= \\begin{bmatrix}\n",
        "-3 & 2 & 0\\\\\n",
        "-4 & 1 & -\\frac{2}{3}\\\\\n",
        "1 & 0 & \\frac{1}{3}\n",
        "\\end{bmatrix}\n",
        "\\end{align*}\n",
        "$$"
      ],
      "metadata": {
        "id": "FLf8WJQRTYPI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Determine of inverse matrix\n",
        "\n",
        "$$\n",
        "|\\det(A)| = \\frac{1}{|\\det(A^{-1})|}\n",
        "$$"
      ],
      "metadata": {
        "id": "sfjlE2GpD3W0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Invertible Matrices\n",
        "\n",
        "An invertible matrix is a matrix that has an inverse. For a matrix to have an invertible matrix, it's detemine should not be 0."
      ],
      "metadata": {
        "id": "Rr2CMfPMESiT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Coordinates with Respect to Basis\n",
        "\n",
        "$V$ is subspace of $R^n$, $B=\\{ \\vec v_1, \\vec v_2, \\cdots, \\vec v_k \\}$, $\\vec a \\in V \\Rightarrow \\vec a = c_1\\vec v_1 + c_2\\vec v_2 + \\cdots + c_k \\vec v_k$.\n",
        "\n",
        "We call $c_1, c_2, \\cdots, c_k$ the \"**coordinates of $\\vec a$ with respect to $B$**\".\n",
        "\n",
        "$$\n",
        "[\\vec a]_B = \\begin{bmatrix}\n",
        "c_1 \\\\ c_2 \\\\ \\vdots \\\\ c_k\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "\n",
        "Example:\n",
        "\n",
        "$\\displaystyle{\n",
        "\\vec v_1 = \\begin{bmatrix}2 \\\\ 1\\end{bmatrix} \\quad\n",
        "\\vec v_2 = \\begin{bmatrix}1 \\\\ 2\\end{bmatrix} \\quad\n",
        "B= \\{ \\vec v_1, \\vec v_2 \\} \\text{ basis for } R^2 \\\\\n",
        "\\vec a  = 3\\vec v_1 + 2\\vec v_2 = \\begin{bmatrix}8 \\\\ 7 \\end{bmatrix} \\\\\n",
        "[\\vec a ]_B = \\begin{bmatrix}3 \\\\ 2 \\end{bmatrix}\n",
        "}$"
      ],
      "metadata": {
        "id": "BSCVdCtceklu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Change of Basis\n",
        "> The tranformation that converts our basis vectors to the second grid system basis vectors is the **change of basis**\n",
        "\n",
        "For example:\n",
        "* Our basis $\n",
        "\\begin{bmatrix}\n",
        "1 & 0 \\\\\n",
        "0 & 1\n",
        "\\end{bmatrix}\n",
        "$\n",
        "* Second grid basis:$\n",
        "\\begin{bmatrix}\n",
        "2 & -1 \\\\\n",
        "1 & 1\n",
        "\\end{bmatrix}$\n",
        "* Change of basis $\\begin{bmatrix}\n",
        "2 & -1 \\\\\n",
        "1 & 1 \\\\\n",
        "\\end{bmatrix}$\n",
        "\n",
        "This transforamtion, can convert our grid to the second grid, interestingly, numerically, it's converting the second grid to our grid"
      ],
      "metadata": {
        "id": "LiPYXEv97iNJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "B= \\{ \\vec v_1, \\vec v_2, \\cdots, \\vec v_k \\} \\\\\n",
        "[\\vec a ]_B = \\begin{bmatrix}c_1 \\\\ c_2 \\\\ \\vdots \\\\ c_k \\end{bmatrix} \\\\\n",
        "\\vec a = c_1  \\vec v_1 + c_2\\vec v_2+ \\cdots+c_k \\vec v_k  \\\\[1cm]\n",
        "c_{n\\times k} =  \\begin{bmatrix}\n",
        "\\vdots & \\vdots &&\\vdots \\\\\n",
        "\\vec v_1 & \\vec v_2 & \\cdots & \\vec v_k \\\\\n",
        "\\vdots & \\vdots &&\\vdots\n",
        "\\end{bmatrix} \\\\\n",
        "\\vec a = \\begin{bmatrix}\n",
        "\\vdots & \\vdots &&\\vdots \\\\\n",
        "\\vec v_1 & \\vec v_2 & \\cdots & \\vec v_k \\\\\n",
        "\\vdots & \\vdots &&\\vdots\n",
        "\\end{bmatrix} \\begin{bmatrix}c_1 \\\\ c_2 \\\\ \\vdots \\\\ c_k \\end{bmatrix} \\\\\n",
        "C[\\vec a ]_B = \\vec a \\quad \\text{C is for change of basis}\n",
        "$$\n",
        "\n",
        "Example:\n",
        "\n",
        "$\\displaystyle{\n",
        "\\vec v_1 \\begin{bmatrix}1 \\\\ 2 \\\\ 3\\end{bmatrix} \\quad\n",
        "\\vec v_1 \\begin{bmatrix}1 \\\\ 0 \\\\ 1\\end{bmatrix} \\quad B = \\{\\vec v_1 , \\vec v_2 \\} \\quad\n",
        "[\\vec a]_B = \\begin{bmatrix}7 \\\\ - 4\\end{bmatrix}\\quad \\vec a = ? \\\\\n",
        "\\begin{bmatrix}\n",
        "1 & 1 \\\\ 2  & 0\\\\ 3 &1\n",
        "\\end{bmatrix}\\begin{bmatrix}7 \\\\ - 4\\end{bmatrix} = \\begin{bmatrix}\n",
        " 3 \\\\ 14 \\\\ 17\n",
        "\\end{bmatrix} = \\vec a\n",
        "}$"
      ],
      "metadata": {
        "id": "4zln40Ljh7dR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Inverting Change of Basis Matrix\n",
        "\n",
        "$$\n",
        "C[\\vec a ]_B = \\vec a \\\\\n",
        "[\\vec a ]_B = C^{-1} \\vec a\n",
        "$$\n",
        "\n",
        "Example:\n",
        "\n",
        "$\\displaystyle{\n",
        "\\vec v_1 \\begin{bmatrix}1 \\\\  3\\end{bmatrix} \\quad\n",
        "\\vec v_1 \\begin{bmatrix}2 \\\\ 1\\end{bmatrix} \\quad B = \\{\\vec v_1 , \\vec v_2 \\} \\\\\n",
        "C =  \\begin{bmatrix}1 &2 \\\\ 3 &1 \\end{bmatrix}\\quad \\vec a = \\begin{bmatrix}7 \\\\ 2\\end{bmatrix} \\quad  [\\vec a ]_B  = ? \\\\\n",
        "C^{-1} = \\frac{1}{1-6}\\begin{bmatrix}1 & -2 \\\\ -3  & 1 \\end{bmatrix}\\\\\n",
        "[\\vec a ]_B  = -\\frac{1}{5} \\begin{bmatrix}1 & -2 \\\\ -3  & 1 \\end{bmatrix}\\begin{bmatrix}7 \\\\ 2\\end{bmatrix} = \\begin{bmatrix} -3/5 \\\\ 19/5 \\end{bmatrix}\n",
        "}$"
      ],
      "metadata": {
        "id": "haKrbbfPmoD7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Transformation Matrix with Respect to Basis\n",
        "\n",
        "$A$ is the transformation matrix for $T$ with respect to the standard basis.\n",
        "\n",
        "$$\n",
        "T: R^n \\rightarrow R^n \\\\\n",
        "T(\\vec x) = A\\vec x \\\\[1cm]\n",
        "\\text{B is a basis for }R^n \\\\\n",
        "B= \\{ \\vec v_1, \\vec v_2, \\cdots, \\vec v_k \\} \\\\\n",
        "[T(\\vec x)]_B = D [\\vec x ]_B \\\\\n",
        "$$\n",
        "\n",
        "$D$ is the transformation matrix for $T$ with respect to $B$.\n",
        "\n",
        "$$\n",
        "c_{n\\times n} =  \\begin{bmatrix}\n",
        "\\vdots & \\vdots &&\\vdots \\\\\n",
        "\\vec v_1 & \\vec v_2 & \\cdots & \\vec v_k \\\\\n",
        "\\vdots & \\vdots &&\\vdots\n",
        "\\end{bmatrix} \\\\\n",
        "C[\\vec x ]_B = \\vec x \\quad [\\vec x ]_B = C^{-1}\\vec x \\quad \\text{C is invertible} \\\\\n",
        "D[\\vec x ]_B = T(\\vec x)_B = [A\\vec x]_B = C^{-1}A\\vec x = C^{-1}AC[\\vec x]_B \\\\\n",
        "D[\\vec x ]_B = C^{-1}AC[\\vec x]_B \\\\[0.5cm]\n",
        "\\therefore D = C^{-1}AC \\\\\n",
        "A = CDC^{-1}\n",
        "$$\n",
        "\n",
        "> $D$ is the tranformaion matrix for $T$ with respect to the basis $B$, and $C$ is the change of the basis matrix for $B$, and $A$ is the tranformation matrix for $T$ with respect to standard basis,\n",
        "then:\n",
        "$$\n",
        "D = C^{-1}AC \\\\[1cm]\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\begin{matrix}\n",
        "\\text{standard  coordinates} & \\vec x & \\overset{A}{\\longrightarrow} & T(\\vec x) \\\\ \\\\\n",
        "& \\downarrow C^{-1} &  &  \\downarrow C^{-1} \\\\  \\\\\n",
        "{\\text{coordinates with}\\\\ \\text{respect to B}} & [\\vec x]_B & \\overset{D}{\\longrightarrow} & [T(\\vec x)]_B\n",
        "\\end{matrix} \\\\[3cm]\n",
        "$$\n",
        "\n",
        "Example:\n",
        "\n",
        "$B$ is a basis for $R^n$ and $C$ is change of basis matrix for $B$. Looking for $D$.\n",
        "\n",
        "$\\displaystyle{\n",
        "B = \\{\\begin{bmatrix}1 \\\\ 2\\end{bmatrix}, \\begin{bmatrix}2 \\\\ 1\\end{bmatrix} \\} \\quad\n",
        "T(\\vec x) = \\begin{bmatrix}3 & -2 \\\\ 2 & -2\\end{bmatrix}\\vec x \\\\\n",
        "C^{-1} = \\frac{-1}{3} \\begin{bmatrix}1 & -2 \\\\ -2 & 1\\end{bmatrix} \\\\\n",
        "D = C^{-1}  A C = \\frac{-1}{3} \\begin{bmatrix}1 & -2 \\\\ -2 & 1\\end{bmatrix}\\begin{bmatrix}3 & -2 \\\\ 2 & -2\\end{bmatrix}\\begin{bmatrix}1 &2  \\\\ 2 &1 \\end{bmatrix} \\\\\n",
        "D = \\begin{bmatrix}-1  & 0\\\\0 & 2\\end{bmatrix}\n",
        "}$"
      ],
      "metadata": {
        "id": "dKgTq39soNui"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Translating between coordinate systems**\n",
        "$$\n",
        "\\text{Inverse} \\begin{bmatrix}\n",
        "\\hat{i}_{x} & \\hat{i}_{y} \\\\\n",
        "\\hat{j}_{x} & \\hat{j}_{y} \\\\\n",
        "\\end{bmatrix}^{-1} = A^{-1} \\\\[1cm]\n",
        "\\vec{V}_x A^{-1} = \\vec{V}_y\n",
        "$$\n",
        "\n",
        "Translating a tranformation\n",
        "$$\n",
        "A^{-1} M {A}\n",
        "$$\n",
        "The outer two matrixes are called empathy."
      ],
      "metadata": {
        "id": "eG00iKCnf63r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Orthonormal Bases\n",
        "\n",
        "All the vectors in $B$ have length 1. i.e. they have all been *normallized*.\n",
        "\n",
        "$B = \\{ \\vec v_1, \\vec v_2, \\cdots, \\vec v_k \\} $\n",
        "\n",
        "$\\| \\vec v_i \\| = 1$ for $i= 1,2,\\cdots, k$\n",
        "\n",
        "All the vectors are orthagonal to each other:\n",
        "- $\\vec v_i \\cdot \\vec v_j = 0 \\ $  for $i\\ne j$\n",
        "- $\\vec v_i \\cdot \\vec v_i = 1 \\ $  for $i= 1,2,\\cdots, k$\n",
        "\n",
        "B is an **orthonormal set**.\n",
        "\n",
        "B is also *linearly independent*"
      ],
      "metadata": {
        "id": "xa3UAOUErSxX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Coordinates with Respect to Orthonormal Bases\n",
        "\n",
        "Orthonormal basis are good coordinate systems because they make it easy to figure out coordinates.\n",
        "\n",
        "The standard cooridanate system is also a orthonormal basis.\n",
        "\n",
        "$$\n",
        "\\text{Standard basis for }R^n = \\{\n",
        "\\begin{bmatrix}1 \\\\ 0 \\\\ \\vdots \\\\ 0\\end{bmatrix}\n",
        "\\begin{bmatrix}0 \\\\ 1 \\\\ \\vdots \\\\ 0\\end{bmatrix}\n",
        "\\begin{bmatrix}0 \\\\ 0 \\\\ \\vdots \\\\ 1\\end{bmatrix}\n",
        "\\} \\\\[2cm]\n",
        "$$\n",
        "\n",
        "\n",
        "$B = \\{ \\vec v_1, \\vec v_2, \\cdots, \\vec v_k \\} $ is an orthonormal basis for $V$.\n",
        "\n",
        "$$\n",
        "\\vec x \\in V \\\\\n",
        "\\vec x = c_1 \\vec v_1 + c_2 \\vec v_2 + \\cdots + c_k \\vec v_k \\\\\n",
        "\\vec v_i \\cdot \\vec x = c_1\\vec v_i\\vec v_1 + c_2\\vec v_i \\vec v_2 + \\cdots + c_i\\vec v_i \\vec v_i +\\cdots + c_k \\vec v_i \\vec v_k \\\\\n",
        "= 0 + 0 + \\cdots + 1c_i + \\cdots + 0 = c_i \\\\\n",
        "\\vec v_i \\cdot \\vec x = c_i \\\\[1cm]\n",
        "[\\vec x ]_B = \\begin{bmatrix}c_1 \\\\ c_2 \\\\ \\vdots \\\\ c_k \\end{bmatrix} =  \\begin{bmatrix}\\vec v_1 \\cdot \\vec x \\\\ \\vec v_2 \\cdot \\vec x \\\\ \\vdots \\\\ \\vec v_k \\cdot \\vec x \\end{bmatrix}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "UkzUfHvWu_0g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Projections onto Subspaces with Orthonormal Bases\n",
        "\n",
        "$V$ is a subspace of $R^n$\n",
        "\n",
        "$B = \\{ \\vec v_1, \\vec v_2, \\cdots, \\vec v_k \\} $ orthonormal basis for $V$\n",
        "\n",
        "$\\displaystyle{\n",
        "\\vec x \\in R^n \\Rightarrow \\vec x = \\underbrace{\\vec v}_{\\text{Proj}_V\\vec x} + \\vec w \\quad $ where $\\vec v \\in V$ and $\\vec w \\in V^\\perp \\\\\n",
        "\\vec x =  \\underbrace{c_1 \\vec v_1 + c_2 \\vec v_2 + \\cdots + c_k \\vec v_k}_{\\vec v = \\text{Proj}_V\\vec x } + \\vec w \\\\\n",
        "\\vec v_i \\cdot \\vec x = c_1\\vec v_i\\vec v_1 + c_2\\vec v_i \\vec v_2 + \\cdots + c_i\\vec v_i \\vec v_i +\\cdots + c_k \\vec v_i \\vec v_k + \\vec v_i  \\vec w \\\\ \\quad \\quad\n",
        "= 0 + 0 + \\cdots + 1 c_i + \\cdots + 0 + 0 \\\\ \\quad\\quad = c_i \\\\\n",
        "}$\n",
        "$$\n",
        "\\text{Proj}_V\\vec x =  ( \\vec v_1 \\cdot \\vec x) \\vec v_1 + ( \\vec v_2 \\cdot \\vec x) \\vec v_2 + \\cdots + ( \\vec v_k \\cdot \\vec x) \\vec v_k \\\\[0.5cm]\n",
        "\\text{Proj}_V\\vec x = AA^T \\vec x\n",
        "$$"
      ],
      "metadata": {
        "id": "IornFHEayi5w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Orthogonal Matrices\n",
        "\n",
        "\n",
        "$\\underset{n\\times n}{C}$ cols form an orthonormal set.  It is called an **orthogonal matrix**\n",
        "\n",
        "$$\n",
        "C^T = C^{-1}\n",
        "$$\n",
        "\n",
        "Orthogonal matrices preserve angles and lengths. They cause *no distortion to vectors*\n",
        "- Same length: $\\| \\vec x \\| = \\| C \\vec x\\|$\n",
        "\n",
        "$\\| C\\vec x \\|^2 = C\\vec x \\cdot C \\vec x = (C \\vec x)^T C \\vec x = \\vec x^TC^TC\\vec x = \\vec x^T I \\vec x = \\vec x \\vec x = \\| \\vec x \\|^2$\n",
        "- Same angle: $\\vec v \\cdot \\vec w = \\| \\vec v \\| \\| \\vec w \\| \\cos \\theta$\n",
        "\n",
        "$\\displaystyle{\n",
        "\\cos \\theta = \\frac{\\vec v \\cdot \\vec w}{\\| \\vec v \\| \\| \\vec w \\|} =\n",
        "\\frac{C\\vec v \\cdot C\\vec w}{\\|C \\vec v \\| \\|C \\vec w \\|} =  \n",
        "\\frac{C\\vec v \\cdot C\\vec w}{\\| \\vec v \\| \\| \\vec w \\|} =  \n",
        "\\frac{(C\\vec w)^T C \\vec v}{\\| \\vec v \\| \\| \\vec w \\|} = \\\\\\quad\\quad\n",
        "\\frac{\\vec w^T C^T C \\vec v}{\\| \\vec v \\| \\| \\vec w \\|} =\n",
        "\\frac{\\vec w^T C^T C \\vec v}{\\| \\vec v \\| \\| \\vec w \\|} =\n",
        "\\frac{\\vec w^T \\vec v}{\\| \\vec v \\| \\| \\vec w \\|} =\n",
        "\\frac{\\vec v \\cdot \\vec w}{\\| \\vec v \\| \\| \\vec w \\|} = \\cos \\theta\n",
        "}$"
      ],
      "metadata": {
        "id": "ayymun1w8Cnh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Gram-Schmidt Process\n",
        "\n",
        "A set of linearly independent vectors that are a basis for $V$.\n",
        "\n",
        "How to generate an orthonormal basis for $V$ from this set.\n",
        "\n",
        "\n",
        "$$\n",
        "\\underset{1}{V} = \\text{span}(\\vec v_1) \\quad \\vec u_1 = \\frac{\\vec v_1}{\\| \\vec v_1\\|}= \\frac{1}{\\| \\vec v_1\\|} {\\| \\vec v_1\\|} = 1  \\\\\n",
        "\\underset{1}{V} = \\text{span}(\\vec u_1) \\\\\n",
        "\\{ \\vec u_1 \\} \\text { is an orthonormal basis for } \\underset{1}{V}\\\\[1cm]\n",
        "\\underset{2}{V} = \\text{span}(\\vec v_1, \\vec v_2) = \\text{span}(\\vec u_1, \\vec v_2) = \\text{span}(\\vec u_1, \\vec y_2)  \\\\\n",
        "\\vec y_2 = \\vec v_2 - \\text{proj}_{V_1}\\vec v_2 \\\\\n",
        "\\text{proj}_{V_1}\\vec v_2 = (\\vec v_2 \\cdot \\vec u_1) \\vec u_1 \\\\\n",
        "\\vec y_2 = \\vec v_2 - (\\vec v_2 \\cdot \\vec u_1) \\vec u_1 \\\\\n",
        "\\vec u_2 = \\frac{\\vec y_2}{\\| \\vec y_2\\|} \\\\\n",
        "\\underset{2}{V} = \\text{span}(\\vec v_1, \\vec u_2)\\\\[1cm]\n",
        "\\underset{3}{V} = \\text{span}(\\vec u_1, \\vec u_2, \\vec v_3)  \\\\\n",
        "\\vec y_3 = \\vec v_3 - \\text{proj}_{V_2}\\vec v_3 \\\\\n",
        "\\text{proj}_{V_2}\\vec v_3  = (\\vec v_3 \\cdot \\vec u_1) \\vec u_1 + (\\vec v_3 \\cdot \\vec u_2) \\vec u_2 \\\\\n",
        "\\vec y_3 =\\vec v_3 - (\\vec v_3 \\cdot \\vec u_1) \\vec u_1 + (\\vec v_3 \\cdot \\vec u_2) \\vec u_2 \\\\\n",
        "\\vec u_2 = \\frac{\\vec y_3}{\\| \\vec y_3\\|} \\\\\n",
        "\\underset{3}{V} = \\text{span}(\\vec u_1, \\vec u_2, \\vec u_3) \\\\\n",
        "$$\n",
        "\n",
        "This process is called *the Gram-Schmidt process*."
      ],
      "metadata": {
        "id": "q1pv35i1AjgB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example:\n",
        "\n",
        "$V$ is plane defined by $x_1+ x_2 + x_3 = 0$.\n",
        "\n",
        "$\\displaystyle{\n",
        "x_2 = c_1 \\quad x_3 = c_2 \\quad x_1 = -c_1 -c_2 \\\\\n",
        "V = \\{ \\begin{bmatrix}x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix} |\n",
        "c_1\\begin{bmatrix}-1 \\\\ 1 \\\\ 0 \\end{bmatrix} +\n",
        "c_2\\begin{bmatrix}-1 \\\\ 0 \\\\ 1 \\end{bmatrix} +\n",
        "c_1, c_2 \\in R \\} \\\\\n",
        "V = \\text{span}\\left(\\begin{bmatrix}-1 \\\\ 1 \\\\ 0 \\end{bmatrix},\n",
        "\\begin{bmatrix}-1 \\\\ 0 \\\\ 1 \\end{bmatrix}\\right) = \\text{span}(\\vec v_1, \\vec v_2) \\\\[2cm]\n",
        "\\|\\vec v_1 \\| = \\sqrt{2} \\quad \\vec u_1 = \\frac{1}{\\sqrt{2}} \\begin{bmatrix}-1 \\\\ 1 \\\\ 0 \\end{bmatrix} \\\\\n",
        "\\underset{1}{V} = \\text{span}(\\vec v_1)= \\text{span}(\\vec u_1) \\\\[1cm]\n",
        "\\underset{2}{V} = \\text{span}(\\vec u_1, \\vec v_2) \\\\\n",
        "\\vec y_2 = \\vec v_2 - \\text{proj}_{V_1}\\vec v_2 = \\begin{bmatrix}-1 \\\\ 1 \\\\ 0 \\end{bmatrix} - \\left(\\frac{1}{\\sqrt{2}} \\begin{bmatrix}-1 \\\\ 1 \\\\ 0 \\end{bmatrix}\\right) \\frac{1}{\\sqrt{2}} \\begin{bmatrix}-1 \\\\ 1 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix}-1/2 \\\\ -1/2 \\\\ 1 \\end{bmatrix} \\\\\n",
        "\\|\\vec y_2 \\| = \\sqrt{3/2} \\\\\n",
        "\\vec u_2 =  \\sqrt{2/3}\\begin{bmatrix}-1/2 \\\\ -1/2 \\\\ 1 \\end{bmatrix} \\\\[1cm]\n",
        "\\{ \\vec u_1, \\vec u_2 \\} \\rightarrow \\text{ is the orthonormal basis for } V\n",
        "}$"
      ],
      "metadata": {
        "id": "YSP4f8jtFywz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Eigenvectors and Eigenvalues\n",
        "During a tranformation, the vetors (lines) that remain on the same span (only expand or squish) are called **Eigenvectors**, and their scale is called **Eigenvalues**.\n",
        "$$\n",
        "A\\vec{v} = \\lambda \\vec{v}\n",
        "$$\n",
        "* $A$ Transformation matrix\n",
        "* $\\vec{v}$ Eigenvector\n",
        "* $\\lambda$ a number, Eigenvalue\n",
        "\n",
        "The matrix-vector product, $A\\vec{v}$, gives the same result as just scaling the **eigenvector**, $\\vec{v}$, by some value, $\\lambda$.\n",
        "\n",
        "Rewritting the vector-scaler multiplication as a matrix multiplication:\n",
        "$$\n",
        "\\lambda \\vec{v}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "\\lambda & 0 & 0 \\\\\n",
        "0 & \\lambda & 0 \\\\\n",
        "0 & 0 & \\lambda\n",
        "\\end{bmatrix}\n",
        "\\vec{v}\n",
        "=\n",
        "\\left(\n",
        "\\lambda\n",
        "\\begin{bmatrix}\n",
        "1 & 0 & 0 \\\\\n",
        "0 & 1 & 0 \\\\\n",
        "0 & 0 & 1\n",
        "\\end{bmatrix}\n",
        "\\right)\n",
        "\\vec{v}\n",
        "=\n",
        "(\\lambda I)\n",
        "\\vec{v}\n",
        "$$\n",
        "\n",
        "Factoring the $\\vec{v}$:\n",
        "$$\n",
        "(A - \\lambda I) \\vec{v} =\\vec{0}\n",
        "$$\n",
        "Assuming $\\vec{v} \\neq 0$, It will only be zero if the span is reduced, ie the determinant is zero.\n",
        "$$\n",
        "\\det(A - \\lambda I) = 0\n",
        "$$\n",
        "If there is $\\det(A - \\lambda I) = 0$, we can read off as saying the $\\vec{v}$ is an **eigenvector** of $A$, staying on its own span during the tranformation A.\n",
        "\n",
        "\n",
        "\\\n",
        "\n",
        "The determinant of the matrix $A$ is equal to the product of all of the eigenvalues for that matrix.\n",
        "\n",
        "$$\n",
        "\\det(A) = \\prod \\lambda\n",
        "$$\n"
      ],
      "metadata": {
        "id": "MiJFEx1DmdJY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example:\n",
        "Given the matrix tranformation of $\n",
        "\\begin{bmatrix}\n",
        "3 & 1 \\\\\n",
        "0 & 2\n",
        "\\end{bmatrix}\n",
        "$, find if a value $\\lambda$ is an eigenvalue.\n",
        "\n",
        "$\\displaystyle{\n",
        "\\det \\left (\n",
        "\\begin{bmatrix}\n",
        "3 - \\lambda & 1 \\\\\n",
        "0 & 2 - \\lambda\n",
        "\\end{bmatrix}\n",
        "\\right ) = 0 \\\\[0.5cm]\n",
        "(3-\\lambda)(2-\\lambda) - (1)(0) = 0 \\\\[0.5cm]\n",
        "(3-\\lambda)(2-\\lambda) = 0 \\\\[1cm]\n",
        "\\lambda=2 \\text{  or  } \\lambda=3\n",
        "}$"
      ],
      "metadata": {
        "id": "aWD_b90XsHCc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matrix types base on their eigenvalues\n",
        "\n",
        "| Matrix type | if all its eigenvalues are|\n",
        "| --- | --- |\n",
        "|Positive definite | $>0$ |\n",
        "|Positive semidefinite | $\\ge0$ |\n",
        "|Negative definite | $<0$ |\n",
        "|Negative semidefinite | $\\le0$ |"
      ],
      "metadata": {
        "id": "SfWqsxhySGzk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Eigenspace\n",
        "\n",
        "> Eigenspace just means all of the eigenvectors that correspond to some eigenvalue. The eigenspace for some particular eigenvalue is going to be equal to the set of vectors that satisfy the equation: $(\\lambda I -A) \\vec{v} =\\vec{0}$\n",
        "$$\n",
        "E_\\lambda = N(\\lambda I -A)\n",
        "$$\n",
        "\n",
        "Example: eigenspace of the before example:\n",
        "$\\displaystyle{\n",
        "A = \\begin{bmatrix}3 & 1 \\\\0 & 2\\end{bmatrix}\n",
        "\\quad \\lambda=2 \\text{  or  } \\lambda=3 \\\\\n",
        "E_2 = N(\n",
        "\\begin{bmatrix}2 & 0 \\\\0 & 2\\end{bmatrix} -\n",
        "\\begin{bmatrix}3 & 1 \\\\0 & 2\\end{bmatrix}\n",
        ") = N(\\begin{bmatrix}-1 & -1 \\\\0 & 0\\end{bmatrix}) \\\\\n",
        "\\begin{bmatrix}-1 & -1 \\\\0 & 0\\end{bmatrix} \\vec v = \\vec 0 \\rightarrow\n",
        "\\begin{bmatrix}1 & 1 \\\\0 & 0\\end{bmatrix} \\begin{bmatrix}v_1 \\\\ v_2 \\end{bmatrix} = \\begin{bmatrix}0 \\\\ 0 \\end{bmatrix} \\\\\n",
        "\\left \\{ \\begin{matrix}\n",
        "v_1 + v_2 = 0 \\\\ v_1 = v_2\n",
        "\\end{matrix} \\right . \\Rightarrow\n",
        "E_2 = \\{ \\begin{bmatrix}v_1 \\\\ v_2 \\end{bmatrix} = t  \\begin{bmatrix}1 \\\\ 1 \\end{bmatrix}, t\\in R \\} \\\\\n",
        "E_2 = \\text{span}(\\begin{bmatrix}1 \\\\ 1 \\end{bmatrix})\n",
        "\\\\[1cm]\n",
        "E_3 = N(\n",
        "\\begin{bmatrix}3 & 0 \\\\0 & 3\\end{bmatrix} -\n",
        "\\begin{bmatrix}3 & 1 \\\\0 & 2\\end{bmatrix}\n",
        ") = N(\\begin{bmatrix}0& -1 \\\\0 & 1\\end{bmatrix}) \\\\\n",
        "\\begin{bmatrix}0 & -1 \\\\0 & 1\\end{bmatrix} \\vec v = \\vec 0 \\rightarrow\n",
        "\\begin{bmatrix}1 & 0 \\\\0 & 0\\end{bmatrix} \\begin{bmatrix}v_1 \\\\ v_2 \\end{bmatrix} = \\begin{bmatrix}0 \\\\ 0 \\end{bmatrix} \\\\\n",
        "v_1 = 0 \\Rightarrow E_3 = \\text{DNE}\n",
        "}$"
      ],
      "metadata": {
        "id": "9oB2xNaoznqA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Eigenbasis**\n",
        "> During a matrix tranformation, if both basis vectors are eigenvectors, they're called **Eigenbasis**\n",
        "\n",
        "If the basis vectors are not eigenvectors in a tranformation, but there are at least 2 eigenvectors in the transformation, we can create a new grid system with the eigenvectors as the basis vectors.\n",
        "\n",
        "For the above example, that would be: $\\hat{i}=\\begin{bmatrix}3 \\\\ 0\\end{bmatrix}$, and $\\hat{j}=\\begin{bmatrix}1 \\\\ 2\\end{bmatrix}$ resulting the a tranformation of $\\begin{bmatrix}3 & 1 \\\\ 0 & 2\\end{bmatrix}$\n",
        "\n",
        "To convert to and from our new grid system, we can wrap the tranforamtion in the change of basis matrix and inverse of change of basis vector:\n",
        "$$\n",
        "A^{-1}MA \\\\\n",
        "$$\n",
        "\n",
        "In the above example,$\\begin{bmatrix}1 \\\\ 0 \\end{bmatrix}$ and $\\begin{bmatrix} -1 \\\\ 1\\end{bmatrix}$ are the eigenvectors, the tranformation matrix with perspective of the new basis would be:\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}1 & -1 \\\\ 0 & 1\\end{bmatrix}^{-1}\n",
        "\\begin{bmatrix}3 & 1 \\\\ 0 & 2\\end{bmatrix}\n",
        "\\begin{bmatrix}1 & -1 \\\\ 0 & 1\\end{bmatrix} =\n",
        "\\begin{bmatrix}3 & 0 \\\\ 0 & 2\\end{bmatrix} \\\\\n",
        "$$\n",
        "\n",
        "**The resulting matrix is guaranteed to be diagonal with its corresponding eigenvalues down that diagonal**"
      ],
      "metadata": {
        "id": "GSjkAC7GuLMz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculating Eigenvalues Formula**\n",
        "\n",
        "Facts:\n",
        "\n",
        "1) $\\frac{1}{2}\\text{tr}\\left( \\begin{bmatrix}a & b \\\\ c & d \\end{bmatrix} \\right) = \\frac{a+d}{2} = \\frac{\\lambda_1 + \\lambda_2}{2} = m \\text{ (mean)}$\n",
        "\n",
        "2) $\\det\\left( \\begin{bmatrix}a & b \\\\ c & d \\end{bmatrix} \\right) = ad-bc = \\lambda_1 \\lambda_2 = p \\text{ (product)}$\n",
        "\n",
        "From 1 and 2:\n",
        "$$\n",
        "\\begin{align}\n",
        "p = m^2 - d^2 &= (m+d)(m-d) \\\\\n",
        "d^2 &= m^2 - p \\\\\n",
        "\\lambda_1, \\lambda_2 &= m \\pm \\sqrt{m^2 -p }\n",
        "\\end{align}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "cXoonmqfhdKZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Eigendecomposition\n",
        "\n",
        "$$\n",
        "A = V \\Lambda  V^{-1}\n",
        "$$\n",
        "\n",
        "Where:\n",
        "\n",
        "* $V$ is the concatenation of all the eigenvectors of $A$\n",
        "* $\\Lambda$ (upper-case $\\lambda$) is the diagonal matrix diag($\\lambda$). Note that the convention is to arrange the lambda values in descending order; as a result, the first eigenvalue (and its associated eigenvector) may be a primary characteristic of the matrix $A$.\n",
        "\n",
        "\\\n",
        "\n",
        "$\n",
        "\\Lambda = \\begin{bmatrix}\n",
        "\\lambda_1 & 0 & \\cdots & 0 \\\\\n",
        "0 & \\lambda_2 & \\cdots & 0 \\\\\n",
        "0 & 0 & \\ddots & 0 \\\\\n",
        "0 & 0 & \\cdots & \\lambda_n &  \\\\\n",
        "\\end{bmatrix}\n",
        "$\n",
        "\n",
        "\\\n",
        "\n",
        "\n",
        "The decomposition of a matrix into eigenvectors and eigenvalues reveals characteristics of the matrix, eg:\n",
        "- Matrix is singular if and only if any of its eigenvalues are zero.\n",
        "- Under specific conditions, can optimize quadratic expressions:\n",
        "  - Maximum of $f(x)$ = largest eigenvalue\n",
        "  - Minimum of $f(x)$ = smallest eigenvalue\n"
      ],
      "metadata": {
        "id": "TvGTKyqAKQOP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Singular Value Decomposition\n",
        "\n",
        "Unlike Eigendecomposition, which is applicable to square matrices only, SVD is applicable to *any* real-valued matrix.\n",
        "\n",
        "SVD decomposes a matrix into:\n",
        "* Singular vectors (analogous to eigenvectors)\n",
        "* Singular values (analogous to eigenvalues)\n",
        "\n"
      ],
      "metadata": {
        "id": "6dbJ4tP6Y2xT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Alegbra in Machine Learning"
      ],
      "metadata": {
        "id": "zYTbTlV1KPjo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Contemporary applications:\n",
        "* Solving for unknown in Ml algos, including deep learning\n",
        "* Reducing dimensionality (eg, principal component analysis)\n",
        "* Ranking results (eg with eigenvector)\n",
        "* Recommenders (eg singular value decomposition, SVD)\n",
        "* Natural language processing (eg SVD, matrix factorization)\n",
        "  * Topic modeling\n",
        "  * Semantic analysis"
      ],
      "metadata": {
        "id": "sx7gJm94KZ50"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Components and terminologies"
      ],
      "metadata": {
        "id": "n5ZltHajOEtm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Algebra Data Structures\n",
        "\n",
        "> ML generalization of vectors and matrices to any number of dimensions\n",
        "\n",
        "| Dimensions | Name | Description |\n",
        "| ---------- | ---- | ----------- |\n",
        "| 0 | scalar | magnitude only |\n",
        "| 1 | vector | array |\n",
        "| 2 | matrix | flat table, squre |\n",
        "| 3 | 3-tensor | 3D table, cube |\n",
        "| n | n-tensor | higher dimensional |\n",
        "\n"
      ],
      "metadata": {
        "id": "viQVRsfjOLeF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Scalars\n",
        "\n",
        "- No dimensions\n",
        "- Single Number\n",
        "- Denoted in lowercase, italics, eg, *x*\n",
        "- should be typed, like all other tensors: eg: int, float32"
      ],
      "metadata": {
        "id": "jkuL_P83PMFF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Vectors\n",
        "- One-dimensional array of numbers\n",
        "- Denoted in lowercase, italics, bold, eg: ***x***\n",
        "- Arranged in an order, so elementcan be accessed by its index\n",
        "  - Elements are scalars so not bold, eg: second element of ***x*** is $\\mathit{x_2}$\n",
        "- Representing a point in space:\n",
        "  - Vector of length two represents location in 2D matrix\n",
        "  - Length of three represents location in 3D cube\n",
        "  - Length of *n* represents location in *n*-dimensional tensor\n",
        "\n",
        "\n",
        "In machine learning, the most common norm is the *L2* norm, and we often don't write the subscript 2.\n",
        "\n",
        "Norms, particularly L1 and L2, are used to regularize objective functions."
      ],
      "metadata": {
        "id": "Bg_6oXy6S6Sd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Matrices\n",
        "\n",
        "- Two-dimensional arrays of number\n",
        "- Denoted in uppercase, italics, bold. eg $\\mathbf{X}$\n",
        "- Shape is denoted in row, column\n",
        "- an Element is denoted using uppercase, italics: eg $\\mathit{X}_{1,2}$\n",
        "- Colons are used to represent entier rows/columns. eg $X_{:,1}$\n"
      ],
      "metadata": {
        "id": "hUTiFYSxcor2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tensors\n",
        "\n",
        "\n",
        "- Denoted in uppercase, italics, bold, and sans serif font. eg ***X***\n",
        "- Shape is denoted in row, column\n",
        "- A 4-tensor ***X*** is denoted using ***X***$_{(i,j,k,l)}$\n",
        "- Colons are used to represent entier rows/columns. eg $X_{:,1}$\n"
      ],
      "metadata": {
        "id": "uMUSQGUFg6Da"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Eigendecomposition\n",
        "\n",
        "Eigendecomposition is not possible with all matrices. And in some cases where it is possible, the eigendecomposition involves complex numbers instead of straightforward real numbers.\n",
        "\n",
        "In machine learning, however, we are typically working with real symmetric matrices, which can be conveniently and efficiently decomposed into real-only eigenvectors and real-only eigenvalues. If $A$ is a real symmetric matrix then...\n",
        "\n",
        "$A = Q \\Lambda Q^T$\n",
        "\n",
        "...where $Q$ is analogous to $V$ from the previous equation except that it's special because it's an orthogonal matrix."
      ],
      "metadata": {
        "id": "Bee7YgI_OiRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Alegbra with Python\n",
        "\n",
        "https://github.com/jonkrohn/ML-foundations/blob/master/notebooks/1-intro-to-linear-algebra.ipynb"
      ],
      "metadata": {
        "id": "xET4Mhr-KTt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "vB5sDZtYRGvO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Algebra Data Structures"
      ],
      "metadata": {
        "id": "3qG3rsFJQ8Jm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scalars\n",
        "\n",
        "TensorFlow\n",
        "\n",
        "Tensors created with a wrapper, all of which [you can read about here](https://www.tensorflow.org/guide/tensor):  \n",
        "\n",
        "* `tf.Variable` - Most widely-used\n",
        "* `tf.constant`\n",
        "* `tf.placeholder`\n",
        "* `tf.SparseTensor`\n",
        "\n",
        "\n",
        "PyTorch\n",
        "\n",
        "PyTorch tensors are designed to be pythonic, i.e., to feel and behave like NumPy arrays and can be used on GPU"
      ],
      "metadata": {
        "id": "2DEyMiqLREeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic Python scalar\n",
        "x = 25\n",
        "x, type(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8g60YtndVkcC",
        "outputId": "2e6b79f7-a072-4d08-cfa8-a6e31696c095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25, int)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensorflow scalar\n",
        "x_tf = tf.Variable(25, dtype=tf.int16) # dtype is optional\n",
        "x_tf, x_tf.shape # no dimensionality"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCU4byimR0IE",
        "outputId": "9d0ba640-bfd4-4d85-9928-62a58b5748a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Variable 'Variable:0' shape=() dtype=int16, numpy=25>, TensorShape([]))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch scalar\n",
        "x_pt = torch.tensor(25) # type specification optional, e.g.: dtype=torch.float16\n",
        "x_pt, x_pt.shape # no dimensionality"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alpakX1wRtE4",
        "outputId": "da236786-e0fa-4b64-fc0c-e4ec34ba2147"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(25), torch.Size([]))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vectors\n",
        "\n",
        "Vectors + Vector Transposition"
      ],
      "metadata": {
        "id": "7T56m3JyVWup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NumPy vector\n",
        "x = np.array([[25, 2, 5]])\n",
        "x, len(x), x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfOq_VIGVai9",
        "outputId": "f327fea4-2889-4deb-d7e5-975abfe77544"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[25,  2,  5]]), 1, (1, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NumPy vector transposition\n",
        "x_t = x.T\n",
        "x_t, x_t.shape"
      ],
      "metadata": {
        "id": "9YNyplxKWAt6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dac1f65-6086-4e5c-d9d5-5b9480f8f9df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[25],\n",
              "        [ 2],\n",
              "        [ 5]]),\n",
              " (3, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectors in PyTorch\n",
        "x_pt = torch.tensor([25, 2, 5])\n",
        "x_pt"
      ],
      "metadata": {
        "id": "3FhTinWJX5sW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bd63b86-97df-44f8-e0bc-007dea90ee91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([25,  2,  5])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectors in TensorFlow\n",
        "x_tf = tf.Variable([25, 2, 5])\n",
        "x_tf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9vTzUkLYIs1",
        "outputId": "5a0bb394-121e-41b7-8131-32cf7b35430c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(3,) dtype=int32, numpy=array([25,  2,  5], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Vector Norm"
      ],
      "metadata": {
        "id": "aOToo72eNbdC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = [25,  2,  5]\n",
        "# L1 Norm\n",
        "(25**2 + 2**2 + 5**2)**(1/2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNui3OdjNePU",
        "outputId": "a066a1df-ae99-49b5-c74b-581dd2f34d45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25.573423705088842"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.linalg.norm(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_GulETjN3FZ",
        "outputId": "e0878e50-c0d7-4d34-8671-b6c7694e334d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25.573423705088842"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Squared L1 Norm\n",
        "(25**2 + 2**2 + 5**2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVh2Bi_AQVFB",
        "outputId": "c246dbb9-8485-43c5-db18-eb28e771dfc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "654"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.dot(x,x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ajcGnPrQcXu",
        "outputId": "7290ff89-921f-4285-fda9-df3fe099c3e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "654"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matrices"
      ],
      "metadata": {
        "id": "yh1tKxq2chmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[25, 2], [5, 26], [3, 7]])\n",
        "X, X.shape, X.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kG-0zDqeEcw",
        "outputId": "9749d456-9606-4ffb-ae1c-2a8fcba9d03c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[25,  2],\n",
              "        [ 5, 26],\n",
              "        [ 3,  7]]),\n",
              " (3, 2),\n",
              " 6)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrices in PyTorch\n",
        "X_pt = torch.tensor([[25, 2], [5, 26], [3, 7]])\n",
        "X_pt, X_pt.shape,"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpKMOJE6eLZV",
        "outputId": "1ff10141-086b-4283-ecb3-db0826cb9195"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[25,  2],\n",
              "         [ 5, 26],\n",
              "         [ 3,  7]]),\n",
              " torch.Size([3, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrices in TensorFlow\n",
        "X_tf = tf.Variable([[25, 2], [5, 26], [3, 7]])\n",
        "X_tf, tf.rank(X_tf), tf.shape(X_tf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_vNzFRqeXU9",
        "outputId": "a0685d93-315f-4c06-a171-2c202563fab3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Variable 'Variable:0' shape=(3, 2) dtype=int32, numpy=\n",
              " array([[25,  2],\n",
              "        [ 5, 26],\n",
              "        [ 3,  7]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(), dtype=int32, numpy=2>,\n",
              " <tf.Tensor: shape=(2,), dtype=int32, numpy=array([3, 2], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensors"
      ],
      "metadata": {
        "id": "rPFjl60WiLgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pytorch zero tensor\n",
        "images_pt = torch.zeros([2, 8, 8, 3])\n",
        "# Tensorflow zero tensor\n",
        "images_tf = tf.zeros([2, 8, 8, 3])"
      ],
      "metadata": {
        "id": "eTw80acyiOpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor Operations\n",
        "\n",
        "Adding or multiplying with scalar applies operation to all elements and tensor shape is retained\n",
        "\n",
        "If two tensors have the same size, operations are often by default applied element-wise. This is **not matrix multiplication**, but is rather called the **Hadamard product** or simply the **element-wise product**.\n",
        "\n",
        "The mathematical notation is $A \\odot X$"
      ],
      "metadata": {
        "id": "F7XyS8HNi26f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor transpose\n",
        "X.T, X_pt.T, tf.transpose(X_tf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FD4KKqAXkCeE",
        "outputId": "74617406-e65a-4bde-fbf3-c1a07b28aacc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[25,  5,  3],\n",
              "        [ 2, 26,  7]]),\n",
              " tensor([[25,  5,  3],\n",
              "         [ 2, 26,  7]]),\n",
              " <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              " array([[25,  5,  3],\n",
              "        [ 2, 26,  7]], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor arithmetic\n",
        "X_tf*2, X_pt + 2, X/2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7cRmTi_kL8I",
        "outputId": "a32e20a5-c08c-46ca-f410-796003241757"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
              " array([[50,  4],\n",
              "        [10, 52],\n",
              "        [ 6, 14]], dtype=int32)>,\n",
              " tensor([[27,  4],\n",
              "         [ 7, 28],\n",
              "         [ 5,  9]]),\n",
              " array([[12.5,  1. ],\n",
              "        [ 2.5, 13. ],\n",
              "        [ 1.5,  3.5]]))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor dot product\n",
        "torch.dot(torch.tensor([25, 2, 5.]), torch.tensor([0, 1, 2.])), \\\n",
        "np.dot([0,1,2], [3,4,5]), \\\n",
        "tf.tensordot(tf.Variable([0, 1, 2]), tf.Variable([3,4,5]), axes=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpEqrih0Y9HH",
        "outputId": "6f4ad5db-da9b-4217-8a37-e398f92b2b0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(12.), 14, <tf.Tensor: shape=(), dtype=int32, numpy=14>)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Frobenius Norm\n",
        "np.linalg.norm(np.array([[1, 2], [3, 4]])), \\\n",
        "torch.norm( torch.tensor([[1, 2], [3, 4.]])), \\\n",
        "tf.norm( tf.Variable([[1, 2], [3, 4.]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLixl0plmnhe",
        "outputId": "ed746dee-f3ad-4034-b57c-b4bf871ec0a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5.477225575051661,\n",
              " tensor(5.4772),\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=5.477226>)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matrix Multiplication"
      ],
      "metadata": {
        "id": "M2DxxgUGoAHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix Multiplication with Numpy\n",
        "A = np.array([[3, 4], [5, 6], [7, 8]])\n",
        "B = np.array([[1, 9], [2, 0]])\n",
        "b = np.array([1, 2])\n",
        "\n",
        "np.dot(A, b), \\\n",
        "np.dot(A, B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IF6_9rmIn6-V",
        "outputId": "1c1612cc-7be7-4422-cd56-2a64f3e40bc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([11, 17, 23]),\n",
              " array([[11, 27],\n",
              "        [17, 45],\n",
              "        [23, 63]]))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix Multiplication with PyTorch\n",
        "A_pt = torch.tensor([[3, 4], [5, 6], [7, 8]])\n",
        "B_pt = torch.from_numpy(B)\n",
        "b_pt = torch.tensor([1, 2])\n",
        "\n",
        "torch.matmul(A_pt, b_pt), \\\n",
        "torch.matmul(A_pt, B_pt)\n",
        "# like np.dot() automatically infers dims in order to perform\n",
        "# dot product, matvec, or matrix multiplication"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9XAt9rAoJWM",
        "outputId": "e7c3b5fc-ca53-4828-f23d-4554b11e1e46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([11, 17, 23]),\n",
              " tensor([[11, 27],\n",
              "         [17, 45],\n",
              "         [23, 63]]))"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix Multiplication with Tensorflow\n",
        "A_tf = tf.Variable([[3, 4], [5, 6], [7, 8]])\n",
        "B_tf = tf.convert_to_tensor(B, dtype=tf.int32)\n",
        "b_tf = tf.Variable([1, 2])\n",
        "\n",
        "tf.linalg.matvec(A_tf, b_tf), \\\n",
        "tf.matmul(A_tf, B_tf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90d523d2-4717-433b-f633-b163c0d1d987",
        "id": "99tM_f9EoT5g"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3,), dtype=int32, numpy=array([11, 17, 23], dtype=int32)>,\n",
              " <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
              " array([[11, 27],\n",
              "        [17, 45],\n",
              "        [23, 63]], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matrix Inversion"
      ],
      "metadata": {
        "id": "VmHEQfX2vs4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix Inversion in Numpy\n",
        "np.linalg.inv(np.array([[4, 2], [-5, -3]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCZxKlMAvq3P",
        "outputId": "577a2df4-fa6b-4714-edb2-bf530cb9be39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.5,  1. ],\n",
              "       [-2.5, -2. ]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix Inversion in PyTorch\n",
        "torch.inverse(torch.tensor([[4, 2], [-5, -3.]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gu_vIeUCvy6W",
        "outputId": "a1746a04-6da9-4628-d190-87b09caaa97c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.5000,  1.0000],\n",
              "        [-2.5000, -2.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix Inversion in TensorFlow\n",
        "tf.linalg.inv(tf.Variable([[4, 2], [-5, -3.]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvzJzugVv4fK",
        "outputId": "75da63bc-8f44-488a-c902-7de4f6323fc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              "array([[ 1.4999998,  0.9999998],\n",
              "       [-2.4999995, -1.9999996]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Eigenvectors"
      ],
      "metadata": {
        "id": "xH6ehFLwk_WT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.array([[-1, 4], [2, -2]])\n",
        "# Returns (a vector of eigenvalues, a matrix of eigenvectors)\n",
        "lambdas, V = np.linalg.eig(A)"
      ],
      "metadata": {
        "id": "Gt2X2eN7lH_D"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "V # each column is a separate eigenvector v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqxhCGuVzMcz",
        "outputId": "3ed71ae4-0d04-40e4-de0a-5637bcfd4c2a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.86011126, -0.76454754],\n",
              "       [ 0.51010647,  0.64456735]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# corresponding eigenvalue for each eigenvector:\n",
        "lambdas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D57YZ-l7zPNY",
        "outputId": "7393d2c8-d284-4d65-c8be-a7c2f8887847"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.37228132, -4.37228132])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Proof Av=λv\n",
        "v = V[:,0]\n",
        "lambduh = lambdas[0]\n",
        "\n",
        "Av = np.dot(A, v)\n",
        "Av, lambduh * v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtHAIhcNzauo",
        "outputId": "5e6676c3-a553-472c-92c4-0a4522460f4b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1.18031462, 0.70000958]), array([1.18031462, 0.70000958]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In Pytorch\n",
        "A_p = torch.tensor([[-1, 4], [2, -2.]]) # must be float for PyTorch eig()\n",
        "A_p"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JN48RikI1Q2z",
        "outputId": "7958e7d2-99e4-499b-b558-cd6402385989"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.,  4.],\n",
              "        [ 2., -2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# outputs complex numbers because real matrices can have complex eigenvectors\n",
        "lambdas_cplx, V_cplx = torch.linalg.eig(A_p)"
      ],
      "metadata": {
        "id": "h9PUrBtF1Wsy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# complex-typed values with \"0.j\" imaginary part are in fact real numbers\n",
        "V_cplx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTWm4JO91bGu",
        "outputId": "cb1f6311-3f9c-4726-eada-f48b31d97071"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.8601+0.j, -0.7645+0.j],\n",
              "        [ 0.5101+0.j,  0.6446+0.j]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "V_p = V_cplx.float()\n",
        "V_p"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwzqGjI61jel",
        "outputId": "346d8980-bd0a-472c-e457-92f6c01e35b0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-1ff842aa4f17>:1: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at ../aten/src/ATen/native/Copy.cpp:299.)\n",
            "  V_p = V_cplx.float()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.8601, -0.7645],\n",
              "        [ 0.5101,  0.6446]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lambdas_p = lambdas_cplx.float()\n",
        "\n",
        "lambdas_cplx, lambdas_p"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7k0GKxH1pUC",
        "outputId": "5e9a96e2-dd2d-47b2-c59a-b021f7728f21"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 1.3723+0.j, -4.3723+0.j]), tensor([ 1.3723, -4.3723]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v_p = V_p[:,0]\n",
        "lambda_p = lambdas_p[0]\n",
        "# Proof\n",
        "torch.matmul(A_p, v_p), lambda_p*v_p"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTga2Tvb1uFd",
        "outputId": "80cc3ed8-38ec-4f2a-8bcc-4e82404cea76"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1.1803, 0.7000]), tensor([1.1803, 0.7000]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Eigenvectors in >2 Dimensions"
      ],
      "metadata": {
        "id": "RfewmeO34iOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[25, 2, 9], [5, 26, -5], [3, 7, -1]])\n",
        "\n",
        "lambdas_X, V_X = np.linalg.eig(X)"
      ],
      "metadata": {
        "id": "M50kpyAW3lXl"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "V_X # one eigenvector per column of X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gVZ8k4W307C",
        "outputId": "7f70e671-342f-497f-9b6a-5d61a6d32589"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.71175736, -0.6501921 , -0.34220476],\n",
              "       [-0.66652125,  0.74464056,  0.23789717],\n",
              "       [-0.22170001,  0.15086635,  0.90901091]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lambdas_X # a corresponding eigenvalue for each eigenvector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obIrsyJs329R",
        "outputId": "a7c1ef9f-4f1e-4628-e4ae-333701c3d294"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([29.67623202, 20.62117365, -0.29740567])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v_X = V_X[:,0]\n",
        "lambda_X = lambdas_X[0]\n",
        "\n",
        "# Proof Xv=λv\n",
        "np.dot(X, v_X), lambda_X * v_X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXKb8I1q4EWc",
        "outputId": "bad1631a-be90-4d11-a270-657e3c623831"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-21.12227645, -19.77983919,  -6.5792208 ]),\n",
              " array([-21.12227645, -19.77983919,  -6.5792208 ]))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matrix Determinants"
      ],
      "metadata": {
        "id": "siemQLQr4cDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[4, 2], [-5, -3]])\n",
        "\n",
        "np.linalg.det(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxyHLfu-4mtb",
        "outputId": "44b74c46-e789-4e6b-9e38-c8422cb763c1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-2.0000000000000013"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N = np.array([[-4, 1], [-8, 2]])\n",
        "\n",
        "np.linalg.det(N)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3V05FKV4wFL",
        "outputId": "79f91c7b-74cf-4d76-c6df-5b359802de46"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Determinants in Pytorch\n",
        "N = torch.tensor([[-4, 1], [-8, 2.]])\n",
        "\n",
        "torch.det(N)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsU20_Y-460m",
        "outputId": "b47f29c9-1b8c-499d-c14c-4eb933a7a355"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Determinants & Eigenvalues\n",
        "# Proof: det(A)= ∏ λ\n",
        "X = np.array([[1, 2, 4], [2, -1, 3], [0, 5, 1]])\n",
        "\n",
        "det = np.linalg.det(X)\n",
        "lambdas, V = np.linalg.eig(X)\n",
        "\n",
        "det, np.product(lambdas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwcVw2nJClkK",
        "outputId": "b3ea0fdc-d0ff-4879-9e18-22082c987e5d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19.999999999999996, 19.99999999999999)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Eigendecomposition\n",
        "\n",
        "\n",
        "$A = V \\Lambda V^{-1}$"
      ],
      "metadata": {
        "id": "rV4pIzRJLpAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.array([[4, 2], [-5, -3]])\n",
        "\n",
        "lambdas, V = np.linalg.eig(A)\n",
        "\n",
        "V"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPAZ8yTxLwny",
        "outputId": "cb893600-544b-4a07-d021-ec6a3f811487"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.70710678, -0.37139068],\n",
              "       [-0.70710678,  0.92847669]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Vinv = np.linalg.inv(V) # V Inverse\n",
        "Vinv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exlDdmL6MDah",
        "outputId": "8cf184fe-1f3d-424b-a325-9f7e4fd710e3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.3570226 , 0.94280904],\n",
              "       [1.79505494, 1.79505494]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Lambda = np.diag(lambdas)\n",
        "lambdas, Lambda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFlR4lxcMGUg",
        "outputId": "345c59f6-377f-4a75-cfff-d1d8d5dccb16"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 2., -1.]),\n",
              " array([[ 2.,  0.],\n",
              "        [ 0., -1.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confirm $A = V \\Lambda V^{-1}$"
      ],
      "metadata": {
        "id": "voqax7rbOGJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.dot(V, np.dot(Lambda, Vinv)), A"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vF7oU9VN8B0",
        "outputId": "7f5df05e-02c5-47b4-9c8c-eb53f2e3fa6a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 4.,  2.],\n",
              "        [-5., -3.]]),\n",
              " array([[ 4,  2],\n",
              "        [-5, -3]]))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With orthogonal matrix\n",
        "\n",
        "$A = Q \\Lambda Q^T$"
      ],
      "metadata": {
        "id": "7klpWTD5O4oj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.array([[2, 1], [1, 2]])\n",
        "\n",
        "lambdas, Q = np.linalg.eig(A)\n",
        "\n",
        "Q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBtvTKSvO8Er",
        "outputId": "32237daf-0c87-4c39-cad4-ad0df2872ca7"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.70710678, -0.70710678],\n",
              "       [ 0.70710678,  0.70710678]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Lambda = np.diag(lambdas)\n",
        "lambdas, Lambda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZBAwUXnPAlo",
        "outputId": "ddf01222-6383-4b91-9338-691018896490"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([3., 1.]),\n",
              " array([[3., 0.],\n",
              "        [0., 1.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Proof\n",
        "np.dot(Q, np.dot(Lambda, Q.T))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dQ8vMKbPCbC",
        "outputId": "5c5bc817-3684-44c2-afdf-268605fa66ac"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2., 1.],\n",
              "       [1., 2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Algebra: Eigendecomposition + Eigenvectors + Matrix Determinants w/ Python"
      ],
      "metadata": {
        "id": "7SoLcUsoSZa-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "\n",
        "# Resouces\n",
        "* [3Blue1Brown: Essence of linear algebra](https://youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)\n",
        "* [Math is fun](https://www.mathsisfun.com)\n",
        "* [Khan Academy](https://www.khanacademy.org/)\n",
        "* [Jon Krohn: Linear Algebra for Machine Learning](https://youtube.com/playlist?list=PLRDl2inPrWQW1QSWhBU0ki-jq_uElkh2a&si=Omg08sWG_CZ-HBrg)"
      ],
      "metadata": {
        "id": "hO6aVIMt58u7"
      }
    }
  ]
}