{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "u0ap0Y0nr8m-",
        "YmGgpU-LsG2m",
        "92HcrfMvAAnZ",
        "-ksKH_UKAIBC",
        "NZueTxW6AIFg",
        "EEA6Fa1PC-GU",
        "WZygPlVj5a9U",
        "9V1D70z63dLj",
        "uRvqO_Tc4vdm",
        "mb7_jN9K3gN1",
        "sNU8KS2131WX",
        "PtJ1MXxG64cP",
        "ZOP0Xd6045Xj",
        "3UIFNF0F47Ci",
        "v3bFS7nz7va9",
        "tMuqIIejCmgf",
        "Ll7RkCdG9ZDZ",
        "o6pyjehC5nr-",
        "3b5D-QPP587x",
        "wDyvkOc7-Vnq",
        "UcixJu9mgo3D"
      ],
      "authorship_tag": "ABX9TyNE56eqHKEtOhSJ4NDMUxMp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cyrus2281/notes/blob/main/Math/Statistics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Contents"
      ],
      "metadata": {
        "id": "7mH0_bADdRR1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oxtbCyieRIjF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">[Contents](#scrollTo=7mH0_bADdRR1)\n",
        "\n",
        ">[Statistics](#scrollTo=eh--wBRornXE)\n",
        "\n",
        ">>[Descriptive Statistics](#scrollTo=u0ap0Y0nr8m-)\n",
        "\n",
        ">>[Inferential Statistics](#scrollTo=YmGgpU-LsG2m)\n",
        "\n",
        ">>[Data](#scrollTo=9V1D70z63dLj)\n",
        "\n",
        ">>>[Data Types](#scrollTo=uRvqO_Tc4vdm)\n",
        "\n",
        ">>>>[Quantitative Data](#scrollTo=mb7_jN9K3gN1)\n",
        "\n",
        ">>>>[Categorical Data](#scrollTo=sNU8KS2131WX)\n",
        "\n",
        ">>>[Binning](#scrollTo=PtJ1MXxG64cP)\n",
        "\n",
        ">>>[Charts](#scrollTo=ZOP0Xd6045Xj)\n",
        "\n",
        ">>>>[Bar Charts](#scrollTo=3UIFNF0F47Ci)\n",
        "\n",
        ">>>>[Histograms](#scrollTo=v3bFS7nz7va9)\n",
        "\n",
        ">>>>[Cumulative Frequency plots](#scrollTo=tMuqIIejCmgf)\n",
        "\n",
        ">>>>[Venn Diagram](#scrollTo=pFXEXD-FQYTM)\n",
        "\n",
        ">>>>[Dot Plot](#scrollTo=Ll7RkCdG9ZDZ)\n",
        "\n",
        ">>>>[Pie Charts](#scrollTo=o6pyjehC5nr-)\n",
        "\n",
        ">>>>[Pictographs](#scrollTo=3b5D-QPP587x)\n",
        "\n",
        ">>>>[Box and Whiskers plots](#scrollTo=wDyvkOc7-Vnq)\n",
        "\n",
        ">>[Measure of Spread](#scrollTo=e3V7c4GRy3iU)\n",
        "\n",
        ">>>[Mean (Average)](#scrollTo=92HcrfMvAAnZ)\n",
        "\n",
        ">>>[Median](#scrollTo=-ksKH_UKAIBC)\n",
        "\n",
        ">>>[Mode](#scrollTo=NZueTxW6AIFg)\n",
        "\n",
        ">>>>[Bimodal](#scrollTo=EEA6Fa1PC-GU)\n",
        "\n",
        ">>>[Frequency](#scrollTo=WZygPlVj5a9U)\n",
        "\n",
        ">>>[Range](#scrollTo=48QbOK-pi_ta)\n",
        "\n",
        ">>>>[Mid-Range](#scrollTo=DEZjmnCokHB1)\n",
        "\n",
        ">>>[InterQuartile Range](#scrollTo=amyYKSLuzUXi)\n",
        "\n",
        ">>>[Outlier](#scrollTo=8NyWTKdibNwG)\n",
        "\n",
        ">>>[Variance](#scrollTo=MV6rxxNKG3IJ)\n",
        "\n",
        ">>>>[Expecation of variance](#scrollTo=AJa-YIpLKtHn)\n",
        "\n",
        ">>>[Standard Deviation](#scrollTo=XIeOyqVtGnwu)\n",
        "\n",
        ">>>[Mean Absolute Deviation (MAD)](#scrollTo=TOf7_s4DltUu)\n",
        "\n",
        ">>>[Skewness](#scrollTo=rZQLfEBSLiq4)\n",
        "\n",
        ">>>[Kurtosis](#scrollTo=TH0fLRDWN81u)\n",
        "\n",
        ">>>[Correlation](#scrollTo=TpG6IoZcOs7b)\n",
        "\n",
        ">>>>[Correlation Coefficient](#scrollTo=MD0DuTQ7QILW)\n",
        "\n",
        ">>>>[Squared Correlation](#scrollTo=skoZ6WeyRHvH)\n",
        "\n",
        ">>>[Z-Score](#scrollTo=2YVGHjFkYQ0N)\n",
        "\n",
        ">>>[Percentiles](#scrollTo=jsmU3S4pZKkl)\n",
        "\n",
        ">>>[Confidence Interval](#scrollTo=ZFwb5UDLjcgJ)\n",
        "\n",
        ">>>[Margin of Error](#scrollTo=fY2UTQ6VrXNk)\n",
        "\n",
        ">>[Distributions](#scrollTo=eerCb1gSBSKR)\n",
        "\n",
        ">>>[Normal Distribution](#scrollTo=P82w9NlgBVFU)\n",
        "\n",
        ">>>>[Central limit theorem](#scrollTo=E7EJicljfmis)\n",
        "\n",
        ">>>>[Standard Error](#scrollTo=93IIAs5lhXg_)\n",
        "\n",
        ">>>>[T-Distribution](#scrollTo=oDO2sbURncmf)\n",
        "\n",
        ">>>[Bimodal Distribution](#scrollTo=aPn4ViLtMN_8)\n",
        "\n",
        ">>>[Binomial Distribution](#scrollTo=XFy1-nTHDcbp)\n",
        "\n",
        ">>>>[Binomial Coefficient](#scrollTo=hck7KKWlFlzh)\n",
        "\n",
        ">>>>[Probability of a binomial coefficient](#scrollTo=zbm2rgtDGasw)\n",
        "\n",
        ">>>[Bernoulli Distribution](#scrollTo=PKyxjSRDJflN)\n",
        "\n",
        ">>>[Geometric Probability Distribution](#scrollTo=EqIkkOMv-sfB)\n",
        "\n",
        ">>>[Chi Square Distribution](#scrollTo=L20IGOPFQ4v7)\n",
        "\n",
        ">>[Inference](#scrollTo=3AxJ-s56Qv0-)\n",
        "\n",
        ">>>[Null Hypothesis Significance Testing (NHST)](#scrollTo=jr4zuaIZRssn)\n",
        "\n",
        ">>>[P-Value](#scrollTo=1Ape6Y7UTPwa)\n",
        "\n",
        ">>[Bias](#scrollTo=C3uKTXKggmmN)\n",
        "\n",
        ">>>[Allocation Bias](#scrollTo=UcixJu9mgo3D)\n",
        "\n",
        ">>>[Selection Bias](#scrollTo=MT5GYoF9gs-5)\n",
        "\n",
        ">>[Anova](#scrollTo=ebIr32MH-CvW)\n",
        "\n",
        ">>>[F-Statistic](#scrollTo=w3xTNg84A29H)\n",
        "\n",
        ">>>[Factorial Anova](#scrollTo=5wdkbWX1-GfB)\n",
        "\n",
        ">[Probability](#scrollTo=yCOk3GoCbD0z)\n",
        "\n",
        ">>[Definitions](#scrollTo=ogMwtqMCz1Bi)\n",
        "\n",
        ">>>[Symbols](#scrollTo=4PXWQfSY6PJ5)\n",
        "\n",
        ">>>[Empirical Probabiliy](#scrollTo=J2EmONgIz2Nt)\n",
        "\n",
        ">>>[Theoretical Probability](#scrollTo=ECMLcAsS0Kck)\n",
        "\n",
        ">>>[Independent](#scrollTo=9hGQSk6h5JoE)\n",
        "\n",
        ">>[Rules & Theories](#scrollTo=iKhpbfAGz-ZO)\n",
        "\n",
        ">>>[Sum Rule](#scrollTo=eNBHdiWO1q5d)\n",
        "\n",
        ">>>[Multiplication Rule](#scrollTo=FVKePYUp1962)\n",
        "\n",
        ">>>[Conditional Probabilites](#scrollTo=iwKV13Kw5h8_)\n",
        "\n",
        ">>>[Bayes' Theorem](#scrollTo=GiDQ16Ui_M7N)\n",
        "\n",
        ">>>>[Bayesian Hypothesis Testing](#scrollTo=hYmgASo2zi-U)\n",
        "\n",
        ">>>>[Bayes Factor](#scrollTo=hZN_do7T0Wnn)\n",
        "\n",
        ">>>[Permutations](#scrollTo=j5kfhAusoyPw)\n",
        "\n",
        ">[Resources](#scrollTo=hO6aVIMt58u7)\n",
        "\n"
      ],
      "metadata": {
        "colab_type": "toc",
        "id": "T35rJt36B2wN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Statistics"
      ],
      "metadata": {
        "id": "eh--wBRornXE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descriptive Statistics\n",
        "\n",
        "> they describe what the data show! Descriptive statistics usually include things like where the middle of the data is, what statisticians call measures of central tendency, and measures of how spread out the data are.\n",
        ">\n",
        "> Describing the data with a smaller set of numbers."
      ],
      "metadata": {
        "id": "u0ap0Y0nr8m-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inferential Statistics\n",
        "\n",
        "> Inferential statistics allows us to make inferences. Inferential statistics allow us to make conclusions that extend beyond the data we have in hand.\n",
        ">\n",
        "> We ask inferential statistics to do all sorts of much more complicated work for us. Inferential statistics let us test an idea or a hypothesis."
      ],
      "metadata": {
        "id": "YmGgpU-LsG2m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "9V1D70z63dLj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Types\n",
        "\n"
      ],
      "metadata": {
        "id": "uRvqO_Tc4vdm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Quantitative Data\n",
        "\n",
        "> Quantits; Numbers that have both order and consistent spacing"
      ],
      "metadata": {
        "id": "mb7_jN9K3gN1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Categorical Data\n",
        "> Doesn't have a meaningful order or consistent spacing."
      ],
      "metadata": {
        "id": "sNU8KS2131WX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Binning\n",
        "> Takes a quantitative variable and bins it into categories that are either pre-existing or made up. For example giving values like low, normal, and high to quantitative values."
      ],
      "metadata": {
        "id": "PtJ1MXxG64cP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Charts"
      ],
      "metadata": {
        "id": "ZOP0Xd6045Xj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bar Charts\n",
        "> Bar charts uses the frequencies\n",
        "\n",
        "![Bar Charts](https://www.mathsisfun.com/data/images/bar-chart-movies.svg)"
      ],
      "metadata": {
        "id": "3UIFNF0F47Ci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Histograms\n",
        "> Squished together bar charts. The data are 'continuous' which means the values in one bar flow into the next bar. There's no separation like in our categorical bar charts.\n",
        ">\n",
        "> A histogram displays numerical data by grouping data into \"bins\" of equal width. Each bin is plotted as a bar whose height corresponds to how many data points are in that bin.\n",
        "Bins are also sometimes called \"intervals\", \"classes\", or \"buckets\".\n",
        "\n",
        "![Histograms](https://www.mathsisfun.com/data/images/histogram-heights.svg)"
      ],
      "metadata": {
        "id": "v3bFS7nz7va9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cumulative Frequency plots\n",
        "> Cumulative frequency plots are like histogram but instead of the height of a bar telling you how much of data is in that specific bin, it tells you how much data is in that bin and all previous bins. That's why it's called \"cumulative\".\n",
        "\n",
        "![Cumulative Frequency plots](https://www150.statcan.gc.ca/n1/edu/power-pouvoir/ch10/img/5214862_02-eng.jpg)0"
      ],
      "metadata": {
        "id": "tMuqIIejCmgf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Venn Diagram\n",
        "\n",
        "A Venn diagram is an illustration that uses circles to show the relationships among things or finite groups of things. Circles that overlap have a commonality while circles that do not overlap do not share those traits. Venn diagrams help to visually represent the similarities and differences between two concepts.\n",
        "\n",
        "![Venn Diagram](https://upload.wikimedia.org/wikipedia/commons/e/e4/Venn_diagram_gr_la_ru.svg)"
      ],
      "metadata": {
        "id": "pFXEXD-FQYTM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dot Plot\n",
        "> A dotplot takes a histogram and replaces the solid bars which use their height to show their frequency with dots. There's one dot for each data point contained in the bar, so we can just count the number of dots to find out how many there are.\n",
        "\n",
        "![Dot Plot](https://www.mathsisfun.com/data/images/dot-plot-b.svg)"
      ],
      "metadata": {
        "id": "Ll7RkCdG9ZDZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pie Charts\n",
        "> Pie charts are used for categorical data\n",
        "\n",
        "![pie charts](https://www.mathsisfun.com/data/images/pie-chart-movies.svg)"
      ],
      "metadata": {
        "id": "o6pyjehC5nr-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pictographs\n",
        "> Pictographs represent frequency with pictures\n",
        "\n",
        "![Pictographs](https://www.mathsisfun.com/data/images/pictograph.svg)"
      ],
      "metadata": {
        "id": "3b5D-QPP587x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Box and Whiskers plots\n",
        "> Box plots use some the our measures of central tendency and spread to visually display our data\n",
        "\n",
        "Whiskers show the minimum and maximum, the box starts with $Q_1$ and ends with $Q_3$ and has a line in middle at median.\n",
        "\n",
        "![Box and Whiskers](https://www150.statcan.gc.ca/edu/power-pouvoir/fig/fig04-5-2-1-eng.png)\n",
        "\n",
        "![Box plots](https://www.simplypsychology.org/wp-content/uploads/compare-boxplots.jpg)\n",
        "\n",
        "![Box plots and skew](https://www.simplypsychology.org/wp-content/uploads/bloxplots-skewed.jpg)"
      ],
      "metadata": {
        "id": "wDyvkOc7-Vnq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Measure of Spread\n",
        "\n"
      ],
      "metadata": {
        "id": "e3V7c4GRy3iU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mean (Average)\n",
        "\n",
        "> The mean (or average, or expectation) takes the sum of all the numbers in a data set, and divides by the number of data points.\n",
        ">\n",
        "> Mean is the the balancing point of a dataset.\n",
        "\n",
        "$$\n",
        "\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n}x_i\n",
        "$$\n",
        "\n",
        "Also notated with $\\mu$.\n",
        "\n",
        "Means changes linearly as the dataset is shifted or scaled."
      ],
      "metadata": {
        "id": "92HcrfMvAAnZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Median\n",
        "\n",
        "> The median is the middle number if we lined up our data from smallest to largest.\n",
        "\n",
        "$$\n",
        "\\text{Median} =\n",
        "\\begin{cases}\n",
        "\\text{middle value}, & \\text{if the number of data points is odd} \\\\\n",
        "\\frac{\\text{sum of the two middle values}}{2}, & \\text{if the number of data points is even}\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "Median changes linearly as the dataset is shifted or scaled."
      ],
      "metadata": {
        "id": "-ksKH_UKAIBC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mode\n",
        "\n",
        "> The value that appears most (the most frequent number) in our data set.\n",
        "\n",
        "$$\n",
        "\\text{Mode} = \\text{value(s) with the highest frequency}\n",
        "$$\n",
        "\n",
        "The mode is most useful when you have a relatively large sample so that you have a large number of the popular values."
      ],
      "metadata": {
        "id": "NZueTxW6AIFg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bimodal\n",
        "\n",
        "> Bimodal data is an example of “Multimodal” data which has many values that are similarly common. Usually multimodal data results from two or more underlying groups all being measured together."
      ],
      "metadata": {
        "id": "EEA6Fa1PC-GU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Frequency\n",
        "> The frequency (f) of a particular value is the number of times the value occurs in the data. The distribution of a variable is the pattern of frequencies, meaning the set of all possible values and the frequencies associated with these values.\n",
        "\n",
        "$$\n",
        "f = \\frac{n}{N}\n",
        "$$"
      ],
      "metadata": {
        "id": "WZygPlVj5a9U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Range\n",
        "\n",
        "> Range tells us how spread apart the numbers are. The range is equal to the difference between the largest and smallest data points in a set of numerical data. The smaller the range is, the tighter the spread is.\n",
        "$$\n",
        "\\text{range}(D) = \\max(D) - \\min(D)\n",
        "$$"
      ],
      "metadata": {
        "id": "48QbOK-pi_ta"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Mid-Range\n",
        "\n",
        "> \"mid-range\" is the average of the biggest number (maximum) and the smallest number (minimum). It's the \"middle of the range\" if all of the numbers were evenly distributed from smallest to largest. mid-range is a measure of central tendency.\n",
        "$$\n",
        "\\text{mid-range}(D) = \\frac{\\max(D) + \\min(D)}{2}\n",
        "$$"
      ],
      "metadata": {
        "id": "DEZjmnCokHB1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### InterQuartile Range\n",
        "\n",
        "> InterQuartile Range (or IQR) doesn’t consider extreme values. The IQR looks at the spread of the middle 50% of your data.\n",
        "For example, in terms of audience, the would be the primary group\n",
        "\n",
        "$$\n",
        "\\text{IQR} = Q_3 - Q_1\n",
        "$$\n",
        "\n",
        "![iqr](https://cdn1.byjus.com/wp-content/uploads/2021/03/interquartile-range.png)\n",
        "\n",
        "\n",
        "IQR remains the same if the dataset is shifted, and it changes linearly as the dataset is scaled."
      ],
      "metadata": {
        "id": "amyYKSLuzUXi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Outlier\n",
        "\n",
        "> An outlier is a data point that's way off of where the other data points are. It's way larger or way smaller than where all of the other data points are.\n",
        "\n",
        "$$\n",
        "\\text{outliers} < Q_1 - 1.5 \\cdot \\text{IQR} \\quad \\quad\n",
        "\\text{outliers} > Q_3 + 1.5 \\cdot \\text{IQR}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "8NyWTKdibNwG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variance\n",
        "\n",
        "> The average of the squared differences from the Mean. Gives us a sense of how spread out the whole dataset is.\n",
        "\n",
        "To calculate the variance follow these steps (On total population)\n",
        "\n",
        "1. Work out the Mean (the simple average of the numbers)\n",
        "2. Then for each number: subtract the Mean and square the result (the squared difference).\n",
        "3. Then work out the average of those squared differences.\n",
        "\n",
        "\n",
        "If measuring on a sample of all data, variance is devided by N-1 while calculating the average\n",
        "\n",
        "**Population** variance:\n",
        "$$\n",
        "\\sigma^2 =\\frac{1}{N}\\sum_{i=1}^{N}(x_{i}-\\mu)^{2} \\\\\n",
        "$$\n",
        "\n",
        "**Sample** variance: (Unbiased)\n",
        "$$\n",
        "\\sigma^2 = \\frac{1}{N-1}\\sum_{i=1}^{N}(x_{i}-\\mu)^{2} \\\\\n",
        "$$\n",
        "\n",
        "Since sample is an estimate of the whole population, we'd have a more accurate result if we divide by one less that the number of the population.\n",
        "\n",
        "Dividing a sample set by n would result in a biased result since variance is not a linear function.\n",
        "\n",
        "Variance remains the same if the dataset is shifted, and it changes linearly as the dataset is scaled."
      ],
      "metadata": {
        "id": "MV6rxxNKG3IJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Expecation of variance\n",
        "\n",
        "> Variance is also an expecation. It tells us how spread out we expect the data to be. Also known as **second moment** of data.\n",
        "\n",
        "$$\n",
        "E(x-\\mu)^2 = \\sum (x-\\mu)^2\n",
        "$$"
      ],
      "metadata": {
        "id": "AJa-YIpLKtHn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Standard Deviation\n",
        "\n",
        "> The average amount we expect a point to differ (or deviate) from the mean. The measure of how spread out numbers are.\n",
        "\n",
        "Its symbol is $\\sigma$ (the greek letter sigma)\n",
        "\n",
        "**Population** Standard Deviation:\n",
        "$$\n",
        "\\sigma = \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N}(x_{i}-\\mu)^{2}}\n",
        "$$\n",
        "\n",
        "**Sample** Standard Deviation: (Unbiased)\n",
        "$$\n",
        "\\sigma = \\sqrt{\\frac{1}{N-1}\\sum_{i=1}^{N}(x_{i}-\\mu)^{2}}\n",
        "$$\n",
        "\n",
        "Standard Deviation remains the same if the dataset is shifted, and it changes linearly as the dataset is scaled."
      ],
      "metadata": {
        "id": "XIeOyqVtGnwu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mean Absolute Deviation (MAD)\n",
        "\n",
        "> Mean absolute deviation (MAD) of a data set is the average distance between each data value and the mean. Mean absolute deviation is a way to describe variation in a data set. Mean absolute deviation helps us get a sense of how \"spread out\" the values in a data set are.\n",
        "$$\n",
        "\\text{MAD} =\\frac{1}{N}\\sum_{i=1}^{N}|x_{i}-\\mu| \\\\\n",
        "$$"
      ],
      "metadata": {
        "id": "TOf7_s4DltUu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Skewness\n",
        "\n",
        "> Tells us whether there are more extreme values on one side. If there are a lot more extreme values smaller than the mean, skewness will tend to be negative. On the other hand, if there are a lot more values bigger than the mean, skewness will tend to be positive.\n",
        "\n",
        "$$\n",
        "\\tilde \\mu_3 = \\frac{\\sum^N_i (X_i-\\bar{X})^3}{(N-1) \\; \\sigma^3}\n",
        "$$\n",
        "\n",
        "\n",
        "$\\tilde {\\mu }_{3}$\t=\tskewness\n",
        "\n",
        "${N}$\t=\tnumber of variables in the distribution\n",
        "\n",
        "$X_{i}$\t=\trandom variable\n",
        "\n",
        "$\\bar{X}$\t=\tmean of the distribution\n",
        "\n",
        "$\\sigma$\t=\tstandard deviation\n"
      ],
      "metadata": {
        "id": "rZQLfEBSLiq4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Kurtosis\n",
        "> The measurement of how thick the tails on a distriubtion are. This tells how common it is to have values that are really far from the mean.\n",
        "\n",
        "$$\n",
        "\\mathrm{Kurt} =\\frac{\\mu_{4}}{\\sigma^{4}}\n",
        "$$\n",
        "\n",
        "$\\mathrm{Kurt}$\t=\tkurtosis\n",
        "\n",
        "$\\mu_{4}$\t=\tfourth central moment\n",
        "\n",
        "$\\sigma^{4}$\t=\tstandard deviation\n"
      ],
      "metadata": {
        "id": "TH0fLRDWN81u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Correlation\n",
        "> Measures the way two variables move together, both the direction and closeness of their movement. Correlation doesn't equal causation."
      ],
      "metadata": {
        "id": "TpG6IoZcOs7b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Correlation Coefficient\n",
        "\n",
        "> We use standard deviations to scale the correlation so that it is always between -1 and 1. This is the correlation coefficient, $r$.\n",
        "\n",
        "$r=1$ means a positive correlation and $r=-1$ means a negative correlation\n",
        "\n",
        "$$\n",
        "r = \\frac{N\\sum{XY}-(\\sum{X}\\sum{Y})}{\\sqrt{ [N \\sum{x^2}-(\\sum{x})^2 ][N \\sum{y^2}-(\\sum{y})^2 }]}\n",
        "$$\n",
        "\n",
        "\n",
        "![correlation](https://d138zd1ktt9iqe.cloudfront.net/media/seo_landing_files/diksha-q-how-to-calculate-correlation-coefficient-01-1609233340.png)"
      ],
      "metadata": {
        "id": "MD0DuTQ7QILW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Squared Correlation\n",
        "\n",
        "> $r^2$ is always between 0 and 1, and tells us, in decimal form, how much of the variance in one variable is predicted by the other. A measure of how accurate our prediction would be.\n",
        "\n",
        "$$\n",
        "R^2 = \\frac{\\text{SSR}}{\\text{SST}} = \\frac{\\sum (\\hat{y_i}-\\bar{y})^2}{\\sum (y_i-\\bar{y})^2}\n",
        "$$\n",
        "\n",
        "$\\hat{y}$ represents the prediction or a point on the regression line, $\\bar{y}$ represents the mean of all the values and $y_i$ represents the actual values or the points."
      ],
      "metadata": {
        "id": "skoZ6WeyRHvH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Z-Score\n",
        "\n",
        "> The distance between the mean of a distribution and a data point in a standard deviation (scaled normalized) distribution is called the z-score. In other words, how many standard deviation away from the mean.\n",
        "$$\n",
        "z = \\frac{x - \\mu}{\\sigma} \\\\\n",
        "$$\n",
        "\n",
        "- A positive z-score means that above the mean.\n",
        "- A negative z-score means that below the mean.\n",
        "- A zero z-score means that equal to the mean."
      ],
      "metadata": {
        "id": "2YVGHjFkYQ0N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Percentiles\n",
        "\n",
        "> Percentiles tell you what percentage of the populcation is at or lower than a score.\n",
        ">\n",
        "> A percentile is a term that describes how a score compares to other scores from the same set.\n",
        "\n",
        "\n",
        "Example:\n",
        "What percentil of the values are below or at 7.\n",
        "\n",
        "$\n",
        "D = \\{ 1, 3, 4, 5, 5, 7, 9, 10, 12, 13 \\} \\\\\n",
        "\\text{percentil}_7 = \\frac{6}{10} = 60^{\\text{th}}\n",
        "$"
      ],
      "metadata": {
        "id": "jsmU3S4pZKkl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confidence Interval\n",
        "\n",
        "> An estimated range of values that seem reasonable based on what we've observed. It's center is still the sample mean, but we've got some room on either side for our uncertainity.\n",
        "Confidence intervals quantify our uncertainity. They also demonstrate the tradeoff of accuracy for precision.\n",
        "\n",
        "The 95% in a 95% confidence itnerval tells us that if we calculated a confidence itnerval from 100 different samples, about 95 of them would contain the true population mean.\n",
        "\n",
        "Our \"confidence\" is in the fact that the procedure of calculating this confidence interval will only exlcude the population mean 5% of the time."
      ],
      "metadata": {
        "id": "ZFwb5UDLjcgJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Margin of Error\n",
        "\n",
        "> The margin or error is usually telling you how far the bounds of the confidence interval are from the mean, and is represented by this part of the confidence interval formula:\n",
        "$$\n",
        "t - \\text{value} \\times \\text{Standard error}\n",
        "$$\n",
        "The margin of error, just like a confidence interval, reflects the uncertainty that surrounds sample estimates of parameters like the mean or a proportion.\n"
      ],
      "metadata": {
        "id": "fY2UTQ6VrXNk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Distributions\n",
        "\n",
        "> A distribution represents all possible values for a set of data, and how often those values occur."
      ],
      "metadata": {
        "id": "eerCb1gSBSKR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normal Distribution\n",
        "\n",
        "> “Normal” means a distribution of data that has roughly the same amount of data on either side of the middle, and has its most common values around the middle of the data. Data that are distributed normally will have a symmetrical bell shape.\n",
        "The fact that the median and mean are the same tells us that the distribution is symmetric: there’s equal amounts of data on either side of the median, and equal amounts on either side of the mean."
      ],
      "metadata": {
        "id": "P82w9NlgBVFU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is often called a \"Bell Curve\" because it looks like a bell.\n",
        "\n",
        "* mean = median = mode\n",
        "* symmetry about the centre\n",
        "* 50% of values less than the mean and 50% greater than the mean\n",
        "\n",
        "It is good to know the standard deviation, because we can say that any value is:\n",
        "\n",
        "* likely to be within 1 standard deviation (68 out of 100 should be)\n",
        "* very likely to be within 2 standard deviations (95 out of 100 should be)\n",
        "* almost certainly within 3 standard deviations (997 out of 1000 should be)\n",
        "\n",
        "The number of standard deviations from the mean is also called the \"Standard Score\", \"sigma\" or \"z-score\".\n",
        "\n",
        "To convert a value to a Standard Score (\"z-score\") (Standardize):\n",
        "1. first subtract the mean,\n",
        "2. then divide by the Standard Deviation\n",
        "$$\n",
        "z = \\frac{x - \\mu }{\\sigma }\n",
        "$$\n",
        "\n",
        "* z is the \"z-score\" (Standard Score)\n",
        "* x is the value to be standardised\n",
        "* μ ('mu\") is the mean\n",
        "* σ (\"sigma\") is the standard deviation"
      ],
      "metadata": {
        "id": "p8WqfAO_PdI1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![normal distribution](https://www.mathsisfun.com/data/images/normal-distrubution-large.svg)\n",
        "\n",
        "Skew\n",
        "![skew](https://upload.wikimedia.org/wikipedia/commons/c/cc/Relationship_between_mean_and_median_under_different_skewness.png)"
      ],
      "metadata": {
        "id": "RKn-k1o1W0I-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Central limit theorem\n",
        "\n",
        "> The distribution of sample means for an independent, random variable, will get closer and closer to a normal distribution as the size of the samples gets bigger and bigger, even if the original population distribution isn't normal itself."
      ],
      "metadata": {
        "id": "E7EJicljfmis"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\sigma_{\\text{sampling distribution}} = \\frac{\\sigma_{\\text{population}}}{\\sqrt{n}}\n",
        "$$"
      ],
      "metadata": {
        "id": "Fhd4GLirh5QZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Standard Error\n",
        "> Standard error tells us the average distance between a sample mean and the true mean of a distribution."
      ],
      "metadata": {
        "id": "93IIAs5lhXg_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### T-Distribution\n",
        "\n",
        "> A continuous probability distribution that's unimodal; It's a useful way to represent sampling distriubtions.\n",
        "The t-distribution changes its shape according to how much information there is. With small sample sizes there’s less information so the t-distribution has thicker tails to represent that our estimates are more uncertain when there’s not much data. However as we get more and more data, the t-distribution becomes identical to the z-distribution.\n",
        "\n",
        "Generally, sample sizes that are greater than 30 are considered “large enough” because scientists generally believe that sampling distributions where the sample is 30+ are close enough to normal...though 30 is an arbitrary cutoff just like 0.05.\n",
        "\n",
        "To convert to a raw score from a t-score:\n",
        "$$\n",
        "mean \\pm t - value \\times \\text{standard error}\n",
        "$$\n",
        "\n",
        "T-Statistics tells us how many standard errros away from the mean our observed difference is.\n",
        "\n",
        "![t-distribution](https://media.geeksforgeeks.org/wp-content/uploads/20230518132346/8-(1)-min.png)"
      ],
      "metadata": {
        "id": "oDO2sbURncmf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bimodal Distribution\n",
        "\n",
        "> A distribution with 2 peeks.\n",
        "\n",
        "Bimodal distributions could be a result of 2 combined unimodals.\n",
        "\n",
        "![bimodal distribution](https://upload.wikimedia.org/wikipedia/commons/e/e2/Bimodal.png)"
      ],
      "metadata": {
        "id": "aPn4ViLtMN_8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Binomial Distribution\n",
        "\n",
        "> Binomial distribution is a statistical probability distribution that states the likelihood that a value will take one of two independent values under a given set of parameters or assumptions.\n",
        "\n",
        "\n",
        "$$\n",
        "\\binom{n}{k} = _nC_k (p) ^k (1-p)^{n-k}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "XFy1-nTHDcbp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Binomial Coefficient\n",
        "> The Binomial Coefficient formula makes it easy for us to find out how many ways a certain ratio of successes to failure, can occur. Binomial coefficients tell us how many ways there are to choose k things out of larger set\n",
        "\n",
        "$$\n",
        "_nC_k \\quad \\text{  or  } \\quad \\binom{n}{k}\n",
        "$$\n",
        "Reads $n$ choose $k$.\n",
        "$$\n",
        "\\binom{n}{k} = \\frac{n!}{k!(n-k)!}\n",
        "$$\n",
        "\n",
        "Example:\n",
        "\n",
        "Imagine you have 5 elements {a, b, c, d, f}. To find out how many different subsets of 2 elements it has, look at the binomial coefficient $_5C_2$\n",
        "$$\n",
        "\\binom{5}{2} = \\frac{5!}{2!(5-2)!}\n",
        "$$"
      ],
      "metadata": {
        "id": "hck7KKWlFlzh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Probability of a binomial coefficient\n",
        "\n",
        "$$\n",
        "\\binom{n}{k} = _nC_k (p) ^k (1-p)^{n-k}\n",
        "$$\n",
        "\n",
        "Example\n",
        "\n",
        "$\n",
        "\\binom{5}{3} = _5C_3 (0.5) ^3 (1-0.5)^{5-3} =  _5C_3 (0.125)(0.25) = _5C_3 (0.031) = 10 (0.031) = 0.31\n",
        "$"
      ],
      "metadata": {
        "id": "zbm2rgtDGasw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bernoulli Distribution\n",
        "\n",
        "> The Bernoulli distribution is a discrete distribution having two possible outcomes labelled by n=0 and n=1 in which n=1 (\"success\") occurs with probability p and n=0 (\"failure\") occurs with probability q=1-p, where 0<p<1.\n",
        "\n",
        "$$\n",
        "P(n)=p^n(1-p)^{1-n}\n",
        "$$\n",
        "\n",
        "![Bernoulli Distribution](https://mathworld.wolfram.com/images/eps-svg/BernoulliDistribution_1000.svg)"
      ],
      "metadata": {
        "id": "PKyxjSRDJflN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Geometric Probability Distribution\n",
        "\n",
        "> Geometric probabilities tell you the probability that your first success will be on your nth try.\n",
        "\n",
        "$$\n",
        "\\text{geom}(k;p) = (1-p)^{k-1}p\n",
        "$$\n",
        "\n",
        "Example: What's the probability of having a red bead on your 5th try from a bag of 5-color-beads. (the first 4 tries are other colors)\n",
        "$$\n",
        "\\text{geom}(5;0.05)=(0.95)^4(0.05)^1 \\approx 4.07\\%\n",
        "$$"
      ],
      "metadata": {
        "id": "EqIkkOMv-sfB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chi Square Distribution\n",
        "\n",
        "> In probability theory and statistics, the chi-squared distribution with k degrees of freedom is the distribution of a sum of the squares of k independent standard normal random variables.\n",
        "\n",
        "**Chi Square:**\n",
        "\n",
        "$$\n",
        "X^2 = \\sum \\frac{(O_i-E_i)^2}{E_i}\n",
        "$$\n",
        "\n",
        "E = Expected value\n",
        "\n",
        "O = Observed value\n",
        "\n",
        "**Probability density function:**\n",
        "\n",
        "$$\n",
        "f(x) = \\begin{cases} \\frac{x^{k/2-1}e^{-x/2}}{2^{k/2}\\Gamma(k/2)} & \\text{for}\\, x \\geq 0 \\\\ 0 & \\text{otherwise} \\end{cases}\n",
        "$$\n",
        "\n",
        "$f(x)$\t=\tprobability density function\n",
        "\n",
        "$k$\t=\tdegrees of freedom\n",
        "\n",
        "$\\Gamma(k/2)$\t=\tgamma function\n",
        "\n",
        "![Chi Square Distribution](https://www.scribbr.com/wp-content/uploads/2022/05/chi-square-distribution-k-example.webp)\n",
        "\n"
      ],
      "metadata": {
        "id": "L20IGOPFQ4v7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference\n",
        "\n",
        "> Statistical inference is the process of using data analysis to infer properties of an underlying distribution of probability."
      ],
      "metadata": {
        "id": "3AxJ-s56Qv0-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Null Hypothesis Significance Testing (NHST)\n",
        "> Null Hypothesis Significance testing is a form of the reductio ad absurdum argument which tries to discredit an idea by assuming the idea is true, and then showing that if you make that assumption, something contradictory happens.\n",
        "\n",
        "In general tests of significance are base on hypothetical probabilities calculated from their null hypothese. They do not generally lead to any probability  statements about the real world, but to a rational and well-defined measure of reluctance to the acceptance of the hypotheses they test.\n",
        "\n",
        "**\"Failing to reject\"** the null hypothesis doesn't mean that there isn't an effect or relationship, it just means we didn't get enough evidence to say there definitely is one."
      ],
      "metadata": {
        "id": "jr4zuaIZRssn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### P-Value\n",
        "\n",
        "> A p-value answers the question of how “rare” your data is by telling you the probability of getting data that’s as extreme as the data you observed if the null hypothesis was true. If your p-value was 0.10 you could say that your sample is in the top 10% most extreme samples we’d expect to see based on the distribution of sample means.\n",
        "\n",
        "$$\n",
        "P ( \\text{data} | \\text{null})\n",
        "$$\n",
        "\n",
        "Probability of the data assuming that the \"null hypothesis\" is true.\n",
        "\n",
        "Arguments have been made that we can have different P-value cutoffs - the alphas - depending on the situation, and that scientists should be allowed to justify their reasosn for picking a certain cutoff."
      ],
      "metadata": {
        "id": "1Ape6Y7UTPwa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bias"
      ],
      "metadata": {
        "id": "C3uKTXKggmmN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Allocation Bias\n",
        "\n",
        "> Allocation bias occurs when there is a systematic difference in how participants are assigned to groups in a trial. The trial is unfair because the groups are not fairly balanced from the outset."
      ],
      "metadata": {
        "id": "UcixJu9mgo3D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selection Bias\n",
        "\n",
        "> Selection bias is a distortion in a measure of association (such as a risk ratio) due to a sample selection that does not accurately reflect the target population."
      ],
      "metadata": {
        "id": "MT5GYoF9gs-5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Anova\n",
        "\n",
        "> **An**alysis **o**f **Va**riance. It's similar to regression expect we're using a categorical variable to predict a continuous one. Like regression, the anova builds a model of how the world works. Anovas allow us to analyze the effect of variables with two or more groups on continuous variables.\n",
        "\n",
        "SST = N x Variance\n",
        "\n",
        "SST = SSR + SSE\n",
        "\n",
        "Data = Model + Error\n",
        "\n",
        "\n",
        "Sums of squares for error: The amount of information that our model doesn't explain."
      ],
      "metadata": {
        "id": "ebIr32MH-CvW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### F-Statistic\n",
        "\n",
        "$$\n",
        "\\text{F-Statistic} : \\frac{\\frac{\\text{SSM}}{df_m}}{\\frac{\\text{SS}}{df_E}} = \\frac{\\text{MSE}_{model}}{\\text{MSE}_{error}}\n",
        "$$"
      ],
      "metadata": {
        "id": "w3xTNg84A29H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Factorial Anova\n",
        "\n",
        "> A factorial anova does almost exactly what a regular anova does; It takes the overall variation - or sums of squares - and portions it out into different categories."
      ],
      "metadata": {
        "id": "5wdkbWX1-GfB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Probability"
      ],
      "metadata": {
        "id": "yCOk3GoCbD0z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definitions"
      ],
      "metadata": {
        "id": "ogMwtqMCz1Bi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Symbols\n",
        "\n",
        "$\n",
        "\\bullet \\quad P: Probability \\\\\n",
        "\\bullet \\quad \\cap: AND \\\\\n",
        "\\bullet \\quad \\cup: OR \\\\\n",
        "$"
      ],
      "metadata": {
        "id": "4PXWQfSY6PJ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Empirical Probabiliy\n",
        "> Something we observe in actual data. Empirical probabilities, like sample statistics, give us a glimpse at the true theoretical probability, but they won’t always be equal to it because of the uncertainty and randomness of any sample."
      ],
      "metadata": {
        "id": "J2EmONgIz2Nt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Theoretical Probability\n",
        "> More of an ideal or a truth out there that we can't directly see.  The empirical probability can be a good estimation of the theoretical one, even if it’s not exact."
      ],
      "metadata": {
        "id": "ECMLcAsS0Kck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Independent\n",
        "> if the probability of one event occurring is not changed by whether or not the second event occurred"
      ],
      "metadata": {
        "id": "9hGQSk6h5JoE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rules & Theories"
      ],
      "metadata": {
        "id": "iKhpbfAGz-ZO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sum Rule\n",
        "$$\n",
        "P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\n",
        "$$"
      ],
      "metadata": {
        "id": "eNBHdiWO1q5d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multiplication Rule\n",
        "$$\n",
        "P(A \\cap B) = P(A) \\times P(B)\n",
        "$$"
      ],
      "metadata": {
        "id": "FVKePYUp1962"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conditional Probabilites\n",
        "\n",
        "> Conditional probabilities tell us the probability of Event 1, given that Event 2 has already happened.\n",
        "\n",
        "$$\n",
        "P(B | A) = \\frac{P( B \\cap A)}{P(A)}\n",
        "$$\n",
        "\n",
        "$A$ happens before $B$"
      ],
      "metadata": {
        "id": "iwKV13Kw5h8_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bayes' Theorem\n",
        "\n",
        "$$\n",
        "P(B|A) = \\frac{P(A|B)P(B)}{P(A)}\n",
        "$$\n",
        "\n",
        "It can also be concluded that: $P(A \\cap B) = P(A|B)P(B)$\n",
        "\n",
        "Bayesian statistics is all about UPDATING your beliefs based on new information"
      ],
      "metadata": {
        "id": "GiDQ16Ui_M7N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bayesian Hypothesis Testing\n",
        "\n",
        "$$\n",
        "P(H_1|X) = P(H_1) \\frac{P(X|H_1)}{P(X)}\n",
        "$$\n",
        "\n",
        "$P(H_1|X)$: Posterior\n",
        "\n",
        "$P(H_1)$: Prior\n",
        "\n",
        "$P(X|H_1)$: Likelihood\n",
        "\n",
        "$P(x)$: Normalization\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hYmgASo2zi-U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bayes Factor\n",
        "\n",
        "$$\n",
        "\\frac{P(H_1|X)}{P(H_2|X)} = \\frac{P(H_1)}{P(H_2)} \\times \\frac{P(X|H_1)}{P(X|H_2)}\n",
        "$$\n",
        "\n",
        "$\\frac{P(H_1|X)}{P(H_2|X)}$: Posterior Odds\n",
        "\n",
        "$\\frac{P(H_1)}{P(H_2)}$: Prior Odds\n",
        "\n",
        "$\\frac{P(X|H_1)}{P(X|H_2)}$: Bayes' Factor\n"
      ],
      "metadata": {
        "id": "hZN_do7T0Wnn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Permutations\n",
        "\n",
        "Ways to arrange thing.\n",
        "\n",
        "$$\n",
        "P(n,r) = _nP_r = \\frac{n!}{(n -r)!}\n",
        "$$\n",
        "\n",
        "$n$: Total number of things\n",
        "\n",
        "$r$: Total number of possible arrangments\n",
        "\n",
        "\n",
        "Example: All possible 3 letter words (does not need to have a meaning)\n",
        "\n",
        "$\n",
        "P(26,3) = \\frac{26!}{(26-3)!} = \\frac{26!}{23!} = 26 \\times 25 \\times 24\n",
        "$"
      ],
      "metadata": {
        "id": "j5kfhAusoyPw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "\n",
        "# Resources\n",
        "* [Crash Course Statistics](https://youtube.com/playlist?list=PL8dPuuaLjXtNM_Y-bUAhblSAdWRnmBUcr)\n",
        "* [Math is fun](https://www.mathsisfun.com)\n",
        "* [LaTex Generator](https://latex.codecogs.com/eqneditor/editor.php)"
      ],
      "metadata": {
        "id": "hO6aVIMt58u7"
      }
    }
  ]
}