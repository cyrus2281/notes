{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOY56wL/AcconXX0w39lclJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cyrus2281/notes/blob/main/MachineLearning/Generative_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Content"
      ],
      "metadata": {
        "id": "9CWyV4beAH0q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">[Content](#scrollTo=9CWyV4beAH0q)\n",
        "\n",
        ">[Generative AI](#scrollTo=d95n8HFhAJ3m)\n",
        "\n",
        ">>[OpenAI](#scrollTo=i4ToZgP9-rIo)\n",
        "\n",
        ">>>[Few shot Prompt](#scrollTo=wW5Py1HkneoI)\n",
        "\n",
        ">>>[Function Calling](#scrollTo=_sHjRxqRu1SE)\n",
        "\n"
      ],
      "metadata": {
        "colab_type": "toc",
        "id": "Hse3FiY9AOWW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generative AI"
      ],
      "metadata": {
        "id": "d95n8HFhAJ3m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAI"
      ],
      "metadata": {
        "id": "i4ToZgP9-rIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "GGsVDqbG-20h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2265dea6-af44-498c-87d3-63dd3130ea90"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "uFIeRudPAEFG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4afebc1-0605-4737-823b-1579201c926f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.14.1\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "print(openai.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key = \"\" # @param {type:\"string\"}"
      ],
      "metadata": {
        "id": "tzaXoSE1IRfR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=openai_api_key)"
      ],
      "metadata": {
        "id": "IEgFPXKt-vpG"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
        "  ], # Roles: system, user, assistant, tool\n",
        "  max_tokens=128, # Maximum number of tokens you want result\n",
        "  temperature=1, # How creative the output should be\n",
        "  n=2 # Number of the outputs\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIo3YSteA1e5",
        "outputId": "b7b96b55-c363-40d6-b49f-71e58ec65000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content='In the realm of code, a concept lives and breathes,\\nWhere functions call themselves, like whispers in the trees.\\nRecursion is the art, a trance-like dance,\\nUnfolding mysteries with each recursive glance.\\n\\nLike a mirror reflecting its own reflection,\\nA function loops back, with no objection.\\nIt breaks down a problem, into smaller parts,\\nAnd solves them one by one, with gentle smarts.\\n\\nA journey through layers, like a dream unfurled,\\nEach invocation a thread in the code world.\\nIt reaches the base case, like a destination,\\nUnwinding the stack, with jubilation.\\n\\nSo embrace recursion, with courage and grace,\\nLet it guide your code through time and space.\\nFor in its elegant cycle, we find our place,\\nA recursive enchantment, woven with grace.', role='assistant', function_call=None, tool_calls=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This is an example of zero shot prompt**"
      ],
      "metadata": {
        "id": "aY6pLUaLpj55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Few shot Prompt\n"
      ],
      "metadata": {
        "id": "wW5Py1HkneoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "person_info=\"My name is Cyrus, I'm a software engineer at X, and I live in Canada.\""
      ],
      "metadata": {
        "id": "lnlScmEgnicb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f'''\n",
        "Extract the following information from the given text and return it as a JSON object:\n",
        "\n",
        "name\n",
        "job\n",
        "company\n",
        "country\n",
        "\n",
        "This is the body of text to extract the information from:\n",
        "{person_info}\n",
        "'''"
      ],
      "metadata": {
        "id": "WTl8OVAen3T1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiR1k8oJoQWx",
        "outputId": "23d7e648-a643-425f-dc32-d24951445fdc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"name\": \"Cyrus\",\n",
            "  \"job\": \"software engineer\",\n",
            "  \"company\": \"X\",\n",
            "  \"country\": \"Canada\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This is an example of few shot prompt**"
      ],
      "metadata": {
        "id": "M86yU2LppbrR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function Calling"
      ],
      "metadata": {
        "id": "_sHjRxqRu1SE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Example dummy function hard coded to return the same weather\n",
        "# In production, this could be your backend API or an external API\n",
        "def get_current_weather(location, unit=\"fahrenheit\"):\n",
        "    \"\"\"Get the current weather in a given location\"\"\"\n",
        "    if \"tokyo\" in location.lower():\n",
        "        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": unit})\n",
        "    elif \"san francisco\" in location.lower():\n",
        "        return json.dumps({\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": unit})\n",
        "    elif \"paris\" in location.lower():\n",
        "        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": unit})\n",
        "    else:\n",
        "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})\n"
      ],
      "metadata": {
        "id": "nOKVKSi1u--n"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: send the conversation and available functions to the model\n",
        "messages = [{\"role\": \"user\", \"content\": \"What's the weather like in San Francisco, Tokyo, and Paris?\"}]\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_current_weather\",\n",
        "            \"description\": \"Get the current weather in a given location\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"location\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
        "                    },\n",
        "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
        "                },\n",
        "                \"required\": [\"location\"],\n",
        "            },\n",
        "        },\n",
        "    }\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo-0125\",\n",
        "    messages=messages,\n",
        "    tools=tools,\n",
        "    tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
        ")\n",
        "response_message = response.choices[0].message\n",
        "tool_calls = response_message.tool_calls"
      ],
      "metadata": {
        "id": "ABv2CX9svGQD"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: check if the model wanted to call a function\n",
        "if tool_calls:\n",
        "    # Step 3: call the function\n",
        "    # Note: the JSON response may not always be valid; be sure to handle errors\n",
        "    available_functions = {\n",
        "        \"get_current_weather\": get_current_weather,\n",
        "    }  # only one function in this example, but you can have multiple\n",
        "    messages.append(response_message)  # extend conversation with assistant's reply\n",
        "    # Step 4: send the info for each function call and function response to the model\n",
        "    for tool_call in tool_calls:\n",
        "        print(tool_call)\n",
        "        function_name = tool_call.function.name\n",
        "        function_to_call = available_functions[function_name]\n",
        "        function_args = json.loads(tool_call.function.arguments)\n",
        "        function_response = function_to_call(\n",
        "            location=function_args.get(\"location\"),\n",
        "            unit=function_args.get(\"unit\"),\n",
        "        )\n",
        "        messages.append(\n",
        "            {\n",
        "                \"tool_call_id\": tool_call.id,\n",
        "                \"role\": \"tool\",\n",
        "                \"name\": function_name,\n",
        "                \"content\": function_response,\n",
        "            }\n",
        "        )  # extend conversation with function response\n",
        "    second_response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo-0125\",\n",
        "        messages=messages,\n",
        "    )  # get a new response from the model where it can see the function response\n",
        "    print(second_response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOO64huru4Eo",
        "outputId": "d3b38c5f-05db-43d7-d320-a7351a0aa7b5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessageToolCall(id='call_Q6tNs8Yd24ROxqmgrMYYYAC1', function=Function(arguments='{\"location\": \"San Francisco\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function')\n",
            "ChatCompletionMessageToolCall(id='call_efCZ1xEyMhMqKCVvFNsU3gax', function=Function(arguments='{\"location\": \"Tokyo\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function')\n",
            "ChatCompletionMessageToolCall(id='call_UgPOHn0Gls5GEtPiNdYlseoB', function=Function(arguments='{\"location\": \"Paris\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function')\n",
            "Currently in San Francisco, the weather is 72°C. In Tokyo, it is 10°C, and in Paris, it is 22°C.\n"
          ]
        }
      ]
    }
  ]
}