{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "collapsed_sections": [
        "Qrmc6aYCmyBE"
      ],
      "authorship_tag": "ABX9TyOmb9kXYLti5fkTturtWlqN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "31ab97db73884279b802cb28597f854c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_83ea4eee162148dea469ec22b6d1b275",
              "IPY_MODEL_71354a94885f4bc0816fba8c827373bd",
              "IPY_MODEL_90762208daa542f3935dbe2549e90f43"
            ],
            "layout": "IPY_MODEL_2cf0fe806ec74d4ca38f71e237d7af8c"
          }
        },
        "83ea4eee162148dea469ec22b6d1b275": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a724b525e98840cd929e54a2fc3110ba",
            "placeholder": "​",
            "style": "IPY_MODEL_5f360f5280bf43e68376ed445a07b067",
            "value": "config.json: 100%"
          }
        },
        "71354a94885f4bc0816fba8c827373bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f761f1c1c4bb451ba9d318261cc33972",
            "max": 662,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af2b9d318404498881e4bbfe0bc03255",
            "value": 662
          }
        },
        "90762208daa542f3935dbe2549e90f43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fc3724136a94b84a9c343160e965867",
            "placeholder": "​",
            "style": "IPY_MODEL_e4ce9cc0e8d046138ddbc983220e3caf",
            "value": " 662/662 [00:00&lt;00:00, 7.68kB/s]"
          }
        },
        "2cf0fe806ec74d4ca38f71e237d7af8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a724b525e98840cd929e54a2fc3110ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f360f5280bf43e68376ed445a07b067": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f761f1c1c4bb451ba9d318261cc33972": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af2b9d318404498881e4bbfe0bc03255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2fc3724136a94b84a9c343160e965867": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4ce9cc0e8d046138ddbc983220e3caf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6e090223748466d900c662e6d060c54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6da618803553499b966c312dc1491989",
              "IPY_MODEL_ea1d91b9a9584cdb922a5e0971cc08a0",
              "IPY_MODEL_334783b8076e49c0a81c415edbe778f1"
            ],
            "layout": "IPY_MODEL_37c511f431f74754bf6058a0dd3f2b2b"
          }
        },
        "6da618803553499b966c312dc1491989": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4aa6d6755b94621a1230d18daf22abb",
            "placeholder": "​",
            "style": "IPY_MODEL_c4503b22420e4317859594ac50db13c4",
            "value": "model.safetensors: 100%"
          }
        },
        "ea1d91b9a9584cdb922a5e0971cc08a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43fb970ef5624a6698203d167c7d6331",
            "max": 3132668804,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d899640d5f414e06b8eefd9802f90806",
            "value": 3132668804
          }
        },
        "334783b8076e49c0a81c415edbe778f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3beccb37c1ee4ade92557e5b794179fd",
            "placeholder": "​",
            "style": "IPY_MODEL_86bfebfe2d0d4476baa19ff64bcd017e",
            "value": " 3.13G/3.13G [00:34&lt;00:00, 121MB/s]"
          }
        },
        "37c511f431f74754bf6058a0dd3f2b2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4aa6d6755b94621a1230d18daf22abb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4503b22420e4317859594ac50db13c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43fb970ef5624a6698203d167c7d6331": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d899640d5f414e06b8eefd9802f90806": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3beccb37c1ee4ade92557e5b794179fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86bfebfe2d0d4476baa19ff64bcd017e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3af5eeaeab4a4d2fa721eb72774835e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b34eb9ade264304823a5abf4a57ce87",
              "IPY_MODEL_2628ef1c25864a3f9aac2411ecac840c",
              "IPY_MODEL_b73289dc59d4419984670acc900eac59"
            ],
            "layout": "IPY_MODEL_91df9796cd7a4a67829ec2fa3232ccec"
          }
        },
        "6b34eb9ade264304823a5abf4a57ce87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cde5b28a46d845a491de5a021f736265",
            "placeholder": "​",
            "style": "IPY_MODEL_61446619d4e14a5d888b14d741c21692",
            "value": "generation_config.json: 100%"
          }
        },
        "2628ef1c25864a3f9aac2411ecac840c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0523ac8d13cf4140a70ab3cb6bc458da",
            "max": 147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df1ef81a0eb84a76bd042f77a40977c0",
            "value": 147
          }
        },
        "b73289dc59d4419984670acc900eac59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ec03853ac8b42228896c35a775f3b6f",
            "placeholder": "​",
            "style": "IPY_MODEL_cc5d6dde52414ba18e89e8f2a519495b",
            "value": " 147/147 [00:00&lt;00:00, 2.87kB/s]"
          }
        },
        "91df9796cd7a4a67829ec2fa3232ccec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cde5b28a46d845a491de5a021f736265": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61446619d4e14a5d888b14d741c21692": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0523ac8d13cf4140a70ab3cb6bc458da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df1ef81a0eb84a76bd042f77a40977c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ec03853ac8b42228896c35a775f3b6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc5d6dde52414ba18e89e8f2a519495b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9475298cfa58414d9e8b61133ff6a7ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a39a243aa03429bbbddb3d33554fb14",
              "IPY_MODEL_47ef6b493cf6414396992e6489b57dfe",
              "IPY_MODEL_5c3e900e036147819899cfb31a4b3b8b"
            ],
            "layout": "IPY_MODEL_88c5af1d05bb4befb65ce9941a060f5c"
          }
        },
        "0a39a243aa03429bbbddb3d33554fb14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4aba50bc42fe4b3b88f2ca9c1b95f012",
            "placeholder": "​",
            "style": "IPY_MODEL_de673b9799c94d588436403033cf0a06",
            "value": "llama-2-13b-chat.Q5_K_M.gguf: 100%"
          }
        },
        "47ef6b493cf6414396992e6489b57dfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22a369b084f146618a174c5e54bd2061",
            "max": 9229924224,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f2c6df2a5a84cd9b982987a3700d29d",
            "value": 9229924224
          }
        },
        "5c3e900e036147819899cfb31a4b3b8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2ea3f101e4b4d519761357c3c43255c",
            "placeholder": "​",
            "style": "IPY_MODEL_a55734deae1b43f7887d9ef536a169f3",
            "value": " 9.23G/9.23G [00:59&lt;00:00, 95.0MB/s]"
          }
        },
        "88c5af1d05bb4befb65ce9941a060f5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4aba50bc42fe4b3b88f2ca9c1b95f012": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de673b9799c94d588436403033cf0a06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22a369b084f146618a174c5e54bd2061": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f2c6df2a5a84cd9b982987a3700d29d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c2ea3f101e4b4d519761357c3c43255c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a55734deae1b43f7887d9ef536a169f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ad01cefe6094addb48c31ec17b3ff9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c89fc33db374be9b2d2ae5c28aa27ab",
              "IPY_MODEL_19554aacc62c432b84fc8826bf03187b",
              "IPY_MODEL_fd5d4e2d81c1498193022318ce5eb2ad"
            ],
            "layout": "IPY_MODEL_c98ee2458ff84e2db4c7952f6be68455"
          }
        },
        "0c89fc33db374be9b2d2ae5c28aa27ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd0d1aab4bb54cb9b69db39dfd6471df",
            "placeholder": "​",
            "style": "IPY_MODEL_a95ebb492d5442df811c5090ae3f9ad5",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "19554aacc62c432b84fc8826bf03187b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03da0c1ec63d40edbe18b1f6a8e6268e",
            "max": 776,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_904de62e67e74a6285cde9dd843ee13f",
            "value": 776
          }
        },
        "fd5d4e2d81c1498193022318ce5eb2ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_717ef9f7b6884bc0932b369425851426",
            "placeholder": "​",
            "style": "IPY_MODEL_af841b98084c45539b404f6beae732fe",
            "value": " 776/776 [00:00&lt;00:00, 28.3kB/s]"
          }
        },
        "c98ee2458ff84e2db4c7952f6be68455": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd0d1aab4bb54cb9b69db39dfd6471df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a95ebb492d5442df811c5090ae3f9ad5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03da0c1ec63d40edbe18b1f6a8e6268e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "904de62e67e74a6285cde9dd843ee13f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "717ef9f7b6884bc0932b369425851426": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af841b98084c45539b404f6beae732fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3377bc33e1a74fd8a75fe212e5fa16ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_22a7e96256a1485ca9bca831a6c72c37",
              "IPY_MODEL_57e4ece7aa8942a98433c148cd94d579",
              "IPY_MODEL_5d52463878e34fd99cc17a1ba384477d"
            ],
            "layout": "IPY_MODEL_88fcb3d99fc141d3a7a92eee63af5835"
          }
        },
        "22a7e96256a1485ca9bca831a6c72c37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe9331421ec643348497a5ef32928d89",
            "placeholder": "​",
            "style": "IPY_MODEL_72be241a59eb47cfa3101474f95d0c80",
            "value": "tokenizer.model: 100%"
          }
        },
        "57e4ece7aa8942a98433c148cd94d579": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61f2312c79034af0bf2a08e4ac454bb3",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_624127ce96b247f7b04521ec451f3539",
            "value": 499723
          }
        },
        "5d52463878e34fd99cc17a1ba384477d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b17b42fd7c7a42deb3903bdea7cb391c",
            "placeholder": "​",
            "style": "IPY_MODEL_468adb776f2d4709b368dbde66936386",
            "value": " 500k/500k [00:00&lt;00:00, 6.46MB/s]"
          }
        },
        "88fcb3d99fc141d3a7a92eee63af5835": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe9331421ec643348497a5ef32928d89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72be241a59eb47cfa3101474f95d0c80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61f2312c79034af0bf2a08e4ac454bb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "624127ce96b247f7b04521ec451f3539": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b17b42fd7c7a42deb3903bdea7cb391c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "468adb776f2d4709b368dbde66936386": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be14f06bde77434b92f72225d60fc137": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bdbf831e1f2e40478d753537305b370c",
              "IPY_MODEL_72c4c6ac886a48f2bbadbaf627048752",
              "IPY_MODEL_9c02f8870d6242ec8bdada2eb8e2cf37"
            ],
            "layout": "IPY_MODEL_9ec1bc80cebd4f7db342b4a9c215a24e"
          }
        },
        "bdbf831e1f2e40478d753537305b370c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f9b65405fa945328fe59f50f7f77c20",
            "placeholder": "​",
            "style": "IPY_MODEL_a59aa85c87aa4fa49b4258fb69769f3b",
            "value": "tokenizer.json: 100%"
          }
        },
        "72c4c6ac886a48f2bbadbaf627048752": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_830a032c4dfd49b8b9088b882638a662",
            "max": 1842767,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8bfa5b3c42fb484b8d7d4f439732ad65",
            "value": 1842767
          }
        },
        "9c02f8870d6242ec8bdada2eb8e2cf37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc5eeb809f3041708ef25f722e74c00d",
            "placeholder": "​",
            "style": "IPY_MODEL_fd17baf92ed1493fa8a3f83e5ba95544",
            "value": " 1.84M/1.84M [00:00&lt;00:00, 7.15MB/s]"
          }
        },
        "9ec1bc80cebd4f7db342b4a9c215a24e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f9b65405fa945328fe59f50f7f77c20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a59aa85c87aa4fa49b4258fb69769f3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "830a032c4dfd49b8b9088b882638a662": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bfa5b3c42fb484b8d7d4f439732ad65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dc5eeb809f3041708ef25f722e74c00d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd17baf92ed1493fa8a3f83e5ba95544": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b17e94c3af2346d88e2dbbc97e3a1eaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e3bd9b7f37fe42699e738ec8063d1fc3",
              "IPY_MODEL_a605f69557d446009475194b62ae2060",
              "IPY_MODEL_e51e5c46d14a4ffe872b9f28dc3d80d9"
            ],
            "layout": "IPY_MODEL_7374f710a79b4f6ca1bff5340d8bc238"
          }
        },
        "e3bd9b7f37fe42699e738ec8063d1fc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d750cacc912b4f368ac87b81ccda4be1",
            "placeholder": "​",
            "style": "IPY_MODEL_7287e6edce384b97974cab51adbe6a04",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "a605f69557d446009475194b62ae2060": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c067d3cc8d941d4bb74f957504fbd1d",
            "max": 414,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_31f37a37192944cfa9fb88015f04c09f",
            "value": 414
          }
        },
        "e51e5c46d14a4ffe872b9f28dc3d80d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fd681a9e62944488fbaf368045a24a7",
            "placeholder": "​",
            "style": "IPY_MODEL_c5324dc3d6ea4b08bacc65930062bcd8",
            "value": " 414/414 [00:00&lt;00:00, 10.7kB/s]"
          }
        },
        "7374f710a79b4f6ca1bff5340d8bc238": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d750cacc912b4f368ac87b81ccda4be1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7287e6edce384b97974cab51adbe6a04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c067d3cc8d941d4bb74f957504fbd1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31f37a37192944cfa9fb88015f04c09f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9fd681a9e62944488fbaf368045a24a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5324dc3d6ea4b08bacc65930062bcd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7f74c8ab34648418fef2eba5d0de7ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bdbe190d3d4f41fba500c1ef4bd4d0dc",
              "IPY_MODEL_7ab6020d76374911a6f9c70bd1447d8b",
              "IPY_MODEL_210bbffb8c474b039492d7d6205ffe40"
            ],
            "layout": "IPY_MODEL_0120a802a7a84634854f3054d33c9c42"
          }
        },
        "bdbe190d3d4f41fba500c1ef4bd4d0dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68cab4488533469b9706921df559f640",
            "placeholder": "​",
            "style": "IPY_MODEL_c2a222f270494b5daaacc3d2045a79bb",
            "value": "config.json: 100%"
          }
        },
        "7ab6020d76374911a6f9c70bd1447d8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d47eec8533634439928e4a61de211144",
            "max": 609,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a55db660d9fd4e6c89f23c9fab5dbba6",
            "value": 609
          }
        },
        "210bbffb8c474b039492d7d6205ffe40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_535cdc3ba82b460f9708ba6327b1d9ae",
            "placeholder": "​",
            "style": "IPY_MODEL_5678dc6dc8bd4dde88e0b32d97cec6f1",
            "value": " 609/609 [00:00&lt;00:00, 32.5kB/s]"
          }
        },
        "0120a802a7a84634854f3054d33c9c42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68cab4488533469b9706921df559f640": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2a222f270494b5daaacc3d2045a79bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d47eec8533634439928e4a61de211144": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a55db660d9fd4e6c89f23c9fab5dbba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "535cdc3ba82b460f9708ba6327b1d9ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5678dc6dc8bd4dde88e0b32d97cec6f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14f1deeee7a843278c9e872b78d738e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d7f129de6cd4e7d8fa67ffbdea352f2",
              "IPY_MODEL_c438d273aa564adead144a56111fc9a3",
              "IPY_MODEL_5c45b5a9c6c942ee971211083f5d6511"
            ],
            "layout": "IPY_MODEL_51ca40a393544a77a2674ac5fd351a38"
          }
        },
        "1d7f129de6cd4e7d8fa67ffbdea352f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7280e66f62e49f580d9fcbafbe4b964",
            "placeholder": "​",
            "style": "IPY_MODEL_e9b0f02f314747b68472090393b1507d",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "c438d273aa564adead144a56111fc9a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb605b7078ab479992160717cf9e9323",
            "max": 26788,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e152a129d4b40d59a5d4ba30a37e2f2",
            "value": 26788
          }
        },
        "5c45b5a9c6c942ee971211083f5d6511": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50b5c0a165934831918592a84e154dd5",
            "placeholder": "​",
            "style": "IPY_MODEL_64c1218247464d98a4cd08fdfac5bae9",
            "value": " 26.8k/26.8k [00:00&lt;00:00, 1.39MB/s]"
          }
        },
        "51ca40a393544a77a2674ac5fd351a38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7280e66f62e49f580d9fcbafbe4b964": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9b0f02f314747b68472090393b1507d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb605b7078ab479992160717cf9e9323": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e152a129d4b40d59a5d4ba30a37e2f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "50b5c0a165934831918592a84e154dd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64c1218247464d98a4cd08fdfac5bae9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "096d9321a7a340cd8c38e93be3c9cc0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb5fda1fb0654542ba9fa8fe4517c97b",
              "IPY_MODEL_c61f881a333144f7accf2bbaf4ffee51",
              "IPY_MODEL_cc3ee1371d36482d9775448ce9cd184f"
            ],
            "layout": "IPY_MODEL_e41918b59b8c4e56bc38ef10af37125c"
          }
        },
        "eb5fda1fb0654542ba9fa8fe4517c97b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1557836a3ead474897b155897b268192",
            "placeholder": "​",
            "style": "IPY_MODEL_4464b318cc1243d69b9b9628b5064064",
            "value": "Downloading shards: 100%"
          }
        },
        "c61f881a333144f7accf2bbaf4ffee51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31d5af25471e49dbad950123ac4c6df8",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a9f8531e55d844fb810e19b030083733",
            "value": 2
          }
        },
        "cc3ee1371d36482d9775448ce9cd184f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e3d161f1de144a7a27344bdf9ca5f76",
            "placeholder": "​",
            "style": "IPY_MODEL_827502d848fa458784b831e9d6e8793f",
            "value": " 2/2 [01:54&lt;00:00, 53.49s/it]"
          }
        },
        "e41918b59b8c4e56bc38ef10af37125c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1557836a3ead474897b155897b268192": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4464b318cc1243d69b9b9628b5064064": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31d5af25471e49dbad950123ac4c6df8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9f8531e55d844fb810e19b030083733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7e3d161f1de144a7a27344bdf9ca5f76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "827502d848fa458784b831e9d6e8793f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0af7243c07340269e0b71ca3583047e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be528ffd28614b248d72cf26f52bb71e",
              "IPY_MODEL_a953545824f448af8432897cec3968fa",
              "IPY_MODEL_cbef3319bfaa4a73a747d56b3ad0fd49"
            ],
            "layout": "IPY_MODEL_571bc7dfb9c14d538063524e8fcf6b7e"
          }
        },
        "be528ffd28614b248d72cf26f52bb71e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_228549e6c8664f62b007035729b4fa64",
            "placeholder": "​",
            "style": "IPY_MODEL_2686798d57e74c67a565255fed662ecd",
            "value": "model-00001-of-00002.safetensors: 100%"
          }
        },
        "a953545824f448af8432897cec3968fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d37b750dd714711b806e67a1268474a",
            "max": 9976578928,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b1e6bc0b85746bb8a192e628ddf717e",
            "value": 9976578928
          }
        },
        "cbef3319bfaa4a73a747d56b3ad0fd49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_279c2f82c21742c4aea1b8a6aa87bd58",
            "placeholder": "​",
            "style": "IPY_MODEL_e6ebdc428ab8467eb8e8859f03ef5257",
            "value": " 9.98G/9.98G [01:19&lt;00:00, 92.7MB/s]"
          }
        },
        "571bc7dfb9c14d538063524e8fcf6b7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "228549e6c8664f62b007035729b4fa64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2686798d57e74c67a565255fed662ecd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d37b750dd714711b806e67a1268474a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b1e6bc0b85746bb8a192e628ddf717e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "279c2f82c21742c4aea1b8a6aa87bd58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6ebdc428ab8467eb8e8859f03ef5257": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fd63e3624544ec68f6b7cfe4c15ec24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c4b4078471f42fab8dbd10bf750bcac",
              "IPY_MODEL_bd0518b12a62452f9a8c610583f72fc1",
              "IPY_MODEL_fac2bb8899b046f2a34c8623cdf75ead"
            ],
            "layout": "IPY_MODEL_7322d152aa3043d4bc9891643dc9ac02"
          }
        },
        "6c4b4078471f42fab8dbd10bf750bcac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1a8ed9d8c5b433bb7981d9042482f60",
            "placeholder": "​",
            "style": "IPY_MODEL_8ee27a186c894b78bd2c3d5c321500be",
            "value": "model-00002-of-00002.safetensors: 100%"
          }
        },
        "bd0518b12a62452f9a8c610583f72fc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3253761249b34778aca53557e4dcd4f1",
            "max": 3500297344,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a92844dbd3843eb824de0635fa8bc45",
            "value": 3500297344
          }
        },
        "fac2bb8899b046f2a34c8623cdf75ead": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f70e78a6f2364a2ca6e9f2b432b37872",
            "placeholder": "​",
            "style": "IPY_MODEL_cfe22643342147eda07789413d78de99",
            "value": " 3.50G/3.50G [00:35&lt;00:00, 144MB/s]"
          }
        },
        "7322d152aa3043d4bc9891643dc9ac02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1a8ed9d8c5b433bb7981d9042482f60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ee27a186c894b78bd2c3d5c321500be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3253761249b34778aca53557e4dcd4f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a92844dbd3843eb824de0635fa8bc45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f70e78a6f2364a2ca6e9f2b432b37872": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfe22643342147eda07789413d78de99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55c257592607455ebfd649c4e03421fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_95e4836fa4d74b51ba4c0ab8fb48f434",
              "IPY_MODEL_1ea2cb9c6dc641f2b8a34810325520da",
              "IPY_MODEL_36cff9ecbffb4fc481f959eaf842e49f"
            ],
            "layout": "IPY_MODEL_60315265a33845289585f51d3c1bf774"
          }
        },
        "95e4836fa4d74b51ba4c0ab8fb48f434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fa6b1f83bc84697aac4a2f121769762",
            "placeholder": "​",
            "style": "IPY_MODEL_d7b9e092a2024bfbac870383b392ea62",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "1ea2cb9c6dc641f2b8a34810325520da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_254eb8994b51406cb5a3d848841be189",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc1254165fa74e178c1dc13e6dac6199",
            "value": 2
          }
        },
        "36cff9ecbffb4fc481f959eaf842e49f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36a64993d2464c15bfc9876ef42ed0ef",
            "placeholder": "​",
            "style": "IPY_MODEL_02a372d8f39e4f35a309b3d053b90d00",
            "value": " 2/2 [01:00&lt;00:00, 27.84s/it]"
          }
        },
        "60315265a33845289585f51d3c1bf774": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fa6b1f83bc84697aac4a2f121769762": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7b9e092a2024bfbac870383b392ea62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "254eb8994b51406cb5a3d848841be189": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc1254165fa74e178c1dc13e6dac6199": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "36a64993d2464c15bfc9876ef42ed0ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02a372d8f39e4f35a309b3d053b90d00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66c650b6e1cb4111aca156f1b5d0954d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b53d4fb423fa4c2da894cd0763a5a3a4",
              "IPY_MODEL_a901b0a8d50d459699b8a88909654c2d",
              "IPY_MODEL_e5b01842a3a54a1e8407d0ad33340d59"
            ],
            "layout": "IPY_MODEL_2c9307e3231e49818c6ce27b07f0a3bb"
          }
        },
        "b53d4fb423fa4c2da894cd0763a5a3a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dc8784fc30a47bcbb7ba7d099c20ec8",
            "placeholder": "​",
            "style": "IPY_MODEL_08e7f300f4fe4dcba6e18f155055523b",
            "value": "generation_config.json: 100%"
          }
        },
        "a901b0a8d50d459699b8a88909654c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb82bbe8020045948e0f15c2c70c1662",
            "max": 188,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5825facf48cf407faa6d68a1bc3fb41f",
            "value": 188
          }
        },
        "e5b01842a3a54a1e8407d0ad33340d59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f805abc759a4a388a2ec7a847223aa5",
            "placeholder": "​",
            "style": "IPY_MODEL_aba8bc42b5034beda172178bbf863f24",
            "value": " 188/188 [00:00&lt;00:00, 10.3kB/s]"
          }
        },
        "2c9307e3231e49818c6ce27b07f0a3bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dc8784fc30a47bcbb7ba7d099c20ec8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08e7f300f4fe4dcba6e18f155055523b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb82bbe8020045948e0f15c2c70c1662": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5825facf48cf407faa6d68a1bc3fb41f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f805abc759a4a388a2ec7a847223aa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aba8bc42b5034beda172178bbf863f24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cyrus2281/notes/blob/main/MachineLearning/Generative_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Content"
      ],
      "metadata": {
        "id": "9CWyV4beAH0q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">[Content](#scrollTo=9CWyV4beAH0q&uniqifier=4)\n",
        "\n",
        ">[Generative AI](#scrollTo=d95n8HFhAJ3m&uniqifier=4)\n",
        "\n",
        ">>[OpenAI](#scrollTo=i4ToZgP9-rIo&uniqifier=4)\n",
        "\n",
        ">>>[Few shot Prompt](#scrollTo=wW5Py1HkneoI&uniqifier=4)\n",
        "\n",
        ">>>[Function Calling](#scrollTo=_sHjRxqRu1SE&uniqifier=4)\n",
        "\n",
        ">>[LangChain](#scrollTo=VaZgHOlOly0L&uniqifier=4)\n",
        "\n",
        ">>>[Prompt Templating](#scrollTo=Qrmc6aYCmyBE&uniqifier=4)\n",
        "\n",
        ">>>[Agents](#scrollTo=OSJlfKhYm05y&uniqifier=4)\n",
        "\n",
        ">>>[Chains](#scrollTo=wZB8-VEzm0qW&uniqifier=4)\n",
        "\n",
        ">>>[Document Loader](#scrollTo=094HkTgJ3LgE&uniqifier=4)\n",
        "\n",
        ">>>[Memory](#scrollTo=1yM7479RABo5&uniqifier=4)\n",
        "\n",
        ">>>>[Conversation Buffer Memory](#scrollTo=xUDLj9bZDX1H&uniqifier=4)\n",
        "\n",
        ">>>>[Conversation Chain](#scrollTo=34Wx_PAVHJZc&uniqifier=4)\n",
        "\n",
        ">>>>[Conversation Buffer Window Memory](#scrollTo=bE0qBhKn1sfW&uniqifier=4)\n",
        "\n",
        ">>[Hugging Face](#scrollTo=4J6b25uaB5TP&uniqifier=4)\n",
        "\n",
        ">>>[Using Models from HuggingFace](#scrollTo=Pq3G4sxRDmAH&uniqifier=4)\n",
        "\n",
        ">>>[Downloading Models Locally](#scrollTo=9VtpZ9UlMPlr&uniqifier=4)\n",
        "\n",
        ">>[Llama](#scrollTo=cIbus3vrIFjB&uniqifier=4)\n",
        "\n",
        ">>>[Llama CPP Python](#scrollTo=KwSz42p_TGN4&uniqifier=4)\n",
        "\n",
        ">>>[Llama with Langchain](#scrollTo=U_LQmLSHMnoO&uniqifier=4)\n",
        "\n",
        ">>[LangGraph](#scrollTo=e7WbSwZe0sd1&uniqifier=4)\n",
        "\n",
        ">>>[Simple Agent](#scrollTo=P5C_c7aBijmC&uniqifier=4)\n",
        "\n",
        ">>>[Agent Executor](#scrollTo=NcVLSks00vwG&uniqifier=4)\n",
        "\n",
        ">>>[Chat Agent Executor](#scrollTo=ZVSc3odHCyAG&uniqifier=4)\n",
        "\n",
        ">>>[Multi-Agent Workflows](#scrollTo=SxZnY3SCO-jU&uniqifier=4)\n",
        "\n",
        ">>>>[Agent Supervisor](#scrollTo=9iMJUxC7A8-C&uniqifier=4)\n",
        "\n",
        ">>>[Persistence and Streaming](#scrollTo=v3u6c2P2knVs&uniqifier=4)\n",
        "\n",
        ">>>[Human in the Loop](#scrollTo=wr0RqaZ-pEGN&uniqifier=4)\n",
        "\n",
        ">>>[Modifying Graph State](#scrollTo=9UJsipiCs5uQ&uniqifier=4)\n",
        "\n",
        ">>[CrewAI](#scrollTo=kyZD8W_RdoXA&uniqifier=4)\n",
        "\n",
        ">>>[Agentic Design Pattern](#scrollTo=MPxfeexmdq3h&uniqifier=4)\n",
        "\n",
        ">>>[Multi-Agent Systems](#scrollTo=4HrBs6wseFgJ&uniqifier=4)\n",
        "\n",
        ">>>>[Article Writer Example](#scrollTo=tGUx0w7JmHsO&uniqifier=4)\n",
        "\n",
        ">>>>[Customer Support Automation Example](#scrollTo=F5HL_6fumNPC&uniqifier=4)\n",
        "\n",
        ">>>[CrewAI Tools](#scrollTo=NVQh0lz0tHFK&uniqifier=4)\n",
        "\n",
        ">[Vector Databases](#scrollTo=3TY5pCv8w-5H&uniqifier=4)\n",
        "\n",
        ">>[Pinecone VectorDB](#scrollTo=fX0221ouxAfx&uniqifier=4)\n",
        "\n",
        ">>>[Creating Embeddings from text chunks](#scrollTo=ChlWuiNPB4er&uniqifier=4)\n",
        "\n",
        ">>>[Querying VectorDB](#scrollTo=WtglMMDjKD-i&uniqifier=4)\n",
        "\n",
        ">>[ChromaDB](#scrollTo=kD8z-5adnZ4T&uniqifier=4)\n",
        "\n",
        ">>>[Creating ChromaDB](#scrollTo=glV_-rzq8mBE&uniqifier=4)\n",
        "\n",
        ">>>[Retrieval](#scrollTo=EtSO9IhK-iZC&uniqifier=4)\n",
        "\n",
        ">>>[Making a Chain](#scrollTo=Rz1W-meADHuS&uniqifier=4)\n",
        "\n",
        ">>>[Removing ChromaDB](#scrollTo=nTnNTxUCHD2o&uniqifier=4)\n",
        "\n",
        ">[Retrieval Augmented Generation (RAG)](#scrollTo=_EuCaWra8AX_&uniqifier=4)\n",
        "\n",
        ">>[RAG with Llama Index](#scrollTo=IPUey0lX9HBq&uniqifier=4)\n",
        "\n",
        ">>>[Agentic RAG](#scrollTo=mwgMyk0s-xnJ&uniqifier=4)\n",
        "\n",
        ">>>[Agent Reasoning Loop](#scrollTo=F9BDdFEmBKB8&uniqifier=4)\n",
        "\n",
        ">>[Evaluating RAG](#scrollTo=-s1Be-b-KktR&uniqifier=4)\n",
        "\n",
        ">>>[RAG Triad of metrics](#scrollTo=VCw8sEvHj6xX&uniqifier=4)\n",
        "\n",
        ">>>[Auto-merging Retrieval](#scrollTo=Ekyk-jRaEiqy&uniqifier=4)\n",
        "\n",
        ">[Serving LLMs](#scrollTo=revomOFbe7lN&uniqifier=4)\n",
        "\n",
        ">>[Text Generation](#scrollTo=TnghqQQsfv96&uniqifier=4)\n",
        "\n",
        ">>>[Optimizing text generation with KV-caching](#scrollTo=1lj8HSS1gwsP&uniqifier=4)\n",
        "\n",
        ">>[Batching](#scrollTo=XxoSxWcQi-wj&uniqifier=4)\n",
        "\n",
        ">>>[Throughput vs Latency](#scrollTo=l5kHfIoDoMwa&uniqifier=4)\n",
        "\n",
        ">>>[Continuous Batching](#scrollTo=M6VLBm8Wtom0&uniqifier=4)\n",
        "\n",
        ">>[Quantization](#scrollTo=MPwF3Y_PV3T0&uniqifier=4)\n",
        "\n",
        ">[Fine-Tuning](#scrollTo=s8tRQu9eS9Yv&uniqifier=4)\n",
        "\n",
        ">>[Parameter-Efficient Fine-Tuning (PEFT)](#scrollTo=-WFpUVghVoad&uniqifier=4)\n",
        "\n",
        ">>[Adapter Tuning](#scrollTo=8T4beGTiWInB&uniqifier=4)\n",
        "\n",
        ">>>[AdapterFusion](#scrollTo=p0rZtDfybRt8&uniqifier=4)\n",
        "\n",
        ">>[Low-Rank Adaptation (LoRA)](#scrollTo=ssTHZig_CFSb&uniqifier=4)\n",
        "\n",
        ">>>[Implementing LoRA](#scrollTo=nUppikWVgfwZ&uniqifier=4)\n",
        "\n",
        ">>>[Implementing Multi-LoRA](#scrollTo=lnFGYyZskYxD&uniqifier=4)\n",
        "\n",
        ">>[Quantization](#scrollTo=c80BXEChZl2h&uniqifier=4)\n",
        "\n",
        ">>>[4-Bit NormalFloat Quantization](#scrollTo=jZARw3V4Z5v3&uniqifier=4)\n",
        "\n",
        ">>>[Quantization and Low Rank Adaptors (QLoRA)](#scrollTo=gqa83-O9gTE_&uniqifier=4)\n",
        "\n",
        ">>>>[Implementation](#scrollTo=xM44VjYlhpRV&uniqifier=4)\n",
        "\n",
        ">>>[Mixed Precision Training](#scrollTo=BE6k_bXIzJ6A&uniqifier=4)\n",
        "\n"
      ],
      "metadata": {
        "colab_type": "toc",
        "id": "Hse3FiY9AOWW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generative AI"
      ],
      "metadata": {
        "id": "d95n8HFhAJ3m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAI"
      ],
      "metadata": {
        "id": "i4ToZgP9-rIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "GGsVDqbG-20h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFIeRudPAEFG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4afebc1-0605-4737-823b-1579201c926f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.14.1\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "print(openai.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key = \"\" # @param {type:\"string\"}"
      ],
      "metadata": {
        "id": "tzaXoSE1IRfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=openai_api_key)"
      ],
      "metadata": {
        "id": "IEgFPXKt-vpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
        "  ], # Roles: system, user, assistant, tool\n",
        "  max_tokens=128, # Maximum number of tokens you want result\n",
        "  temperature=1, # How creative the output should be\n",
        "  n=2 # Number of the outputs\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIo3YSteA1e5",
        "outputId": "b7b96b55-c363-40d6-b49f-71e58ec65000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content='In the realm of code, a concept lives and breathes,\\nWhere functions call themselves, like whispers in the trees.\\nRecursion is the art, a trance-like dance,\\nUnfolding mysteries with each recursive glance.\\n\\nLike a mirror reflecting its own reflection,\\nA function loops back, with no objection.\\nIt breaks down a problem, into smaller parts,\\nAnd solves them one by one, with gentle smarts.\\n\\nA journey through layers, like a dream unfurled,\\nEach invocation a thread in the code world.\\nIt reaches the base case, like a destination,\\nUnwinding the stack, with jubilation.\\n\\nSo embrace recursion, with courage and grace,\\nLet it guide your code through time and space.\\nFor in its elegant cycle, we find our place,\\nA recursive enchantment, woven with grace.', role='assistant', function_call=None, tool_calls=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This is an example of zero shot prompt**"
      ],
      "metadata": {
        "id": "aY6pLUaLpj55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Few shot Prompt\n"
      ],
      "metadata": {
        "id": "wW5Py1HkneoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "person_info=\"My name is Cyrus, I'm a software engineer at X, and I live in Canada.\""
      ],
      "metadata": {
        "id": "lnlScmEgnicb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f'''\n",
        "Extract the following information from the given text and return it as a JSON object:\n",
        "\n",
        "name\n",
        "job\n",
        "company\n",
        "country\n",
        "\n",
        "This is the body of text to extract the information from:\n",
        "{person_info}\n",
        "'''"
      ],
      "metadata": {
        "id": "WTl8OVAen3T1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiR1k8oJoQWx",
        "outputId": "23d7e648-a643-425f-dc32-d24951445fdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"name\": \"Cyrus\",\n",
            "  \"job\": \"software engineer\",\n",
            "  \"company\": \"X\",\n",
            "  \"country\": \"Canada\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This is an example of few shot prompt**"
      ],
      "metadata": {
        "id": "M86yU2LppbrR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function Calling"
      ],
      "metadata": {
        "id": "_sHjRxqRu1SE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Example dummy function hard coded to return the same weather\n",
        "# In production, this could be your backend API or an external API\n",
        "def get_current_weather(location, unit=\"fahrenheit\"):\n",
        "    \"\"\"Get the current weather in a given location\"\"\"\n",
        "    if \"tokyo\" in location.lower():\n",
        "        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": unit})\n",
        "    elif \"san francisco\" in location.lower():\n",
        "        return json.dumps({\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": unit})\n",
        "    elif \"paris\" in location.lower():\n",
        "        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": unit})\n",
        "    else:\n",
        "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})\n"
      ],
      "metadata": {
        "id": "nOKVKSi1u--n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: send the conversation and available functions to the model\n",
        "messages = [{\"role\": \"user\", \"content\": \"What's the weather like in San Francisco, Tokyo, and Paris?\"}]\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_current_weather\",\n",
        "            \"description\": \"Get the current weather in a given location\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"location\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
        "                    },\n",
        "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
        "                },\n",
        "                \"required\": [\"location\"],\n",
        "            },\n",
        "        },\n",
        "    }\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo-0125\",\n",
        "    messages=messages,\n",
        "    tools=tools,\n",
        "    tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
        ")\n",
        "response_message = response.choices[0].message\n",
        "tool_calls = response_message.tool_calls"
      ],
      "metadata": {
        "id": "ABv2CX9svGQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: check if the model wanted to call a function\n",
        "if tool_calls:\n",
        "    # Step 3: call the function\n",
        "    # Note: the JSON response may not always be valid; be sure to handle errors\n",
        "    available_functions = {\n",
        "        \"get_current_weather\": get_current_weather,\n",
        "    }  # only one function in this example, but you can have multiple\n",
        "    messages.append(response_message)  # extend conversation with assistant's reply\n",
        "    # Step 4: send the info for each function call and function response to the model\n",
        "    for tool_call in tool_calls:\n",
        "        print(tool_call)\n",
        "        function_name = tool_call.function.name\n",
        "        function_to_call = available_functions[function_name]\n",
        "        function_args = json.loads(tool_call.function.arguments)\n",
        "        function_response = function_to_call(\n",
        "            location=function_args.get(\"location\"),\n",
        "            unit=function_args.get(\"unit\"),\n",
        "        )\n",
        "        messages.append(\n",
        "            {\n",
        "                \"tool_call_id\": tool_call.id,\n",
        "                \"role\": \"tool\",\n",
        "                \"name\": function_name,\n",
        "                \"content\": function_response,\n",
        "            }\n",
        "        )  # extend conversation with function response\n",
        "    second_response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo-0125\",\n",
        "        messages=messages,\n",
        "    )  # get a new response from the model where it can see the function response\n",
        "    print(second_response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOO64huru4Eo",
        "outputId": "d3b38c5f-05db-43d7-d320-a7351a0aa7b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessageToolCall(id='call_Q6tNs8Yd24ROxqmgrMYYYAC1', function=Function(arguments='{\"location\": \"San Francisco\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function')\n",
            "ChatCompletionMessageToolCall(id='call_efCZ1xEyMhMqKCVvFNsU3gax', function=Function(arguments='{\"location\": \"Tokyo\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function')\n",
            "ChatCompletionMessageToolCall(id='call_UgPOHn0Gls5GEtPiNdYlseoB', function=Function(arguments='{\"location\": \"Paris\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function')\n",
            "Currently in San Francisco, the weather is 72°C. In Tokyo, it is 10°C, and in Paris, it is 22°C.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LangChain"
      ],
      "metadata": {
        "id": "VaZgHOlOly0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "id": "xZHmSegSlwDb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3e86d40-634f-437d-8948-baa58d89c15f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.20)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.6)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.38 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.38)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.52 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.52)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.59)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain) (2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "print(langchain.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RcCAU_3lxwo",
        "outputId": "2d2901b6-c9a5-4eb4-abe6-8ca09319bcb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "client=OpenAI(openai_api_key=openai_api_key)"
      ],
      "metadata": {
        "id": "gzwDMWWJkRwR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5639bda1-4c1c-43d0-e613-948632a6e5a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Zero shot prompting\n",
        "prompt=\"Can you tell me total number of counntries in north america\"\n",
        "print(client.invoke(prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TISsuVVflAZ3",
        "outputId": "9007d70a-d576-43de-b6b8-69b5761c3dda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "There are 23 countries in North America. They are:\n",
            "\n",
            "1. Antigua and Barbuda\n",
            "2. Bahamas\n",
            "3. Barbados\n",
            "4. Belize\n",
            "5. Canada\n",
            "6. Costa Rica\n",
            "7. Cuba\n",
            "8. Dominica\n",
            "9. Dominican Republic\n",
            "10. El Salvador\n",
            "11. Grenada\n",
            "12. Guatemala\n",
            "13. Haiti\n",
            "14. Honduras\n",
            "15. Jamaica\n",
            "16. Mexico\n",
            "17. Nicaragua\n",
            "18. Panama\n",
            "19. Saint Kitts and Nevis\n",
            "20. Saint Lucia\n",
            "21. Saint Vincent and the Grenadines\n",
            "22. Trinidad and Tobago\n",
            "23. United States of America\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompt Templating"
      ],
      "metadata": {
        "id": "Qrmc6aYCmyBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"country\"],\n",
        "    template=\"Can you tell me the capital {country}\"\n",
        ")\n",
        "prompt_template"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYe_bl8wlJ_D",
        "outputId": "c1c90e1f-2e33-4a51-8174-9f1e0ccd8ba9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['country'], template='Can you tell me the capital {country}')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = prompt_template.format(country=\"Canada\")"
      ],
      "metadata": {
        "id": "7jmpqHl4xHDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(client.invoke(prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h72pXwUtxi2k",
        "outputId": "e87371cc-de2e-4bb4-cfe7-73ff888cc94f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "The capital of Canada is Ottawa.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = PromptTemplate.from_template(\"What is the language of {country}\")"
      ],
      "metadata": {
        "id": "WTt4288nx5N6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template.format(country=\"Canada\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5F2a9CoxyEAx",
        "outputId": "129f1bc5-953e-4d40-c5eb-49fd91b836ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What is the language of Canada'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agents\n",
        "\n",
        "Used to call third-party tools"
      ],
      "metadata": {
        "id": "OSJlfKhYm05y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = PromptTemplate.from_template(\"What is the weather in {city} now?\")\n",
        "prompt=prompt_template.format(city=\"Ottawa\")"
      ],
      "metadata": {
        "id": "NItv_FVdxqCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(client.invoke(prompt)) # Not a good answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7uqD_n80LbW",
        "outputId": "0503c606-ee15-406b-eb84-a176286cf4f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "I am an AI and do not have access to real-time weather data. Please check a weather website or app for the current weather in Ottawa.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-search-results"
      ],
      "metadata": {
        "id": "HaXUoHBs0Vo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "serp_api_key = \"\" # @param {type:\"string\"}"
      ],
      "metadata": {
        "id": "djK_ONZ_2Exi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentType, load_tools, initialize_agent"
      ],
      "metadata": {
        "id": "hDttvoWH0tzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tool = load_tools([\"serpapi\"], serpapi_api_key=serp_api_key, llm=client)\n",
        "tool"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwXgMdFr2q0w",
        "outputId": "1ce274b2-4178-44a2-c72f-79ac7ac1be7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Tool(name='Search', description='A search engine. Useful for when you need to answer questions about current events. Input should be a search query.', func=<bound method SerpAPIWrapper.run of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='46f2201c74213cb9e5f88667f9bc98ea9b2ce2343d5cc3a206bc5c67c9c85b33', aiosession=None)>, coroutine=<bound method SerpAPIWrapper.arun of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='46f2201c74213cb9e5f88667f9bc98ea9b2ce2343d5cc3a206bc5c67c9c85b33', aiosession=None)>)]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent=initialize_agent(\n",
        "    tool,\n",
        "    client,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "9mkEsC7X2_0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "m_WVIwuU4GI1",
        "outputId": "0b2c8b2a-fdff-428c-e202-1af26bfad568"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should use the search engine to find the current weather in Ottawa\n",
            "Action: Search\n",
            "Action Input: \"weather in Ottawa\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m{'type': 'weather_result', 'temperature': '33', 'unit': 'Fahrenheit', 'precipitation': '19%', 'humidity': '91%', 'wind': '8 mph', 'location': 'Ottawa, ON, Canada', 'date': 'Tuesday 11:00 PM', 'weather': 'Cloudy'}\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m The current weather in Ottawa is cloudy with a temperature of 33 degrees Fahrenheit.\n",
            "Final Answer: The current weather in Ottawa is cloudy with a temperature of 33 degrees Fahrenheit.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The current weather in Ottawa is cloudy with a temperature of 33 degrees Fahrenheit.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chains\n",
        "\n",
        "Chains refer to sequences of calls - whether to an LLM, a tool, or a data preprocessing step."
      ],
      "metadata": {
        "id": "wZB8-VEzm0qW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "prompt_template1 = PromptTemplate.from_template(\"What is a good name for a {obj} bussiness? (Only one example)\")\n",
        "prompt_template2 = PromptTemplate.from_template(\"Creating a startup with the name {name} , give me ideas?\")"
      ],
      "metadata": {
        "id": "aE8Odg_R9-3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "name_chain = LLMChain(llm=client, prompt=prompt_template1, output_key=\"name\")"
      ],
      "metadata": {
        "id": "3-edf8MhAb8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(name_chain.run(\"flower\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43nqtzUCA99x",
        "outputId": "e217b417-8779-4173-c020-d7acd8f7dd63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"Blooming Blossoms\" \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idea_chain = LLMChain(llm=client, prompt=prompt_template2, output_key=\"ideas\")"
      ],
      "metadata": {
        "id": "s2v2vqiXDiJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SimpleSequentialChain\n",
        "chain=SimpleSequentialChain(chains=[name_chain, idea_chain])"
      ],
      "metadata": {
        "id": "pvHtM5lKDvnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.run(\"flower\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9Q6DXhtD3Cc",
        "outputId": "bfcc7899-3a86-4a45-9feb-1641a89096b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. A unique and personalized floral subscription service, where customers can receive a fresh bouquet of flowers every week or month.\n",
            "\n",
            "2. Offering floral arrangements for special events such as weddings, birthdays, and corporate events.\n",
            "\n",
            "3. Partnering with local businesses to provide floral arrangements for their offices or storefronts.\n",
            "\n",
            "4. Hosting workshops and classes on floral arrangement and design for individuals or groups.\n",
            "\n",
            "5. Developing a line of eco-friendly and sustainable floral products, such as biodegradable flower pots and packaging.\n",
            "\n",
            "6. Providing flower delivery services for last-minute gifts or special occasions.\n",
            "\n",
            "7. Collaborating with local artists to create unique and one-of-a-kind floral art installations for public spaces.\n",
            "\n",
            "8. Offering a selection of dried and preserved flowers for long-lasting home decor.\n",
            "\n",
            "9. Creating a social media presence to showcase the beauty of flowers and engage with customers.\n",
            "\n",
            "10. Partnering with local flower farms to source fresh, locally grown blooms for a farm-to-table approach.\n",
            "\n",
            "11. Developing a line of handmade botanical skincare and wellness products using natural flower essences.\n",
            "\n",
            "12. Expanding into event planning services, offering a full package of floral design, venue decoration, and coordination.\n",
            "\n",
            "13. Creating a loyalty program to reward frequent customers with discounts and special perks.\n",
            "\n",
            "14. Offering a \"flower bar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Alternative syntax**"
      ],
      "metadata": {
        "id": "nNP2DkUzBtKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt_template1 | client\n",
        "\n",
        "print(chain.invoke({\"obj\": \"flower bussiness\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2NBE0aDBD4M",
        "outputId": "8cac257e-fcb8-4b88-c7f7-d95673ec34c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"Petals & Blooms Co.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def str_parser(input):\n",
        "  print(input)\n",
        "  return {\"name\": input}\n",
        "\n",
        "chain = prompt_template1 | client | str_parser | prompt_template2 | client\n",
        "print(chain.invoke({\"obj\": \"flower bussiness\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTHj9tEeEByy",
        "outputId": "e7ea6077-f407-45e9-92c8-b893227d3ee9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"Blooming Oasis Florals\"\n",
            "\n",
            "\n",
            "1. Unique floral arrangements: Offer a variety of unique and creative floral arrangements, such as succulent bouquets, preserved flower displays, and personalized floral designs.\n",
            "\n",
            "2. Subscription services: Provide a subscription service for weekly or monthly flower deliveries to homes and businesses, offering a convenient and cost-effective option for customers.\n",
            "\n",
            "3. Event and wedding services: Partner with event planners and wedding venues to offer floral design services for special occasions, including customized centerpieces, bouquets, and installations.\n",
            "\n",
            "4. Online presence: Create a strong online presence through a website and social media platforms to showcase your work, promote your services, and interact with customers.\n",
            "\n",
            "5. Green and sustainable practices: Promote eco-friendly and sustainable practices, such as using locally sourced flowers and recyclable packaging, to appeal to environmentally conscious customers.\n",
            "\n",
            "6. Collaborations: Collaborate with local businesses, such as cafes and boutiques, to offer floral arrangements for their spaces, creating a mutually beneficial partnership.\n",
            "\n",
            "7. Workshops and classes: Host workshops and classes to teach customers how to create their own floral arrangements and offer team-building events for corporate clients.\n",
            "\n",
            "8. Mobile flower truck: Take your business on the road by converting a truck into a mobile flower shop, allowing you to reach new customers and attend events and markets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sequential Chains"
      ],
      "metadata": {
        "id": "XCI8L81d0L8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SequentialChain\n",
        "\n",
        "chain=SequentialChain(\n",
        "    chains=[name_chain, idea_chain],\n",
        "    input_variables=[\"obj\"],\n",
        "    output_variables=[\"name\", \"ideas\"]\n",
        "    )"
      ],
      "metadata": {
        "id": "3zTJJY1k0K1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain({\"obj\": \"flower\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UM34GHEx04uM",
        "outputId": "11acb812-69ad-4187-f8d4-647a1421575c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'obj': 'flower',\n",
              " 'name': '\\n\\n\"Petals & Blooms Floral Co.\" ',\n",
              " 'ideas': ' \\n\\n1. Online Flower Delivery Service: Offer a convenient and easy way for customers to order and send flowers to their loved ones with same-day delivery options.\\n\\n2. Custom Floral Arrangements: Create unique and personalized floral arrangements for special occasions such as weddings, birthdays, and anniversaries.\\n\\n3. Subscription Services: Offer a subscription service where customers can receive a fresh bouquet of flowers every week or month.\\n\\n4. Event Planning and Decor: Partner with event planners and offer floral decor for weddings, corporate events, and other special occasions.\\n\\n5. Floral Workshops: Host workshops for customers to learn how to create their own floral arrangements and bouquets.\\n\\n6. Greenhouse and Nursery: Have a greenhouse and nursery on-site where customers can purchase plants and flowers for their home or garden.\\n\\n7. Corporate Gifting: Partner with businesses to provide custom floral arrangements for employee recognition, client gifts, and office decor.\\n\\n8. Online Floral Design Courses: Offer online courses for customers to learn the art of floral design and create their own arrangements at home.\\n\\n9. Eco-Friendly Options: Use sustainable and eco-friendly materials for packaging and offer options for customers to recycle or compost their flowers after use.\\n\\n10. Collaborations with Local Artists: Partner with local artists to create unique and one'}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Document Loader"
      ],
      "metadata": {
        "id": "094HkTgJ3LgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf langchain_openai  faiss-cpu"
      ],
      "metadata": {
        "id": "6S31iTBN3Pn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://papers.neurips.cc/paper/7181-attention-is-all-you-need.pdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lkci7D_D4pM7",
        "outputId": "7f18316a-8cce-4547-8259-63fa08a79c33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-21 02:42:10--  https://papers.neurips.cc/paper/7181-attention-is-all-you-need.pdf\n",
            "Resolving papers.neurips.cc (papers.neurips.cc)... 198.202.70.94\n",
            "Connecting to papers.neurips.cc (papers.neurips.cc)|198.202.70.94|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf [following]\n",
            "--2024-03-21 02:42:10--  https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf\n",
            "Resolving proceedings.neurips.cc (proceedings.neurips.cc)... 198.202.70.94\n",
            "Connecting to proceedings.neurips.cc (proceedings.neurips.cc)|198.202.70.94|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 569417 (556K) [application/pdf]\n",
            "Saving to: ‘7181-attention-is-all-you-need.pdf’\n",
            "\n",
            "7181-attention-is-a 100%[===================>] 556.07K  1.69MB/s    in 0.3s    \n",
            "\n",
            "2024-03-21 02:42:11 (1.69 MB/s) - ‘7181-attention-is-all-you-need.pdf’ saved [569417/569417]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"/content/7181-attention-is-all-you-need.pdf\")\n",
        "pages = loader.load_and_split()"
      ],
      "metadata": {
        "id": "jjaTv_s14fNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(pages), pages[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8r8zdgk43CE",
        "outputId": "3843d22c-adce-432a-d08b-c967884d8176"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12,\n",
              " Document(page_content='Attention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.comNoam Shazeer∗\\nGoogle Brain\\nnoam@google.comNiki Parmar∗\\nGoogle Research\\nnikip@google.comJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.comAidan N. Gomez∗†\\nUniversity of Toronto\\naidan@cs.toronto.eduŁukasz Kaiser∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring signiﬁcantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41.0 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature.\\n1 Introduction\\nRecurrent neural networks, long short-term memory [ 12] and gated recurrent [ 7] neural networks\\nin particular, have been ﬁrmly established as state of the art approaches in sequence modeling and\\ntransduction problems such as language modeling and machine translation [ 29,2,5]. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\\narchitectures [31, 21, 13].\\n∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the ﬁrst Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\\nefﬁcient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research.\\n†Work performed while at Google Brain.\\n‡Work performed while at Google Research.\\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.', metadata={'source': '/content/7181-attention-is-all-you-need.pdf', 'page': 0}))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "faiss_index = FAISS.from_documents(pages[0:3], OpenAIEmbeddings(api_key=openai_api_key))"
      ],
      "metadata": {
        "id": "5RZa2_hZ4315"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = faiss_index.similarity_search(\"What is attention?\", k=2)\n",
        "for doc in docs:\n",
        "    print(str(doc.metadata[\"page\"]) + \":\", doc.page_content[:300])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaqX1z0R5PzU",
        "outputId": "9c9ddc95-9782-4456-dff1-18896a3057c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: Attention Is All You Need\n",
            "Ashish Vaswani∗\n",
            "Google Brain\n",
            "avaswani@google.comNoam Shazeer∗\n",
            "Google Brain\n",
            "noam@google.comNiki Parmar∗\n",
            "Google Research\n",
            "nikip@google.comJakob Uszkoreit∗\n",
            "Google Research\n",
            "usz@google.com\n",
            "Llion Jones∗\n",
            "Google Research\n",
            "llion@google.comAidan N. Gomez∗†\n",
            "University of Toronto\n",
            "aidan@c\n",
            "1: Recurrent models typically factor computation along the symbol positions of the input and output\n",
            "sequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\n",
            "statesht, as a function of the previous hidden state ht−1and the input for position t. This inherently\n",
            "s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Memory"
      ],
      "metadata": {
        "id": "1yM7479RABo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "prompt_template = PromptTemplate.from_template(\"What is a good name for a {obj} bussiness? (Only one example)\")"
      ],
      "metadata": {
        "id": "7dk_BQgHBtlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "chain = LLMChain(llm=client, prompt=prompt_template)"
      ],
      "metadata": {
        "id": "IlDyTgOQCLpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(\"AI\").strip()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9XIGaBLnCTar",
        "outputId": "19596f39-ba7a-4cf5-a301-0fc15c0cb061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"Synapse Solutions\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.memory"
      ],
      "metadata": {
        "id": "VMb4uJSiCXJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(chain.memory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0M-9C2MgCtXB",
        "outputId": "0e2f4b92-fa3f-4239-c0cd-e6f1b9bd45a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NoneType"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Conversation Buffer Memory"
      ],
      "metadata": {
        "id": "xUDLj9bZDX1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory()"
      ],
      "metadata": {
        "id": "H9G9Cny2DZ09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manually adding to memory\n",
        "\n",
        "```python\n",
        "memory.chat_memory.add_user_message(\"hi!\")\n",
        "memory.chat_memory.add_ai_message(\"what's up?\")\n",
        "```"
      ],
      "metadata": {
        "id": "uOLXXSULGbUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(llm=client, prompt=prompt_template, memory=memory)"
      ],
      "metadata": {
        "id": "TMJ0urxAGQNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(\"AI\").strip()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0AERpcGdGl41",
        "outputId": "51b12bd9-ccaf-4282-97a2-625d2b75e2bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"NeuroNexus Solutions\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.memory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceEhfhEsGpwr",
        "outputId": "e49229f8-d933-4084-e9e2-59da1e5bec8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConversationBufferMemory(chat_memory=ChatMessageHistory(messages=[HumanMessage(content='AI'), AIMessage(content='\\n\\n\"NeuroNexus Solutions\"')]))"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0bvf3qjG20T",
        "outputId": "1ef5974c-1a55-4602-d46e-c9579ec129f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: AI\n",
            "AI: \n",
            "\n",
            "\"NeuroNexus Solutions\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Conversation Chain\n",
        "\n",
        "Conversation buffer memory goes growing endlessly.\n",
        "\n",
        "Restrict to last 5 conversation chain"
      ],
      "metadata": {
        "id": "34Wx_PAVHJZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationChain\n",
        "from langchain_openai import OpenAI"
      ],
      "metadata": {
        "id": "xkrkvedyG4a4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convo = ConversationChain(llm=OpenAI(openai_api_key=openai_api_key, temperature=0.7))"
      ],
      "metadata": {
        "id": "4mRaPep2yN_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(convo.prompt.template)"
      ],
      "metadata": {
        "id": "17fDiJ21x9Kp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5f41531-495b-4b7d-f6ab-78334a8d17ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "{history}\n",
            "Human: {input}\n",
            "AI:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"Who invented the light bulb?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "euQlvcdkzbk7",
        "outputId": "22b0e0ab-a756-4abe-d3d8-ab057064da92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The light bulb was invented by Thomas Edison in 1879. However, he was not the only person working on this technology at the time. Other inventors like Joseph Swan and Hiram Maxim were also working on improving the design and functionality of the light bulb.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"When did he born?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "SmqvsT9zzpvQ",
        "outputId": "33db61b3-b94a-47d1-9c43-8dde604bbc3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Thomas Edison was born on February 11, 1847 in Milan, Ohio. He was the youngest of seven children and showed an interest in science and technology from a young age.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Conversation Buffer Window Memory\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bE0qBhKn1sfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferWindowMemory"
      ],
      "metadata": {
        "id": "SV3LxDRlz7Gg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory=ConversationBufferWindowMemory(k=1)"
      ],
      "metadata": {
        "id": "CvRBbBWy2SD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convo = ConversationChain(llm=OpenAI(openai_api_key=openai_api_key, temperature=0.7), memory=memory)"
      ],
      "metadata": {
        "id": "I4Zog2WE2ami"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"Who invented the light bulb?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "PKfoI9342fV5",
        "outputId": "89cf197f-8a7c-45da-f9c5-1cebdc15b5bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The light bulb was invented by Thomas Edison in 1879. He experimented with over 6,000 different materials before discovering that carbonized bamboo worked best as a filament.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"What year is today?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bjmITB8m2mjR",
        "outputId": "da79f502-9001-40ca-93f5-9f011db59002"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Today is Monday, December 13, 2021.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"When did he born?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UPcOg3a-2iBM",
        "outputId": "ee95307e-8da0-4674-aabc-6c2d714651d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' I do not have enough information to accurately answer your question. Who are you referring to?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hugging Face"
      ],
      "metadata": {
        "id": "4J6b25uaB5TP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub transformers accelerate bitsandbytes langchain"
      ],
      "metadata": {
        "id": "g3Y6kbhhB6_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gttbGrgCTTE",
        "outputId": "003de5bd-4f32-4867-97d7-0509e8950cff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.13 langchain-community-0.0.29 langchain-core-0.1.33 langchain-text-splitters-0.0.1 langsmith-0.1.31 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.9.15 packaging-23.2 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate, HuggingFaceHub, LLMChain\n",
        "import os"
      ],
      "metadata": {
        "id": "J8jGZNxJCiwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HUGGINGFACEHUB_API_TOKEN = \"\" # @param {type:\"string\"}\n"
      ],
      "metadata": {
        "id": "ABDFJje9Cu50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['HUGGINGFACEHUB_API_TOKEN']=HUGGINGFACEHUB_API_TOKEN"
      ],
      "metadata": {
        "id": "yLX-4sMIDJzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Models from HuggingFace"
      ],
      "metadata": {
        "id": "Pq3G4sxRDmAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"product\"],\n",
        "    template=\"What is a good name for a company that make {product}\"\n",
        ")"
      ],
      "metadata": {
        "id": "DNEAaltpDpSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(\n",
        "    llm=HuggingFaceHub(repo_id=\"google/flan-t5-large\", model_kwargs={'temperature': 0}),\n",
        "    prompt=prompt\n",
        "  )"
      ],
      "metadata": {
        "id": "pPmBiUntEKf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(\"flower\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vjwES_yREe_M",
        "outputId": "8643c442-3982-40ad-8e72-7c3fcdb6073c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'lilies'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading Models Locally"
      ],
      "metadata": {
        "id": "9VtpZ9UlMPlr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFacePipeline\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModelForSeq2SeqLM"
      ],
      "metadata": {
        "id": "w3vYjqsqMUlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id=\"google/flan-t5-large\""
      ],
      "metadata": {
        "id": "2DybuFhXH0Uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ],
      "metadata": {
        "id": "k6NeqlrYMohf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_id, device_map=\"auto\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "31ab97db73884279b802cb28597f854c",
            "83ea4eee162148dea469ec22b6d1b275",
            "71354a94885f4bc0816fba8c827373bd",
            "90762208daa542f3935dbe2549e90f43",
            "2cf0fe806ec74d4ca38f71e237d7af8c",
            "a724b525e98840cd929e54a2fc3110ba",
            "5f360f5280bf43e68376ed445a07b067",
            "f761f1c1c4bb451ba9d318261cc33972",
            "af2b9d318404498881e4bbfe0bc03255",
            "2fc3724136a94b84a9c343160e965867",
            "e4ce9cc0e8d046138ddbc983220e3caf",
            "e6e090223748466d900c662e6d060c54",
            "6da618803553499b966c312dc1491989",
            "ea1d91b9a9584cdb922a5e0971cc08a0",
            "334783b8076e49c0a81c415edbe778f1",
            "37c511f431f74754bf6058a0dd3f2b2b",
            "c4aa6d6755b94621a1230d18daf22abb",
            "c4503b22420e4317859594ac50db13c4",
            "43fb970ef5624a6698203d167c7d6331",
            "d899640d5f414e06b8eefd9802f90806",
            "3beccb37c1ee4ade92557e5b794179fd",
            "86bfebfe2d0d4476baa19ff64bcd017e",
            "3af5eeaeab4a4d2fa721eb72774835e7",
            "6b34eb9ade264304823a5abf4a57ce87",
            "2628ef1c25864a3f9aac2411ecac840c",
            "b73289dc59d4419984670acc900eac59",
            "91df9796cd7a4a67829ec2fa3232ccec",
            "cde5b28a46d845a491de5a021f736265",
            "61446619d4e14a5d888b14d741c21692",
            "0523ac8d13cf4140a70ab3cb6bc458da",
            "df1ef81a0eb84a76bd042f77a40977c0",
            "6ec03853ac8b42228896c35a775f3b6f",
            "cc5d6dde52414ba18e89e8f2a519495b"
          ]
        },
        "id": "-AachrPDMtYP",
        "outputId": "0f273dbb-aa12-4e14-ddff-c545d92da6d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31ab97db73884279b802cb28597f854c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.13G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6e090223748466d900c662e6d060c54"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3af5eeaeab4a4d2fa721eb72774835e7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pline = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, max_length=128)"
      ],
      "metadata": {
        "id": "gFUDZxcEMznE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "local_llm = HuggingFacePipeline(pipeline=pline)"
      ],
      "metadata": {
        "id": "LbxVjo8ONB-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"item\"],\n",
        "    template=\"Tell me about {item}\"\n",
        ")"
      ],
      "metadata": {
        "id": "8nO8RwC_FIgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(llm=local_llm, prompt=prompt)"
      ],
      "metadata": {
        "id": "fkn-Y40PNSng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain(\"Sun\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwgUyZlVNoJs",
        "outputId": "c1fdda49-7d3a-4205-e716-5141e08ef5a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'item': 'Sun',\n",
              " 'text': 'Sun is a constellation in the constellation of Aries.'}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Llama"
      ],
      "metadata": {
        "id": "cIbus3vrIFjB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Llama CPP Python"
      ],
      "metadata": {
        "id": "KwSz42p_TGN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!CMAKE_ARGS=\"-DLLAMA_CUDA=on\" pip install llama-cpp-python"
      ],
      "metadata": {
        "id": "hsojIcPp-94X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'TheBloke/Llama-2-13B-chat-GGUF'\n",
        "model_basename= 'llama-2-13b-chat.Q5_K_M.gguf'"
      ],
      "metadata": {
        "id": "nBgnCtnUA6Mu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "from llama_cpp import Llama"
      ],
      "metadata": {
        "id": "lRY2ijJsB0p9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = hf_hub_download(\n",
        "    repo_id=model_name,\n",
        "    filename=model_basename\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "9475298cfa58414d9e8b61133ff6a7ef",
            "0a39a243aa03429bbbddb3d33554fb14",
            "47ef6b493cf6414396992e6489b57dfe",
            "5c3e900e036147819899cfb31a4b3b8b",
            "88c5af1d05bb4befb65ce9941a060f5c",
            "4aba50bc42fe4b3b88f2ca9c1b95f012",
            "de673b9799c94d588436403033cf0a06",
            "22a369b084f146618a174c5e54bd2061",
            "8f2c6df2a5a84cd9b982987a3700d29d",
            "c2ea3f101e4b4d519761357c3c43255c",
            "a55734deae1b43f7887d9ef536a169f3"
          ]
        },
        "id": "iB3eSu-WB6D3",
        "outputId": "a4ce49a8-689a-4207-f145-77b897020508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "llama-2-13b-chat.Q5_K_M.gguf:   0%|          | 0.00/9.23G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9475298cfa58414d9e8b61133ff6a7ef"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "HMiYUvU2CEnx",
        "outputId": "8dbc2252-44b2-49ee-8619-5ad65f11e9a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGUF/snapshots/4458acc949de0a9914c3eab623904d4fe999050a/llama-2-13b-chat.Q5_K_M.gguf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLuKNbgoC8Bz",
        "outputId": "3c6fa03f-2a8c-4337-8ea8-70a28602433b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Apr  5 03:00:23 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU\n",
        "lcpp_llm = Llama(\n",
        "    model_path=model_path,\n",
        "    n_threads=2, # CPU Cores\n",
        "    n_batch=1024, # Should be between 1 and n_ctx, consider the amount of VRAM in GPU\n",
        "    n_gpu_layers=-1 # Change this value based on your model and your GPU VRAM pool\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iF-MaNMTCgbf",
        "outputId": "a8689234-3db1-4c8f-83b3-97a22f72af31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 19 key-value pairs and 363 tensors from /root/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGUF/snapshots/4458acc949de0a9914c3eab623904d4fe999050a/llama-2-13b-chat.Q5_K_M.gguf (version GGUF V2)\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 5120\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 40\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 13824\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 40\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 40\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 17\n",
            "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   81 tensors\n",
            "llama_model_loader: - type q5_K:  241 tensors\n",
            "llama_model_loader: - type q6_K:   41 tensors\n",
            "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
            "llm_load_print_meta: format           = GGUF V2\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 4096\n",
            "llm_load_print_meta: n_embd           = 5120\n",
            "llm_load_print_meta: n_head           = 40\n",
            "llm_load_print_meta: n_head_kv        = 40\n",
            "llm_load_print_meta: n_layer          = 40\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: n_embd_k_gqa     = 5120\n",
            "llm_load_print_meta: n_embd_v_gqa     = 5120\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 13824\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 13B\n",
            "llm_load_print_meta: model ftype      = Q5_K - Medium\n",
            "llm_load_print_meta: model params     = 13.02 B\n",
            "llm_load_print_meta: model size       = 8.60 GiB (5.67 BPW) \n",
            "llm_load_print_meta: general.name     = LLaMA v2\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.28 MiB\n",
            "llm_load_tensors: offloading 40 repeating layers to GPU\n",
            "llm_load_tensors: offloading non-repeating layers to GPU\n",
            "llm_load_tensors: offloaded 41/41 layers to GPU\n",
            "llm_load_tensors:        CPU buffer size =   107.42 MiB\n",
            "llm_load_tensors:      CUDA0 buffer size =  8694.21 MiB\n",
            "....................................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 512\n",
            "llama_new_context_with_model: n_batch    = 512\n",
            "llama_new_context_with_model: n_ubatch   = 512\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:      CUDA0 KV buffer size =   400.00 MiB\n",
            "llama_new_context_with_model: KV self size  =  400.00 MiB, K (f16):  200.00 MiB, V (f16):  200.00 MiB\n",
            "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.12 MiB\n",
            "llama_new_context_with_model:      CUDA0 compute buffer size =    85.00 MiB\n",
            "llama_new_context_with_model:  CUDA_Host compute buffer size =    11.01 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1286\n",
            "llama_new_context_with_model: graph splits = 2\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n",
            "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '5120', 'llama.feed_forward_length': '13824', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '40', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '40', 'llama.attention.head_count_kv': '40', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '17'}\n",
            "Using fallback chat format: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"Write a linear regression code\"\n",
        "prompt_template=f'''SYSTEM: You are a helpful assistant.\n",
        "\n",
        "USER: {prompt}\n",
        "\n",
        "ASSISTANT:\n",
        "'''\n",
        "\n",
        "print(prompt_template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IMZwZY_Duzu",
        "outputId": "64cc22dd-22bc-4b51-bd85-7bf1412f717d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SYSTEM: You are a helpful assistant.\n",
            "\n",
            "USER: Write a linear regression code\n",
            "\n",
            "ASSISTANT:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = lcpp_llm(\n",
        "    prompt=prompt_template,\n",
        "    max_tokens=256,\n",
        "    temperature=0.5,\n",
        "    top_p=0.95,\n",
        "    repeat_penalty=1.2,\n",
        "    top_k=150,\n",
        "    echo=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rZkQQw5GsbV",
        "outputId": "5207fcb6-2401-418a-c406-d705d2e076fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     892.48 ms\n",
            "llama_print_timings:      sample time =     156.96 ms /   256 runs   (    0.61 ms per token,  1631.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =     892.37 ms /    27 tokens (   33.05 ms per token,    30.26 tokens per second)\n",
            "llama_print_timings:        eval time =   12067.04 ms /   255 runs   (   47.32 ms per token,    21.13 tokens per second)\n",
            "llama_print_timings:       total time =   13926.02 ms /   282 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9YkQavvG5aO",
        "outputId": "20b84e61-55f6-42ab-c1cb-19a56d0c8a58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 'cmpl-2d9e8f48-31fa-40b8-8071-68055287c39b',\n",
              " 'object': 'text_completion',\n",
              " 'created': 1712286064,\n",
              " 'model': '/root/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGUF/snapshots/4458acc949de0a9914c3eab623904d4fe999050a/llama-2-13b-chat.Q5_K_M.gguf',\n",
              " 'choices': [{'text': 'SYSTEM: You are a helpful assistant.\\n\\nUSER: Write a linear regression code\\n\\nASSISTANT:\\n\\nHere is an example of how you could write a linear regression code in Python using scikit-learn library:\\n```\\nimport pandas as pd\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn.model_selection import train_test_split\\n\\n# Load the data\\ndf = pd.read_csv(\\'data.csv\\')\\n\\n# Split the data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(df.drop(\\'target\\', axis=1), df[\\'target\\'], test_size=0.2)\\n\\n# Create a linear regression object and fit it to the training data\\nreg = LinearRegression()\\nreg.fit(X_train, y_train)\\n\\n# Make predictions on the testing data\\ny_pred = reg.predict(X_test)\\n\\n# Evaluate the model using mean squared error\\nmse = ((y_test - y_pred) ** 2).mean()\\nprint(\\'Mean squared error:\\', mse)\\n```\\nThis code assumes that you have a CSV file called \"data.csv\" containing the data, with',\n",
              "   'index': 0,\n",
              "   'logprobs': None,\n",
              "   'finish_reason': 'length'}],\n",
              " 'usage': {'prompt_tokens': 27, 'completion_tokens': 256, 'total_tokens': 283}}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response['choices'][0]['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDDoW_myJkIq",
        "outputId": "83fe3e0a-dc83-40c1-9495-4a982eda880b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SYSTEM: You are a helpful assistant.\n",
            "\n",
            "USER: Write a linear regression code\n",
            "\n",
            "ASSISTANT:\n",
            "\n",
            "Here is an example of how you could write a linear regression code in Python using scikit-learn library:\n",
            "```\n",
            "import pandas as pd\n",
            "from sklearn.linear_model import LinearRegression\n",
            "from sklearn.model_selection import train_test_split\n",
            "\n",
            "# Load the data\n",
            "df = pd.read_csv('data.csv')\n",
            "\n",
            "# Split the data into training and testing sets\n",
            "X_train, X_test, y_train, y_test = train_test_split(df.drop('target', axis=1), df['target'], test_size=0.2)\n",
            "\n",
            "# Create a linear regression object and fit it to the training data\n",
            "reg = LinearRegression()\n",
            "reg.fit(X_train, y_train)\n",
            "\n",
            "# Make predictions on the testing data\n",
            "y_pred = reg.predict(X_test)\n",
            "\n",
            "# Evaluate the model using mean squared error\n",
            "mse = ((y_test - y_pred) ** 2).mean()\n",
            "print('Mean squared error:', mse)\n",
            "```\n",
            "This code assumes that you have a CSV file called \"data.csv\" containing the data, with\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Llama with Langchain"
      ],
      "metadata": {
        "id": "U_LQmLSHMnoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers einops accelerate langchain bitsandbytes"
      ],
      "metadata": {
        "id": "XUD4jbMrMqHs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41ca29d7-c448-4e7f-b818-6330c4d79a9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.2/121.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkJEulaVNSRZ",
        "outputId": "ccdd89ce-605e-4ba2-d5ff-4b443b25146e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFacePipeline\n",
        "from transformers import AutoTokenizer\n",
        "import transformers\n",
        "import torch"
      ],
      "metadata": {
        "id": "fR9cmUEwNUiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=\"meta-llama/Llama-2-7b-hf\""
      ],
      "metadata": {
        "id": "UqGr6-rhN8FN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=AutoTokenizer.from_pretrained(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269,
          "referenced_widgets": [
            "7ad01cefe6094addb48c31ec17b3ff9b",
            "0c89fc33db374be9b2d2ae5c28aa27ab",
            "19554aacc62c432b84fc8826bf03187b",
            "fd5d4e2d81c1498193022318ce5eb2ad",
            "c98ee2458ff84e2db4c7952f6be68455",
            "bd0d1aab4bb54cb9b69db39dfd6471df",
            "a95ebb492d5442df811c5090ae3f9ad5",
            "03da0c1ec63d40edbe18b1f6a8e6268e",
            "904de62e67e74a6285cde9dd843ee13f",
            "717ef9f7b6884bc0932b369425851426",
            "af841b98084c45539b404f6beae732fe",
            "3377bc33e1a74fd8a75fe212e5fa16ac",
            "22a7e96256a1485ca9bca831a6c72c37",
            "57e4ece7aa8942a98433c148cd94d579",
            "5d52463878e34fd99cc17a1ba384477d",
            "88fcb3d99fc141d3a7a92eee63af5835",
            "fe9331421ec643348497a5ef32928d89",
            "72be241a59eb47cfa3101474f95d0c80",
            "61f2312c79034af0bf2a08e4ac454bb3",
            "624127ce96b247f7b04521ec451f3539",
            "b17b42fd7c7a42deb3903bdea7cb391c",
            "468adb776f2d4709b368dbde66936386",
            "be14f06bde77434b92f72225d60fc137",
            "bdbf831e1f2e40478d753537305b370c",
            "72c4c6ac886a48f2bbadbaf627048752",
            "9c02f8870d6242ec8bdada2eb8e2cf37",
            "9ec1bc80cebd4f7db342b4a9c215a24e",
            "3f9b65405fa945328fe59f50f7f77c20",
            "a59aa85c87aa4fa49b4258fb69769f3b",
            "830a032c4dfd49b8b9088b882638a662",
            "8bfa5b3c42fb484b8d7d4f439732ad65",
            "dc5eeb809f3041708ef25f722e74c00d",
            "fd17baf92ed1493fa8a3f83e5ba95544",
            "b17e94c3af2346d88e2dbbc97e3a1eaa",
            "e3bd9b7f37fe42699e738ec8063d1fc3",
            "a605f69557d446009475194b62ae2060",
            "e51e5c46d14a4ffe872b9f28dc3d80d9",
            "7374f710a79b4f6ca1bff5340d8bc238",
            "d750cacc912b4f368ac87b81ccda4be1",
            "7287e6edce384b97974cab51adbe6a04",
            "1c067d3cc8d941d4bb74f957504fbd1d",
            "31f37a37192944cfa9fb88015f04c09f",
            "9fd681a9e62944488fbaf368045a24a7",
            "c5324dc3d6ea4b08bacc65930062bcd8"
          ]
        },
        "id": "InK-cdDjOH1P",
        "outputId": "f36ada80-65e5-44d2-ffd2-4afb7bc8a556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ad01cefe6094addb48c31ec17b3ff9b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3377bc33e1a74fd8a75fe212e5fa16ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be14f06bde77434b92f72225d60fc137"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b17e94c3af2346d88e2dbbc97e3a1eaa"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline=transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    trust_remote_code=True,\n",
        "    device_map=\"auto\",\n",
        "    max_length=1000,\n",
        "    do_sample=True,\n",
        "    top_k=10,\n",
        "    num_return_sequences=1,\n",
        "    eos_token_id=tokenizer.eos_token_id\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "d7f74c8ab34648418fef2eba5d0de7ff",
            "bdbe190d3d4f41fba500c1ef4bd4d0dc",
            "7ab6020d76374911a6f9c70bd1447d8b",
            "210bbffb8c474b039492d7d6205ffe40",
            "0120a802a7a84634854f3054d33c9c42",
            "68cab4488533469b9706921df559f640",
            "c2a222f270494b5daaacc3d2045a79bb",
            "d47eec8533634439928e4a61de211144",
            "a55db660d9fd4e6c89f23c9fab5dbba6",
            "535cdc3ba82b460f9708ba6327b1d9ae",
            "5678dc6dc8bd4dde88e0b32d97cec6f1",
            "14f1deeee7a843278c9e872b78d738e7",
            "1d7f129de6cd4e7d8fa67ffbdea352f2",
            "c438d273aa564adead144a56111fc9a3",
            "5c45b5a9c6c942ee971211083f5d6511",
            "51ca40a393544a77a2674ac5fd351a38",
            "c7280e66f62e49f580d9fcbafbe4b964",
            "e9b0f02f314747b68472090393b1507d",
            "bb605b7078ab479992160717cf9e9323",
            "5e152a129d4b40d59a5d4ba30a37e2f2",
            "50b5c0a165934831918592a84e154dd5",
            "64c1218247464d98a4cd08fdfac5bae9",
            "096d9321a7a340cd8c38e93be3c9cc0e",
            "eb5fda1fb0654542ba9fa8fe4517c97b",
            "c61f881a333144f7accf2bbaf4ffee51",
            "cc3ee1371d36482d9775448ce9cd184f",
            "e41918b59b8c4e56bc38ef10af37125c",
            "1557836a3ead474897b155897b268192",
            "4464b318cc1243d69b9b9628b5064064",
            "31d5af25471e49dbad950123ac4c6df8",
            "a9f8531e55d844fb810e19b030083733",
            "7e3d161f1de144a7a27344bdf9ca5f76",
            "827502d848fa458784b831e9d6e8793f",
            "a0af7243c07340269e0b71ca3583047e",
            "be528ffd28614b248d72cf26f52bb71e",
            "a953545824f448af8432897cec3968fa",
            "cbef3319bfaa4a73a747d56b3ad0fd49",
            "571bc7dfb9c14d538063524e8fcf6b7e",
            "228549e6c8664f62b007035729b4fa64",
            "2686798d57e74c67a565255fed662ecd",
            "8d37b750dd714711b806e67a1268474a",
            "4b1e6bc0b85746bb8a192e628ddf717e",
            "279c2f82c21742c4aea1b8a6aa87bd58",
            "e6ebdc428ab8467eb8e8859f03ef5257",
            "8fd63e3624544ec68f6b7cfe4c15ec24",
            "6c4b4078471f42fab8dbd10bf750bcac",
            "bd0518b12a62452f9a8c610583f72fc1",
            "fac2bb8899b046f2a34c8623cdf75ead",
            "7322d152aa3043d4bc9891643dc9ac02",
            "b1a8ed9d8c5b433bb7981d9042482f60",
            "8ee27a186c894b78bd2c3d5c321500be",
            "3253761249b34778aca53557e4dcd4f1",
            "0a92844dbd3843eb824de0635fa8bc45",
            "f70e78a6f2364a2ca6e9f2b432b37872",
            "cfe22643342147eda07789413d78de99",
            "55c257592607455ebfd649c4e03421fa",
            "95e4836fa4d74b51ba4c0ab8fb48f434",
            "1ea2cb9c6dc641f2b8a34810325520da",
            "36cff9ecbffb4fc481f959eaf842e49f",
            "60315265a33845289585f51d3c1bf774",
            "3fa6b1f83bc84697aac4a2f121769762",
            "d7b9e092a2024bfbac870383b392ea62",
            "254eb8994b51406cb5a3d848841be189",
            "bc1254165fa74e178c1dc13e6dac6199",
            "36a64993d2464c15bfc9876ef42ed0ef",
            "02a372d8f39e4f35a309b3d053b90d00",
            "66c650b6e1cb4111aca156f1b5d0954d",
            "b53d4fb423fa4c2da894cd0763a5a3a4",
            "a901b0a8d50d459699b8a88909654c2d",
            "e5b01842a3a54a1e8407d0ad33340d59",
            "2c9307e3231e49818c6ce27b07f0a3bb",
            "7dc8784fc30a47bcbb7ba7d099c20ec8",
            "08e7f300f4fe4dcba6e18f155055523b",
            "cb82bbe8020045948e0f15c2c70c1662",
            "5825facf48cf407faa6d68a1bc3fb41f",
            "6f805abc759a4a388a2ec7a847223aa5",
            "aba8bc42b5034beda172178bbf863f24"
          ]
        },
        "id": "EC-JRg2oPfI3",
        "outputId": "b3004abf-2d6c-4556-c829-ff7eeca6bbe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/609 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7f74c8ab34648418fef2eba5d0de7ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "14f1deeee7a843278c9e872b78d738e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "096d9321a7a340cd8c38e93be3c9cc0e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a0af7243c07340269e0b71ca3583047e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8fd63e3624544ec68f6b7cfe4c15ec24"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "55c257592607455ebfd649c4e03421fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66c650b6e1cb4111aca156f1b5d0954d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This LLM can be used with all other langchain functions\n",
        "llm=HuggingFacePipeline(pipeline=pipeline, model_kwargs={'temperature':0})"
      ],
      "metadata": {
        "id": "iGc9dOTURF48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"What is a good name for a tech company\""
      ],
      "metadata": {
        "id": "eHUZr0NERPPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm.invoke(prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZOJYmQyRTr4",
        "outputId": "f7849692-8660-4022-bd50-e538914dc09e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is a good name for a tech company?\n",
            "What is a good name for a tech company?\n",
            "What is the most successful tech company?\n",
            "What is the most successful tech company in the world?\n",
            "What are the top 10 tech companies?\n",
            "What is the best tech company to work for?\n",
            "What is the best tech company to work for?\n",
            "What is the best tech company in the world?\n",
            "What is the most successful company in the world?\n",
            "What is the most successful company in the world?\n",
            "What is the best company in the world?\n",
            "What is the best tech company to work for?\n",
            "What is the best tech company to work for?\n",
            "What is the best tech company to work for?\n",
            "What is the best tech company to work for?\n",
            "What is the best tech company to work for?\n",
            "What is the best tech company to work for?What is the best tech company to work for?\n",
            "What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LangGraph\n",
        "\n",
        "Official examples: https://github.com/langchain-ai/langgraph/tree/main/examples"
      ],
      "metadata": {
        "id": "e7WbSwZe0sd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U langchain langchainhub langchain_openai openai tavily-python langgraph langsmith langchain_experimental pygraphviz aiosqlite"
      ],
      "metadata": {
        "id": "nuTPbCTP3Pev",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "546b48c9-6783-4b30-f200-1cfd9fe33e19"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.6/973.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.1/324.1 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.4/310.4 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple Agent"
      ],
      "metadata": {
        "id": "P5C_c7aBijmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "from typing import TypedDict, Annotated\n",
        "import operator\n",
        "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults"
      ],
      "metadata": {
        "id": "qp0ytCeEimYr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n",
        "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Tavily API Key:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mS9knMuLi5LD",
        "outputId": "2cb370f0-0927-4d90-c6b1-aae7f7e0e08f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key:··········\n",
            "Tavily API Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tool = TavilySearchResults(max_results=4) #increased number of results\n",
        "print(type(tool))\n",
        "print(tool.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxVxD9iCipMI",
        "outputId": "9078776a-e114-452d-e475-320255f42d0c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'langchain_community.tools.tavily_search.tool.TavilySearchResults'>\n",
            "tavily_search_results_json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[list[AnyMessage], operator.add]"
      ],
      "metadata": {
        "id": "_iTls9ACiqvG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "\n",
        "    def __init__(self, model, tools, system=\"\"):\n",
        "        self.system = system\n",
        "        graph = StateGraph(AgentState)\n",
        "        graph.add_node(\"llm\", self.call_openai)\n",
        "        graph.add_node(\"action\", self.take_action)\n",
        "        graph.add_conditional_edges(\n",
        "            \"llm\",\n",
        "            self.exists_action,\n",
        "            {True: \"action\", False: END}\n",
        "        )\n",
        "        graph.add_edge(\"action\", \"llm\")\n",
        "        graph.set_entry_point(\"llm\")\n",
        "        self.graph = graph.compile()\n",
        "        self.tools = {t.name: t for t in tools}\n",
        "        self.model = model.bind_tools(tools)\n",
        "\n",
        "    def exists_action(self, state: AgentState):\n",
        "        result = state['messages'][-1]\n",
        "        return len(result.tool_calls) > 0\n",
        "\n",
        "    def call_openai(self, state: AgentState):\n",
        "        messages = state['messages']\n",
        "        if self.system:\n",
        "            messages = [SystemMessage(content=self.system)] + messages\n",
        "        message = self.model.invoke(messages)\n",
        "        return {'messages': [message]}\n",
        "\n",
        "    def take_action(self, state: AgentState):\n",
        "        tool_calls = state['messages'][-1].tool_calls\n",
        "        results = []\n",
        "        for t in tool_calls:\n",
        "            print(f\"Calling: {t}\")\n",
        "            result = self.tools[t['name']].invoke(t['args'])\n",
        "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
        "        print(\"Back to the model!\")\n",
        "        return {'messages': results}"
      ],
      "metadata": {
        "id": "CPnPP7dCirMy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
        "You are allowed to make multiple calls (either together or in sequence). \\\n",
        "Only look up information when you are sure of what you want. \\\n",
        "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
        "\"\"\"\n",
        "model = ChatOpenAI(model=\"gpt-4-turbo\")\n",
        "abot = Agent(model, [tool], system=prompt)"
      ],
      "metadata": {
        "id": "b86V0m2liwAN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install graphviz libgraphviz-dev pkg-config\n",
        "!pip install pygraphviz==1.9"
      ],
      "metadata": {
        "id": "lsAoBDX-jETa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "Image(abot.graph.get_graph().draw_png())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "KDRnFyCLiseL",
        "outputId": "25afcf12-d4d3-4a9e-e9f5-2d15914d4c35"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [HumanMessage(content=\"What is the weather in sf?\")]\n",
        "result = abot.graph.invoke({\"messages\": messages})"
      ],
      "metadata": {
        "id": "oGkou4_Diz4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "id": "4JZdxf3ui08I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agent Executor"
      ],
      "metadata": {
        "id": "NcVLSks00vwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n",
        "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Tavily API Key:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfbSqFTw3IfO",
        "outputId": "c4744123-c246-4187-9129-5eb8e2489086"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key:··········\n",
            "Tavily API Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create the LangChain agent**"
      ],
      "metadata": {
        "id": "nvSnxiFc4ZDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "from langchain.agents import create_openai_functions_agent\n",
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "tools = [TavilySearchResults(max_results=1)]\n",
        "\n",
        "# Get the prompt to use\n",
        "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
        "\n",
        "# Choose the LLM that will drive the agent\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", streaming=True)\n",
        "\n",
        "# Construct the OpenAI Functions agent\n",
        "agent_runnable = create_openai_functions_agent(llm, tools, prompt)"
      ],
      "metadata": {
        "id": "JerFKlwo4JfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the graph sta**te\n",
        "\n",
        "We now define the graph state. The state for the traditional LangChain agent has a few attributes:\n",
        "\n",
        "1. **input**: This is the input string representing the main ask from the user, passed in as input.\n",
        "2. **chat_history**: This is any previous conversation messages, also passed in as input.\n",
        "3. **intermediate_steps**: This is list of actions and corresponding observations that the agent takes over time. This is updated each iteration of the agent.\n",
        "4. **agent_outcome**: This is the response from the agent, either an AgentAction or AgentFinish. The AgentExecutor should finish when this is an AgentFinish, otherwise it should call the requested tools."
      ],
      "metadata": {
        "id": "0Lg-rkVE5U86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, Annotated, List, Union\n",
        "from langchain_core.agents import AgentAction, AgentFinish\n",
        "from langchain_core.messages import BaseMessage\n",
        "import operator\n",
        "\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    # The input string\n",
        "    input: str\n",
        "    # The list of previous messages in the conversation\n",
        "    chat_history: list[BaseMessage]\n",
        "    # The outcome of a given call to the agent\n",
        "    # Needs `None` as a valid type, since this is what this will start as\n",
        "    agent_outcome: Union[AgentAction, AgentFinish, None]\n",
        "    # List of actions and corresponding observations\n",
        "    # Here we annotate this with `operator.add` to indicate that operations to\n",
        "    # this state should be ADDED to the existing values (not overwrite it)\n",
        "    intermediate_steps: Annotated[list[tuple[AgentAction, str]], operator.add]"
      ],
      "metadata": {
        "id": "iq6xYbJk55aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the nodes**\n",
        "\n",
        "We now need to define a few different nodes in our graph. In langgraph, a node can be either a function or a runnable. There are two main nodes we need for this:\n",
        "\n",
        "1. The agent: responsible for deciding what (if any) actions to take.\n",
        "2. A function to invoke tools: if the agent decides to take an action, this node will then execute that action.\n",
        "\n",
        "\n",
        "We will also need to define some edges. Some of these edges may be conditional. The reason they are conditional is that based on the output of a node, one of several paths may be taken. The path that is taken is not known until that node is run (the LLM decides).\n",
        "\n",
        "1. Conditional Edge: after the agent is called, we should either: a. If the agent said to take an action, then the function to invoke tools should be called b. If the agent said that it was finished, then it should finish\n",
        "2. Normal Edge: after the tools are invoked, it should always go back to the agent to decide what to do next\n",
        "\n",
        "\n",
        "Let's define the nodes, as well as a function to decide how what conditional edge to take."
      ],
      "metadata": {
        "id": "Cuyl0cg256K9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.agents import AgentFinish\n",
        "from langgraph.prebuilt.tool_executor import ToolExecutor\n",
        "\n",
        "# This a helper class we have that is useful for running tools\n",
        "# It takes in an agent action and calls that tool and returns the result\n",
        "tool_executor = ToolExecutor(tools)\n",
        "\n",
        "\n",
        "# Define the agent\n",
        "def run_agent(data):\n",
        "    agent_outcome = agent_runnable.invoke(data)\n",
        "    return {\"agent_outcome\": agent_outcome}\n",
        "\n",
        "\n",
        "# Define the function to execute tools\n",
        "def execute_tools(data):\n",
        "    # Get the most recent agent_outcome - this is the key added in the `agent` above\n",
        "    agent_action = data[\"agent_outcome\"]\n",
        "    output = tool_executor.invoke(agent_action)\n",
        "    return {\"intermediate_steps\": [(agent_action, str(output))]}\n",
        "\n",
        "\n",
        "# Define logic that will be used to determine which conditional edge to go down\n",
        "def should_continue(data):\n",
        "    # If the agent outcome is an AgentFinish, then we return `exit` string\n",
        "    # This will be used when setting up the graph to define the flow\n",
        "    if isinstance(data[\"agent_outcome\"], AgentFinish):\n",
        "        return \"end\"\n",
        "    # Otherwise, an AgentAction is returned\n",
        "    # Here we return `continue` string\n",
        "    # This will be used when setting up the graph to define the flow\n",
        "    else:\n",
        "        return \"continue\""
      ],
      "metadata": {
        "id": "e6lap60D6NM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the graph**\n",
        "\n",
        "We can now put it all together and define the graph!"
      ],
      "metadata": {
        "id": "haDkVAkp6P8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import END, StateGraph\n",
        "\n",
        "# Define a new graph\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# Define the two nodes we will cycle between\n",
        "workflow.add_node(\"agent\", run_agent)\n",
        "workflow.add_node(\"action\", execute_tools)\n",
        "\n",
        "# Set the entrypoint as `agent`\n",
        "# This means that this node is the first one called\n",
        "workflow.set_entry_point(\"agent\")\n",
        "\n",
        "# We now add a conditional edge\n",
        "workflow.add_conditional_edges(\n",
        "    # First, we define the start node. We use `agent`.\n",
        "    # This means these are the edges taken after the `agent` node is called.\n",
        "    \"agent\",\n",
        "    # Next, we pass in the function that will determine which node is called next.\n",
        "    should_continue,\n",
        "    # Finally we pass in a mapping.\n",
        "    # The keys are strings, and the values are other nodes.\n",
        "    # END is a special node marking that the graph should finish.\n",
        "    # What will happen is we will call `should_continue`, and then the output of that\n",
        "    # will be matched against the keys in this mapping.\n",
        "    # Based on which one it matches, that node will then be called.\n",
        "    {\n",
        "        # If `tools`, then we call the tool node.\n",
        "        \"continue\": \"action\",\n",
        "        # Otherwise we finish.\n",
        "        \"end\": END,\n",
        "    },\n",
        ")\n",
        "\n",
        "# We now add a normal edge from `tools` to `agent`.\n",
        "# This means that after `tools` is called, `agent` node is called next.\n",
        "workflow.add_edge(\"action\", \"agent\")\n",
        "\n",
        "# Finally, we compile it!\n",
        "# This compiles it into a LangChain Runnable,\n",
        "# meaning you can use it as you would any other runnable\n",
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "YzPwe3av6Pww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\"input\": \"what is the weather in sf\", \"chat_history\": []}\n",
        "for s in app.stream(inputs):\n",
        "    print(list(s.values())[0])\n",
        "    print(\"----\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8iC-63R6VbW",
        "outputId": "d4b719ae-1b4b-4122-e31f-635c183c70c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'agent_outcome': AgentActionMessageLog(tool='tavily_search_results_json', tool_input={'query': 'weather in San Francisco'}, log=\"\\nInvoking: `tavily_search_results_json` with `{'query': 'weather in San Francisco'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"weather in San Francisco\"}', 'name': 'tavily_search_results_json'}}, response_metadata={'finish_reason': 'function_call'}, id='run-9517941b-08d3-47c1-894d-8945838ac958-0')])}\n",
            "----\n",
            "{'intermediate_steps': [(AgentActionMessageLog(tool='tavily_search_results_json', tool_input={'query': 'weather in San Francisco'}, log=\"\\nInvoking: `tavily_search_results_json` with `{'query': 'weather in San Francisco'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"weather in San Francisco\"}', 'name': 'tavily_search_results_json'}}, response_metadata={'finish_reason': 'function_call'}, id='run-9517941b-08d3-47c1-894d-8945838ac958-0')]), '[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.78, \\'lon\\': -122.42, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1714682434, \\'localtime\\': \\'2024-05-02 13:40\\'}, \\'current\\': {\\'last_updated_epoch\\': 1714681800, \\'last_updated\\': \\'2024-05-02 13:30\\', \\'temp_c\\': 18.3, \\'temp_f\\': 64.9, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Partly cloudy\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/116.png\\', \\'code\\': 1003}, \\'wind_mph\\': 20.6, \\'wind_kph\\': 33.1, \\'wind_degree\\': 270, \\'wind_dir\\': \\'W\\', \\'pressure_mb\\': 1017.0, \\'pressure_in\\': 30.02, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 61, \\'cloud\\': 25, \\'feelslike_c\\': 18.3, \\'feelslike_f\\': 64.9, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 5.0, \\'gust_mph\\': 25.1, \\'gust_kph\\': 40.3}}\"}]')]}\n",
            "----\n",
            "{'agent_outcome': AgentFinish(return_values={'output': 'The current weather in San Francisco is 64.9°F (18.3°C) with partly cloudy conditions. The wind speed is 33.1 kph coming from the west, and the humidity is at 61%.'}, log='The current weather in San Francisco is 64.9°F (18.3°C) with partly cloudy conditions. The wind speed is 33.1 kph coming from the west, and the humidity is at 61%.')}\n",
            "----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chat Agent Executor"
      ],
      "metadata": {
        "id": "ZVSc3odHCyAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangSmith API Key:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEaz3FuMC8Oc",
        "outputId": "ac391a28-59ff-4cd0-eefb-c0d3957faaed"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LangSmith API Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "tools = [TavilySearchResults(max_results=1)]"
      ],
      "metadata": {
        "id": "kMtaqT9AD0i4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import ToolExecutor\n",
        "\n",
        "tool_executor = ToolExecutor(tools)"
      ],
      "metadata": {
        "id": "iD_wgTXsD25i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Set up the model**\n",
        "\n",
        "Now we need to load the chat model we want to use. Importantly, this should satisfy two criteria:\n",
        "\n",
        "1. It should work with messages. We will represent all agent state in the form of messages, so it needs to be able to work well with them.\n",
        "2. It should work with OpenAI function calling. This means it should either be an OpenAI model or a model that exposes a similar interface.\n",
        "\n",
        "Note: these model requirements are not requirements for using LangGraph - they are just requirements for this one example."
      ],
      "metadata": {
        "id": "Zpn0UwVFD53h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# We will set streaming=True so that we can stream tokens\n",
        "# See the streaming section for more information on this.\n",
        "model = ChatOpenAI(temperature=0, streaming=True)"
      ],
      "metadata": {
        "id": "QFpHy3Q2D6H5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.utils.function_calling import convert_to_openai_function\n",
        "\n",
        "functions = [convert_to_openai_function(t) for t in tools]\n",
        "model = model.bind_functions(functions)"
      ],
      "metadata": {
        "id": "HpwN-8aiEHg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the agent state**\n",
        "\n",
        "The main type of graph in langgraph is the StatefulGraph. This graph is parameterized by a state object that it passes around to each node. Each node then returns operations to update that state. These operations can either SET specific attributes on the state (e.g. overwrite the existing values) or ADD to the existing attribute. Whether to set or add is denoted by annotating the state object you construct the graph with.\n",
        "\n",
        "For this example, the state we will track will just be a list of messages. We want each node to just add messages to that list. Therefore, we will use a TypedDict with one key (messages) and annotate it so that the messages attribute is always added to."
      ],
      "metadata": {
        "id": "qCgwewJwFEPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, Annotated, Sequence\n",
        "import operator\n",
        "from langchain_core.messages import BaseMessage\n",
        "\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[Sequence[BaseMessage], operator.add]"
      ],
      "metadata": {
        "id": "2w9C60ikEa8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the nodes**\n",
        "\n",
        "We now need to define a few different nodes in our graph. In langgraph, a node can be either a function or a runnable. There are two main nodes we need for this:\n",
        "\n",
        "1. The agent: responsible for deciding what (if any) actions to take.\n",
        "2. A function to invoke tools: if the agent decides to take an action, this node will then execute that action.\n",
        "\n",
        "\n",
        "We will also need to define some edges. Some of these edges may be conditional. The reason they are conditional is that based on the output of a node, one of several paths may be taken. The path that is taken is not known until that node is run (the LLM decides).\n",
        "\n",
        "1. Conditional Edge: after the agent is called, we should either: a. If the agent said to take an action, then the function to invoke tools should be called b. If the agent said that it was finished, then it should finish\n",
        "2. Normal Edge: after the tools are invoked, it should always go back to the agent to decide what to do next\n",
        "\n",
        "Let's define the nodes, as well as a function to decide how what conditional edge to take."
      ],
      "metadata": {
        "id": "S9ZmW8UgFGn6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import ToolInvocation\n",
        "import json\n",
        "from langchain_core.messages import FunctionMessage\n",
        "\n",
        "\n",
        "# Define the function that determines whether to continue or not\n",
        "def should_continue(state):\n",
        "    messages = state[\"messages\"]\n",
        "    last_message = messages[-1]\n",
        "    # If there is no function call, then we finish\n",
        "    if \"function_call\" not in last_message.additional_kwargs:\n",
        "        return \"end\"\n",
        "    # Otherwise if there is, we continue\n",
        "    else:\n",
        "        return \"continue\"\n",
        "\n",
        "\n",
        "# Define the function that calls the model\n",
        "def call_model(state):\n",
        "    messages = state[\"messages\"]\n",
        "    response = model.invoke(messages)\n",
        "    # We return a list, because this will get added to the existing list\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "\n",
        "# Define the function to execute tools\n",
        "def call_tool(state):\n",
        "    messages = state[\"messages\"]\n",
        "    # Based on the continue condition\n",
        "    # we know the last message involves a function call\n",
        "    last_message = messages[-1]\n",
        "    # We construct an ToolInvocation from the function_call\n",
        "    action = ToolInvocation(\n",
        "        tool=last_message.additional_kwargs[\"function_call\"][\"name\"],\n",
        "        tool_input=json.loads(\n",
        "            last_message.additional_kwargs[\"function_call\"][\"arguments\"]\n",
        "        ),\n",
        "    )\n",
        "    # We call the tool_executor and get back a response\n",
        "    response = tool_executor.invoke(action)\n",
        "    # We use the response to create a FunctionMessage\n",
        "    function_message = FunctionMessage(content=str(response), name=action.tool)\n",
        "    # We return a list, because this will get added to the existing list\n",
        "    return {\"messages\": [function_message]}"
      ],
      "metadata": {
        "id": "mjICdqofFGSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the graph**\n",
        "We can now put it all together and define the graph!"
      ],
      "metadata": {
        "id": "f6hg057dFG8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# Define a new graph\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# Define the two nodes we will cycle between\n",
        "workflow.add_node(\"agent\", call_model)\n",
        "workflow.add_node(\"action\", call_tool)\n",
        "\n",
        "# Set the entrypoint as `agent`\n",
        "# This means that this node is the first one called\n",
        "workflow.set_entry_point(\"agent\")\n",
        "\n",
        "# We now add a conditional edge\n",
        "workflow.add_conditional_edges(\n",
        "    # First, we define the start node. We use `agent`.\n",
        "    # This means these are the edges taken after the `agent` node is called.\n",
        "    \"agent\",\n",
        "    # Next, we pass in the function that will determine which node is called next.\n",
        "    should_continue,\n",
        "    # Finally we pass in a mapping.\n",
        "    # The keys are strings, and the values are other nodes.\n",
        "    # END is a special node marking that the graph should finish.\n",
        "    # What will happen is we will call `should_continue`, and then the output of that\n",
        "    # will be matched against the keys in this mapping.\n",
        "    # Based on which one it matches, that node will then be called.\n",
        "    {\n",
        "        # If `tools`, then we call the tool node.\n",
        "        \"continue\": \"action\",\n",
        "        # Otherwise we finish.\n",
        "        \"end\": END,\n",
        "    },\n",
        ")\n",
        "\n",
        "# We now add a normal edge from `tools` to `agent`.\n",
        "# This means that after `tools` is called, `agent` node is called next.\n",
        "workflow.add_edge(\"action\", \"agent\")\n",
        "\n",
        "# Finally, we compile it!\n",
        "# This compiles it into a LangChain Runnable,\n",
        "# meaning you can use it as you would any other runnable\n",
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "5zro-d1jFHN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use it!\n",
        "We can now use it! This now exposes the same interface as all other LangChain runnables."
      ],
      "metadata": {
        "id": "LkUGP2McFHbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "inputs = {\"messages\": [HumanMessage(content=\"what is the weather in sf\")]}\n",
        "app.invoke(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-B6h6OZFH5I",
        "outputId": "9f04d308-d794-4622-e5b0-1cda2fd66820"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='what is the weather in sf'),\n",
              "  AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"weather in San Francisco\"}', 'name': 'tavily_search_results_json'}}, response_metadata={'finish_reason': 'function_call'}, id='run-2d0d7907-d9cc-4136-b447-2803ec05a60a-0'),\n",
              "  FunctionMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.78, \\'lon\\': -122.42, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1714683271, \\'localtime\\': \\'2024-05-02 13:54\\'}, \\'current\\': {\\'last_updated_epoch\\': 1714682700, \\'last_updated\\': \\'2024-05-02 13:45\\', \\'temp_c\\': 18.3, \\'temp_f\\': 64.9, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Partly cloudy\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/116.png\\', \\'code\\': 1003}, \\'wind_mph\\': 20.6, \\'wind_kph\\': 33.1, \\'wind_degree\\': 270, \\'wind_dir\\': \\'W\\', \\'pressure_mb\\': 1017.0, \\'pressure_in\\': 30.02, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 61, \\'cloud\\': 25, \\'feelslike_c\\': 18.3, \\'feelslike_f\\': 64.9, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 5.0, \\'gust_mph\\': 25.1, \\'gust_kph\\': 40.3}}\"}]', name='tavily_search_results_json'),\n",
              "  AIMessage(content='The current weather in San Francisco is partly cloudy with a temperature of 64.9°F (18.3°C). The wind speed is 33.1 kph coming from the west. The humidity is at 61% and the visibility is 16.0 km.', response_metadata={'finish_reason': 'stop'}, id='run-2785fde4-c1c6-4641-93f1-7546a55d75a8-0')]}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Streaming**\n",
        "LangGraph has support for several different types of streaming."
      ],
      "metadata": {
        "id": "kowmp9tqFYEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\"messages\": [HumanMessage(content=\"what is the weather in sf\")]}\n",
        "for output in app.stream(inputs):\n",
        "    # stream() yields dictionaries with output keyed by node name\n",
        "    for key, value in output.items():\n",
        "        print(f\"Output from node '{key}':\")\n",
        "        print(\"---\")\n",
        "        print(value)\n",
        "    print(\"\\n---\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFNBcddKFXpD",
        "outputId": "0b672b64-c030-43ea-b9b6-fd6caa3d60db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output from node 'agent':\n",
            "---\n",
            "{'messages': [AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"weather in San Francisco\"}', 'name': 'tavily_search_results_json'}}, response_metadata={'finish_reason': 'function_call'}, id='run-d221e860-f027-4832-a86f-493517294c50-0')]}\n",
            "\n",
            "---\n",
            "\n",
            "Output from node 'action':\n",
            "---\n",
            "{'messages': [FunctionMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.78, \\'lon\\': -122.42, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1714683271, \\'localtime\\': \\'2024-05-02 13:54\\'}, \\'current\\': {\\'last_updated_epoch\\': 1714682700, \\'last_updated\\': \\'2024-05-02 13:45\\', \\'temp_c\\': 18.3, \\'temp_f\\': 64.9, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Partly cloudy\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/116.png\\', \\'code\\': 1003}, \\'wind_mph\\': 20.6, \\'wind_kph\\': 33.1, \\'wind_degree\\': 270, \\'wind_dir\\': \\'W\\', \\'pressure_mb\\': 1017.0, \\'pressure_in\\': 30.02, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 61, \\'cloud\\': 25, \\'feelslike_c\\': 18.3, \\'feelslike_f\\': 64.9, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 5.0, \\'gust_mph\\': 25.1, \\'gust_kph\\': 40.3}}\"}]', name='tavily_search_results_json')]}\n",
            "\n",
            "---\n",
            "\n",
            "Output from node 'agent':\n",
            "---\n",
            "{'messages': [AIMessage(content='The current weather in San Francisco is partly cloudy with a temperature of 64.9°F (18.3°C). The wind speed is 20.6 mph (33.1 kph) coming from the west. The humidity is at 61% and the visibility is 9.0 miles.', response_metadata={'finish_reason': 'stop'}, id='run-a189b2e8-ba09-44fe-bc08-4442b47a0e97-0')]}\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-Agent Workflows\n"
      ],
      "metadata": {
        "id": "SxZnY3SCO-jU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Basic Multi-agent Collaboration**\n",
        "\n",
        "A single agent can usually operate effectively using a handful of tools within a single domain, but even using powerful models like gpt-4, it can be less effective at using many tools.\n",
        "\n",
        "One way to approach complicated tasks is through a \"divide-and-conquer\" approach: create an specialized agent for each task or domain and route tasks to the correct \"expert\".\n",
        "\n",
        "This notebook (inspired by the paper AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation, by Wu, et. al.) shows one way to do this using LangGraph.\n",
        "\n",
        "The resulting graph will look something like the following diagram:\n",
        "\n",
        "![graph](https://raw.githubusercontent.com/langchain-ai/langgraph/8a38226078383d49f57cd30c0df4203b0ea7cb2d/examples/multi_agent/img/simple_multi_agent_diagram.png)\n",
        "\n"
      ],
      "metadata": {
        "id": "g8aoh_ds8J7g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create Agents**\n",
        "The following helper functions will help create agents. These agents will then be nodes in the graph.\n",
        "\n",
        "You can skip ahead if you just want to see what the graph looks like."
      ],
      "metadata": {
        "id": "bch54l2h8Z8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "from langchain_core.messages import (\n",
        "    AIMessage,\n",
        "    BaseMessage,\n",
        "    ChatMessage,\n",
        "    FunctionMessage,\n",
        "    HumanMessage,\n",
        ")\n",
        "from langchain.tools.render import format_tool_to_openai_function\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langgraph.graph import END, StateGraph\n",
        "from langgraph.prebuilt.tool_executor import ToolExecutor, ToolInvocation\n",
        "\n",
        "\n",
        "def create_agent(llm, tools, system_message: str):\n",
        "    \"\"\"Create an agent.\"\"\"\n",
        "    functions = [format_tool_to_openai_function(t) for t in tools]\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\n",
        "                \"system\",\n",
        "                \"You are a helpful AI assistant, collaborating with other assistants.\"\n",
        "                \" Use the provided tools to progress towards answering the question.\"\n",
        "                \" If you are unable to fully answer, that's OK, another assistant with different tools \"\n",
        "                \" will help where you left off. Execute what you can to make progress.\"\n",
        "                \" If you or any of the other assistants have the final answer or deliverable,\"\n",
        "                \" prefix your response with FINAL ANSWER so the team knows to stop.\"\n",
        "                \" You have access to the following tools: {tool_names}.\\n{system_message}\",\n",
        "            ),\n",
        "            MessagesPlaceholder(variable_name=\"messages\"),\n",
        "        ]\n",
        "    )\n",
        "    prompt = prompt.partial(system_message=system_message)\n",
        "    prompt = prompt.partial(tool_names=\", \".join([tool.name for tool in tools]))\n",
        "    return prompt | llm.bind_functions(functions)"
      ],
      "metadata": {
        "id": "qWK7gnKD8ZKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define tools**\n",
        "We will also define some tools that our agents will use in the future"
      ],
      "metadata": {
        "id": "zUAKhVQD8eiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import tool\n",
        "from typing import Annotated\n",
        "from langchain_experimental.utilities import PythonREPL\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "tavily_tool = TavilySearchResults(max_results=5)\n",
        "\n",
        "# Warning: This executes code locally, which can be unsafe when not sandboxed\n",
        "\n",
        "repl = PythonREPL()\n",
        "\n",
        "\n",
        "@tool\n",
        "def python_repl(\n",
        "    code: Annotated[str, \"The python code to execute to generate your chart.\"]\n",
        "):\n",
        "    \"\"\"Use this to execute python code. If you want to see the output of a value,\n",
        "    you should print it out with `print(...)`. This is visible to the user.\"\"\"\n",
        "    try:\n",
        "        result = repl.run(code)\n",
        "    except BaseException as e:\n",
        "        return f\"Failed to execute. Error: {repr(e)}\"\n",
        "    return f\"Succesfully executed:\\n```python\\n{code}\\n```\\nStdout: {result}\""
      ],
      "metadata": {
        "id": "4A58Hy7M8ZHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create graph**\n",
        "Now that we've defined our tools and made some helper functions, will create the individual agents below and tell them how to talk to each other using LangGraph.\n",
        "\n",
        "**Define State**\n",
        "We first define the state of the graph. This will just a list of messages, along with a key to track the most recent sender"
      ],
      "metadata": {
        "id": "qPV3rBKo8hHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import operator\n",
        "from typing import Annotated, List, Sequence, Tuple, TypedDict, Union\n",
        "\n",
        "from langchain.agents import create_openai_functions_agent\n",
        "from langchain.tools.render import format_tool_to_openai_function\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "\n",
        "# This defines the object that is passed between each node\n",
        "# in the graph. We will create different nodes for each agent and tool\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
        "    sender: str"
      ],
      "metadata": {
        "id": "I604q12K8ZEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Agent Nodes**\n",
        "We now need to define the nodes. First, let's define the nodes for the agents."
      ],
      "metadata": {
        "id": "lHbF6Yqs8kCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import functools\n",
        "\n",
        "\n",
        "# Helper function to create a node for a given agent\n",
        "def agent_node(state, agent, name):\n",
        "    result = agent.invoke(state)\n",
        "    # We convert the agent output into a format that is suitable to append to the global state\n",
        "    if isinstance(result, FunctionMessage):\n",
        "        pass\n",
        "    else:\n",
        "        result = HumanMessage(**result.dict(exclude={\"type\", \"name\"}), name=name)\n",
        "    return {\n",
        "        \"messages\": [result],\n",
        "        # Since we have a strict workflow, we can\n",
        "        # track the sender so we know who to pass to next.\n",
        "        \"sender\": name,\n",
        "    }\n",
        "\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4-1106-preview\")\n",
        "\n",
        "# Research agent and node\n",
        "research_agent = create_agent(\n",
        "    llm,\n",
        "    [tavily_tool],\n",
        "    system_message=\"You should provide accurate data for the chart generator to use.\",\n",
        ")\n",
        "research_node = functools.partial(agent_node, agent=research_agent, name=\"Researcher\")\n",
        "\n",
        "# Chart Generator\n",
        "chart_agent = create_agent(\n",
        "    llm,\n",
        "    [python_repl],\n",
        "    system_message=\"Any charts you display will be visible by the user.\",\n",
        ")\n",
        "chart_node = functools.partial(agent_node, agent=chart_agent, name=\"Chart Generator\")"
      ],
      "metadata": {
        "id": "bliShcj78Y_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Tool Node**\n",
        "We now define a node to run the tools"
      ],
      "metadata": {
        "id": "JhBfizEl8mPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [tavily_tool, python_repl]\n",
        "tool_executor = ToolExecutor(tools)\n",
        "\n",
        "\n",
        "def tool_node(state):\n",
        "    \"\"\"This runs tools in the graph\n",
        "\n",
        "    It takes in an agent action and calls that tool and returns the result.\"\"\"\n",
        "    messages = state[\"messages\"]\n",
        "    # Based on the continue condition\n",
        "    # we know the last message involves a function call\n",
        "    last_message = messages[-1]\n",
        "    # We construct an ToolInvocation from the function_call\n",
        "    tool_input = json.loads(\n",
        "        last_message.additional_kwargs[\"function_call\"][\"arguments\"]\n",
        "    )\n",
        "    # We can pass single-arg inputs by value\n",
        "    if len(tool_input) == 1 and \"__arg1\" in tool_input:\n",
        "        tool_input = next(iter(tool_input.values()))\n",
        "    tool_name = last_message.additional_kwargs[\"function_call\"][\"name\"]\n",
        "    action = ToolInvocation(\n",
        "        tool=tool_name,\n",
        "        tool_input=tool_input,\n",
        "    )\n",
        "    # We call the tool_executor and get back a response\n",
        "    response = tool_executor.invoke(action)\n",
        "    # We use the response to create a FunctionMessage\n",
        "    function_message = FunctionMessage(\n",
        "        content=f\"{tool_name} response: {str(response)}\", name=action.tool\n",
        "    )\n",
        "    # We return a list, because this will get added to the existing list\n",
        "    return {\"messages\": [function_message]}"
      ],
      "metadata": {
        "id": "f53amOuP8mdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Edge Logic**\n",
        "We can define some of the edge logic that is needed to decide what to do based on results of the agents"
      ],
      "metadata": {
        "id": "5DU5CowM8p3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Either agent can decide to end\n",
        "def router(state):\n",
        "    # This is the router\n",
        "    messages = state[\"messages\"]\n",
        "    last_message = messages[-1]\n",
        "    if \"function_call\" in last_message.additional_kwargs:\n",
        "        # The previus agent is invoking a tool\n",
        "        return \"call_tool\"\n",
        "    if \"FINAL ANSWER\" in last_message.content:\n",
        "        # Any agent decided the work is done\n",
        "        return \"end\"\n",
        "    return \"continue\""
      ],
      "metadata": {
        "id": "t-XY11oq8qk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the Graph**\n",
        "We can now put it all together and define the graph!"
      ],
      "metadata": {
        "id": "YVj9t0_j8sr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "workflow.add_node(\"Researcher\", research_node)\n",
        "workflow.add_node(\"Chart Generator\", chart_node)\n",
        "workflow.add_node(\"call_tool\", tool_node)\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"Researcher\",\n",
        "    router,\n",
        "    {\"continue\": \"Chart Generator\", \"call_tool\": \"call_tool\", \"end\": END},\n",
        ")\n",
        "workflow.add_conditional_edges(\n",
        "    \"Chart Generator\",\n",
        "    router,\n",
        "    {\"continue\": \"Researcher\", \"call_tool\": \"call_tool\", \"end\": END},\n",
        ")\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"call_tool\",\n",
        "    # Each agent node updates the 'sender' field\n",
        "    # the tool calling node does not, meaning\n",
        "    # this edge will route back to the original agent\n",
        "    # who invoked the tool\n",
        "    lambda x: x[\"sender\"],\n",
        "    {\n",
        "        \"Researcher\": \"Researcher\",\n",
        "        \"Chart Generator\": \"Chart Generator\",\n",
        "    },\n",
        ")\n",
        "workflow.set_entry_point(\"Researcher\")\n",
        "graph = workflow.compile()"
      ],
      "metadata": {
        "id": "zE5hV_pK8tnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Invoke**\n",
        "With the graph created, you can invoke it! Let's have it chart some stats for us."
      ],
      "metadata": {
        "id": "K-3MGKxY8vfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for s in graph.stream(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            HumanMessage(\n",
        "                content=\"Fetch the UK's GDP over the past 5 years,\"\n",
        "                \" then draw a line graph of it.\"\n",
        "                \" Once you code it up, finish.\"\n",
        "            )\n",
        "        ],\n",
        "    },\n",
        "    # Maximum number of steps to take in the graph\n",
        "    {\"recursion_limit\": 150},\n",
        "):\n",
        "    print(s)\n",
        "    print(\"----\")"
      ],
      "metadata": {
        "id": "lEXbn4RS8wPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Agent Supervisor"
      ],
      "metadata": {
        "id": "9iMJUxC7A8-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also choose to use an LLM to orchestrate the different agents.\n",
        "\n",
        "Below, we will create an agent group, with an agent supervisor to help delegate tasks.\n",
        "\n",
        "![Agent Supervisor](https://raw.githubusercontent.com/langchain-ai/langgraph/8a38226078383d49f57cd30c0df4203b0ea7cb2d/examples/multi_agent/img/supervisor-diagram.png)\n",
        "\n",
        "To simplify the code in each agent node, we will use the AgentExecutor class from LangChain. This and other \"advanced agent\" notebooks are designed to show how you can implement certain design patterns in LangGraph. If the pattern suits your needs, we recommend combining it with some of the other fundamental patterns described elsewhere in the docs for best performance."
      ],
      "metadata": {
        "id": "so2ElI1XBAo5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create tools**\n",
        "\n",
        "For this example, you will make an agent to do web research with a search engine, and one agent to create plots. Define the tools they'll use below:"
      ],
      "metadata": {
        "id": "JfOXWBBkBMzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated, List, Tuple, Union\n",
        "\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_core.tools import tool\n",
        "from langchain_experimental.tools import PythonREPLTool\n",
        "\n",
        "tavily_tool = TavilySearchResults(max_results=5)\n",
        "\n",
        "# This executes code locally, which can be unsafe\n",
        "python_repl_tool = PythonREPLTool()"
      ],
      "metadata": {
        "id": "BE_5SZpeA_Vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Helper Utilites**\n",
        "\n",
        "Define a helper function below, which make it easier to add new agent worker nodes."
      ],
      "metadata": {
        "id": "Of38MF9wBPgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
        "from langchain_core.messages import BaseMessage, HumanMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "\n",
        "def create_agent(llm: ChatOpenAI, tools: list, system_prompt: str):\n",
        "    # Each worker node will be given a name and some tools.\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\n",
        "                \"system\",\n",
        "                system_prompt,\n",
        "            ),\n",
        "            MessagesPlaceholder(variable_name=\"messages\"),\n",
        "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "        ]\n",
        "    )\n",
        "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
        "    executor = AgentExecutor(agent=agent, tools=tools)\n",
        "    return executor"
      ],
      "metadata": {
        "id": "0SPJF9YxBPzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also define a function that we will use to be the nodes in the graph - it takes care of converting the agent response to a human message. This is important because that is how we will add it the global state of the graph"
      ],
      "metadata": {
        "id": "rL4kQFuoBTtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def agent_node(state, agent, name):\n",
        "    result = agent.invoke(state)\n",
        "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}"
      ],
      "metadata": {
        "id": "-iysFO_LBQTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create Agent Supervisor**\n",
        "\n",
        "It will use function calling to choose the next worker node OR finish processing."
      ],
      "metadata": {
        "id": "F-r5ifHpBVgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "members = [\"Researcher\", \"Coder\"]\n",
        "system_prompt = (\n",
        "    \"You are a supervisor tasked with managing a conversation between the\"\n",
        "    \" following workers:  {members}. Given the following user request,\"\n",
        "    \" respond with the worker to act next. Each worker will perform a\"\n",
        "    \" task and respond with their results and status. When finished,\"\n",
        "    \" respond with FINISH.\"\n",
        ")\n",
        "# Our team supervisor is an LLM node. It just picks the next agent to process\n",
        "# and decides when the work is completed\n",
        "options = [\"FINISH\"] + members\n",
        "# Using openai function calling can make output parsing easier for us\n",
        "function_def = {\n",
        "    \"name\": \"route\",\n",
        "    \"description\": \"Select the next role.\",\n",
        "    \"parameters\": {\n",
        "        \"title\": \"routeSchema\",\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"next\": {\n",
        "                \"title\": \"Next\",\n",
        "                \"anyOf\": [\n",
        "                    {\"enum\": options},\n",
        "                ],\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"next\"],\n",
        "    },\n",
        "}\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "        (\n",
        "            \"system\",\n",
        "            \"Given the conversation above, who should act next?\"\n",
        "            \" Or should we FINISH? Select one of: {options}\",\n",
        "        ),\n",
        "    ]\n",
        ").partial(options=str(options), members=\", \".join(members))\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4-1106-preview\")\n",
        "\n",
        "supervisor_chain = (\n",
        "    prompt\n",
        "    | llm.bind_functions(functions=[function_def], function_call=\"route\")\n",
        "    | JsonOutputFunctionsParser()\n",
        ")"
      ],
      "metadata": {
        "id": "idXl8lORBQQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Construct Graph**\n",
        "\n",
        "We're ready to start building the graph. Below, define the state and worker nodes using the function we just defined."
      ],
      "metadata": {
        "id": "iQYKckixBYOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import operator\n",
        "from typing import Annotated, Any, Dict, List, Optional, Sequence, TypedDict\n",
        "import functools\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "\n",
        "# The agent state is the input to each node in the graph\n",
        "class AgentState(TypedDict):\n",
        "    # The annotation tells the graph that new messages will always\n",
        "    # be added to the current states\n",
        "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
        "    # The 'next' field indicates where to route to next\n",
        "    next: str\n",
        "\n",
        "\n",
        "research_agent = create_agent(llm, [tavily_tool], \"You are a web researcher.\")\n",
        "research_node = functools.partial(agent_node, agent=research_agent, name=\"Researcher\")\n",
        "\n",
        "# NOTE: THIS PERFORMS ARBITRARY CODE EXECUTION. PROCEED WITH CAUTION\n",
        "code_agent = create_agent(\n",
        "    llm,\n",
        "    [python_repl_tool],\n",
        "    \"You may generate safe python code to analyze data and generate charts using matplotlib.\",\n",
        ")\n",
        "code_node = functools.partial(agent_node, agent=code_agent, name=\"Coder\")\n",
        "\n",
        "workflow = StateGraph(AgentState)\n",
        "workflow.add_node(\"Researcher\", research_node)\n",
        "workflow.add_node(\"Coder\", code_node)\n",
        "workflow.add_node(\"supervisor\", supervisor_chain)"
      ],
      "metadata": {
        "id": "gK6PAZ0wBQNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now connect all the edges in the graph."
      ],
      "metadata": {
        "id": "rmfyUhqyBbj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for member in members:\n",
        "    # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
        "    workflow.add_edge(member, \"supervisor\")\n",
        "# The supervisor populates the \"next\" field in the graph state\n",
        "# which routes to a node or finishes\n",
        "conditional_map = {k: k for k in members}\n",
        "conditional_map[\"FINISH\"] = END\n",
        "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
        "# Finally, add entrypoint\n",
        "workflow.set_entry_point(\"supervisor\")\n",
        "\n",
        "graph = workflow.compile()"
      ],
      "metadata": {
        "id": "bkoY_Ry5BQHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Invoke the team\n",
        "With the graph created, we can now invoke it and see how it performs!"
      ],
      "metadata": {
        "id": "GWOPaa-BBd4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for s in graph.stream(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            HumanMessage(content=\"Code hello world and print it to the terminal\")\n",
        "        ]\n",
        "    }\n",
        "):\n",
        "    if \"__end__\" not in s:\n",
        "        print(s)\n",
        "        print(\"----\")"
      ],
      "metadata": {
        "id": "uBoMUODlBcBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for s in graph.stream(\n",
        "    {\"messages\": [HumanMessage(content=\"Write a brief research report on pikas.\")]},\n",
        "    {\"recursion_limit\": 100},\n",
        "):\n",
        "    if \"__end__\" not in s:\n",
        "        print(s)\n",
        "        print(\"----\")"
      ],
      "metadata": {
        "id": "SUfHoVPGBb0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Persistence and Streaming"
      ],
      "metadata": {
        "id": "v3u6c2P2knVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n",
        "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Tavily API Key:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "um81EoaJkprf",
        "outputId": "2a316cf8-bd8b-442c-abc2-d8048e14a804"
      },
      "execution_count": 15,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tavily API Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "from typing import TypedDict, Annotated\n",
        "import operator\n",
        "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults"
      ],
      "metadata": {
        "id": "PzlvhaVbk4ah"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tool = TavilySearchResults(max_results=2)"
      ],
      "metadata": {
        "id": "9zOqhejNk4ws"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[list[AnyMessage], operator.add]"
      ],
      "metadata": {
        "id": "FftY_V_Qk60J"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.checkpoint.sqlite import SqliteSaver\n",
        "\n",
        "memory = SqliteSaver.from_conn_string(\":memory:\")"
      ],
      "metadata": {
        "id": "6htsCtTQk74F"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "    def __init__(self, model, tools, checkpointer, system=\"\"):\n",
        "        self.system = system\n",
        "        graph = StateGraph(AgentState)\n",
        "        graph.add_node(\"llm\", self.call_openai)\n",
        "        graph.add_node(\"action\", self.take_action)\n",
        "        graph.add_conditional_edges(\"llm\", self.exists_action, {True: \"action\", False: END})\n",
        "        graph.add_edge(\"action\", \"llm\")\n",
        "        graph.set_entry_point(\"llm\")\n",
        "        self.graph = graph.compile(checkpointer=checkpointer)\n",
        "        self.tools = {t.name: t for t in tools}\n",
        "        self.model = model.bind_tools(tools)\n",
        "\n",
        "    def call_openai(self, state: AgentState):\n",
        "        messages = state['messages']\n",
        "        if self.system:\n",
        "            messages = [SystemMessage(content=self.system)] + messages\n",
        "        message = self.model.invoke(messages)\n",
        "        return {'messages': [message]}\n",
        "\n",
        "    def exists_action(self, state: AgentState):\n",
        "        result = state['messages'][-1]\n",
        "        return len(result.tool_calls) > 0\n",
        "\n",
        "    def take_action(self, state: AgentState):\n",
        "        tool_calls = state['messages'][-1].tool_calls\n",
        "        results = []\n",
        "        for t in tool_calls:\n",
        "            print(f\"Calling: {t}\")\n",
        "            result = self.tools[t['name']].invoke(t['args'])\n",
        "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
        "        print(\"Back to the model!\")\n",
        "        return {'messages': results}"
      ],
      "metadata": {
        "id": "WrxubJCEk-tN"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
        "You are allowed to make multiple calls (either together or in sequence). \\\n",
        "Only look up information when you are sure of what you want. \\\n",
        "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
        "\"\"\"\n",
        "model = ChatOpenAI(model=\"gpt-4o\")\n",
        "abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
      ],
      "metadata": {
        "id": "-3CYyChSlOfQ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [HumanMessage(content=\"What is the weather in sf?\")]"
      ],
      "metadata": {
        "id": "_56eGlBRlQ2Q"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "thread = {\"configurable\": {\"thread_id\": \"1\"}}"
      ],
      "metadata": {
        "id": "SqQhf6tnlQzh"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
        "    for v in event.values():\n",
        "        print(v['messages'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hspjxV0IlQwn",
        "outputId": "2c3f5b92-7751-4f5b-95a7-9df93789f877"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_wXvhAzcFynLVif5mU4GfmioD', 'function': {'arguments': '{\"query\":\"current weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 151, 'total_tokens': 173}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_319be4768e', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-522563dd-2138-4ee1-a77d-55274bab4ca1-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_wXvhAzcFynLVif5mU4GfmioD'}], usage_metadata={'input_tokens': 151, 'output_tokens': 22, 'total_tokens': 173})]\n",
            "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_wXvhAzcFynLVif5mU4GfmioD'}\n",
            "Back to the model!\n",
            "[ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.78, \\'lon\\': -122.42, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1717610812, \\'localtime\\': \\'2024-06-05 11:06\\'}, \\'current\\': {\\'last_updated_epoch\\': 1717610400, \\'last_updated\\': \\'2024-06-05 11:00\\', \\'temp_c\\': 15.0, \\'temp_f\\': 59.0, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Mist\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/143.png\\', \\'code\\': 1030}, \\'wind_mph\\': 10.5, \\'wind_kph\\': 16.9, \\'wind_degree\\': 310, \\'wind_dir\\': \\'NW\\', \\'pressure_mb\\': 1013.0, \\'pressure_in\\': 29.91, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 82, \\'cloud\\': 0, \\'feelslike_c\\': 14.7, \\'feelslike_f\\': 58.5, \\'windchill_c\\': 18.8, \\'windchill_f\\': 65.9, \\'heatindex_c\\': 18.8, \\'heatindex_f\\': 65.9, \\'dewpoint_c\\': 11.9, \\'dewpoint_f\\': 53.4, \\'vis_km\\': 6.4, \\'vis_miles\\': 3.0, \\'uv\\': 5.0, \\'gust_mph\\': 15.0, \\'gust_kph\\': 24.1}}\"}, {\\'url\\': \\'https://www.wunderground.com/weather/us/ca/san-francisco\\', \\'content\\': \\'San Francisco Weather Forecasts. Weather Underground provides local & long-range weather forecasts, weatherreports, maps & tropical weather conditions for the San Francisco area. ... 05 PM PDT on ...\\'}]', name='tavily_search_results_json', tool_call_id='call_wXvhAzcFynLVif5mU4GfmioD')]\n",
            "[AIMessage(content='The current weather in San Francisco is:\\n\\n- **Temperature**: 15°C (59°F)\\n- **Condition**: Mist\\n- **Wind**: 10.5 mph (16.9 kph) from the NW\\n- **Humidity**: 82%\\n- **Visibility**: 6.4 km (3.0 miles)\\n- **UV Index**: 5\\n\\n![Weather Icon](//cdn.weatherapi.com/weather/64x64/day/143.png)\\n\\nFor more details, you can check [WeatherAPI](https://www.weatherapi.com/) or [Weather Underground](https://www.wunderground.com/weather/us/ca/san-francisco).', response_metadata={'token_usage': {'completion_tokens': 141, 'prompt_tokens': 651, 'total_tokens': 792}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_319be4768e', 'finish_reason': 'stop', 'logprobs': None}, id='run-d23bb6c1-e8b1-436a-9ff6-24b07f3a3287-0', usage_metadata={'input_tokens': 651, 'output_tokens': 141, 'total_tokens': 792})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [HumanMessage(content=\"What about in la?\")]\n",
        "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
        "    for v in event.values():\n",
        "        print(v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O94aCDKYlVEy",
        "outputId": "388364c9-308a-47b1-dcce-1ed40100ca58"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_qkDXe5i94VE3pxM51ltEzyv3', 'function': {'arguments': '{\"query\":\"current weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 804, 'total_tokens': 826}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_319be4768e', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-7064520f-c3c5-4f10-97b0-5ad699aff950-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Los Angeles'}, 'id': 'call_qkDXe5i94VE3pxM51ltEzyv3'}], usage_metadata={'input_tokens': 804, 'output_tokens': 22, 'total_tokens': 826})]}\n",
            "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Los Angeles'}, 'id': 'call_qkDXe5i94VE3pxM51ltEzyv3'}\n",
            "Back to the model!\n",
            "{'messages': [ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'Los Angeles\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 34.05, \\'lon\\': -118.24, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1717610820, \\'localtime\\': \\'2024-06-05 11:07\\'}, \\'current\\': {\\'last_updated_epoch\\': 1717610400, \\'last_updated\\': \\'2024-06-05 11:00\\', \\'temp_c\\': 21.0, \\'temp_f\\': 69.8, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Mist\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/143.png\\', \\'code\\': 1030}, \\'wind_mph\\': 6.9, \\'wind_kph\\': 11.2, \\'wind_degree\\': 170, \\'wind_dir\\': \\'S\\', \\'pressure_mb\\': 1013.0, \\'pressure_in\\': 29.9, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 73, \\'cloud\\': 25, \\'feelslike_c\\': 21.0, \\'feelslike_f\\': 69.8, \\'windchill_c\\': 24.8, \\'windchill_f\\': 76.7, \\'heatindex_c\\': 25.6, \\'heatindex_f\\': 78.1, \\'dewpoint_c\\': 13.7, \\'dewpoint_f\\': 56.6, \\'vis_km\\': 8.0, \\'vis_miles\\': 4.0, \\'uv\\': 6.0, \\'gust_mph\\': 7.5, \\'gust_kph\\': 12.0}}\"}, {\\'url\\': \\'https://www.weathertab.com/en/c/e/06/united-states/california/los-angeles/\\', \\'content\\': \\'Avg High Temps 75 to 85 °F. Avg Low Temps 50 to 60 °F. Explore comprehensive June 2024 weather forecasts for Los Angeles, including daily high and low temperatures, precipitation risks, and monthly temperature trends. Featuring detailed day-by-day forecasts, dynamic graphs of daily rain probabilities, and temperature trends to help you plan ...\\'}]', name='tavily_search_results_json', tool_call_id='call_qkDXe5i94VE3pxM51ltEzyv3')]}\n",
            "{'messages': [AIMessage(content='The current weather in Los Angeles is:\\n\\n- **Temperature**: 21°C (69.8°F)\\n- **Condition**: Mist\\n- **Wind**: 6.9 mph (11.2 kph) from the S\\n- **Humidity**: 73%\\n- **Visibility**: 8.0 km (4.0 miles)\\n- **UV Index**: 6\\n\\n![Weather Icon](//cdn.weatherapi.com/weather/64x64/day/143.png)\\n\\nFor more details, you can check [WeatherAPI](https://www.weatherapi.com/) or [WeatherTAB](https://www.weathertab.com/en/c/e/06/united-states/california/los-angeles/).', response_metadata={'token_usage': {'completion_tokens': 151, 'prompt_tokens': 1345, 'total_tokens': 1496}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_aa87380ac5', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd937ce2-f188-4be9-8b88-c4ca2b802b7e-0', usage_metadata={'input_tokens': 1345, 'output_tokens': 151, 'total_tokens': 1496})]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
        "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
        "    for v in event.values():\n",
        "        print(v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJ7ZBFvPlU6d",
        "outputId": "a060e763-7303-4255-cd92-b8f310d4891a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'messages': [AIMessage(content='Los Angeles is currently warmer than San Francisco. The temperature in Los Angeles is 21°C (69.8°F) compared to 15°C (59°F) in San Francisco.', response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 1508, 'total_tokens': 1546}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_319be4768e', 'finish_reason': 'stop', 'logprobs': None}, id='run-852c9ebf-98c0-4f25-af30-1a4714f8d410-0', usage_metadata={'input_tokens': 1508, 'output_tokens': 38, 'total_tokens': 1546})]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
        "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
        "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
        "    for v in event.values():\n",
        "        print(v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnfhrmBhlW6M",
        "outputId": "3a30b13f-2a9a-4d81-c624-1447e8ce5629"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'messages': [AIMessage(content='Could you please clarify what you are comparing? Are you asking about the temperature difference between two specific locations, objects, or something else?', response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 149, 'total_tokens': 177}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_319be4768e', 'finish_reason': 'stop', 'logprobs': None}, id='run-176c423a-0f91-4cbc-8398-6b01031d9cb6-0', usage_metadata={'input_tokens': 149, 'output_tokens': 28, 'total_tokens': 177})]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Streaming tokens**"
      ],
      "metadata": {
        "id": "QmoIsJmlmKQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.checkpoint.aiosqlite import AsyncSqliteSaver\n",
        "\n",
        "memory = AsyncSqliteSaver.from_conn_string(\":memory:\")\n",
        "abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
      ],
      "metadata": {
        "id": "iLtq_-KJmLCJ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [HumanMessage(content=\"What is the weather in SF?\")]\n",
        "thread = {\"configurable\": {\"thread_id\": \"4\"}}\n",
        "\n",
        "async for event in abot.graph.astream_events({\"messages\": messages}, thread, version=\"v1\"):\n",
        "    kind = event[\"event\"]\n",
        "    if kind == \"on_chat_model_stream\":\n",
        "        content = event[\"data\"][\"chunk\"].content\n",
        "        if content:\n",
        "            # Empty content in the context of OpenAI means\n",
        "            # that the model is asking for a tool to be invoked.\n",
        "            # So we only print non-empty content\n",
        "            print(content, end=\"|\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPoFFppOmM7-",
        "outputId": "4d39590b-8af8-4a0e-de3a-b391301f695f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_eszDySpx0r99Rq9OVuupxHiF'}\n",
            "Back to the model!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Human in the Loop"
      ],
      "metadata": {
        "id": "wr0RqaZ-pEGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "from typing import TypedDict, Annotated\n",
        "import operator\n",
        "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langgraph.checkpoint.sqlite import SqliteSaver\n",
        "\n",
        "memory = SqliteSaver.from_conn_string(\":memory:\")"
      ],
      "metadata": {
        "id": "g1iOaupbpEta"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from uuid import uuid4\n",
        "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, AIMessage\n",
        "\n",
        "\"\"\"\n",
        "In previous examples we've annotated the `messages` state key\n",
        "with the default `operator.add` or `+` reducer, which always\n",
        "appends new messages to the end of the existing messages array.\n",
        "\n",
        "Now, to support replacing existing messages, we annotate the\n",
        "`messages` key with a customer reducer function, which replaces\n",
        "messages with the same `id`, and appends them otherwise.\n",
        "\"\"\"\n",
        "def reduce_messages(left: list[AnyMessage], right: list[AnyMessage]) -> list[AnyMessage]:\n",
        "    # assign ids to messages that don't have them\n",
        "    for message in right:\n",
        "        if not message.id:\n",
        "            message.id = str(uuid4())\n",
        "    # merge the new messages with the existing messages\n",
        "    merged = left.copy()\n",
        "    for message in right:\n",
        "        for i, existing in enumerate(merged):\n",
        "            # replace any existing messages with the same id\n",
        "            if existing.id == message.id:\n",
        "                merged[i] = message\n",
        "                break\n",
        "        else:\n",
        "            # append any new messages to the end\n",
        "            merged.append(message)\n",
        "    return merged\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[list[AnyMessage], reduce_messages]"
      ],
      "metadata": {
        "id": "lEudPpn0pJSb"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tool = TavilySearchResults(max_results=2)"
      ],
      "metadata": {
        "id": "7117BDAwpKHu"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Manual human approval**"
      ],
      "metadata": {
        "id": "nwAPvBs5pOnb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "    def __init__(self, model, tools, system=\"\", checkpointer=None):\n",
        "        self.system = system\n",
        "        graph = StateGraph(AgentState)\n",
        "        graph.add_node(\"llm\", self.call_openai)\n",
        "        graph.add_node(\"action\", self.take_action)\n",
        "        graph.add_conditional_edges(\"llm\", self.exists_action, {True: \"action\", False: END})\n",
        "        graph.add_edge(\"action\", \"llm\")\n",
        "        graph.set_entry_point(\"llm\")\n",
        "        self.graph = graph.compile(\n",
        "            checkpointer=checkpointer,\n",
        "            interrupt_before=[\"action\"] # Intrupt before action\n",
        "        )\n",
        "        self.tools = {t.name: t for t in tools}\n",
        "        self.model = model.bind_tools(tools)\n",
        "\n",
        "    def call_openai(self, state: AgentState):\n",
        "        messages = state['messages']\n",
        "        if self.system:\n",
        "            messages = [SystemMessage(content=self.system)] + messages\n",
        "        message = self.model.invoke(messages)\n",
        "        return {'messages': [message]}\n",
        "\n",
        "    def exists_action(self, state: AgentState):\n",
        "        print(state)\n",
        "        result = state['messages'][-1]\n",
        "        return len(result.tool_calls) > 0\n",
        "\n",
        "    def take_action(self, state: AgentState):\n",
        "        tool_calls = state['messages'][-1].tool_calls\n",
        "        results = []\n",
        "        for t in tool_calls:\n",
        "            print(f\"Calling: {t}\")\n",
        "            result = self.tools[t['name']].invoke(t['args'])\n",
        "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
        "        print(\"Back to the model!\")\n",
        "        return {'messages': results}"
      ],
      "metadata": {
        "id": "V4Kqws6NpKFD"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
        "You are allowed to make multiple calls (either together or in sequence). \\\n",
        "Only look up information when you are sure of what you want. \\\n",
        "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
        "\"\"\"\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
      ],
      "metadata": {
        "id": "vi4QKrFMpKCo"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [HumanMessage(content=\"Whats the weather in SF?\")]\n",
        "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
        "    for v in event.values():\n",
        "        print(v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzkY6uGUpKAN",
        "outputId": "b2157d8f-1177-493a-cb0e-b45cd7a3374d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'messages': [HumanMessage(content='Whats the weather in SF?', id='afc8b1e1-787d-47f1-853c-9cfe3ee84d77'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_mdMWl2szbkoyfAQMPcfeE4Lv', 'function': {'arguments': '{\"query\":\"weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-580085f4-5ee3-4518-952c-67f7a83a2142-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in San Francisco'}, 'id': 'call_mdMWl2szbkoyfAQMPcfeE4Lv'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173})]}\n",
            "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_mdMWl2szbkoyfAQMPcfeE4Lv', 'function': {'arguments': '{\"query\":\"weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-580085f4-5ee3-4518-952c-67f7a83a2142-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in San Francisco'}, 'id': 'call_mdMWl2szbkoyfAQMPcfeE4Lv'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173})]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abot.graph.get_state(thread)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UYPdNKcpJ9T",
        "outputId": "ab709321-4369-4ef3-94b3-54030f95194a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StateSnapshot(values={'messages': [HumanMessage(content='Whats the weather in SF?', id='afc8b1e1-787d-47f1-853c-9cfe3ee84d77'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_mdMWl2szbkoyfAQMPcfeE4Lv', 'function': {'arguments': '{\"query\":\"weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-580085f4-5ee3-4518-952c-67f7a83a2142-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in San Francisco'}, 'id': 'call_mdMWl2szbkoyfAQMPcfeE4Lv'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173})]}, next=('action',), config={'configurable': {'thread_id': '1', 'thread_ts': '1ef23697-96a0-6338-8001-bb7a7ea6c2dd'}}, metadata={'source': 'loop', 'step': 1, 'writes': {'llm': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_mdMWl2szbkoyfAQMPcfeE4Lv', 'function': {'arguments': '{\"query\":\"weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-580085f4-5ee3-4518-952c-67f7a83a2142-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in San Francisco'}, 'id': 'call_mdMWl2szbkoyfAQMPcfeE4Lv'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173})]}}}, created_at='2024-06-05T18:28:58.730333+00:00', parent_config={'configurable': {'thread_id': '1', 'thread_ts': '1ef23697-8ce6-6b3f-8000-2ebcf0e410f1'}})"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abot.graph.get_state(thread).next"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1MKJXAnpJ6x",
        "outputId": "8ccfb77f-52fe-4527-9aaa-22e88d9e0f22"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('action',)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**continue after interrupt**"
      ],
      "metadata": {
        "id": "BCd2cZr8pV_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for event in abot.graph.stream(None, thread):\n",
        "    for v in event.values():\n",
        "        print(v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moWw3OzipJ4F",
        "outputId": "240bd07a-ff2f-4710-9b5b-4034b243af1b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'weather in San Francisco'}, 'id': 'call_mdMWl2szbkoyfAQMPcfeE4Lv'}\n",
            "Back to the model!\n",
            "{'messages': [ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.78, \\'lon\\': -122.42, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1717612151, \\'localtime\\': \\'2024-06-05 11:29\\'}, \\'current\\': {\\'last_updated_epoch\\': 1717611300, \\'last_updated\\': \\'2024-06-05 11:15\\', \\'temp_c\\': 15.0, \\'temp_f\\': 59.0, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Mist\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/143.png\\', \\'code\\': 1030}, \\'wind_mph\\': 10.5, \\'wind_kph\\': 16.9, \\'wind_degree\\': 310, \\'wind_dir\\': \\'NW\\', \\'pressure_mb\\': 1013.0, \\'pressure_in\\': 29.91, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 82, \\'cloud\\': 0, \\'feelslike_c\\': 14.7, \\'feelslike_f\\': 58.5, \\'windchill_c\\': 18.6, \\'windchill_f\\': 65.4, \\'heatindex_c\\': 18.6, \\'heatindex_f\\': 65.4, \\'dewpoint_c\\': 11.9, \\'dewpoint_f\\': 53.5, \\'vis_km\\': 6.4, \\'vis_miles\\': 3.0, \\'uv\\': 5.0, \\'gust_mph\\': 15.0, \\'gust_kph\\': 24.1}}\"}, {\\'url\\': \\'https://weatherspark.com/h/m/557/2024/5/Historical-Weather-in-May-2024-in-San-Francisco-California-United-States\\', \\'content\\': \\'San Francisco Temperature History May 2024. The daily range of reported temperatures (gray bars) and 24-hour highs (red ticks) and lows (blue ticks), placed over the daily average high (faint red line) and low (faint blue line) temperature, with 25th to 75th and 10th to 90th percentile bands.\\'}]', name='tavily_search_results_json', tool_call_id='call_mdMWl2szbkoyfAQMPcfeE4Lv')]}\n",
            "{'messages': [HumanMessage(content='Whats the weather in SF?', id='afc8b1e1-787d-47f1-853c-9cfe3ee84d77'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_mdMWl2szbkoyfAQMPcfeE4Lv', 'function': {'arguments': '{\"query\":\"weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-580085f4-5ee3-4518-952c-67f7a83a2142-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in San Francisco'}, 'id': 'call_mdMWl2szbkoyfAQMPcfeE4Lv'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173}), ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.78, \\'lon\\': -122.42, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1717612151, \\'localtime\\': \\'2024-06-05 11:29\\'}, \\'current\\': {\\'last_updated_epoch\\': 1717611300, \\'last_updated\\': \\'2024-06-05 11:15\\', \\'temp_c\\': 15.0, \\'temp_f\\': 59.0, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Mist\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/143.png\\', \\'code\\': 1030}, \\'wind_mph\\': 10.5, \\'wind_kph\\': 16.9, \\'wind_degree\\': 310, \\'wind_dir\\': \\'NW\\', \\'pressure_mb\\': 1013.0, \\'pressure_in\\': 29.91, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 82, \\'cloud\\': 0, \\'feelslike_c\\': 14.7, \\'feelslike_f\\': 58.5, \\'windchill_c\\': 18.6, \\'windchill_f\\': 65.4, \\'heatindex_c\\': 18.6, \\'heatindex_f\\': 65.4, \\'dewpoint_c\\': 11.9, \\'dewpoint_f\\': 53.5, \\'vis_km\\': 6.4, \\'vis_miles\\': 3.0, \\'uv\\': 5.0, \\'gust_mph\\': 15.0, \\'gust_kph\\': 24.1}}\"}, {\\'url\\': \\'https://weatherspark.com/h/m/557/2024/5/Historical-Weather-in-May-2024-in-San-Francisco-California-United-States\\', \\'content\\': \\'San Francisco Temperature History May 2024. The daily range of reported temperatures (gray bars) and 24-hour highs (red ticks) and lows (blue ticks), placed over the daily average high (faint red line) and low (faint blue line) temperature, with 25th to 75th and 10th to 90th percentile bands.\\'}]', name='tavily_search_results_json', id='74b1426a-9c49-49f7-a645-e3cf3cffaf8a', tool_call_id='call_mdMWl2szbkoyfAQMPcfeE4Lv'), AIMessage(content='The current weather in San Francisco is as follows:\\n- Temperature: 15.0°C (59.0°F)\\n- Condition: Mist\\n- Wind: 10.5 mph from the northwest\\n- Pressure: 1013.0 mb\\n- Humidity: 82%\\n- Visibility: 6.4 km\\n\\nIf you need more detailed information or historical weather data, please let me know!', response_metadata={'token_usage': {'completion_tokens': 84, 'prompt_tokens': 714, 'total_tokens': 798}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f0f84812-4cc0-45e0-91dd-21b87d092f03-0', usage_metadata={'input_tokens': 714, 'output_tokens': 84, 'total_tokens': 798})]}\n",
            "{'messages': [AIMessage(content='The current weather in San Francisco is as follows:\\n- Temperature: 15.0°C (59.0°F)\\n- Condition: Mist\\n- Wind: 10.5 mph from the northwest\\n- Pressure: 1013.0 mb\\n- Humidity: 82%\\n- Visibility: 6.4 km\\n\\nIf you need more detailed information or historical weather data, please let me know!', response_metadata={'token_usage': {'completion_tokens': 84, 'prompt_tokens': 714, 'total_tokens': 798}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f0f84812-4cc0-45e0-91dd-21b87d092f03-0', usage_metadata={'input_tokens': 714, 'output_tokens': 84, 'total_tokens': 798})]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abot.graph.get_state(thread)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJc8dTNOpJ1U",
        "outputId": "9c6df466-8167-4c6e-8d2a-78b0baafd68e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StateSnapshot(values={'messages': [HumanMessage(content='Whats the weather in SF?', id='afc8b1e1-787d-47f1-853c-9cfe3ee84d77'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_mdMWl2szbkoyfAQMPcfeE4Lv', 'function': {'arguments': '{\"query\":\"weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-580085f4-5ee3-4518-952c-67f7a83a2142-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in San Francisco'}, 'id': 'call_mdMWl2szbkoyfAQMPcfeE4Lv'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173}), ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.78, \\'lon\\': -122.42, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1717612151, \\'localtime\\': \\'2024-06-05 11:29\\'}, \\'current\\': {\\'last_updated_epoch\\': 1717611300, \\'last_updated\\': \\'2024-06-05 11:15\\', \\'temp_c\\': 15.0, \\'temp_f\\': 59.0, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Mist\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/143.png\\', \\'code\\': 1030}, \\'wind_mph\\': 10.5, \\'wind_kph\\': 16.9, \\'wind_degree\\': 310, \\'wind_dir\\': \\'NW\\', \\'pressure_mb\\': 1013.0, \\'pressure_in\\': 29.91, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 82, \\'cloud\\': 0, \\'feelslike_c\\': 14.7, \\'feelslike_f\\': 58.5, \\'windchill_c\\': 18.6, \\'windchill_f\\': 65.4, \\'heatindex_c\\': 18.6, \\'heatindex_f\\': 65.4, \\'dewpoint_c\\': 11.9, \\'dewpoint_f\\': 53.5, \\'vis_km\\': 6.4, \\'vis_miles\\': 3.0, \\'uv\\': 5.0, \\'gust_mph\\': 15.0, \\'gust_kph\\': 24.1}}\"}, {\\'url\\': \\'https://weatherspark.com/h/m/557/2024/5/Historical-Weather-in-May-2024-in-San-Francisco-California-United-States\\', \\'content\\': \\'San Francisco Temperature History May 2024. The daily range of reported temperatures (gray bars) and 24-hour highs (red ticks) and lows (blue ticks), placed over the daily average high (faint red line) and low (faint blue line) temperature, with 25th to 75th and 10th to 90th percentile bands.\\'}]', name='tavily_search_results_json', id='74b1426a-9c49-49f7-a645-e3cf3cffaf8a', tool_call_id='call_mdMWl2szbkoyfAQMPcfeE4Lv'), AIMessage(content='The current weather in San Francisco is as follows:\\n- Temperature: 15.0°C (59.0°F)\\n- Condition: Mist\\n- Wind: 10.5 mph from the northwest\\n- Pressure: 1013.0 mb\\n- Humidity: 82%\\n- Visibility: 6.4 km\\n\\nIf you need more detailed information or historical weather data, please let me know!', response_metadata={'token_usage': {'completion_tokens': 84, 'prompt_tokens': 714, 'total_tokens': 798}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f0f84812-4cc0-45e0-91dd-21b87d092f03-0', usage_metadata={'input_tokens': 714, 'output_tokens': 84, 'total_tokens': 798})]}, next=(), config={'configurable': {'thread_id': '1', 'thread_ts': '1ef23699-85d8-6bd5-8003-b7b5b39f0293'}}, metadata={'source': 'loop', 'step': 3, 'writes': {'llm': {'messages': [AIMessage(content='The current weather in San Francisco is as follows:\\n- Temperature: 15.0°C (59.0°F)\\n- Condition: Mist\\n- Wind: 10.5 mph from the northwest\\n- Pressure: 1013.0 mb\\n- Humidity: 82%\\n- Visibility: 6.4 km\\n\\nIf you need more detailed information or historical weather data, please let me know!', response_metadata={'token_usage': {'completion_tokens': 84, 'prompt_tokens': 714, 'total_tokens': 798}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f0f84812-4cc0-45e0-91dd-21b87d092f03-0', usage_metadata={'input_tokens': 714, 'output_tokens': 84, 'total_tokens': 798})]}}}, created_at='2024-06-05T18:29:50.658017+00:00', parent_config={'configurable': {'thread_id': '1', 'thread_ts': '1ef23699-76d5-6595-8002-0c3be82ee2d8'}})"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abot.graph.get_state(thread).next"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTuYAdIOpZFV",
        "outputId": "a43f8842-1f06-4381-8772-b0db0dfff7b4"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "()"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [HumanMessage(\"Whats the weather in LA?\")]\n",
        "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
        "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
        "    for v in event.values():\n",
        "        print(v)\n",
        "while abot.graph.get_state(thread).next:\n",
        "    print(\"\\n\", abot.graph.get_state(thread),\"\\n\")\n",
        "    _input = input(\"proceed?\")\n",
        "    if _input != \"y\":\n",
        "        print(\"aborting\")\n",
        "        break\n",
        "    for event in abot.graph.stream(None, thread):\n",
        "        for v in event.values():\n",
        "            print(v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppLcGO4apZC1",
        "outputId": "92056009-f231-4f83-da8a-e2ade50d5ed7"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'messages': [HumanMessage(content='Whats the weather in LA?', id='c26ccab9-9398-4a8d-9b3f-8368af8cdbdf'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_4ZSkUmLv9xQtbL5EbjHJE82p', 'function': {'arguments': '{\"query\":\"weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-0e8a29b6-2223-42ac-b60c-d8f428df70c9-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in Los Angeles'}, 'id': 'call_4ZSkUmLv9xQtbL5EbjHJE82p'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173})]}\n",
            "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_4ZSkUmLv9xQtbL5EbjHJE82p', 'function': {'arguments': '{\"query\":\"weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-0e8a29b6-2223-42ac-b60c-d8f428df70c9-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in Los Angeles'}, 'id': 'call_4ZSkUmLv9xQtbL5EbjHJE82p'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173})]}\n",
            "\n",
            " StateSnapshot(values={'messages': [HumanMessage(content='Whats the weather in LA?', id='c26ccab9-9398-4a8d-9b3f-8368af8cdbdf'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_4ZSkUmLv9xQtbL5EbjHJE82p', 'function': {'arguments': '{\"query\":\"weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-0e8a29b6-2223-42ac-b60c-d8f428df70c9-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in Los Angeles'}, 'id': 'call_4ZSkUmLv9xQtbL5EbjHJE82p'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173})]}, next=('action',), config={'configurable': {'thread_id': '2', 'thread_ts': '1ef2369a-8289-69ba-8001-0b7ddae7882f'}}, metadata={'source': 'loop', 'step': 1, 'writes': {'llm': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_4ZSkUmLv9xQtbL5EbjHJE82p', 'function': {'arguments': '{\"query\":\"weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-0e8a29b6-2223-42ac-b60c-d8f428df70c9-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in Los Angeles'}, 'id': 'call_4ZSkUmLv9xQtbL5EbjHJE82p'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173})]}}}, created_at='2024-06-05T18:30:17.154581+00:00', parent_config={'configurable': {'thread_id': '2', 'thread_ts': '1ef2369a-7bef-69ce-8000-9b5792958c25'}}) \n",
            "\n",
            "proceed?y\n",
            "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'weather in Los Angeles'}, 'id': 'call_4ZSkUmLv9xQtbL5EbjHJE82p'}\n",
            "Back to the model!\n",
            "{'messages': [ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'Los Angeles\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 34.05, \\'lon\\': -118.24, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1717612186, \\'localtime\\': \\'2024-06-05 11:29\\'}, \\'current\\': {\\'last_updated_epoch\\': 1717611300, \\'last_updated\\': \\'2024-06-05 11:15\\', \\'temp_c\\': 22.0, \\'temp_f\\': 71.6, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Mist\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/143.png\\', \\'code\\': 1030}, \\'wind_mph\\': 5.6, \\'wind_kph\\': 9.0, \\'wind_degree\\': 200, \\'wind_dir\\': \\'SSW\\', \\'pressure_mb\\': 1013.0, \\'pressure_in\\': 29.9, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 65, \\'cloud\\': 0, \\'feelslike_c\\': 24.5, \\'feelslike_f\\': 76.0, \\'windchill_c\\': 24.3, \\'windchill_f\\': 75.8, \\'heatindex_c\\': 25.3, \\'heatindex_f\\': 77.6, \\'dewpoint_c\\': 13.8, \\'dewpoint_f\\': 56.8, \\'vis_km\\': 9.7, \\'vis_miles\\': 6.0, \\'uv\\': 6.0, \\'gust_mph\\': 7.7, \\'gust_kph\\': 12.4}}\"}, {\\'url\\': \\'https://www.timeanddate.com/weather/usa/los-angeles/historic\\', \\'content\\': \\'Los Angeles Weather History for the Previous 24 Hours Show weather for: Previous 24 hours June 4, 2024 June 3, 2024 June 2, 2024 June 1, 2024 May 31, 2024 May 30, 2024 May 29, 2024 May 28, 2024 May 27, 2024 May 26, 2024 May 25, 2024 May 24, 2024 May 23, 2024 May 22, 2024 May 21, 2024 May 20, 2024\\'}]', name='tavily_search_results_json', tool_call_id='call_4ZSkUmLv9xQtbL5EbjHJE82p')]}\n",
            "{'messages': [HumanMessage(content='Whats the weather in LA?', id='c26ccab9-9398-4a8d-9b3f-8368af8cdbdf'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_4ZSkUmLv9xQtbL5EbjHJE82p', 'function': {'arguments': '{\"query\":\"weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-0e8a29b6-2223-42ac-b60c-d8f428df70c9-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in Los Angeles'}, 'id': 'call_4ZSkUmLv9xQtbL5EbjHJE82p'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173}), ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'Los Angeles\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 34.05, \\'lon\\': -118.24, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1717612186, \\'localtime\\': \\'2024-06-05 11:29\\'}, \\'current\\': {\\'last_updated_epoch\\': 1717611300, \\'last_updated\\': \\'2024-06-05 11:15\\', \\'temp_c\\': 22.0, \\'temp_f\\': 71.6, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Mist\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/143.png\\', \\'code\\': 1030}, \\'wind_mph\\': 5.6, \\'wind_kph\\': 9.0, \\'wind_degree\\': 200, \\'wind_dir\\': \\'SSW\\', \\'pressure_mb\\': 1013.0, \\'pressure_in\\': 29.9, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 65, \\'cloud\\': 0, \\'feelslike_c\\': 24.5, \\'feelslike_f\\': 76.0, \\'windchill_c\\': 24.3, \\'windchill_f\\': 75.8, \\'heatindex_c\\': 25.3, \\'heatindex_f\\': 77.6, \\'dewpoint_c\\': 13.8, \\'dewpoint_f\\': 56.8, \\'vis_km\\': 9.7, \\'vis_miles\\': 6.0, \\'uv\\': 6.0, \\'gust_mph\\': 7.7, \\'gust_kph\\': 12.4}}\"}, {\\'url\\': \\'https://www.timeanddate.com/weather/usa/los-angeles/historic\\', \\'content\\': \\'Los Angeles Weather History for the Previous 24 Hours Show weather for: Previous 24 hours June 4, 2024 June 3, 2024 June 2, 2024 June 1, 2024 May 31, 2024 May 30, 2024 May 29, 2024 May 28, 2024 May 27, 2024 May 26, 2024 May 25, 2024 May 24, 2024 May 23, 2024 May 22, 2024 May 21, 2024 May 20, 2024\\'}]', name='tavily_search_results_json', id='47c3834a-65fe-40e3-8a1f-6cf2f620edad', tool_call_id='call_4ZSkUmLv9xQtbL5EbjHJE82p'), AIMessage(content='The current weather in Los Angeles is as follows:\\n- Temperature: 22.0°C (71.6°F)\\n- Condition: Mist\\n- Wind: 5.6 mph from SSW\\n- Humidity: 65%\\n- Visibility: 6.0 miles\\n- UV Index: 6.0\\n\\nIf you need more detailed information or historical weather data, please let me know!', response_metadata={'token_usage': {'completion_tokens': 83, 'prompt_tokens': 752, 'total_tokens': 835}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-6c2be66e-13e8-496b-82ed-de772c5241cd-0', usage_metadata={'input_tokens': 752, 'output_tokens': 83, 'total_tokens': 835})]}\n",
            "{'messages': [AIMessage(content='The current weather in Los Angeles is as follows:\\n- Temperature: 22.0°C (71.6°F)\\n- Condition: Mist\\n- Wind: 5.6 mph from SSW\\n- Humidity: 65%\\n- Visibility: 6.0 miles\\n- UV Index: 6.0\\n\\nIf you need more detailed information or historical weather data, please let me know!', response_metadata={'token_usage': {'completion_tokens': 83, 'prompt_tokens': 752, 'total_tokens': 835}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-6c2be66e-13e8-496b-82ed-de772c5241cd-0', usage_metadata={'input_tokens': 752, 'output_tokens': 83, 'total_tokens': 835})]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modifying Graph State"
      ],
      "metadata": {
        "id": "9UJsipiCs5uQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "requires runnning the `Human in the loop` section first."
      ],
      "metadata": {
        "id": "aqKZb4Ifs_RI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modify State**\n",
        "\n",
        "Run until the interrupt and then modify the state."
      ],
      "metadata": {
        "id": "cmKwkMuNpdg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [HumanMessage(\"Whats the weather in LA?\")]\n",
        "thread = {\"configurable\": {\"thread_id\": \"3\"}}\n",
        "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
        "    for v in event.values():\n",
        "        print(v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNuxCovbpY_7",
        "outputId": "b3ce5b06-abc0-4f26-90c7-3eb3ad6c03dd"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'messages': [HumanMessage(content='Whats the weather in LA?', id='a517b9d5-ac86-45d9-aa46-d34fd3c11dc5'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_60W51T7TZrBh61shlJb7thBp', 'function': {'arguments': '{\"query\":\"weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-06f906d7-1bad-4ee2-bbc1-07a4e6bbf994-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in Los Angeles'}, 'id': 'call_60W51T7TZrBh61shlJb7thBp'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173})]}\n",
            "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_60W51T7TZrBh61shlJb7thBp', 'function': {'arguments': '{\"query\":\"weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-06f906d7-1bad-4ee2-bbc1-07a4e6bbf994-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in Los Angeles'}, 'id': 'call_60W51T7TZrBh61shlJb7thBp'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173})]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abot.graph.get_state(thread)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVoucr7upY9U",
        "outputId": "8e86fc76-17e4-4fa6-dabd-8bc1da016c10"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StateSnapshot(values={'messages': [HumanMessage(content='Whats the weather in LA?', id='a517b9d5-ac86-45d9-aa46-d34fd3c11dc5'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_60W51T7TZrBh61shlJb7thBp', 'function': {'arguments': '{\"query\":\"weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-06f906d7-1bad-4ee2-bbc1-07a4e6bbf994-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in Los Angeles'}, 'id': 'call_60W51T7TZrBh61shlJb7thBp'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173})]}, next=('action',), config={'configurable': {'thread_id': '3', 'thread_ts': '1ef236a5-aec2-6a37-8001-5f009c95fa18'}}, metadata={'source': 'loop', 'step': 1, 'writes': {'llm': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_60W51T7TZrBh61shlJb7thBp', 'function': {'arguments': '{\"query\":\"weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-06f906d7-1bad-4ee2-bbc1-07a4e6bbf994-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in Los Angeles'}, 'id': 'call_60W51T7TZrBh61shlJb7thBp'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173})]}}}, created_at='2024-06-05T18:35:17.070675+00:00', parent_config={'configurable': {'thread_id': '3', 'thread_ts': '1ef236a5-a7ee-639c-8000-51c27f4ee543'}})"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "current_values = abot.graph.get_state(thread)"
      ],
      "metadata": {
        "id": "oJe4Kd-npY6m"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "current_values.values['messages'][-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCHnW8a4pY3o",
        "outputId": "8f4f81a6-971f-4d7b-803b-8f654676db63"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_60W51T7TZrBh61shlJb7thBp', 'function': {'arguments': '{\"query\":\"weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-06f906d7-1bad-4ee2-bbc1-07a4e6bbf994-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in Los Angeles'}, 'id': 'call_60W51T7TZrBh61shlJb7thBp'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173})"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "current_values.values['messages'][-1].tool_calls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97WR_oDmpJyj",
        "outputId": "77ddc95b-1d6c-4d3b-8a8d-86c1e5344f6a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'tavily_search_results_json',\n",
              "  'args': {'query': 'weather in Los Angeles'},\n",
              "  'id': 'call_60W51T7TZrBh61shlJb7thBp'}]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_id = current_values.values['messages'][-1].tool_calls[0]['id']\n",
        "current_values.values['messages'][-1].tool_calls = [\n",
        "    {'name': 'tavily_search_results_json',\n",
        "  'args': {'query': 'current weather in Louisiana'},\n",
        "  'id': _id}\n",
        "]"
      ],
      "metadata": {
        "id": "YQfxWBoVpiPd"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "abot.graph.update_state(thread, current_values.values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83OvS4zipiNR",
        "outputId": "e7e3dbd4-2e3a-4cbe-cf8d-cc45009d207d"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'messages': [HumanMessage(content='Whats the weather in LA?', id='a517b9d5-ac86-45d9-aa46-d34fd3c11dc5'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_60W51T7TZrBh61shlJb7thBp', 'function': {'arguments': '{\"query\":\"weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-06f906d7-1bad-4ee2-bbc1-07a4e6bbf994-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Louisiana'}, 'id': 'call_60W51T7TZrBh61shlJb7thBp'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173})]}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'configurable': {'thread_id': '3',\n",
              "  'thread_ts': '1ef236a9-796e-6fca-8002-c57684e161f5'}}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abot.graph.get_state(thread)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLcOYaEvpiKf",
        "outputId": "92788dc4-23ef-4867-c491-26b08bc0e3d8"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StateSnapshot(values={'messages': [HumanMessage(content='Whats the weather in LA?', id='a517b9d5-ac86-45d9-aa46-d34fd3c11dc5'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_60W51T7TZrBh61shlJb7thBp', 'function': {'arguments': '{\"query\":\"weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-06f906d7-1bad-4ee2-bbc1-07a4e6bbf994-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Louisiana'}, 'id': 'call_60W51T7TZrBh61shlJb7thBp'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173})]}, next=('action',), config={'configurable': {'thread_id': '3', 'thread_ts': '1ef236a9-796e-6fca-8002-c57684e161f5'}}, metadata={'source': 'update', 'step': 2, 'writes': {'llm': {'messages': [HumanMessage(content='Whats the weather in LA?', id='a517b9d5-ac86-45d9-aa46-d34fd3c11dc5'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_60W51T7TZrBh61shlJb7thBp', 'function': {'arguments': '{\"query\":\"weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-06f906d7-1bad-4ee2-bbc1-07a4e6bbf994-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Louisiana'}, 'id': 'call_60W51T7TZrBh61shlJb7thBp'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173})]}}}, created_at='2024-06-05T18:36:58.853141+00:00', parent_config={'configurable': {'thread_id': '3', 'thread_ts': '1ef236a5-aec2-6a37-8001-5f009c95fa18'}})"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for event in abot.graph.stream(None, thread):\n",
        "    for v in event.values():\n",
        "        print(v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59U9pLjZpkx4",
        "outputId": "a5740e09-b098-4382-93e8-b1bf8a116063"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Louisiana'}, 'id': 'call_60W51T7TZrBh61shlJb7thBp'}\n",
            "Back to the model!\n",
            "{'messages': [ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'Louisiana\\', \\'region\\': \\'Missouri\\', \\'country\\': \\'USA United States of America\\', \\'lat\\': 39.44, \\'lon\\': -91.06, \\'tz_id\\': \\'America/Chicago\\', \\'localtime_epoch\\': 1717612587, \\'localtime\\': \\'2024-06-05 13:36\\'}, \\'current\\': {\\'last_updated_epoch\\': 1717612200, \\'last_updated\\': \\'2024-06-05 13:30\\', \\'temp_c\\': 24.5, \\'temp_f\\': 76.1, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Sunny\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/113.png\\', \\'code\\': 1000}, \\'wind_mph\\': 3.8, \\'wind_kph\\': 6.1, \\'wind_degree\\': 280, \\'wind_dir\\': \\'W\\', \\'pressure_mb\\': 1007.0, \\'pressure_in\\': 29.73, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 57, \\'cloud\\': 0, \\'feelslike_c\\': 25.8, \\'feelslike_f\\': 78.4, \\'windchill_c\\': 23.0, \\'windchill_f\\': 73.4, \\'heatindex_c\\': 24.7, \\'heatindex_f\\': 76.4, \\'dewpoint_c\\': 14.8, \\'dewpoint_f\\': 58.6, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 6.0, \\'gust_mph\\': 12.6, \\'gust_kph\\': 20.3}}\"}, {\\'url\\': \\'https://www.kplctv.com/2024/06/05/first-alert-forecast-scattered-activity-still-trying-push-into-area-warm-humid-conditions-continue/\\', \\'content\\': \\'LAKE CHARLES, La. (KPLC) - Clusters of storms continue to occasionally ride into SWLA as warm and humid weather holds across the area. Still looking at a slightly drier weekend. Wednesday is keeping with the warmer and humid trend, but we might have some potential to see showers and storms a little sooner than yesterday.\\'}]', name='tavily_search_results_json', tool_call_id='call_60W51T7TZrBh61shlJb7thBp')]}\n",
            "{'messages': [HumanMessage(content='Whats the weather in LA?', id='a517b9d5-ac86-45d9-aa46-d34fd3c11dc5'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_60W51T7TZrBh61shlJb7thBp', 'function': {'arguments': '{\"query\":\"weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-06f906d7-1bad-4ee2-bbc1-07a4e6bbf994-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Louisiana'}, 'id': 'call_60W51T7TZrBh61shlJb7thBp'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173}), ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'Louisiana\\', \\'region\\': \\'Missouri\\', \\'country\\': \\'USA United States of America\\', \\'lat\\': 39.44, \\'lon\\': -91.06, \\'tz_id\\': \\'America/Chicago\\', \\'localtime_epoch\\': 1717612587, \\'localtime\\': \\'2024-06-05 13:36\\'}, \\'current\\': {\\'last_updated_epoch\\': 1717612200, \\'last_updated\\': \\'2024-06-05 13:30\\', \\'temp_c\\': 24.5, \\'temp_f\\': 76.1, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Sunny\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/113.png\\', \\'code\\': 1000}, \\'wind_mph\\': 3.8, \\'wind_kph\\': 6.1, \\'wind_degree\\': 280, \\'wind_dir\\': \\'W\\', \\'pressure_mb\\': 1007.0, \\'pressure_in\\': 29.73, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 57, \\'cloud\\': 0, \\'feelslike_c\\': 25.8, \\'feelslike_f\\': 78.4, \\'windchill_c\\': 23.0, \\'windchill_f\\': 73.4, \\'heatindex_c\\': 24.7, \\'heatindex_f\\': 76.4, \\'dewpoint_c\\': 14.8, \\'dewpoint_f\\': 58.6, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 6.0, \\'gust_mph\\': 12.6, \\'gust_kph\\': 20.3}}\"}, {\\'url\\': \\'https://www.kplctv.com/2024/06/05/first-alert-forecast-scattered-activity-still-trying-push-into-area-warm-humid-conditions-continue/\\', \\'content\\': \\'LAKE CHARLES, La. (KPLC) - Clusters of storms continue to occasionally ride into SWLA as warm and humid weather holds across the area. Still looking at a slightly drier weekend. Wednesday is keeping with the warmer and humid trend, but we might have some potential to see showers and storms a little sooner than yesterday.\\'}]', name='tavily_search_results_json', id='f81653ac-328b-47cb-878b-50afa2a8271c', tool_call_id='call_60W51T7TZrBh61shlJb7thBp'), AIMessage(content='The current weather in Louisiana is sunny with a temperature of 76.1°F (24.5°C). The wind speed is 3.8 mph coming from the west. The humidity is at 57%.', response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 712, 'total_tokens': 756}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-83292e02-f223-4439-931f-34dafb0429c6-0', usage_metadata={'input_tokens': 712, 'output_tokens': 44, 'total_tokens': 756})]}\n",
            "{'messages': [AIMessage(content='The current weather in Louisiana is sunny with a temperature of 76.1°F (24.5°C). The wind speed is 3.8 mph coming from the west. The humidity is at 57%.', response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 712, 'total_tokens': 756}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-83292e02-f223-4439-931f-34dafb0429c6-0', usage_metadata={'input_tokens': 712, 'output_tokens': 44, 'total_tokens': 756})]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Time Travel**"
      ],
      "metadata": {
        "id": "yuisv7AUppdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "states = []\n",
        "for state in abot.graph.get_state_history(thread):\n",
        "    print(state)\n",
        "    print('--')\n",
        "    states.append(state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UJe0eXRpkvE",
        "outputId": "f6aabbb0-3c71-4fa0-fb72-e0c2fbd51d8d"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "StateSnapshot(values={'messages': [HumanMessage(content='Whats the weather in LA?', id='a517b9d5-ac86-45d9-aa46-d34fd3c11dc5'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_60W51T7TZrBh61shlJb7thBp', 'function': {'arguments': '{\"query\":\"weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-06f906d7-1bad-4ee2-bbc1-07a4e6bbf994-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Louisiana'}, 'id': 'call_60W51T7TZrBh61shlJb7thBp'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173}), ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'Louisiana\\', \\'region\\': \\'Missouri\\', \\'country\\': \\'USA United States of America\\', \\'lat\\': 39.44, \\'lon\\': -91.06, \\'tz_id\\': \\'America/Chicago\\', \\'localtime_epoch\\': 1717612587, \\'localtime\\': \\'2024-06-05 13:36\\'}, \\'current\\': {\\'last_updated_epoch\\': 1717612200, \\'last_updated\\': \\'2024-06-05 13:30\\', \\'temp_c\\': 24.5, \\'temp_f\\': 76.1, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Sunny\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/113.png\\', \\'code\\': 1000}, \\'wind_mph\\': 3.8, \\'wind_kph\\': 6.1, \\'wind_degree\\': 280, \\'wind_dir\\': \\'W\\', \\'pressure_mb\\': 1007.0, \\'pressure_in\\': 29.73, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 57, \\'cloud\\': 0, \\'feelslike_c\\': 25.8, \\'feelslike_f\\': 78.4, \\'windchill_c\\': 23.0, \\'windchill_f\\': 73.4, \\'heatindex_c\\': 24.7, \\'heatindex_f\\': 76.4, \\'dewpoint_c\\': 14.8, \\'dewpoint_f\\': 58.6, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 6.0, \\'gust_mph\\': 12.6, \\'gust_kph\\': 20.3}}\"}, {\\'url\\': \\'https://www.kplctv.com/2024/06/05/first-alert-forecast-scattered-activity-still-trying-push-into-area-warm-humid-conditions-continue/\\', \\'content\\': \\'LAKE CHARLES, La. (KPLC) - Clusters of storms continue to occasionally ride into SWLA as warm and humid weather holds across the area. Still looking at a slightly drier weekend. Wednesday is keeping with the warmer and humid trend, but we might have some potential to see showers and storms a little sooner than yesterday.\\'}]', name='tavily_search_results_json', id='f81653ac-328b-47cb-878b-50afa2a8271c', tool_call_id='call_60W51T7TZrBh61shlJb7thBp'), AIMessage(content='The current weather in Louisiana is sunny with a temperature of 76.1°F (24.5°C). The wind speed is 3.8 mph coming from the west. The humidity is at 57%.', response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 712, 'total_tokens': 756}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-83292e02-f223-4439-931f-34dafb0429c6-0', usage_metadata={'input_tokens': 712, 'output_tokens': 44, 'total_tokens': 756})]}, next=(), config={'configurable': {'thread_id': '3', 'thread_ts': '1ef236a9-c029-6214-8004-0faeb65cc423'}}, metadata={'source': 'loop', 'step': 4, 'writes': {'llm': {'messages': [AIMessage(content='The current weather in Louisiana is sunny with a temperature of 76.1°F (24.5°C). The wind speed is 3.8 mph coming from the west. The humidity is at 57%.', response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 712, 'total_tokens': 756}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-83292e02-f223-4439-931f-34dafb0429c6-0', usage_metadata={'input_tokens': 712, 'output_tokens': 44, 'total_tokens': 756})]}}}, created_at='2024-06-05T18:37:06.269421+00:00', parent_config={'configurable': {'thread_id': '3', 'thread_ts': '1ef236a9-b695-66c9-8003-b5c4fd866321'}})\n",
            "--\n",
            "StateSnapshot(values={'messages': [HumanMessage(content='Whats the weather in LA?', id='a517b9d5-ac86-45d9-aa46-d34fd3c11dc5'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_60W51T7TZrBh61shlJb7thBp', 'function': {'arguments': '{\"query\":\"weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-06f906d7-1bad-4ee2-bbc1-07a4e6bbf994-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Louisiana'}, 'id': 'call_60W51T7TZrBh61shlJb7thBp'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173}), ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'Louisiana\\', \\'region\\': \\'Missouri\\', \\'country\\': \\'USA United States of America\\', \\'lat\\': 39.44, \\'lon\\': -91.06, \\'tz_id\\': \\'America/Chicago\\', \\'localtime_epoch\\': 1717612587, \\'localtime\\': \\'2024-06-05 13:36\\'}, \\'current\\': {\\'last_updated_epoch\\': 1717612200, \\'last_updated\\': \\'2024-06-05 13:30\\', \\'temp_c\\': 24.5, \\'temp_f\\': 76.1, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Sunny\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/113.png\\', \\'code\\': 1000}, \\'wind_mph\\': 3.8, \\'wind_kph\\': 6.1, \\'wind_degree\\': 280, \\'wind_dir\\': \\'W\\', \\'pressure_mb\\': 1007.0, \\'pressure_in\\': 29.73, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 57, \\'cloud\\': 0, \\'feelslike_c\\': 25.8, \\'feelslike_f\\': 78.4, \\'windchill_c\\': 23.0, \\'windchill_f\\': 73.4, \\'heatindex_c\\': 24.7, \\'heatindex_f\\': 76.4, \\'dewpoint_c\\': 14.8, \\'dewpoint_f\\': 58.6, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 6.0, \\'gust_mph\\': 12.6, \\'gust_kph\\': 20.3}}\"}, {\\'url\\': \\'https://www.kplctv.com/2024/06/05/first-alert-forecast-scattered-activity-still-trying-push-into-area-warm-humid-conditions-continue/\\', \\'content\\': \\'LAKE CHARLES, La. (KPLC) - Clusters of storms continue to occasionally ride into SWLA as warm and humid weather holds across the area. Still looking at a slightly drier weekend. Wednesday is keeping with the warmer and humid trend, but we might have some potential to see showers and storms a little sooner than yesterday.\\'}]', name='tavily_search_results_json', id='f81653ac-328b-47cb-878b-50afa2a8271c', tool_call_id='call_60W51T7TZrBh61shlJb7thBp')]}, next=('llm',), config={'configurable': {'thread_id': '3', 'thread_ts': '1ef236a9-b695-66c9-8003-b5c4fd866321'}}, metadata={'source': 'loop', 'step': 3, 'writes': {'action': {'messages': [ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'Louisiana\\', \\'region\\': \\'Missouri\\', \\'country\\': \\'USA United States of America\\', \\'lat\\': 39.44, \\'lon\\': -91.06, \\'tz_id\\': \\'America/Chicago\\', \\'localtime_epoch\\': 1717612587, \\'localtime\\': \\'2024-06-05 13:36\\'}, \\'current\\': {\\'last_updated_epoch\\': 1717612200, \\'last_updated\\': \\'2024-06-05 13:30\\', \\'temp_c\\': 24.5, \\'temp_f\\': 76.1, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Sunny\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/113.png\\', \\'code\\': 1000}, \\'wind_mph\\': 3.8, \\'wind_kph\\': 6.1, \\'wind_degree\\': 280, \\'wind_dir\\': \\'W\\', \\'pressure_mb\\': 1007.0, \\'pressure_in\\': 29.73, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 57, \\'cloud\\': 0, \\'feelslike_c\\': 25.8, \\'feelslike_f\\': 78.4, \\'windchill_c\\': 23.0, \\'windchill_f\\': 73.4, \\'heatindex_c\\': 24.7, \\'heatindex_f\\': 76.4, \\'dewpoint_c\\': 14.8, \\'dewpoint_f\\': 58.6, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 6.0, \\'gust_mph\\': 12.6, \\'gust_kph\\': 20.3}}\"}, {\\'url\\': \\'https://www.kplctv.com/2024/06/05/first-alert-forecast-scattered-activity-still-trying-push-into-area-warm-humid-conditions-continue/\\', \\'content\\': \\'LAKE CHARLES, La. (KPLC) - Clusters of storms continue to occasionally ride into SWLA as warm and humid weather holds across the area. Still looking at a slightly drier weekend. Wednesday is keeping with the warmer and humid trend, but we might have some potential to see showers and storms a little sooner than yesterday.\\'}]', name='tavily_search_results_json', id='f81653ac-328b-47cb-878b-50afa2a8271c', tool_call_id='call_60W51T7TZrBh61shlJb7thBp')]}}}, created_at='2024-06-05T18:37:05.265194+00:00', parent_config={'configurable': {'thread_id': '3', 'thread_ts': '1ef236a9-796e-6fca-8002-c57684e161f5'}})\n",
            "--\n",
            "StateSnapshot(values={'messages': [HumanMessage(content='Whats the weather in LA?', id='a517b9d5-ac86-45d9-aa46-d34fd3c11dc5'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_60W51T7TZrBh61shlJb7thBp', 'function': {'arguments': '{\"query\":\"weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-06f906d7-1bad-4ee2-bbc1-07a4e6bbf994-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Louisiana'}, 'id': 'call_60W51T7TZrBh61shlJb7thBp'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173})]}, next=('action',), config={'configurable': {'thread_id': '3', 'thread_ts': '1ef236a9-796e-6fca-8002-c57684e161f5'}}, metadata={'source': 'update', 'step': 2, 'writes': {'llm': {'messages': [HumanMessage(content='Whats the weather in LA?', id='a517b9d5-ac86-45d9-aa46-d34fd3c11dc5'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_60W51T7TZrBh61shlJb7thBp', 'function': {'arguments': '{\"query\":\"weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-06f906d7-1bad-4ee2-bbc1-07a4e6bbf994-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Louisiana'}, 'id': 'call_60W51T7TZrBh61shlJb7thBp'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173})]}}}, created_at='2024-06-05T18:36:58.853141+00:00', parent_config={'configurable': {'thread_id': '3', 'thread_ts': '1ef236a5-aec2-6a37-8001-5f009c95fa18'}})\n",
            "--\n",
            "StateSnapshot(values={'messages': [HumanMessage(content='Whats the weather in LA?', id='a517b9d5-ac86-45d9-aa46-d34fd3c11dc5'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_60W51T7TZrBh61shlJb7thBp', 'function': {'arguments': '{\"query\":\"weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-06f906d7-1bad-4ee2-bbc1-07a4e6bbf994-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in Los Angeles'}, 'id': 'call_60W51T7TZrBh61shlJb7thBp'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173})]}, next=('action',), config={'configurable': {'thread_id': '3', 'thread_ts': '1ef236a5-aec2-6a37-8001-5f009c95fa18'}}, metadata={'source': 'loop', 'step': 1, 'writes': {'llm': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_60W51T7TZrBh61shlJb7thBp', 'function': {'arguments': '{\"query\":\"weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-06f906d7-1bad-4ee2-bbc1-07a4e6bbf994-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in Los Angeles'}, 'id': 'call_60W51T7TZrBh61shlJb7thBp'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173})]}}}, created_at='2024-06-05T18:35:17.070675+00:00', parent_config={'configurable': {'thread_id': '3', 'thread_ts': '1ef236a5-a7ee-639c-8000-51c27f4ee543'}})\n",
            "--\n",
            "StateSnapshot(values={'messages': [HumanMessage(content='Whats the weather in LA?', id='a517b9d5-ac86-45d9-aa46-d34fd3c11dc5')]}, next=('llm',), config={'configurable': {'thread_id': '3', 'thread_ts': '1ef236a5-a7ee-639c-8000-51c27f4ee543'}}, metadata={'source': 'loop', 'step': 0, 'writes': None}, created_at='2024-06-05T18:35:16.354514+00:00', parent_config={'configurable': {'thread_id': '3', 'thread_ts': '1ef236a5-a7e3-6d5b-bfff-634a1ea4f125'}})\n",
            "--\n",
            "StateSnapshot(values={'messages': []}, next=('__start__',), config={'configurable': {'thread_id': '3', 'thread_ts': '1ef236a5-a7e3-6d5b-bfff-634a1ea4f125'}}, metadata={'source': 'input', 'step': -1, 'writes': {'messages': [HumanMessage(content='Whats the weather in LA?')]}}, created_at='2024-06-05T18:35:16.350272+00:00', parent_config=None)\n",
            "--\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To fetch the same state as was filmed, the offset below is changed to -3 from -1. This accounts for the initial state __start__ and the first state that are now stored to state memory with the latest version of software."
      ],
      "metadata": {
        "id": "kWLoIG-epsDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "to_replay = states[-3]"
      ],
      "metadata": {
        "id": "X6_g0MRYpkr_"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_replay"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0p1kCtJpkpK",
        "outputId": "519e67e0-2dd1-4e94-8a58-c365041a0095"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StateSnapshot(values={'messages': [HumanMessage(content='Whats the weather in LA?', id='a517b9d5-ac86-45d9-aa46-d34fd3c11dc5'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_60W51T7TZrBh61shlJb7thBp', 'function': {'arguments': '{\"query\":\"weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-06f906d7-1bad-4ee2-bbc1-07a4e6bbf994-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in Los Angeles'}, 'id': 'call_60W51T7TZrBh61shlJb7thBp'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173})]}, next=('action',), config={'configurable': {'thread_id': '3', 'thread_ts': '1ef236a5-aec2-6a37-8001-5f009c95fa18'}}, metadata={'source': 'loop', 'step': 1, 'writes': {'llm': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_60W51T7TZrBh61shlJb7thBp', 'function': {'arguments': '{\"query\":\"weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-06f906d7-1bad-4ee2-bbc1-07a4e6bbf994-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in Los Angeles'}, 'id': 'call_60W51T7TZrBh61shlJb7thBp'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173})]}}}, created_at='2024-06-05T18:35:17.070675+00:00', parent_config={'configurable': {'thread_id': '3', 'thread_ts': '1ef236a5-a7ee-639c-8000-51c27f4ee543'}})"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "branch_state = abot.graph.update_state(to_replay.config, to_replay.values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVCkVCDxsbXj",
        "outputId": "b41efc88-36e7-4c87-845a-94a3590b3591"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'messages': [HumanMessage(content='Whats the weather in LA?', id='a517b9d5-ac86-45d9-aa46-d34fd3c11dc5'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_60W51T7TZrBh61shlJb7thBp', 'function': {'arguments': '{\"query\":\"weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-06f906d7-1bad-4ee2-bbc1-07a4e6bbf994-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in LA, accuweather'}, 'id': 'call_60W51T7TZrBh61shlJb7thBp'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173})]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for event in abot.graph.stream(None, to_replay.config):\n",
        "    for k, v in event.items():\n",
        "        print(v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rn1TB5vNptKv",
        "outputId": "41d1f285-1fc3-4a60-f433-ad7d951252ca"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'weather in Los Angeles'}, 'id': 'call_60W51T7TZrBh61shlJb7thBp'}\n",
            "Back to the model!\n",
            "{'messages': [ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'Los Angeles\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 34.05, \\'lon\\': -118.24, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1717612600, \\'localtime\\': \\'2024-06-05 11:36\\'}, \\'current\\': {\\'last_updated_epoch\\': 1717612200, \\'last_updated\\': \\'2024-06-05 11:30\\', \\'temp_c\\': 22.0, \\'temp_f\\': 71.6, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Mist\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/143.png\\', \\'code\\': 1030}, \\'wind_mph\\': 5.6, \\'wind_kph\\': 9.0, \\'wind_degree\\': 200, \\'wind_dir\\': \\'SSW\\', \\'pressure_mb\\': 1013.0, \\'pressure_in\\': 29.9, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 65, \\'cloud\\': 0, \\'feelslike_c\\': 24.5, \\'feelslike_f\\': 76.0, \\'windchill_c\\': 24.3, \\'windchill_f\\': 75.8, \\'heatindex_c\\': 25.3, \\'heatindex_f\\': 77.6, \\'dewpoint_c\\': 13.8, \\'dewpoint_f\\': 56.8, \\'vis_km\\': 9.7, \\'vis_miles\\': 6.0, \\'uv\\': 6.0, \\'gust_mph\\': 7.7, \\'gust_kph\\': 12.4}}\"}, {\\'url\\': \\'https://www.wunderground.com/hourly/us/ca/los-angeles/90050/date/2024-06-05\\', \\'content\\': \\'Los Angeles Weather Forecasts. Weather Underground provides local & long-range weather forecasts, weatherreports, maps & tropical weather conditions for the Los Angeles area. ... Wednesday 06/05 ...\\'}]', name='tavily_search_results_json', tool_call_id='call_60W51T7TZrBh61shlJb7thBp')]}\n",
            "{'messages': [HumanMessage(content='Whats the weather in LA?', id='a517b9d5-ac86-45d9-aa46-d34fd3c11dc5'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_60W51T7TZrBh61shlJb7thBp', 'function': {'arguments': '{\"query\":\"weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-06f906d7-1bad-4ee2-bbc1-07a4e6bbf994-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in Los Angeles'}, 'id': 'call_60W51T7TZrBh61shlJb7thBp'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173}), ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'Los Angeles\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 34.05, \\'lon\\': -118.24, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1717612600, \\'localtime\\': \\'2024-06-05 11:36\\'}, \\'current\\': {\\'last_updated_epoch\\': 1717612200, \\'last_updated\\': \\'2024-06-05 11:30\\', \\'temp_c\\': 22.0, \\'temp_f\\': 71.6, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Mist\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/143.png\\', \\'code\\': 1030}, \\'wind_mph\\': 5.6, \\'wind_kph\\': 9.0, \\'wind_degree\\': 200, \\'wind_dir\\': \\'SSW\\', \\'pressure_mb\\': 1013.0, \\'pressure_in\\': 29.9, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 65, \\'cloud\\': 0, \\'feelslike_c\\': 24.5, \\'feelslike_f\\': 76.0, \\'windchill_c\\': 24.3, \\'windchill_f\\': 75.8, \\'heatindex_c\\': 25.3, \\'heatindex_f\\': 77.6, \\'dewpoint_c\\': 13.8, \\'dewpoint_f\\': 56.8, \\'vis_km\\': 9.7, \\'vis_miles\\': 6.0, \\'uv\\': 6.0, \\'gust_mph\\': 7.7, \\'gust_kph\\': 12.4}}\"}, {\\'url\\': \\'https://www.wunderground.com/hourly/us/ca/los-angeles/90050/date/2024-06-05\\', \\'content\\': \\'Los Angeles Weather Forecasts. Weather Underground provides local & long-range weather forecasts, weatherreports, maps & tropical weather conditions for the Los Angeles area. ... Wednesday 06/05 ...\\'}]', name='tavily_search_results_json', id='79bd02ba-bc3d-40a7-95cb-e7ad435e907b', tool_call_id='call_60W51T7TZrBh61shlJb7thBp'), AIMessage(content='The current weather in Los Angeles is 71.6°F with mist. The wind speed is 5.6 mph coming from the south-southwest direction. The humidity is 65%, and it feels like 76.0°F.', response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 669, 'total_tokens': 719}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-9812c597-e872-489b-bfc7-28d1c1504197-0', usage_metadata={'input_tokens': 669, 'output_tokens': 50, 'total_tokens': 719})]}\n",
            "{'messages': [AIMessage(content='The current weather in Los Angeles is 71.6°F with mist. The wind speed is 5.6 mph coming from the south-southwest direction. The humidity is 65%, and it feels like 76.0°F.', response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 669, 'total_tokens': 719}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-9812c597-e872-489b-bfc7-28d1c1504197-0', usage_metadata={'input_tokens': 669, 'output_tokens': 50, 'total_tokens': 719})]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Go back in time and edit**"
      ],
      "metadata": {
        "id": "F06gyhpopxD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_id = to_replay.values['messages'][-1].tool_calls[0]['id']\n",
        "to_replay.values['messages'][-1].tool_calls = [{'name': 'tavily_search_results_json',\n",
        "  'args': {'query': 'current weather in LA, accuweather'},\n",
        "  'id': _id}]"
      ],
      "metadata": {
        "id": "FlX9YRHCptIP"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for event in abot.graph.stream(None, branch_state):\n",
        "    for k, v in event.items():\n",
        "        if k != \"__end__\":\n",
        "            print(v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sz1r7b54ptFZ",
        "outputId": "f1283f0a-f61e-40e1-d4fd-c254f623fad5"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in LA, accuweather'}, 'id': 'call_60W51T7TZrBh61shlJb7thBp'}\n",
            "Back to the model!\n",
            "{'messages': [ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'Los Angeles\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 34.05, \\'lon\\': -118.24, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1717612600, \\'localtime\\': \\'2024-06-05 11:36\\'}, \\'current\\': {\\'last_updated_epoch\\': 1717612200, \\'last_updated\\': \\'2024-06-05 11:30\\', \\'temp_c\\': 22.0, \\'temp_f\\': 71.6, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Mist\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/143.png\\', \\'code\\': 1030}, \\'wind_mph\\': 5.6, \\'wind_kph\\': 9.0, \\'wind_degree\\': 200, \\'wind_dir\\': \\'SSW\\', \\'pressure_mb\\': 1013.0, \\'pressure_in\\': 29.9, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 65, \\'cloud\\': 0, \\'feelslike_c\\': 24.5, \\'feelslike_f\\': 76.0, \\'windchill_c\\': 24.3, \\'windchill_f\\': 75.8, \\'heatindex_c\\': 25.3, \\'heatindex_f\\': 77.6, \\'dewpoint_c\\': 13.8, \\'dewpoint_f\\': 56.8, \\'vis_km\\': 9.7, \\'vis_miles\\': 6.0, \\'uv\\': 6.0, \\'gust_mph\\': 7.7, \\'gust_kph\\': 12.4}}\"}, {\\'url\\': \\'https://www.accuweather.com/en/us/los-angeles/90012/current-weather/347625\\', \\'content\\': \\'Current weather in Los Angeles, CA. Check current conditions in Los Angeles, CA with radar, hourly, and more.\\'}]', name='tavily_search_results_json', tool_call_id='call_60W51T7TZrBh61shlJb7thBp')]}\n",
            "{'messages': [HumanMessage(content='Whats the weather in LA?', id='a517b9d5-ac86-45d9-aa46-d34fd3c11dc5'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_60W51T7TZrBh61shlJb7thBp', 'function': {'arguments': '{\"query\":\"weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-06f906d7-1bad-4ee2-bbc1-07a4e6bbf994-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in LA, accuweather'}, 'id': 'call_60W51T7TZrBh61shlJb7thBp'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173}), ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'Los Angeles\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 34.05, \\'lon\\': -118.24, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1717612600, \\'localtime\\': \\'2024-06-05 11:36\\'}, \\'current\\': {\\'last_updated_epoch\\': 1717612200, \\'last_updated\\': \\'2024-06-05 11:30\\', \\'temp_c\\': 22.0, \\'temp_f\\': 71.6, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Mist\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/143.png\\', \\'code\\': 1030}, \\'wind_mph\\': 5.6, \\'wind_kph\\': 9.0, \\'wind_degree\\': 200, \\'wind_dir\\': \\'SSW\\', \\'pressure_mb\\': 1013.0, \\'pressure_in\\': 29.9, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 65, \\'cloud\\': 0, \\'feelslike_c\\': 24.5, \\'feelslike_f\\': 76.0, \\'windchill_c\\': 24.3, \\'windchill_f\\': 75.8, \\'heatindex_c\\': 25.3, \\'heatindex_f\\': 77.6, \\'dewpoint_c\\': 13.8, \\'dewpoint_f\\': 56.8, \\'vis_km\\': 9.7, \\'vis_miles\\': 6.0, \\'uv\\': 6.0, \\'gust_mph\\': 7.7, \\'gust_kph\\': 12.4}}\"}, {\\'url\\': \\'https://www.accuweather.com/en/us/los-angeles/90012/current-weather/347625\\', \\'content\\': \\'Current weather in Los Angeles, CA. Check current conditions in Los Angeles, CA with radar, hourly, and more.\\'}]', name='tavily_search_results_json', id='41938604-5eee-4125-9f93-1832021c89bb', tool_call_id='call_60W51T7TZrBh61shlJb7thBp'), AIMessage(content='The current weather in Los Angeles is misty with a temperature of 71.6°F (22.0°C). The wind is blowing at 5.6 mph from the SSW direction. The humidity is at 65%, and there is no precipitation at the moment. The visibility is 6.0 miles.', response_metadata={'token_usage': {'completion_tokens': 66, 'prompt_tokens': 654, 'total_tokens': 720}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-dd2a022e-0b40-4778-95cb-03a3f5878457-0', usage_metadata={'input_tokens': 654, 'output_tokens': 66, 'total_tokens': 720})]}\n",
            "{'messages': [AIMessage(content='The current weather in Los Angeles is misty with a temperature of 71.6°F (22.0°C). The wind is blowing at 5.6 mph from the SSW direction. The humidity is at 65%, and there is no precipitation at the moment. The visibility is 6.0 miles.', response_metadata={'token_usage': {'completion_tokens': 66, 'prompt_tokens': 654, 'total_tokens': 720}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-dd2a022e-0b40-4778-95cb-03a3f5878457-0', usage_metadata={'input_tokens': 654, 'output_tokens': 66, 'total_tokens': 720})]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Add message to a state at a given time**"
      ],
      "metadata": {
        "id": "LPX24lbhp6Bq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "to_replay"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0Tzoif_p0t_",
        "outputId": "e38dac09-74bf-452b-98fc-c547c45d0a12"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StateSnapshot(values={'messages': [HumanMessage(content='Whats the weather in LA?', id='a517b9d5-ac86-45d9-aa46-d34fd3c11dc5'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_60W51T7TZrBh61shlJb7thBp', 'function': {'arguments': '{\"query\":\"weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-06f906d7-1bad-4ee2-bbc1-07a4e6bbf994-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in LA, accuweather'}, 'id': 'call_60W51T7TZrBh61shlJb7thBp'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173})]}, next=('action',), config={'configurable': {'thread_id': '3', 'thread_ts': '1ef236a5-aec2-6a37-8001-5f009c95fa18'}}, metadata={'source': 'loop', 'step': 1, 'writes': {'llm': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_60W51T7TZrBh61shlJb7thBp', 'function': {'arguments': '{\"query\":\"weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-06f906d7-1bad-4ee2-bbc1-07a4e6bbf994-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in Los Angeles'}, 'id': 'call_60W51T7TZrBh61shlJb7thBp'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173})]}}}, created_at='2024-06-05T18:35:17.070675+00:00', parent_config={'configurable': {'thread_id': '3', 'thread_ts': '1ef236a5-a7ee-639c-8000-51c27f4ee543'}})"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_id = to_replay.values['messages'][-1].tool_calls[0]['id']"
      ],
      "metadata": {
        "id": "R7u50MQSp0rO"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state_update = {\"messages\": [ToolMessage(\n",
        "    tool_call_id=_id,\n",
        "    name=\"tavily_search_results_json\",\n",
        "    content=\"54 degree celcius\",\n",
        ")]}"
      ],
      "metadata": {
        "id": "nBG0y93hp0lQ"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "branch_and_add = abot.graph.update_state(\n",
        "    to_replay.config,\n",
        "    state_update,\n",
        "    as_node=\"action\")"
      ],
      "metadata": {
        "id": "ppG4mP18p3S4"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for event in abot.graph.stream(None, branch_and_add):\n",
        "    for k, v in event.items():\n",
        "        print(v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09sgZVdAp3Qg",
        "outputId": "5ec1c826-8864-4f7b-a0e4-bf24b165fbf3"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'messages': [HumanMessage(content='Whats the weather in LA?', id='a517b9d5-ac86-45d9-aa46-d34fd3c11dc5'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_60W51T7TZrBh61shlJb7thBp', 'function': {'arguments': '{\"query\":\"weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-06f906d7-1bad-4ee2-bbc1-07a4e6bbf994-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in Los Angeles'}, 'id': 'call_60W51T7TZrBh61shlJb7thBp'}], usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173}), ToolMessage(content='54 degree celcius', name='tavily_search_results_json', id='b7056bfd-937f-4d5f-832e-0018053b4c99', tool_call_id='call_60W51T7TZrBh61shlJb7thBp'), AIMessage(content='The weather in Los Angeles is 54 degrees Celsius.', response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 190, 'total_tokens': 202}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-934f8057-5bee-4e39-be05-0995f8b6cca6-0', usage_metadata={'input_tokens': 190, 'output_tokens': 12, 'total_tokens': 202})]}\n",
            "{'messages': [AIMessage(content='The weather in Los Angeles is 54 degrees Celsius.', response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 190, 'total_tokens': 202}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-934f8057-5bee-4e39-be05-0995f8b6cca6-0', usage_metadata={'input_tokens': 190, 'output_tokens': 12, 'total_tokens': 202})]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CrewAI\n",
        "\n",
        "João Moura: Founder and CEO of CrewAI"
      ],
      "metadata": {
        "id": "kyZD8W_RdoXA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agentic Design Pattern\n",
        "\n",
        "In the past you would go from point a to point b, and you can write code to automate that.\n",
        "and then what happens is that as edge cases appear you start to kind of make that a little more complex by adding a lot of if's and conditions there.\n",
        "\n",
        "The beauty of agentic automation is that you don't need to draw a map, you just show all the options and let the agent choose.\n",
        "\n",
        "\n",
        "Traditional: strongly typed inputs, predefined transformation steps, and a strongly typed output.\n",
        "\n",
        "Agentic: Fuzzy inputs, fuzzy tranformations, fuzzy outputs\n",
        "\n",
        "\\\n",
        "\n",
        "**What are Agents:**\n",
        "\n",
        "An agent is born when you get LLMs to engage in their thinking process throughout it ask questions and answer the questions itself to the point that it can move on and ge better by itself.\n",
        "\n",
        "Once at this stage, it allows you to pass a task to this agent, and throughout process this agent can then come up with a better answer, it's not the first answer that it would have given you but it can think through and optimize the answer upto the point that satisfies itself and then spits it out.\n",
        "\n",
        "The ability to use tools (capabilities) make them super powerful.\n",
        "\n"
      ],
      "metadata": {
        "id": "MPxfeexmdq3h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-Agent Systems\n",
        "\n",
        "It grows on top of this topic, where instead of having just one agent, you can now have multiple agents.\n",
        "so each time you task an agent, it can task another agent, and at the end you would get one single final answer.\n",
        "\n",
        "What are the benefits of this?\n",
        "- You can have each agent be customized to don one single thing, and do it well\n",
        "- They could be running on different LLMs\n",
        "\n",
        "\\\n",
        "\n",
        "**What makes an agent great?**\n",
        "\n",
        "- Role playing\n",
        "- Focus\n",
        "- Tools\n",
        "- Cooperation\n",
        "- Guardrails\n",
        "- Memory"
      ],
      "metadata": {
        "id": "4HrBs6wseFgJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Article Writer Example"
      ],
      "metadata": {
        "id": "tGUx0w7JmHsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install crewai==0.28.8 crewai_tools==0.1.6 langchain_community==0.0.29"
      ],
      "metadata": {
        "id": "t2zHXTLzeOfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Task, Crew\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "YTYL_ZlXeSMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "os.environ[\"OPENAI_MODEL_NAME\"] = 'gpt-3.5-turbo'\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYunsmwfegP4",
        "outputId": "589fa08e-64ce-44c3-c9d7-16c075d0f4da"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Agents**\n",
        "\n",
        "- Define your Agents, and provide them a `role`, `goal` and `backstory`.\n",
        "- It has been seen that LLMs perform better when they are role playing."
      ],
      "metadata": {
        "id": "4_bOellbe__4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Agent: Planner**\n"
      ],
      "metadata": {
        "id": "rVtMj0H_fEtN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "planner = Agent(\n",
        "    role=\"Content Planner\",\n",
        "    goal=\"Plan engaging and factually accurate content on {topic}\",\n",
        "    backstory=\"You're working on planning a blog article \"\n",
        "              \"about the topic: {topic}.\"\n",
        "              \"You collect information that helps the \"\n",
        "              \"audience learn something \"\n",
        "              \"and make informed decisions. \"\n",
        "              \"Your work is the basis for \"\n",
        "              \"the Content Writer to write an article on this topic.\",\n",
        "    allow_delegation=False,\n",
        "\tverbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "p1G2WGrJfMaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Agent: Writer**"
      ],
      "metadata": {
        "id": "u6QcsFJ9fekH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "writer = Agent(\n",
        "    role=\"Content Writer\",\n",
        "    goal=\"Write insightful and factually accurate \"\n",
        "         \"opinion piece about the topic: {topic}\",\n",
        "    backstory=\"You're working on a writing \"\n",
        "              \"a new opinion piece about the topic: {topic}. \"\n",
        "              \"You base your writing on the work of \"\n",
        "              \"the Content Planner, who provides an outline \"\n",
        "              \"and relevant context about the topic. \"\n",
        "              \"You follow the main objectives and \"\n",
        "              \"direction of the outline, \"\n",
        "              \"as provide by the Content Planner. \"\n",
        "              \"You also provide objective and impartial insights \"\n",
        "              \"and back them up with information \"\n",
        "              \"provide by the Content Planner. \"\n",
        "              \"You acknowledge in your opinion piece \"\n",
        "              \"when your statements are opinions \"\n",
        "              \"as opposed to objective statements.\",\n",
        "    allow_delegation=False,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "WHHFsv2WffXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Agent: Editor**"
      ],
      "metadata": {
        "id": "2KY_SH--fY67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "editor = Agent(\n",
        "    role=\"Editor\",\n",
        "    goal=\"Edit a given blog post to align with \"\n",
        "         \"the writing style of the organization. \",\n",
        "    backstory=\"You are an editor who receives a blog post \"\n",
        "              \"from the Content Writer. \"\n",
        "              \"Your goal is to review the blog post \"\n",
        "              \"to ensure that it follows journalistic best practices,\"\n",
        "              \"provides balanced viewpoints \"\n",
        "              \"when providing opinions or assertions, \"\n",
        "              \"and also avoids major controversial topics \"\n",
        "              \"or opinions when possible.\",\n",
        "    allow_delegation=False,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "n3O9ILxvfWLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Tasks**\n",
        "\n",
        "- Define your Tasks, and provide them a `description`, `expected_output` and `agent`."
      ],
      "metadata": {
        "id": "JJ9eRSiWfjfv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task: Plan**"
      ],
      "metadata": {
        "id": "U2JCQvLafq7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plan = Task(\n",
        "    description=(\n",
        "        \"1. Prioritize the latest trends, key players, \"\n",
        "            \"and noteworthy news on {topic}.\\n\"\n",
        "        \"2. Identify the target audience, considering \"\n",
        "            \"their interests and pain points.\\n\"\n",
        "        \"3. Develop a detailed content outline including \"\n",
        "            \"an introduction, key points, and a call to action.\\n\"\n",
        "        \"4. Include SEO keywords and relevant data or sources.\"\n",
        "    ),\n",
        "    expected_output=\"A comprehensive content plan document \"\n",
        "        \"with an outline, audience analysis, \"\n",
        "        \"SEO keywords, and resources.\",\n",
        "    agent=planner,\n",
        ")"
      ],
      "metadata": {
        "id": "xgjX2grvfwl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task: Write**"
      ],
      "metadata": {
        "id": "u0McDFCmfq1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "write = Task(\n",
        "    description=(\n",
        "        \"1. Use the content plan to craft a compelling \"\n",
        "            \"blog post on {topic}.\\n\"\n",
        "        \"2. Incorporate SEO keywords naturally.\\n\"\n",
        "\t\t\"3. Sections/Subtitles are properly named \"\n",
        "            \"in an engaging manner.\\n\"\n",
        "        \"4. Ensure the post is structured with an \"\n",
        "            \"engaging introduction, insightful body, \"\n",
        "            \"and a summarizing conclusion.\\n\"\n",
        "        \"5. Proofread for grammatical errors and \"\n",
        "            \"alignment with the brand's voice.\\n\"\n",
        "    ),\n",
        "    expected_output=\"A well-written blog post \"\n",
        "        \"in markdown format, ready for publication, \"\n",
        "        \"each section should have 2 or 3 paragraphs.\",\n",
        "    agent=writer,\n",
        ")"
      ],
      "metadata": {
        "id": "f251KqyKfyB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task: Edit**"
      ],
      "metadata": {
        "id": "cOliQOx9fqoo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "edit = Task(\n",
        "    description=(\"Proofread the given blog post for \"\n",
        "                 \"grammatical errors and \"\n",
        "                 \"alignment with the brand's voice.\"),\n",
        "    expected_output=\"A well-written blog post in markdown format, \"\n",
        "                    \"ready for publication, \"\n",
        "                    \"each section should have 2 or 3 paragraphs.\",\n",
        "    agent=editor\n",
        ")"
      ],
      "metadata": {
        "id": "2RWHtFP1fjya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating the Crew**\n",
        "\n",
        "- Create your crew of Agents\n",
        "- Pass the tasks to be performed by those agents.\n",
        "    - **Note**: *For this simple example*, the tasks will be performed sequentially (i.e they are dependent on each other), so the _order_ of the task in the list _matters_.\n",
        "- `verbose=2` allows you to see all the logs of the execution."
      ],
      "metadata": {
        "id": "vigOexxvf7Hb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "crew = Crew(\n",
        "    agents=[planner, writer, editor],\n",
        "    tasks=[plan, write, edit],\n",
        "    verbose=2\n",
        ")"
      ],
      "metadata": {
        "id": "GekwdeEXf_Wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Running the Crew**"
      ],
      "metadata": {
        "id": "8qWgCSaRgBq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = crew.kickoff(inputs={\"topic\": \"Artificial Intelligence\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BEOslnmgCOo",
        "outputId": "e1439eb4-e3d0-4e74-dcff-19d2e7d19344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Content Planner\u001b[00m\n",
            "\u001b[1m\u001b[95m [INFO]: == Starting Task: 1. Prioritize the latest trends, key players, and noteworthy news on Artificial Intelligence.\n",
            "2. Identify the target audience, considering their interests and pain points.\n",
            "3. Develop a detailed content outline including an introduction, key points, and a call to action.\n",
            "4. Include SEO keywords and relevant data or sources.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI now can give a great answer\n",
            "\n",
            "Final Answer: \n",
            "\n",
            "Title: The Future of Artificial Intelligence: Latest Trends, Key Players, and Noteworthy News\n",
            "\n",
            "Outline:\n",
            "\n",
            "I. Introduction\n",
            "- Definition of Artificial Intelligence (AI)\n",
            "- Brief history of AI development\n",
            "- Importance of AI in various industries\n",
            "\n",
            "II. Latest Trends in Artificial Intelligence\n",
            "- Machine learning advancements\n",
            "- Natural language processing innovations\n",
            "- AI ethics and regulations\n",
            "- AI in healthcare, finance, and other sectors\n",
            "\n",
            "III. Key Players in the AI Industry\n",
            "- Google\n",
            "- Amazon\n",
            "- Microsoft\n",
            "- IBM\n",
            "- Tesla\n",
            "\n",
            "IV. Noteworthy News in Artificial Intelligence\n",
            "- Recent breakthroughs in AI research\n",
            "- AI applications in everyday life\n",
            "- Impact of AI on job markets and society\n",
            "\n",
            "V. Target Audience Analysis\n",
            "- Tech-savvy individuals interested in AI innovations\n",
            "- Business professionals seeking to implement AI solutions\n",
            "- Students and researchers studying AI trends\n",
            "- General audience curious about the future of technology\n",
            "\n",
            "VI. SEO Keywords\n",
            "- Artificial Intelligence trends\n",
            "- Key players in AI industry\n",
            "- Latest news on AI developments\n",
            "- AI applications in various sectors\n",
            "\n",
            "VII. Resources\n",
            "- Forbes article on top AI trends for 2021\n",
            "- Gartner report on key players in the AI industry\n",
            "- MIT Technology Review for latest news in AI\n",
            "- AI Ethics guidelines from IEEE\n",
            "\n",
            "Call to Action: Stay informed about the latest advancements in Artificial Intelligence by following reputable sources and engaging in discussions with industry experts. Embrace the possibilities of AI while also considering the ethical implications and societal impact of its widespread adoption. Remember, the future of AI is in our hands.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[1m\u001b[92m [DEBUG]: == [Content Planner] Task output: Title: The Future of Artificial Intelligence: Latest Trends, Key Players, and Noteworthy News\n",
            "\n",
            "Outline:\n",
            "\n",
            "I. Introduction\n",
            "- Definition of Artificial Intelligence (AI)\n",
            "- Brief history of AI development\n",
            "- Importance of AI in various industries\n",
            "\n",
            "II. Latest Trends in Artificial Intelligence\n",
            "- Machine learning advancements\n",
            "- Natural language processing innovations\n",
            "- AI ethics and regulations\n",
            "- AI in healthcare, finance, and other sectors\n",
            "\n",
            "III. Key Players in the AI Industry\n",
            "- Google\n",
            "- Amazon\n",
            "- Microsoft\n",
            "- IBM\n",
            "- Tesla\n",
            "\n",
            "IV. Noteworthy News in Artificial Intelligence\n",
            "- Recent breakthroughs in AI research\n",
            "- AI applications in everyday life\n",
            "- Impact of AI on job markets and society\n",
            "\n",
            "V. Target Audience Analysis\n",
            "- Tech-savvy individuals interested in AI innovations\n",
            "- Business professionals seeking to implement AI solutions\n",
            "- Students and researchers studying AI trends\n",
            "- General audience curious about the future of technology\n",
            "\n",
            "VI. SEO Keywords\n",
            "- Artificial Intelligence trends\n",
            "- Key players in AI industry\n",
            "- Latest news on AI developments\n",
            "- AI applications in various sectors\n",
            "\n",
            "VII. Resources\n",
            "- Forbes article on top AI trends for 2021\n",
            "- Gartner report on key players in the AI industry\n",
            "- MIT Technology Review for latest news in AI\n",
            "- AI Ethics guidelines from IEEE\n",
            "\n",
            "Call to Action: Stay informed about the latest advancements in Artificial Intelligence by following reputable sources and engaging in discussions with industry experts. Embrace the possibilities of AI while also considering the ethical implications and societal impact of its widespread adoption. Remember, the future of AI is in our hands.\n",
            "\n",
            "\u001b[00m\n",
            "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Content Writer\u001b[00m\n",
            "\u001b[1m\u001b[95m [INFO]: == Starting Task: 1. Use the content plan to craft a compelling blog post on Artificial Intelligence.\n",
            "2. Incorporate SEO keywords naturally.\n",
            "3. Sections/Subtitles are properly named in an engaging manner.\n",
            "4. Ensure the post is structured with an engaging introduction, insightful body, and a summarizing conclusion.\n",
            "5. Proofread for grammatical errors and alignment with the brand's voice.\n",
            "\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI now can give a great answer\n",
            "\n",
            "Final Answer:\n",
            "\n",
            "# The Future of Artificial Intelligence: Latest Trends, Key Players, and Noteworthy News\n",
            "\n",
            "## Introduction\n",
            "Artificial Intelligence (AI) is the simulation of human intelligence processes by machines, typically computer systems. The concept of AI dates back to the 1950s, with significant advancements seen in recent years due to the availability of large datasets and powerful computing resources. AI plays a crucial role in transforming various industries by automating tasks, analyzing data at scale, and enabling predictive capabilities.\n",
            "\n",
            "## Latest Trends in Artificial Intelligence\n",
            "Machine learning, a subset of AI, has seen remarkable advancements with the development of deep learning algorithms that can learn from data and improve over time. Natural language processing (NLP) is another area of AI that has made significant strides, allowing machines to understand and generate human language. Ethical considerations and regulations surrounding AI use have also become increasingly important, with organizations focusing on responsible AI deployment. In sectors like healthcare and finance, AI is revolutionizing processes by enabling personalized treatments and more efficient financial operations.\n",
            "\n",
            "## Key Players in the AI Industry\n",
            "Several tech giants lead the way in AI development, including Google, Amazon, Microsoft, IBM, and Tesla. These companies invest heavily in AI research and development, creating innovative solutions that impact various aspects of our lives. Google, for instance, is known for its advancements in AI-powered search algorithms and voice assistants, while Tesla leads the way in autonomous driving technology.\n",
            "\n",
            "## Noteworthy News in Artificial Intelligence\n",
            "Recent breakthroughs in AI research include the development of AI models that can generate human-like text and images, as well as advancements in AI-driven healthcare diagnostics. AI applications in everyday life range from virtual assistants like Siri to recommendation systems on streaming platforms. However, the widespread adoption of AI raises concerns about its impact on job markets and society, leading to discussions on upskilling the workforce and ensuring equitable access to AI technologies.\n",
            "\n",
            "## Target Audience Analysis\n",
            "Tech-savvy individuals interested in AI innovations can stay informed through reputable sources like Forbes and MIT Technology Review. Business professionals seeking to implement AI solutions can benefit from Gartner's insights on key players in the industry. Students and researchers studying AI trends should explore AI Ethics guidelines from IEEE to understand the ethical implications of AI technologies. For the general audience curious about the future of technology, engaging in discussions with industry experts can provide valuable insights into the potential of AI.\n",
            "\n",
            "## SEO Keywords\n",
            "Artificial Intelligence trends, key players in the AI industry, latest news on AI developments, AI applications in various sectors\n",
            "\n",
            "## Resources\n",
            "- Forbes article on top AI trends for 2021\n",
            "- Gartner report on key players in the AI industry\n",
            "- MIT Technology Review for latest news in AI\n",
            "- AI Ethics guidelines from IEEE\n",
            "\n",
            "## Call to Action\n",
            "Stay informed about the latest advancements in Artificial Intelligence by following reputable sources and engaging in discussions with industry experts. Embrace the possibilities of AI while also considering the ethical implications and societal impact of its widespread adoption. Remember, the future of AI is in our hands.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[1m\u001b[92m [DEBUG]: == [Content Writer] Task output: # The Future of Artificial Intelligence: Latest Trends, Key Players, and Noteworthy News\n",
            "\n",
            "## Introduction\n",
            "Artificial Intelligence (AI) is the simulation of human intelligence processes by machines, typically computer systems. The concept of AI dates back to the 1950s, with significant advancements seen in recent years due to the availability of large datasets and powerful computing resources. AI plays a crucial role in transforming various industries by automating tasks, analyzing data at scale, and enabling predictive capabilities.\n",
            "\n",
            "## Latest Trends in Artificial Intelligence\n",
            "Machine learning, a subset of AI, has seen remarkable advancements with the development of deep learning algorithms that can learn from data and improve over time. Natural language processing (NLP) is another area of AI that has made significant strides, allowing machines to understand and generate human language. Ethical considerations and regulations surrounding AI use have also become increasingly important, with organizations focusing on responsible AI deployment. In sectors like healthcare and finance, AI is revolutionizing processes by enabling personalized treatments and more efficient financial operations.\n",
            "\n",
            "## Key Players in the AI Industry\n",
            "Several tech giants lead the way in AI development, including Google, Amazon, Microsoft, IBM, and Tesla. These companies invest heavily in AI research and development, creating innovative solutions that impact various aspects of our lives. Google, for instance, is known for its advancements in AI-powered search algorithms and voice assistants, while Tesla leads the way in autonomous driving technology.\n",
            "\n",
            "## Noteworthy News in Artificial Intelligence\n",
            "Recent breakthroughs in AI research include the development of AI models that can generate human-like text and images, as well as advancements in AI-driven healthcare diagnostics. AI applications in everyday life range from virtual assistants like Siri to recommendation systems on streaming platforms. However, the widespread adoption of AI raises concerns about its impact on job markets and society, leading to discussions on upskilling the workforce and ensuring equitable access to AI technologies.\n",
            "\n",
            "## Target Audience Analysis\n",
            "Tech-savvy individuals interested in AI innovations can stay informed through reputable sources like Forbes and MIT Technology Review. Business professionals seeking to implement AI solutions can benefit from Gartner's insights on key players in the industry. Students and researchers studying AI trends should explore AI Ethics guidelines from IEEE to understand the ethical implications of AI technologies. For the general audience curious about the future of technology, engaging in discussions with industry experts can provide valuable insights into the potential of AI.\n",
            "\n",
            "## SEO Keywords\n",
            "Artificial Intelligence trends, key players in the AI industry, latest news on AI developments, AI applications in various sectors\n",
            "\n",
            "## Resources\n",
            "- Forbes article on top AI trends for 2021\n",
            "- Gartner report on key players in the AI industry\n",
            "- MIT Technology Review for latest news in AI\n",
            "- AI Ethics guidelines from IEEE\n",
            "\n",
            "## Call to Action\n",
            "Stay informed about the latest advancements in Artificial Intelligence by following reputable sources and engaging in discussions with industry experts. Embrace the possibilities of AI while also considering the ethical implications and societal impact of its widespread adoption. Remember, the future of AI is in our hands.\n",
            "\n",
            "\u001b[00m\n",
            "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Editor\u001b[00m\n",
            "\u001b[1m\u001b[95m [INFO]: == Starting Task: Proofread the given blog post for grammatical errors and alignment with the brand's voice.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI now can give a great answer\n",
            "\n",
            "Final Answer: \n",
            "\n",
            "# The Future of Artificial Intelligence: Latest Trends, Key Players, and Noteworthy News\n",
            "\n",
            "## Introduction\n",
            "Artificial Intelligence (AI) has come a long way since its inception in the 1950s, with recent years witnessing significant advancements fueled by the availability of vast datasets and powerful computing resources. AI, at its core, involves the simulation of human intelligence processes by machines, particularly computer systems. Its impact on various industries is undeniable, as it automates tasks, analyzes data at scale, and enables predictive capabilities, thus transforming the way we work and live.\n",
            "\n",
            "## Latest Trends in Artificial Intelligence\n",
            "Machine learning, a subset of AI, has witnessed remarkable progress with the development of deep learning algorithms that can continuously learn and improve from data. Natural language processing (NLP) is another key area in AI that has made significant strides, enabling machines to understand and generate human language effectively. As AI continues to evolve, ethical considerations and regulations surrounding its use have become increasingly crucial, with organizations emphasizing responsible AI deployment. Industries like healthcare and finance are experiencing a revolution through AI, with personalized treatments and more efficient financial operations becoming the new norm.\n",
            "\n",
            "## Key Players in the AI Industry\n",
            "Leading the charge in AI development are tech giants such as Google, Amazon, Microsoft, IBM, and Tesla, who heavily invest in AI research and development. These companies are at the forefront of creating innovative solutions that have a profound impact on our daily lives. Google, for example, is renowned for its AI-powered search algorithms and voice assistants, while Tesla is a trailblazer in autonomous driving technology, showcasing the diverse applications of AI across industries.\n",
            "\n",
            "## Noteworthy News in Artificial Intelligence\n",
            "Recent breakthroughs in AI research have led to the development of models capable of generating human-like text and images, along with advancements in AI-driven healthcare diagnostics. Everyday AI applications, ranging from virtual assistants like Siri to recommendation systems on streaming platforms, are becoming more prevalent. However, the widespread adoption of AI has raised concerns regarding its impact on job markets and society, sparking discussions on upskilling the workforce and ensuring equitable access to AI technologies.\n",
            "\n",
            "## Target Audience Analysis\n",
            "For tech-savvy individuals keen on staying updated on AI innovations, reputable sources like Forbes and MIT Technology Review offer valuable insights. Business professionals looking to implement AI solutions can benefit from Gartner's analysis of key players in the industry. Students and researchers delving into AI trends should explore AI Ethics guidelines from IEEE to grasp the ethical considerations surrounding AI technologies. Finally, the general audience intrigued by the future of technology can gain valuable insights by engaging in discussions with industry experts to understand the potential of AI.\n",
            "\n",
            "## SEO Keywords\n",
            "Artificial Intelligence trends, key players in the AI industry, latest news on AI developments, AI applications in various sectors\n",
            "\n",
            "## Resources\n",
            "- Forbes article on top AI trends for 2021\n",
            "- Gartner report on key players in the AI industry\n",
            "- MIT Technology Review for the latest news in AI\n",
            "- AI Ethics guidelines from IEEE\n",
            "\n",
            "## Call to Action\n",
            "To stay abreast of the latest advancements in Artificial Intelligence, follow reputable sources and engage in discussions with industry experts. Embrace the possibilities AI offers while also considering its ethical implications and societal impact. Remember, the future of AI is shaped by our choices and actions.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[1m\u001b[92m [DEBUG]: == [Editor] Task output: # The Future of Artificial Intelligence: Latest Trends, Key Players, and Noteworthy News\n",
            "\n",
            "## Introduction\n",
            "Artificial Intelligence (AI) has come a long way since its inception in the 1950s, with recent years witnessing significant advancements fueled by the availability of vast datasets and powerful computing resources. AI, at its core, involves the simulation of human intelligence processes by machines, particularly computer systems. Its impact on various industries is undeniable, as it automates tasks, analyzes data at scale, and enables predictive capabilities, thus transforming the way we work and live.\n",
            "\n",
            "## Latest Trends in Artificial Intelligence\n",
            "Machine learning, a subset of AI, has witnessed remarkable progress with the development of deep learning algorithms that can continuously learn and improve from data. Natural language processing (NLP) is another key area in AI that has made significant strides, enabling machines to understand and generate human language effectively. As AI continues to evolve, ethical considerations and regulations surrounding its use have become increasingly crucial, with organizations emphasizing responsible AI deployment. Industries like healthcare and finance are experiencing a revolution through AI, with personalized treatments and more efficient financial operations becoming the new norm.\n",
            "\n",
            "## Key Players in the AI Industry\n",
            "Leading the charge in AI development are tech giants such as Google, Amazon, Microsoft, IBM, and Tesla, who heavily invest in AI research and development. These companies are at the forefront of creating innovative solutions that have a profound impact on our daily lives. Google, for example, is renowned for its AI-powered search algorithms and voice assistants, while Tesla is a trailblazer in autonomous driving technology, showcasing the diverse applications of AI across industries.\n",
            "\n",
            "## Noteworthy News in Artificial Intelligence\n",
            "Recent breakthroughs in AI research have led to the development of models capable of generating human-like text and images, along with advancements in AI-driven healthcare diagnostics. Everyday AI applications, ranging from virtual assistants like Siri to recommendation systems on streaming platforms, are becoming more prevalent. However, the widespread adoption of AI has raised concerns regarding its impact on job markets and society, sparking discussions on upskilling the workforce and ensuring equitable access to AI technologies.\n",
            "\n",
            "## Target Audience Analysis\n",
            "For tech-savvy individuals keen on staying updated on AI innovations, reputable sources like Forbes and MIT Technology Review offer valuable insights. Business professionals looking to implement AI solutions can benefit from Gartner's analysis of key players in the industry. Students and researchers delving into AI trends should explore AI Ethics guidelines from IEEE to grasp the ethical considerations surrounding AI technologies. Finally, the general audience intrigued by the future of technology can gain valuable insights by engaging in discussions with industry experts to understand the potential of AI.\n",
            "\n",
            "## SEO Keywords\n",
            "Artificial Intelligence trends, key players in the AI industry, latest news on AI developments, AI applications in various sectors\n",
            "\n",
            "## Resources\n",
            "- Forbes article on top AI trends for 2021\n",
            "- Gartner report on key players in the AI industry\n",
            "- MIT Technology Review for the latest news in AI\n",
            "- AI Ethics guidelines from IEEE\n",
            "\n",
            "## Call to Action\n",
            "To stay abreast of the latest advancements in Artificial Intelligence, follow reputable sources and engage in discussions with industry experts. Embrace the possibilities AI offers while also considering its ethical implications and societal impact. Remember, the future of AI is shaped by our choices and actions.\n",
            "\n",
            "\u001b[00m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "Markdown(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 993
        },
        "id": "9qL7dOTQgFfh",
        "outputId": "43a81c08-764e-4e88-ba05-38300fa8b32f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# The Future of Artificial Intelligence: Latest Trends, Key Players, and Noteworthy News\n\n## Introduction\nArtificial Intelligence (AI) has come a long way since its inception in the 1950s, with recent years witnessing significant advancements fueled by the availability of vast datasets and powerful computing resources. AI, at its core, involves the simulation of human intelligence processes by machines, particularly computer systems. Its impact on various industries is undeniable, as it automates tasks, analyzes data at scale, and enables predictive capabilities, thus transforming the way we work and live.\n\n## Latest Trends in Artificial Intelligence\nMachine learning, a subset of AI, has witnessed remarkable progress with the development of deep learning algorithms that can continuously learn and improve from data. Natural language processing (NLP) is another key area in AI that has made significant strides, enabling machines to understand and generate human language effectively. As AI continues to evolve, ethical considerations and regulations surrounding its use have become increasingly crucial, with organizations emphasizing responsible AI deployment. Industries like healthcare and finance are experiencing a revolution through AI, with personalized treatments and more efficient financial operations becoming the new norm.\n\n## Key Players in the AI Industry\nLeading the charge in AI development are tech giants such as Google, Amazon, Microsoft, IBM, and Tesla, who heavily invest in AI research and development. These companies are at the forefront of creating innovative solutions that have a profound impact on our daily lives. Google, for example, is renowned for its AI-powered search algorithms and voice assistants, while Tesla is a trailblazer in autonomous driving technology, showcasing the diverse applications of AI across industries.\n\n## Noteworthy News in Artificial Intelligence\nRecent breakthroughs in AI research have led to the development of models capable of generating human-like text and images, along with advancements in AI-driven healthcare diagnostics. Everyday AI applications, ranging from virtual assistants like Siri to recommendation systems on streaming platforms, are becoming more prevalent. However, the widespread adoption of AI has raised concerns regarding its impact on job markets and society, sparking discussions on upskilling the workforce and ensuring equitable access to AI technologies.\n\n## Target Audience Analysis\nFor tech-savvy individuals keen on staying updated on AI innovations, reputable sources like Forbes and MIT Technology Review offer valuable insights. Business professionals looking to implement AI solutions can benefit from Gartner's analysis of key players in the industry. Students and researchers delving into AI trends should explore AI Ethics guidelines from IEEE to grasp the ethical considerations surrounding AI technologies. Finally, the general audience intrigued by the future of technology can gain valuable insights by engaging in discussions with industry experts to understand the potential of AI.\n\n## SEO Keywords\nArtificial Intelligence trends, key players in the AI industry, latest news on AI developments, AI applications in various sectors\n\n## Resources\n- Forbes article on top AI trends for 2021\n- Gartner report on key players in the AI industry\n- MIT Technology Review for the latest news in AI\n- AI Ethics guidelines from IEEE\n\n## Call to Action\nTo stay abreast of the latest advancements in Artificial Intelligence, follow reputable sources and engage in discussions with industry experts. Embrace the possibilities AI offers while also considering its ethical implications and societal impact. Remember, the future of AI is shaped by our choices and actions."
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Customer Support Automation Example"
      ],
      "metadata": {
        "id": "F5HL_6fumNPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install crewai==0.28.8 crewai_tools==0.1.6 langchain_community==0.0.29"
      ],
      "metadata": {
        "id": "TB1XjrrImNPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Task, Crew\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "6VKzWlkKmNPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "os.environ[\"OPENAI_MODEL_NAME\"] = 'gpt-3.5-turbo'\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "589fa08e-64ce-44c3-c9d7-16c075d0f4da",
        "id": "VP-2N77MmNPI"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Role Playing, Focus and Cooperation**"
      ],
      "metadata": {
        "id": "6ZRfSJXBmT0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "support_agent = Agent(\n",
        "    role=\"Senior Support Representative\",\n",
        "\tgoal=\"Be the most friendly and helpful \"\n",
        "        \"support representative in your team\",\n",
        "\tbackstory=(\n",
        "\t\t\"You work at crewAI (https://crewai.com) and \"\n",
        "        \" are now working on providing \"\n",
        "\t\t\"support to {customer}, a super important customer \"\n",
        "        \" for your company.\"\n",
        "\t\t\"You need to make sure that you provide the best support!\"\n",
        "\t\t\"Make sure to provide full complete answers, \"\n",
        "        \" and make no assumptions.\"\n",
        "\t),\n",
        "\tallow_delegation=False,\n",
        "\tverbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "j2aWR7n-mVnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- By not setting `allow_delegation=False`, `allow_delegation` takes its default value of being `True`.\n",
        "- This means the agent _can_ delegate its work to another agent which is better suited to do a particular task."
      ],
      "metadata": {
        "id": "AySwKLEwmWri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "support_quality_assurance_agent = Agent(\n",
        "\trole=\"Support Quality Assurance Specialist\",\n",
        "\tgoal=\"Get recognition for providing the \"\n",
        "    \"best support quality assurance in your team\",\n",
        "\tbackstory=(\n",
        "\t\t\"You work at crewAI (https://crewai.com) and \"\n",
        "        \"are now working with your team \"\n",
        "\t\t\"on a request from {customer} ensuring that \"\n",
        "        \"the support representative is \"\n",
        "\t\t\"providing the best support possible.\\n\"\n",
        "\t\t\"You need to make sure that the support representative \"\n",
        "        \"is providing full\"\n",
        "\t\t\"complete answers, and make no assumptions.\"\n",
        "\t),\n",
        "\tverbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "uTArSEpwmYIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Role Playing**: Both agents have been given a role, goal and backstory.\n",
        "* **Focus**: Both agents have been prompted to get into the character of the roles they are playing.\n",
        "* **Cooperation**: Support Quality Assurance Agent can delegate work back to the Support Agent, allowing for these agents to work together."
      ],
      "metadata": {
        "id": "zOzzTyx-mcZg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tools, Guardrails and Memory**"
      ],
      "metadata": {
        "id": "Rj4znC8Wml6a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import CrewAI tools"
      ],
      "metadata": {
        "id": "jyj7nznamyT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai_tools import SerperDevTool, \\\n",
        "                         ScrapeWebsiteTool, \\\n",
        "                         WebsiteSearchTool"
      ],
      "metadata": {
        "id": "yiC5vgaOm1tO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Possible Custom Tools**\n",
        "- Load customer data\n",
        "- Tap into previous conversations\n",
        "- Load data from a CRM\n",
        "- Checking existing bug reports\n",
        "- Checking existing feature requests\n",
        "- Checking ongoing tickets\n",
        "- ... and more"
      ],
      "metadata": {
        "id": "SuVC6GQDm9wZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Different Ways to Give Agents Tools**\n",
        "\n",
        "- Agent Level: The Agent can use the Tool(s) on any Task it performs.\n",
        "- Task Level: The Agent will only use the Tool(s) when performing that specific Task.\n",
        "\n",
        "**Note**: Task Tools override the Agent Tools."
      ],
      "metadata": {
        "id": "WSCQO8j4nMt5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Tasks**\n",
        "- You are passing the Tool on the Task Level."
      ],
      "metadata": {
        "id": "_UzdtnunnQ9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs_scrape_tool = ScrapeWebsiteTool(\n",
        "    website_url=\"https://docs.crewai.com/how-to/Creating-a-Crew-and-kick-it-off/\"\n",
        ")"
      ],
      "metadata": {
        "id": "U-paU-lBnZ0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_tool = SerperDevTool()\n",
        "scrape_tool = ScrapeWebsiteTool()"
      ],
      "metadata": {
        "id": "NVc-Wg3Oniaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inquiry_resolution = Task(\n",
        "    description=(\n",
        "        \"{customer} just reached out with a super important ask:\\n\"\n",
        "\t    \"{inquiry}\\n\\n\"\n",
        "        \"{person} from {customer} is the one that reached out. \"\n",
        "\t\t\"Make sure to use everything you know \"\n",
        "        \"to provide the best support possible.\"\n",
        "\t\t\"You must strive to provide a complete \"\n",
        "        \"and accurate response to the customer's inquiry.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "\t    \"A detailed, informative response to the \"\n",
        "        \"customer's inquiry that addresses \"\n",
        "        \"all aspects of their question.\\n\"\n",
        "        \"The response should include references \"\n",
        "        \"to everything you used to find the answer, \"\n",
        "        \"including external data or solutions. \"\n",
        "        \"Ensure the answer is complete, \"\n",
        "\t\t\"leaving no questions unanswered, and maintain a helpful and friendly \"\n",
        "\t\t\"tone throughout.\"\n",
        "    ),\n",
        "\ttools=[docs_scrape_tool],\n",
        "  agent=support_agent,\n",
        ")"
      ],
      "metadata": {
        "id": "uClzrjBGnRtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `quality_assurance_review` is not using any Tool(s)\n",
        "- Here the QA Agent will only review the work of the Support Agent"
      ],
      "metadata": {
        "id": "sIlO6qYLn5V0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quality_assurance_review = Task(\n",
        "    description=(\n",
        "        \"Review the response drafted by the Senior Support Representative for {customer}'s inquiry. \"\n",
        "        \"Ensure that the answer is comprehensive, accurate, and adheres to the \"\n",
        "\t\t\"high-quality standards expected for customer support.\\n\"\n",
        "        \"Verify that all parts of the customer's inquiry \"\n",
        "        \"have been addressed \"\n",
        "\t\t\"thoroughly, with a helpful and friendly tone.\\n\"\n",
        "        \"Check for references and sources used to \"\n",
        "        \" find the information, \"\n",
        "\t\t\"ensuring the response is well-supported and \"\n",
        "        \"leaves no questions unanswered.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A final, detailed, and informative response \"\n",
        "        \"ready to be sent to the customer.\\n\"\n",
        "        \"This response should fully address the \"\n",
        "        \"customer's inquiry, incorporating all \"\n",
        "\t\t\"relevant feedback and improvements.\\n\"\n",
        "\t\t\"Don't be too formal, we are a chill and cool company \"\n",
        "\t    \"but maintain a professional and friendly tone throughout.\"\n",
        "    ),\n",
        "    agent=support_quality_assurance_agent,\n",
        ")"
      ],
      "metadata": {
        "id": "D_UUy4ATn5xO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating the Crew**\n",
        "\n",
        "**Memory**\n",
        "- Setting `memory=True` when putting the crew together enables Memory."
      ],
      "metadata": {
        "id": "HNuhXF47n_0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "crew = Crew(\n",
        "  agents=[support_agent, support_quality_assurance_agent],\n",
        "  tasks=[inquiry_resolution, quality_assurance_review],\n",
        "  verbose=2,\n",
        "  memory=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aA7AReyeoDIf",
        "outputId": "d17d2d9f-1f0d-4ae1-c5eb-76fff8174355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Running the Crew**"
      ],
      "metadata": {
        "id": "_6haFlE-oFZj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Guardrails**\n",
        "- By running the execution below, you can see that the agents and the responses are within the scope of what we expect from them."
      ],
      "metadata": {
        "id": "XaIb2JwVoIXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\n",
        "    \"customer\": \"DeepLearningAI\",\n",
        "    \"person\": \"Andrew Ng\",\n",
        "    \"inquiry\": \"I need help with setting up a Crew \"\n",
        "               \"and kicking it off, specifically \"\n",
        "               \"how can I add memory to my crew? \"\n",
        "               \"Can you provide guidance?\"\n",
        "}\n",
        "result = crew.kickoff(inputs=inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbSNDXGyoJUq",
        "outputId": "1bdca03d-2e94-4422-ffc0-10e903814744"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Senior Support Representative\u001b[00m\n",
            "\u001b[1m\u001b[95m [INFO]: == Starting Task: DeepLearningAI just reached out with a super important ask:\n",
            "I need help with setting up a Crew and kicking it off, specifically how can I add memory to my crew? Can you provide guidance?\n",
            "\n",
            "Andrew Ng from DeepLearningAI is the one that reached out. Make sure to use everything you know to provide the best support possible.You must strive to provide a complete and accurate response to the customer's inquiry.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to provide the best support possible to DeepLearningAI by using the tools available to me and ensuring that I address all aspects of their inquiry.\n",
            "\n",
            "Action: Read website content\n",
            "Action Input: {\"url\": \"https://docs.crewai.com/how-to/Creating-a-Crew-and-kick-it-off/\"}\u001b[0m\u001b[95m \n",
            "\n",
            "Assembling and Activating Your CrewAI Team - crewAI\n",
            " Skip to content\n",
            " crewAI\n",
            " Assembling and Activating Your CrewAI Team\n",
            " crewAI\n",
            " crewAI\n",
            " crewAI\n",
            " Home\n",
            " Core Concepts\n",
            " Core Concepts\n",
            " Agents\n",
            " Tasks\n",
            " Tools\n",
            " Processes\n",
            " Crews\n",
            " Collaboration\n",
            " Memory\n",
            " How to Guides\n",
            " How to Guides\n",
            " Installing CrewAI\n",
            " Getting Started\n",
            " Getting Started\n",
            " Table of contents\n",
            " Introduction\n",
            " Step 0: Installation\n",
            " Step 1: Assemble Your Agents\n",
            " Step 2: Define the Tasks\n",
            " Step 3: Form the Crew\n",
            " Step 4: Kick It Off\n",
            " Conclusion\n",
            " Create Custom Tools\n",
            " Using Sequential Process\n",
            " Using Hierarchical Process\n",
            " Connecting to any LLM\n",
            " Customizing Agents\n",
            " Human Input on Execution\n",
            " Agent Monitoring with AgentOps\n",
            " Tools Docs\n",
            " Tools Docs\n",
            " Google Serper Search\n",
            " Browserbase Web Loader\n",
            " Scrape Website\n",
            " Directory Read\n",
            " File Read\n",
            " Selenium Scraper\n",
            " Directory RAG Search\n",
            " PDF RAG Search\n",
            " TXT RAG Search\n",
            " CSV RAG Search\n",
            " XML RAG Search\n",
            " JSON RAG Search\n",
            " Docx Rag Search\n",
            " MDX RAG Search\n",
            " PG RAG Search\n",
            " Website RAG Search\n",
            " Github RAG Search\n",
            " Code Docs RAG Search\n",
            " Youtube Video RAG Search\n",
            " Youtube Channel RAG Search\n",
            " Examples\n",
            " Examples\n",
            " Trip Planner Crew\n",
            " Create Instagram Post\n",
            " Stock Analysis\n",
            " Game Generator\n",
            " Drafting emails with LangGraph\n",
            " Landing Page Generator\n",
            " Prepare for meetings\n",
            " Telemetry\n",
            "Getting Started\n",
            "Introduction¶\n",
            "Embark on your CrewAI journey by setting up your environment and initiating your AI crew with the latest features. This guide ensures a smooth start, incorporating all recent updates for an enhanced experience.\n",
            "Step 0: Installation¶\n",
            "Install CrewAI and any necessary packages for your project. CrewAI is compatible with Python >=3.10,<=3.13.\n",
            "pip install crewai\n",
            "pip install 'crewai[tools]'\n",
            "Step 1: Assemble Your Agents¶\n",
            "Define your agents with distinct roles, backstories, and enhanced capabilities like verbose mode and memory usage. These elements add depth and guide their task execution and interaction within the crew.\n",
            "import os\n",
            "os.environ[\"SERPER_API_KEY\"] = \"Your Key\" # serper.dev API key\n",
            "os.environ[\"OPENAI_API_KEY\"] = \"Your Key\"\n",
            "from crewai import Agent\n",
            "from crewai_tools import SerperDevTool\n",
            "search_tool = SerperDevTool()\n",
            "# Creating a senior researcher agent with memory and verbose mode\n",
            "researcher = Agent(\n",
            " role='Senior Researcher',\n",
            " goal='Uncover groundbreaking technologies in {topic}',\n",
            " verbose=True,\n",
            " memory=True,\n",
            " backstory=(\n",
            " \"Driven by curiosity, you're at the forefront of\"\n",
            " \"innovation, eager to explore and share knowledge that could change\"\n",
            " \"the world.\"\n",
            " ),\n",
            " tools=[search_tool],\n",
            " allow_delegation=True\n",
            ")\n",
            "# Creating a writer agent with custom tools and delegation capability\n",
            "writer = Agent(\n",
            " role='Writer',\n",
            " goal='Narrate compelling tech stories about {topic}',\n",
            " verbose=True,\n",
            " memory=True,\n",
            " backstory=(\n",
            " \"With a flair for simplifying complex topics, you craft\"\n",
            " \"engaging narratives that captivate and educate, bringing new\"\n",
            " \"discoveries to light in an accessible manner.\"\n",
            " ),\n",
            " tools=[search_tool],\n",
            " allow_delegation=False\n",
            ")\n",
            "Step 2: Define the Tasks¶\n",
            "Detail the specific objectives for your agents, including new features for asynchronous execution and output customization. These tasks ensure a targeted approach to their roles.\n",
            "from crewai import Task\n",
            "# Research task\n",
            "research_task = Task(\n",
            " description=(\n",
            " \"Identify the next big trend in {topic}.\"\n",
            " \"Focus on identifying pros and cons and the overall narrative.\"\n",
            " \"Your final report should clearly articulate the key points,\"\n",
            " \"its market opportunities, and potential risks.\"\n",
            " ),\n",
            " expected_output='A comprehensive 3 paragraphs long report on the latest AI trends.',\n",
            " tools=[search_tool],\n",
            " agent=researcher,\n",
            ")\n",
            "# Writing task with language model configuration\n",
            "write_task = Task(\n",
            " description=(\n",
            " \"Compose an insightful article on {topic}.\"\n",
            " \"Focus on the latest trends and how it's impacting the industry.\"\n",
            " \"This article should be easy to understand, engaging, and positive.\"\n",
            " ),\n",
            " expected_output='A 4 paragraph article on {topic} advancements formatted as markdown.',\n",
            " tools=[search_tool],\n",
            " agent=writer,\n",
            " async_execution=False,\n",
            " output_file='new-blog-post.md' # Example of output customization\n",
            ")\n",
            "Step 3: Form the Crew¶\n",
            "Combine your agents into a crew, setting the workflow process they'll follow to accomplish the tasks. Now with options to configure language models for enhanced interaction and additional configurations for optimizing performance.\n",
            "from crewai import Crew, Process\n",
            "# Forming the tech-focused crew with some enhanced configurations\n",
            "crew = Crew(\n",
            " agents=[researcher, writer],\n",
            " tasks=[research_task, write_task],\n",
            " process=Process.sequential, # Optional: Sequential task execution is default\n",
            " memory=True,\n",
            " cache=True,\n",
            " max_rpm=100,\n",
            " share_crew=True\n",
            ")\n",
            "Step 4: Kick It Off¶\n",
            "Initiate the process with your enhanced crew ready. Observe as your agents collaborate, leveraging their new capabilities for a successful project outcome. Input variables will be interpolated into the agents and tasks for a personalized approach.\n",
            "# Starting the task execution process with enhanced feedback\n",
            "result = crew.kickoff(inputs={'topic': 'AI in healthcare'})\n",
            "print(result)\n",
            "Conclusion¶\n",
            "Building and activating a crew in CrewAI has evolved with new functionalities. By incorporating verbose mode, memory capabilities, asynchronous task execution, output customization, language model configuration, and enhanced crew configurations, your AI team is more equipped than ever to tackle challenges efficiently. The depth of agent backstories and the precision of their objectives enrich collaboration, leading to successful project outcomes. This guide aims to provide you with a clear and detailed understanding of setting up and utilizing the CrewAI framework to its full potential.\n",
            " Back to top\n",
            " Previous\n",
            " Installing CrewAI\n",
            " Next\n",
            " Create Custom Tools\n",
            " Copyright © 2024 crewAI, Inc\n",
            " Made with\n",
            " Material for MkDocs\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3mFinal Answer: \n",
            "\n",
            "Hello Andrew Ng from DeepLearningAI,\n",
            "\n",
            "Thank you for reaching out for assistance with setting up a Crew and kicking it off, specifically on how to add memory to your crew. I have gathered information from the crewAI documentation on how you can achieve this.\n",
            "\n",
            "To add memory to your crew in crewAI, you need to follow these steps:\n",
            "\n",
            "1. Assemble Your Agents:\n",
            "Define your agents with distinct roles, backstories, and enhanced capabilities like memory usage. You can create agents with memory capabilities by setting the memory parameter to True when creating the agent.\n",
            "\n",
            "Example:\n",
            "```python\n",
            "researcher = Agent(\n",
            " role='Senior Researcher',\n",
            " goal='Uncover groundbreaking technologies in {topic}',\n",
            " verbose=True,\n",
            " memory=True,\n",
            " backstory=(\n",
            " \"Driven by curiosity, you're at the forefront of\"\n",
            " \"innovation, eager to explore and share knowledge that could change\"\n",
            " \"the world.\"\n",
            " ),\n",
            " tools=[search_tool],\n",
            " allow_delegation=True\n",
            ")\n",
            "```\n",
            "\n",
            "2. Form the Crew:\n",
            "Combine your agents into a crew and set the workflow process they'll follow to accomplish the tasks. When forming the crew, make sure to set the memory parameter to True to enable memory capabilities for the crew.\n",
            "\n",
            "Example:\n",
            "```python\n",
            "crew = Crew(\n",
            " agents=[researcher, writer],\n",
            " tasks=[research_task, write_task],\n",
            " process=Process.sequential,\n",
            " memory=True,\n",
            " cache=True,\n",
            " max_rpm=100,\n",
            " share_crew=True\n",
            ")\n",
            "```\n",
            "\n",
            "3. Kick It Off:\n",
            "Initiate the process with your crew ready. Your agents will collaborate, leveraging their memory capabilities for a successful project outcome.\n",
            "\n",
            "Example:\n",
            "```python\n",
            "result = crew.kickoff(inputs={'topic': 'AI in healthcare'})\n",
            "print(result)\n",
            "```\n",
            "\n",
            "By following these steps, you can successfully add memory to your crew in crewAI. If you have any further questions or need additional assistance, please feel free to reach out.\n",
            "\n",
            "Best regards,\n",
            "[Your Name]\n",
            "Senior Support Representative\n",
            "crewAI\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[1m\u001b[92m [DEBUG]: == [Senior Support Representative] Task output: Hello Andrew Ng from DeepLearningAI,\n",
            "\n",
            "Thank you for reaching out for assistance with setting up a Crew and kicking it off, specifically on how to add memory to your crew. I have gathered information from the crewAI documentation on how you can achieve this.\n",
            "\n",
            "To add memory to your crew in crewAI, you need to follow these steps:\n",
            "\n",
            "1. Assemble Your Agents:\n",
            "Define your agents with distinct roles, backstories, and enhanced capabilities like memory usage. You can create agents with memory capabilities by setting the memory parameter to True when creating the agent.\n",
            "\n",
            "Example:\n",
            "```python\n",
            "researcher = Agent(\n",
            " role='Senior Researcher',\n",
            " goal='Uncover groundbreaking technologies in {topic}',\n",
            " verbose=True,\n",
            " memory=True,\n",
            " backstory=(\n",
            " \"Driven by curiosity, you're at the forefront of\"\n",
            " \"innovation, eager to explore and share knowledge that could change\"\n",
            " \"the world.\"\n",
            " ),\n",
            " tools=[search_tool],\n",
            " allow_delegation=True\n",
            ")\n",
            "```\n",
            "\n",
            "2. Form the Crew:\n",
            "Combine your agents into a crew and set the workflow process they'll follow to accomplish the tasks. When forming the crew, make sure to set the memory parameter to True to enable memory capabilities for the crew.\n",
            "\n",
            "Example:\n",
            "```python\n",
            "crew = Crew(\n",
            " agents=[researcher, writer],\n",
            " tasks=[research_task, write_task],\n",
            " process=Process.sequential,\n",
            " memory=True,\n",
            " cache=True,\n",
            " max_rpm=100,\n",
            " share_crew=True\n",
            ")\n",
            "```\n",
            "\n",
            "3. Kick It Off:\n",
            "Initiate the process with your crew ready. Your agents will collaborate, leveraging their memory capabilities for a successful project outcome.\n",
            "\n",
            "Example:\n",
            "```python\n",
            "result = crew.kickoff(inputs={'topic': 'AI in healthcare'})\n",
            "print(result)\n",
            "```\n",
            "\n",
            "By following these steps, you can successfully add memory to your crew in crewAI. If you have any further questions or need additional assistance, please feel free to reach out.\n",
            "\n",
            "Best regards,\n",
            "[Your Name]\n",
            "Senior Support Representative\n",
            "crewAI\n",
            "\n",
            "\u001b[00m\n",
            "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Support Quality Assurance Specialist\u001b[00m\n",
            "\u001b[1m\u001b[95m [INFO]: == Starting Task: Review the response drafted by the Senior Support Representative for DeepLearningAI's inquiry. Ensure that the answer is comprehensive, accurate, and adheres to the high-quality standards expected for customer support.\n",
            "Verify that all parts of the customer's inquiry have been addressed thoroughly, with a helpful and friendly tone.\n",
            "Check for references and sources used to  find the information, ensuring the response is well-supported and leaves no questions unanswered.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to ensure that the response from the Senior Support Representative is comprehensive, accurate, and meets the high-quality standards expected for customer support. I must verify that all parts of the customer's inquiry have been thoroughly addressed and that the response is well-supported with no unanswered questions.\n",
            "\n",
            "Action: Ask question to co-worker\n",
            "Action Input:\n",
            "{\n",
            "    \"coworker\": \"Senior Support Representative\",\n",
            "    \"question\": \"Can you confirm if all steps for adding memory to the crew in crewAI have been clearly explained and if any additional information or clarification is needed?\",\n",
            "    \"context\": \"Reviewing the response drafted for DeepLearningAI's inquiry on how to add memory to their crew.\"\n",
            "}\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI now can give a great answer\n",
            "\n",
            "Final Answer: \n",
            "\n",
            "After reviewing the response drafted for DeepLearningAI's inquiry on how to add memory to their crew, I can confirm that all steps for adding memory to the crew in crewAI have been clearly explained. The process involves accessing the Crew Settings, navigating to the Memory section, and then selecting the option to add memory. Additional information or clarification may be needed on specific details such as the maximum memory limit allowed per crew member or any potential restrictions on memory allocation. It is crucial to ensure that DeepLearningAI receives comprehensive guidance to successfully add memory to their crew. If any further assistance is required, please do not hesitate to reach out for more detailed instructions or troubleshooting tips.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[95m \n",
            "\n",
            "After reviewing the response drafted for DeepLearningAI's inquiry on how to add memory to their crew, I can confirm that all steps for adding memory to the crew in crewAI have been clearly explained. The process involves accessing the Crew Settings, navigating to the Memory section, and then selecting the option to add memory. Additional information or clarification may be needed on specific details such as the maximum memory limit allowed per crew member or any potential restrictions on memory allocation. It is crucial to ensure that DeepLearningAI receives comprehensive guidance to successfully add memory to their crew. If any further assistance is required, please do not hesitate to reach out for more detailed instructions or troubleshooting tips.\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mThought: I now can give a great answer\n",
            "\n",
            "Final Answer:\n",
            "Hello Andrew Ng from DeepLearningAI,\n",
            "\n",
            "Thank you for reaching out for assistance with setting up a Crew and adding memory to your crew in crewAI. I appreciate your interest in enhancing your crew's capabilities. Below are the detailed steps you need to follow to successfully add memory to your crew:\n",
            "\n",
            "1. Assemble Your Agents:\n",
            "To add memory to your crew, you first need to define your agents with distinct roles, backstories, and capabilities. When creating an agent, ensure to set the memory parameter to True. This will enable the agent to utilize memory capabilities during crew tasks.\n",
            "\n",
            "Example:\n",
            "```python\n",
            "researcher = Agent(\n",
            " role='Senior Researcher',\n",
            " goal='Uncover groundbreaking technologies in {topic}',\n",
            " verbose=True,\n",
            " memory=True,\n",
            " backstory=(\n",
            " \"Driven by curiosity, you're at the forefront of\"\n",
            " \"innovation, eager to explore and share knowledge that could change\"\n",
            " \"the world.\"\n",
            " ),\n",
            " tools=[search_tool],\n",
            " allow_delegation=True\n",
            ")\n",
            "```\n",
            "\n",
            "2. Form the Crew:\n",
            "Once you have defined your agents with memory capabilities, you can combine them into a crew. When forming the crew, ensure to set the memory parameter to True to activate memory capabilities for the entire crew.\n",
            "\n",
            "Example:\n",
            "```python\n",
            "crew = Crew(\n",
            " agents=[researcher, writer],\n",
            " tasks=[research_task, write_task],\n",
            " process=Process.sequential,\n",
            " memory=True,\n",
            " cache=True,\n",
            " max_rpm=100,\n",
            " share_crew=True\n",
            ")\n",
            "```\n",
            "\n",
            "3. Kick It Off:\n",
            "Initiate the process with your crew ready. Your agents will collaborate, leveraging their memory capabilities for a successful project outcome.\n",
            "\n",
            "Example:\n",
            "```python\n",
            "result = crew.kickoff(inputs={'topic': 'AI in healthcare'})\n",
            "print(result)\n",
            "```\n",
            "\n",
            "By following these steps, you can effectively add memory to your crew in crewAI. If you encounter any challenges or require further assistance, feel free to reach out for additional guidance. We are here to support you in optimizing your crew's performance.\n",
            "\n",
            "Best regards,\n",
            "[Your Name]\n",
            "Senior Support Representative\n",
            "crewAI\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[1m\u001b[92m [DEBUG]: == [Support Quality Assurance Specialist] Task output: Hello Andrew Ng from DeepLearningAI,\n",
            "\n",
            "Thank you for reaching out for assistance with setting up a Crew and adding memory to your crew in crewAI. I appreciate your interest in enhancing your crew's capabilities. Below are the detailed steps you need to follow to successfully add memory to your crew:\n",
            "\n",
            "1. Assemble Your Agents:\n",
            "To add memory to your crew, you first need to define your agents with distinct roles, backstories, and capabilities. When creating an agent, ensure to set the memory parameter to True. This will enable the agent to utilize memory capabilities during crew tasks.\n",
            "\n",
            "Example:\n",
            "```python\n",
            "researcher = Agent(\n",
            " role='Senior Researcher',\n",
            " goal='Uncover groundbreaking technologies in {topic}',\n",
            " verbose=True,\n",
            " memory=True,\n",
            " backstory=(\n",
            " \"Driven by curiosity, you're at the forefront of\"\n",
            " \"innovation, eager to explore and share knowledge that could change\"\n",
            " \"the world.\"\n",
            " ),\n",
            " tools=[search_tool],\n",
            " allow_delegation=True\n",
            ")\n",
            "```\n",
            "\n",
            "2. Form the Crew:\n",
            "Once you have defined your agents with memory capabilities, you can combine them into a crew. When forming the crew, ensure to set the memory parameter to True to activate memory capabilities for the entire crew.\n",
            "\n",
            "Example:\n",
            "```python\n",
            "crew = Crew(\n",
            " agents=[researcher, writer],\n",
            " tasks=[research_task, write_task],\n",
            " process=Process.sequential,\n",
            " memory=True,\n",
            " cache=True,\n",
            " max_rpm=100,\n",
            " share_crew=True\n",
            ")\n",
            "```\n",
            "\n",
            "3. Kick It Off:\n",
            "Initiate the process with your crew ready. Your agents will collaborate, leveraging their memory capabilities for a successful project outcome.\n",
            "\n",
            "Example:\n",
            "```python\n",
            "result = crew.kickoff(inputs={'topic': 'AI in healthcare'})\n",
            "print(result)\n",
            "```\n",
            "\n",
            "By following these steps, you can effectively add memory to your crew in crewAI. If you encounter any challenges or require further assistance, feel free to reach out for additional guidance. We are here to support you in optimizing your crew's performance.\n",
            "\n",
            "Best regards,\n",
            "[Your Name]\n",
            "Senior Support Representative\n",
            "crewAI\n",
            "\n",
            "\u001b[00m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "Markdown(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 808
        },
        "id": "X7jGbI-UoLrz",
        "outputId": "80813090-db94-4065-f70f-d00b3444eae8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Hello Andrew Ng from DeepLearningAI,\n\nThank you for reaching out for assistance with setting up a Crew and adding memory to your crew in crewAI. I appreciate your interest in enhancing your crew's capabilities. Below are the detailed steps you need to follow to successfully add memory to your crew:\n\n1. Assemble Your Agents:\nTo add memory to your crew, you first need to define your agents with distinct roles, backstories, and capabilities. When creating an agent, ensure to set the memory parameter to True. This will enable the agent to utilize memory capabilities during crew tasks.\n\nExample:\n```python\nresearcher = Agent(\n role='Senior Researcher',\n goal='Uncover groundbreaking technologies in {topic}',\n verbose=True,\n memory=True,\n backstory=(\n \"Driven by curiosity, you're at the forefront of\"\n \"innovation, eager to explore and share knowledge that could change\"\n \"the world.\"\n ),\n tools=[search_tool],\n allow_delegation=True\n)\n```\n\n2. Form the Crew:\nOnce you have defined your agents with memory capabilities, you can combine them into a crew. When forming the crew, ensure to set the memory parameter to True to activate memory capabilities for the entire crew.\n\nExample:\n```python\ncrew = Crew(\n agents=[researcher, writer],\n tasks=[research_task, write_task],\n process=Process.sequential,\n memory=True,\n cache=True,\n max_rpm=100,\n share_crew=True\n)\n```\n\n3. Kick It Off:\nInitiate the process with your crew ready. Your agents will collaborate, leveraging their memory capabilities for a successful project outcome.\n\nExample:\n```python\nresult = crew.kickoff(inputs={'topic': 'AI in healthcare'})\nprint(result)\n```\n\nBy following these steps, you can effectively add memory to your crew in crewAI. If you encounter any challenges or require further assistance, feel free to reach out for additional guidance. We are here to support you in optimizing your crew's performance.\n\nBest regards,\n[Your Name]\nSenior Support Representative\ncrewAI"
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CrewAI Tools\n",
        "\n",
        "- Versatility\n",
        "- Fault Tolerance\n",
        "- Caching"
      ],
      "metadata": {
        "id": "NVQh0lz0tHFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install crewai==0.28.8 crewai_tools==0.1.6 langchain_community==0.0.29"
      ],
      "metadata": {
        "id": "oT5FSO5mtJ61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Task, Crew\n",
        "# Warning control\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "RuZ2ZhtqtMph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "os.environ[\"OPENAI_MODEL_NAME\"] = 'gpt-3.5-turbo'\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
      ],
      "metadata": {
        "id": "jOXrY5iUtSmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Agents**"
      ],
      "metadata": {
        "id": "T0QOYxLAtY9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sales_rep_agent = Agent(\n",
        "    role=\"Sales Representative\",\n",
        "    goal=\"Identify high-value leads that match \"\n",
        "         \"our ideal customer profile\",\n",
        "    backstory=(\n",
        "        \"As a part of the dynamic sales team at CrewAI, \"\n",
        "        \"your mission is to scour \"\n",
        "        \"the digital landscape for potential leads. \"\n",
        "        \"Armed with cutting-edge tools \"\n",
        "        \"and a strategic mindset, you analyze data, \"\n",
        "        \"trends, and interactions to \"\n",
        "        \"unearth opportunities that others might overlook. \"\n",
        "        \"Your work is crucial in paving the way \"\n",
        "        \"for meaningful engagements and driving the company's growth.\"\n",
        "    ),\n",
        "    allow_delegation=False,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "-PrOMwbptTH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lead_sales_rep_agent = Agent(\n",
        "    role=\"Lead Sales Representative\",\n",
        "    goal=\"Nurture leads with personalized, compelling communications\",\n",
        "    backstory=(\n",
        "        \"Within the vibrant ecosystem of CrewAI's sales department, \"\n",
        "        \"you stand out as the bridge between potential clients \"\n",
        "        \"and the solutions they need.\"\n",
        "        \"By creating engaging, personalized messages, \"\n",
        "        \"you not only inform leads about our offerings \"\n",
        "        \"but also make them feel seen and heard.\"\n",
        "        \"Your role is pivotal in converting interest \"\n",
        "        \"into action, guiding leads through the journey \"\n",
        "        \"from curiosity to commitment.\"\n",
        "    ),\n",
        "    allow_delegation=False,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "r-DS0Og0taef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Tools**"
      ],
      "metadata": {
        "id": "EzdRs6qrtdHL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**crewAI Tools**"
      ],
      "metadata": {
        "id": "SaR0MqvHtdvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai_tools import DirectoryReadTool, \\\n",
        "                         FileReadTool, \\\n",
        "                         SerperDevTool"
      ],
      "metadata": {
        "id": "Dwj_H1BktfKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory_read_tool = DirectoryReadTool(directory='./instructions')\n",
        "file_read_tool = FileReadTool()\n",
        "search_tool = SerperDevTool()"
      ],
      "metadata": {
        "id": "HkVU96ZPtg4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Custom Tool**\n",
        "\n",
        "- Create a custom tool using crewAi's [BaseTool](https://docs.crewai.com/core-concepts/Tools/#subclassing-basetool) class"
      ],
      "metadata": {
        "id": "jmFD_drhtixw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai_tools import BaseTool"
      ],
      "metadata": {
        "id": "0Gx_rzhetlAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Every Tool needs to have a `name` and a `description`.\n",
        "- For simplicity and classroom purposes, `SentimentAnalysisTool` will return `positive` for every text.\n",
        "- When running locally, you can customize the code with your logic in the `_run` function."
      ],
      "metadata": {
        "id": "czTvpBPDtncN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentAnalysisTool(BaseTool):\n",
        "    name: str =\"Sentiment Analysis Tool\"\n",
        "    description: str = (\"Analyzes the sentiment of text \"\n",
        "         \"to ensure positive and engaging communication.\")\n",
        "\n",
        "    def _run(self, text: str) -> str:\n",
        "        # Your custom code tool goes here\n",
        "        return \"positive\""
      ],
      "metadata": {
        "id": "u6f6g-ewtmWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_analysis_tool = SentimentAnalysisTool()"
      ],
      "metadata": {
        "id": "YMssBZN9tqwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Tasks**\n",
        "\n",
        "- The Lead Profiling Task is using crewAI Tools."
      ],
      "metadata": {
        "id": "yPFw4RaatsnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lead_profiling_task = Task(\n",
        "    description=(\n",
        "        \"Conduct an in-depth analysis of {lead_name}, \"\n",
        "        \"a company in the {industry} sector \"\n",
        "        \"that recently showed interest in our solutions. \"\n",
        "        \"Utilize all available data sources \"\n",
        "        \"to compile a detailed profile, \"\n",
        "        \"focusing on key decision-makers, recent business \"\n",
        "        \"developments, and potential needs \"\n",
        "        \"that align with our offerings. \"\n",
        "        \"This task is crucial for tailoring \"\n",
        "        \"our engagement strategy effectively.\\n\"\n",
        "        \"Don't make assumptions and \"\n",
        "        \"only use information you absolutely sure about.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A comprehensive report on {lead_name}, \"\n",
        "        \"including company background, \"\n",
        "        \"key personnel, recent milestones, and identified needs. \"\n",
        "        \"Highlight potential areas where \"\n",
        "        \"our solutions can provide value, \"\n",
        "        \"and suggest personalized engagement strategies.\"\n",
        "    ),\n",
        "    tools=[directory_read_tool, file_read_tool, search_tool],\n",
        "    agent=sales_rep_agent,\n",
        ")"
      ],
      "metadata": {
        "id": "PdgsKuk_ttf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The Personalized Outreach Task is using your custom Tool `SentimentAnalysisTool`, as well as crewAI's `SerperDevTool` (search_tool)."
      ],
      "metadata": {
        "id": "IbpqWGUptxMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "personalized_outreach_task = Task(\n",
        "    description=(\n",
        "        \"Using the insights gathered from \"\n",
        "        \"the lead profiling report on {lead_name}, \"\n",
        "        \"craft a personalized outreach campaign \"\n",
        "        \"aimed at {key_decision_maker}, \"\n",
        "        \"the {position} of {lead_name}. \"\n",
        "        \"The campaign should address their recent {milestone} \"\n",
        "        \"and how our solutions can support their goals. \"\n",
        "        \"Your communication must resonate \"\n",
        "        \"with {lead_name}'s company culture and values, \"\n",
        "        \"demonstrating a deep understanding of \"\n",
        "        \"their business and needs.\\n\"\n",
        "        \"Don't make assumptions and only \"\n",
        "        \"use information you absolutely sure about.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A series of personalized email drafts \"\n",
        "        \"tailored to {lead_name}, \"\n",
        "        \"specifically targeting {key_decision_maker}.\"\n",
        "        \"Each draft should include \"\n",
        "        \"a compelling narrative that connects our solutions \"\n",
        "        \"with their recent achievements and future goals. \"\n",
        "        \"Ensure the tone is engaging, professional, \"\n",
        "        \"and aligned with {lead_name}'s corporate identity.\"\n",
        "    ),\n",
        "    tools=[sentiment_analysis_tool, search_tool],\n",
        "    agent=lead_sales_rep_agent,\n",
        ")"
      ],
      "metadata": {
        "id": "sAJmw1AAtxg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating the Crew**"
      ],
      "metadata": {
        "id": "fIjXCH9Ctyw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "crew = Crew(\n",
        "    agents=[sales_rep_agent,\n",
        "            lead_sales_rep_agent],\n",
        "\n",
        "    tasks=[lead_profiling_task,\n",
        "           personalized_outreach_task],\n",
        "\n",
        "    verbose=2,\n",
        "\tmemory=True\n",
        ")"
      ],
      "metadata": {
        "id": "gjAgy1rjt0Yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Running the Crew**"
      ],
      "metadata": {
        "id": "FPe42ypkt00W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\n",
        "    \"lead_name\": \"DeepLearningAI\",\n",
        "    \"industry\": \"Online Learning Platform\",\n",
        "    \"key_decision_maker\": \"Andrew Ng\",\n",
        "    \"position\": \"CEO\",\n",
        "    \"milestone\": \"product launch\"\n",
        "}\n",
        "\n",
        "result = crew.kickoff(inputs=inputs)"
      ],
      "metadata": {
        "id": "9DRAJAo7t3AD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vector Databases"
      ],
      "metadata": {
        "id": "3TY5pCv8w-5H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pinecone VectorDB"
      ],
      "metadata": {
        "id": "fX0221ouxAfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain pinecone-client pypdf openai tiktoken langchain_pinecone langchain-openai"
      ],
      "metadata": {
        "id": "pcgnKk1SNq5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFDirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_openai import OpenAI\n",
        "import os"
      ],
      "metadata": {
        "id": "QULNAZX-xwSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir pdfs"
      ],
      "metadata": {
        "id": "cs8UOQR31HCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://papers.neurips.cc/paper/7181-attention-is-all-you-need.pdf\n",
        "!mv /content/7181-attention-is-all-you-need.pdf /content/pdfs/attention-is-all-you-need.pdf"
      ],
      "metadata": {
        "id": "gEjw4N0H4-Pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFDirectoryLoader('pdfs')"
      ],
      "metadata": {
        "id": "qypQypsW4smX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = loader.load()\n",
        "len(data), data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRwx8q085x8L",
        "outputId": "16b9251f-9047-4b5b-c085-7bcf5e4eb3ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11,\n",
              " Document(page_content='Attention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.comNoam Shazeer∗\\nGoogle Brain\\nnoam@google.comNiki Parmar∗\\nGoogle Research\\nnikip@google.comJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.comAidan N. Gomez∗†\\nUniversity of Toronto\\naidan@cs.toronto.eduŁukasz Kaiser∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring signiﬁcantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41.0 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature.\\n1 Introduction\\nRecurrent neural networks, long short-term memory [ 12] and gated recurrent [ 7] neural networks\\nin particular, have been ﬁrmly established as state of the art approaches in sequence modeling and\\ntransduction problems such as language modeling and machine translation [ 29,2,5]. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\\narchitectures [31, 21, 13].\\n∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the ﬁrst Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\\nefﬁcient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research.\\n†Work performed while at Google Brain.\\n‡Work performed while at Google Research.\\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.', metadata={'source': 'pdfs/attention-is-all-you-need.pdf', 'page': 0}))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)"
      ],
      "metadata": {
        "id": "lzsGNVdY5yu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks = text_splitter.split_documents(data)"
      ],
      "metadata": {
        "id": "2T7qWMvc5_E4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text_chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEH3J1O46isS",
        "outputId": "87879de8-62e8-4b05-fd3d-7255c8be81bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "76"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_chunks[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mMjatJ46nsU",
        "outputId": "8a85739d-4a5b-4320-f823-7757351dc852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention Is All You Need\n",
            "Ashish Vaswani∗\n",
            "Google Brain\n",
            "avaswani@google.comNoam Shazeer∗\n",
            "Google Brain\n",
            "noam@google.comNiki Parmar∗\n",
            "Google Research\n",
            "nikip@google.comJakob Uszkoreit∗\n",
            "Google Research\n",
            "usz@google.com\n",
            "Llion Jones∗\n",
            "Google Research\n",
            "llion@google.comAidan N. Gomez∗†\n",
            "University of Toronto\n",
            "aidan@cs.toronto.eduŁukasz Kaiser∗\n",
            "Google Brain\n",
            "lukaszkaiser@google.com\n",
            "Illia Polosukhin∗‡\n",
            "illia.polosukhin@gmail.com\n",
            "Abstract\n",
            "The dominant sequence transduction models are based on complex recurrent or\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_chunks[1].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C80gdjJt6y-e",
        "outputId": "19c3cd13-6ec6-4d26-d8a4-baf869e324dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "convolutional neural networks that include an encoder and a decoder. The best\n",
            "performing models also connect the encoder and decoder through an attention\n",
            "mechanism. We propose a new simple network architecture, the Transformer,\n",
            "based solely on attention mechanisms, dispensing with recurrence and convolutions\n",
            "entirely. Experiments on two machine translation tasks show these models to\n",
            "be superior in quality while being more parallelizable and requiring signiﬁcantly\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key = \"\" # @param {type:\"string\"}"
      ],
      "metadata": {
        "id": "sP8UUFY07rrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = OpenAIEmbeddings(api_key=openai_api_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kqgo5x9Z8TtR",
        "outputId": "2c9f2ea0-b77f-45aa-924c-e06c34c947af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_example = embedding.embed_query(\"Hello World\")\n",
        "len(embedding_example), embedding_example[:15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3Z5US0a8YhY",
        "outputId": "988bccd4-3483-4e9f-fd98-7de4b19621cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1536,\n",
              " [-0.007116983617481661,\n",
              "  0.0034469901452434362,\n",
              "  -0.007148840903008569,\n",
              "  -0.029156057052714266,\n",
              "  -0.013061608137966748,\n",
              "  0.010946264448676999,\n",
              "  -0.020274164077690417,\n",
              "  0.0052533149518593026,\n",
              "  -0.008563317325787047,\n",
              "  -0.03017549950280105,\n",
              "  0.024390162806934363,\n",
              "  0.009863106496213825,\n",
              "  -0.027524949877633466,\n",
              "  -0.006632748500256566,\n",
              "  0.009111268411049814])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pinecone_api_key = \"\" # @param {type:\"string\"}\n",
        "pinecone_api_env = \"\" # @param {type:\"string\"}"
      ],
      "metadata": {
        "id": "wD170J5l1DGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import Pinecone\n",
        "pc = Pinecone(\n",
        "    api_key=pinecone_api_key,\n",
        "    environment=pinecone_api_env\n",
        ")"
      ],
      "metadata": {
        "id": "q6dORQG88Yc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pc.list_indexes()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFRs2YjU8Yab",
        "outputId": "bd6becf5-80ad-40b3-c554-4b52d43bcb4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'indexes': [{'dimension': 1536,\n",
              "              'host': 'genai-course-iqutuem.svc.gcp-starter.pinecone.io',\n",
              "              'metric': 'cosine',\n",
              "              'name': 'genai-course',\n",
              "              'spec': {'pod': {'environment': 'gcp-starter',\n",
              "                               'pod_type': 'starter',\n",
              "                               'pods': 1,\n",
              "                               'replicas': 1,\n",
              "                               'shards': 1}},\n",
              "              'status': {'ready': True, 'state': 'Ready'}}]}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Embeddings from text chunks"
      ],
      "metadata": {
        "id": "ChlWuiNPB4er"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "0SGExxwzDIvs",
        "outputId": "9a525bf5-8d9f-419e-ab92-6c5cdd19bef0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Attention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.comNoam Shazeer∗\\nGoogle Brain\\nnoam@google.comNiki Parmar∗\\nGoogle Research\\nnikip@google.comJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.comAidan N. Gomez∗†\\nUniversity of Toronto\\naidan@cs.toronto.eduŁukasz Kaiser∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_name = \"genai-course\"\n",
        "os.environ[\"PINECONE_API_KEY\"] = pinecone_api_key\n",
        "os.environ[\"PINECONE_INDEX_NAME\"] = index_name"
      ],
      "metadata": {
        "id": "DEhb3ahQEHBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_name = \"genai-course\"\n",
        "\n",
        "docsearch = PineconeVectorStore.from_documents(\n",
        "    text_chunks,\n",
        "    embedding,\n",
        "    index_name=index_name,\n",
        ")"
      ],
      "metadata": {
        "id": "b22MmbDTDVAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Querying VectorDB"
      ],
      "metadata": {
        "id": "WtglMMDjKD-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What are decoder components\""
      ],
      "metadata": {
        "id": "6X-uu_jaFCqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = docsearch.similarity_search(query)"
      ],
      "metadata": {
        "id": "suwasDV8B0dP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs), docs[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XL32AD9WFSo4",
        "outputId": "c4abb9bd-9f66-4a87-f908-a01758119a07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4,\n",
              " 'Decoder: The decoder is also composed of a stack of N= 6identical layers. In addition to the two\\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\\nattention over the output of the encoder stack. Similar to the encoder, we employ residual connections\\naround each of the sub-layers, followed by layer normalization. We also modify the self-attention\\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions. This')"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manually decoding embeded vectors"
      ],
      "metadata": {
        "id": "cafiTMvpFzY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(api_key=openai_api_key)"
      ],
      "metadata": {
        "id": "Zw7aRTtt7sN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=docsearch.as_retriever()\n",
        ")"
      ],
      "metadata": {
        "id": "zXXhDIf7GLas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "XH83DC_qGg6g",
        "outputId": "757145c3-e7a6-4ea7-c164-ee81356af10a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The decoder components include a stack of N= 6 identical layers, with a third sub-layer for multi-head attention over the output of the encoder stack. The decoder also uses residual connections and layer normalization, and modifies the self-attention sub-layer to prevent positions from attending to subsequent positions. Additionally, the decoder follows the same overall architecture as the encoder, using stacked self-attention and point-wise, fully connected layers. '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docsearch.as_retriever()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcsS5xBTJaCq",
        "outputId": "c72495ab-7b0f-4ffd-e638-2d79c5b02ac4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VectorStoreRetriever(tags=['PineconeVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_pinecone.vectorstores.PineconeVectorStore object at 0x7bf5a8303a90>)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Pinecone directly"
      ],
      "metadata": {
        "id": "WZsEJp1WKM3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = pc.Index(index_name)"
      ],
      "metadata": {
        "id": "-rbJrKv2J3nD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pc.list_indexes()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpirQnB4KSKT",
        "outputId": "a5fc6a1f-9844-4dc3-e003-05103979a34b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'indexes': [{'dimension': 1536,\n",
              "              'host': 'genai-course-iqutuem.svc.gcp-starter.pinecone.io',\n",
              "              'metric': 'cosine',\n",
              "              'name': 'genai-course',\n",
              "              'spec': {'pod': {'environment': 'gcp-starter',\n",
              "                               'pod_type': 'starter',\n",
              "                               'pods': 1,\n",
              "                               'replicas': 1,\n",
              "                               'shards': 1}},\n",
              "              'status': {'ready': True, 'state': 'Ready'}}]}"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeded_query = embedding.embed_query(query)\n",
        "len(embeded_query), embeded_query[:15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKeG5UZeKgYS",
        "outputId": "0415829e-87d0-495a-dc9d-5d2eee214bca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1536,\n",
              " [-0.027967285621545507,\n",
              "  0.007272935520456191,\n",
              "  0.00372656855753541,\n",
              "  -0.036588130280438405,\n",
              "  -0.030850511135379583,\n",
              "  0.01670829110761046,\n",
              "  -0.006833243722728746,\n",
              "  -0.011114833238243343,\n",
              "  -0.0013605219229251401,\n",
              "  -0.02120612253666261,\n",
              "  0.03330125095949351,\n",
              "  0.025934610889234464,\n",
              "  -0.02910615895445195,\n",
              "  -0.0020831302940467426,\n",
              "  -0.019865422300200757])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = index.query(\n",
        "    # namespace=\"ns1\",\n",
        "    vector=embeded_query,\n",
        "    top_k=3,\n",
        "    include_values=True\n",
        ")"
      ],
      "metadata": {
        "id": "Ovf4ZeYLJ-5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(result.matches), \\\n",
        "result.matches[0].id, \\\n",
        "result.matches[0].score, \\\n",
        "result.matches[0].values[:15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Xv23QcBKqaQ",
        "outputId": "0afe8c8f-ca26-4967-ff83-5e656cc822a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3,\n",
              " '6127f943-c2e2-4a09-9d60-357eec482557',\n",
              " 0.796478271,\n",
              " [-0.0240785182,\n",
              "  0.0146332774,\n",
              "  0.012422544,\n",
              "  -0.0345504135,\n",
              "  0.0149207413,\n",
              "  0.00992434658,\n",
              "  -0.0147154108,\n",
              "  0.00101125659,\n",
              "  0.00319119077,\n",
              "  -0.00310905813,\n",
              "  0.0283357203,\n",
              "  0.0291296691,\n",
              "  0.00343587715,\n",
              "  0.00145614112,\n",
              "  -0.00544127962])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index.fetch([result.matches[0].id]) \\\n",
        "  .vectors[result.matches[0].id]['metadata'][\"text\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "Ud5w8dgkMKvW",
        "outputId": "8ffea901-1b5f-4c31-b6e5-eeb5f6a113c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Decoder: The decoder is also composed of a stack of N= 6identical layers. In addition to the two\\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\\nattention over the output of the encoder stack. Similar to the encoder, we employ residual connections\\naround each of the sub-layers, followed by layer normalization. We also modify the self-attention\\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions. This'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ChromaDB"
      ],
      "metadata": {
        "id": "kD8z-5adnZ4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q chromadb openai langchain tiktoken langchain-openai"
      ],
      "metadata": {
        "id": "MZG9y6-P7-tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://www.dropbox.com/s/vs6ocyvpzzncvwh/new_articles.zip\n",
        "!unzip -q new_articles.zip -d new_articles\n",
        "!rm -f new_articles/05-03** new_articles/05-04** new_articles/05-05**"
      ],
      "metadata": {
        "id": "4hzdK-o_8D3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "openai_api_key = \"\" # @param {type:\"string\"}\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
      ],
      "metadata": {
        "id": "zep2gqAm93yK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain_openai import OpenAI\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.document_loaders import TextLoader"
      ],
      "metadata": {
        "id": "XjPlqPvD_Lu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = DirectoryLoader(\"./new_articles\", glob=\"./*.txt\", loader_cls=TextLoader)"
      ],
      "metadata": {
        "id": "M9ASBhRdAGWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document = loader.load()\n",
        "\n",
        "len(document), document[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcY-rZuJAJVU",
        "outputId": "8cc722de-70ed-4282-8160-a1340b1330ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6,\n",
              " Document(page_content='Welcome back to This Week in Apps, the weekly TechCrunch series that recaps the latest in mobile OS news, mobile applications and the overall app economy.\\n\\nThe app economy in 2023 hit a few snags, as consumer spending last year dropped for the first time by 2% to $167 billion, according to data.ai’s “State of Mobile” report. However, downloads are continuing to grow, up 11% year-over-year in 2022 to reach 255 billion. Consumers are also spending more time in mobile apps than ever before. On Android devices alone, hours spent in 2022 grew 9%, reaching 4.1 trillion.\\n\\nThis Week in Apps offers a way to keep up with this fast-moving industry in one place with the latest from the world of apps, including news, updates, startup fundings, mergers and acquisitions, and much more.\\n\\nDo you want This Week in Apps in your inbox every Saturday? Sign up here: techcrunch.com/newsletters\\n\\nTop Stories\\n\\nDorsey criticizes Twitter, Musk on the alternative social networks he’s backing\\n\\nAs demand for Bluesky, the Jack Dorsey-backed decentralized Twitter rival grows, the former Twitter CEO took to the app to share his thoughts on Twitter’s future, Elon Musk and the decision to take the company private. As TechCrunch’s Darrell Etherington reported, Dorsey responded to questions posed to him from other users and reporters on Bluesky, including one where he was asked if Musk has proven to be the best possible steward for the social network.\\n\\nDorsey said he had not:\\n\\nNo. Nor do I think he acted right after realizing his timing was bad. Nor do I think the board should have forced the sale. It all went south. But it happened and all we can do now is build something to avoid that ever happening again. So I’m happy Jay and team and nostr devs exist and building it.\\n\\nHowever, the Twitter co-founder stressed that Twitter would have never survived as a public company and defended himself from an accusation that he was deflecting blame for Twitter’s current situation.\\n\\nThough Bluesky is having a moment, particularly as a haven for marginalized groups, sex workers and trans users, it’s not the only Twitter alternative Dorsey is now backing. In fact, he’s been more active in recent days on the social network nostr (which he also financially backed), where he’s also been critical of some of Musk’s recent decisions. For example, as The NYT reported, Dorsey posted last month “This is weak,” in response to Musk’s move to stop Twitter users from linking to Substack after it launched a Twitter-like service for its own community of writers and readers.\\n\\nDorsey also touted his belief in these platforms during Block’s recent earnings call, suggesting on his nostr profile this may be the first time the network’s name had been mentioned during a public earnings event.\\n\\n“Open protocols represent another fork in the road moment for people and companies,” Dorsey told investors. “Bitcoin, nostr, Bluesky, web5 and others are all working to level the playing field for competition and give individuals and organizations entirely new capabilities,” he added.\\n\\nOver the past few weeks, Bluesky has been gaining traction, but the network has been difficult to access due to its invite-only nature. That’s turned Bluesky invites into hot commodities, where they’re even selling for hundreds of dollars on eBay, as most users have to wait to receive only one invite every two weeks.\\n\\nBluesky leadership will also sometimes gift a user with a larger number of invites in order to have them invite members of a specific community. Developers who can demonstrate they’re building a Bluesky app may also request additional invites, we understand.\\n\\nThe network has received outsized press coverage relative to its size — just 50,000+ users — possibly because of the heavy infusion of tech journalists on there and Dorsey’s name attached. But the reality is that Bluesky’s future remains uncertain. The company, for now, is able to build and grow thanks to the $13 million in initial funds it received from Twitter, where it was incubated under Dorsey’s leadership. It has since spun out into its own, independent company (a public benefit LLC). It’s unclear how Bluesky intends to maintain its operations in the long term, not to mention its freewheeling culture and accepting community. Networks can often be pleasant and welcoming when small, like Bluesky — or early Twitter, for that matter — but face challenges once they scale to millions of users.\\n\\nNewFronts round-up\\n\\nThis week was IAB’s NewFronts, where digital media companies and social networks pitched their platforms to advertisers looking to reach online audiences. The event saw major brands introducing a range of new offerings, including both ad products and formats, as well as touting their latest features, in some cases, as Snap did with its My AI integration.\\n\\nHere’s what you may have missed from the app makers’ NewFronts this week:\\n\\nSnap said it’s beginning to test a feature that lets partners leverage its new My AI chatbot to place sponsored links in front of users. Snap also announced new ad slots, including the option to reserve the first video ad seen in Snapchat’s Friend Stories and the ability to advertise within its TikTok-like Spotlight feature.\\n\\nSnap also announced including the option to reserve the and the ability to YouTube introduced new ad opportunities for Shorts, including the expansion of Shorts into Video reach campaigns that leverage Google AI to serve the best combination of ads and improve reach on YouTube. Plus, YouTube Select is now coming to Shorts, allowing advertisers to place their ads alongside the most popular YouTube Shorts’ content, similar to TikTok Pulse. Another option, First Position on Shorts, will let advertisers be the first ad Shorts users see in their viewing session.\\n\\nincluding the that leverage Google AI to serve the best combination of ads and improve reach on YouTube. Plus, allowing advertisers to place their ads alongside the most popular YouTube Shorts’ content, similar to TikTok Pulse. Another option, will let advertisers be the first ad Shorts users see in their viewing session. TikTok announced partnerships with big-name publishers, including NBCU, Condé Nast, DotDash Meredith, BuzzFeed and others, in an effort to pull in more premium ad dollars. The new premium ad product, Pulse Premiere, would allow marketers, for the first time, to position their brand ads directly after TikTok’s publisher and media partners’ content in over a dozen categories, including lifestyle, sports, entertainment, education and more. Publisher partners would receive a rev share as a result.\\n\\nThe would allow marketers, for the first time, to position their brand ads directly after TikTok’s publisher and media partners’ content in over a dozen categories, including lifestyle, sports, entertainment, education and more. Publisher partners would receive a rev share as a result. Meta announced AR would become available to Reels Ads and Facebook Stories. They had previously been available only to the Facebook Feed, Instagram Feed and Instagram Stories. It also announced features to make Reels Ads more interactive, including a t est of a larger “call to action” button with additional advertiser information on Facebook and Instagram Reels ads. Other updates included multi-destination product ads, the ability to pause a video ad to preview a link’s destination and support for Reels Ads campaigns with select third-party measurement firms .\\n\\nThey had previously been available only to the Facebook Feed, Instagram Feed and Instagram Stories. It also announced features to make Reels Ads more interactive, including a t with additional advertiser information on Facebook and Instagram Reels ads. Other updates included the ability to and support for . NBCU will let Peacock users shop products that appear in its content through “Must ShopTV,” which puts a QR code on the screen when a shoppable product appears.\\n\\nApple & Google team up on Bluetooth tracker safety\\n\\nAfter numerous cases of Bluetooth trackers like Apple’s AirTag being used for stalking or other criminal apps, Apple and Google this week released a joint announcement saying they will work together to lead an industry-wide initiative to draft a specification that would alert users in the case of unwanted tracking from Bluetooth devices. The companies said they’re seeking input from other industry participants and advocacy groups in the matter, and noted that other tracker makers like Samsung, Tile, Chipolo, eufy Security and Pebblebee have also expressed interest in the draft.\\n\\nThe companies submitted a proposed specification as an Internet-Draft via a standards development organization, the Internet Engineering Task Force (IETF). Other interested parties are now being invited to review and comment over the next three months. After this time, Apple and Google will offer feedback and will release a production implementation of the specification by year’s end that will be supported in future versions of iOS and Android, they said.\\n\\nThe spec would build on the AirTag protections Apple had already released but also, critically, would ensure that users would be able to combat unwanted tracking by offering tools across both iOS and Android platforms.\\n\\nGoogle’s participation could signal more than a desire to protect its users — it’s been rumored the company may also be developing an AirTag rival.\\n\\nPlatforms\\n\\nApple\\n\\nGoogle — I/O Preview\\n\\nGoogle I/O kicks off next week and we already know at least one of the announcements — because Google leaked it. The company plans to introduce its first foldable smartphone with the Pixel Fold. The device shares Pixel’s familiar camera bar and features an interface that showcases Material UI design. We expect to learn more at the event.\\n\\nIn addition, Google I/O 2023 should bring a Pixel 7a , a budget device that could also help address Pixel demand in emerging markets, plus possibly a Pixel tablet, an AirTag rival, a Wear OS update, and a lot of new developer tools and features. We also expect to hear quite a bit about Google’s AI plans, with generative AI (like Bard) appearing across Google’s line of products.\\n\\n, a budget device that could also help address Pixel demand in emerging markets, plus possibly a Pixel tablet, an AirTag rival, a Wear OS update, and a lot of new developer tools and features. We also expect to hear quite a bit about Google’s AI plans, with generative AI (like Bard) appearing across Google’s line of products. To get ready for I/O, even if you’re attending virtually, Google offered a new planning guide and a playlist of developer content to help attendees prepare.\\n\\nto help attendees prepare. Checks, Google’s AI-powered data protection project, exited to Google from its in-house incubator Area 120. The tool uses AI to check mobile apps for compliance with various privacy rules and regulations.\\n\\nApp Updates\\n\\nSocial\\n\\nSocial networking app IRL’s CEO Abraham Shafi stepped down following allegations he used bots to inflate the number of users IRL reported publicly and to its investors , The Information reported. A former employee had alleged he was fired after expressing concern over the use of bots. The SEC is now investigating if the company violated securities laws. IRL raised around $200 million from SoftBank Vision Fund, Founders Fund and others.\\n\\n, The Information reported. A former employee had alleged he was fired after expressing concern over the use of bots. The SEC is now investigating if the company violated securities laws. IRL raised around $200 million from SoftBank Vision Fund, Founders Fund and others. After laying off 50% of staff, declining audio social network Clubhouse says it’s building “Clubhouse 2.0,” but hasn’t shared exactly what that plan may involve. Last year, the company began shifting its focus away from public audio to private rooms but it’s not clear there’s much demand for audio social networking in the post-pandemic market.\\n\\nbut hasn’t shared exactly what that plan may involve. Last year, the company began shifting its focus away from public audio to private rooms but it’s not clear there’s much demand for audio social networking in the post-pandemic market. Once-hot viral app Poparazzi shuts down and returns remaining funds to investors. The app had let friends tag others to build out their social profiles of real moments, not polished images, but had been on the decline, with only a few thousand MAUs down from a height of 4 million MAUs previously.\\n\\nA Twitter bug saw users able to regain their blue Verification checks just by editing their bio. Shortly afterward, the Twitter desktop website began randomly logging out users. Later in the week, the mobile website was also down.\\n\\nShortly afterward, the Twitter desktop website began randomly logging out users. Later in the week, the mobile website was also down. As Bluesky gains attention, rival decentralized social platform Mastodon announced a new, simpler onboarding experience that provides new users with an account on mastodon.social by default , instead of requiring them to pick a server. This doesn’t eliminate server choice, it simply means that joining another server requires a few extra clicks.\\n\\n, instead of requiring them to pick a server. This doesn’t eliminate server choice, it simply means that joining another server requires a few extra clicks. Neighborhood social network Nextdoor added new features powered by generative AI, including an Assistant feature aimed at helping users write posts that are more likely to drive positive community engagement. The Assistant will offer writing suggestions that users can review and optionally adopt. The company says it will also use AI to better match content to users when providing recommendations.\\n\\nincluding an Assistant feature aimed at helping users write posts that are more likely to drive positive community engagement. The Assistant will offer writing suggestions that users can review and optionally adopt. The company says it will also use AI to better match content to users when providing recommendations. BeReal is testing another new feature in the U.K., “RealPeople,” that shows users a timeline of the “world’s most interesting people” — that is, athletes, artists, activists and other public figures. The company also recently began testing the option to post more often as usage has declined.\\n\\nand other public figures. The company also recently began testing the option to post more often as usage has declined. Meta introduced new discovery and personalization options for Facebook Reels. Users can now choose “Show More” or “Show Less” options to control what sort of Reels they want to see. Facebook will also explain why it’s showing you a Reel, like if a friend viewed it, and is adding Reels to the main navigation at the top of Facebook Watch.\\n\\nWordPress drops Twitter integration, says sharing to Instagram and Mastodon is coming instead. The Automattic-owned publishing platform said the Twitter connection on Jetpack and WordPress.com will cease to work, meaning users’ blog posts will no longer be auto-shared to Twitter as before. The company said Elon Musk’s decision to “dramatically change the terms and pricing” for Twitter’s API was to blame for this decision. The API now starts at $42,000/month for 50 million tweets. The move will likely hurt Twitter more than WordPress, as the latter powers over 40% of the global internet, including WordPress.com blogs.\\n\\nThe Automattic-owned publishing platform said the Twitter connection on Jetpack and WordPress.com will cease to work, meaning users’ blog posts will no longer be auto-shared to Twitter as before. The company said Elon Musk’s decision to “dramatically change the terms and pricing” for Twitter’s API was to blame for this decision. The API now starts at $42,000/month for 50 million tweets. The move will likely hurt Twitter more than WordPress, as the latter powers over 40% of the global internet, including WordPress.com blogs. Mozilla announced it’s opening up its own Mastodon server — or “instance,” in Mastodon lingo — into private beta testing. The company had said last year it planned to create and begin testing a publicly accessible instance at mozilla.social. It explains its approach to Mastodon will involve high levels of moderation.\\n\\nThe company had said last year it planned to create and begin testing a publicly accessible instance at mozilla.social. It explains its approach to Mastodon will involve high levels of moderation. Twitter announced it would make its API free for public service announcements after New York’s Metro Transit Service (MTS) abandoned the service and the National Weather Services (NWS) said it would no longer auto-post warnings.\\n\\nafter New York’s Metro Transit Service (MTS) abandoned the service and the National Weather Services (NWS) said it would no longer auto-post warnings. TikTok’s U.S. head of trust and safety Eric Han is leaving the company on May 12 as lawmakers weigh a TikTok ban. Han had played a key role in TikTok’s strategy to avoid a U.S. ban.\\n\\nas lawmakers weigh a TikTok ban. Han had played a key role in TikTok’s strategy to avoid a U.S. ban. Discord is making all users change their usernames, the company announced this week. Originally, Discord users had been identified by a name and random number separated by a hash sign, but now it wants to adopt a simpler format so people can more easily share their usernames with others. The new plan will include a unique alphanumeric username with the @ symbol in front of it, plus a freely assignable display name that can be changed at any time.\\n\\nAI\\n\\nSlack introduced SlackGPT, its own generative AI built on Slack’s platform which developers can use to create AI-driven experiences.\\n\\nwhich developers can use to create AI-driven experiences. Microsoft launched its Bing chatbot to all users globally, meaning there’s no more waitlist to get started. It’s also adding more image- and graphic-centric answers in Bing Chat, including by creating graphs and charts and generating images from text prompts. It will also allow users to export their Bing Chat histories. And it will embrace multimodality, meaning it can understand queries with images and text combined. Bing now sees more than 100 million daily active users and says visitors have engaged in over half a billion chats.\\n\\nIt’s also adding more image- and graphic-centric answers in Bing Chat, including by creating graphs and charts and generating images from text prompts. It will also allow users to export their Bing Chat histories. And it will embrace multimodality, meaning it can understand queries with images and text combined. Bing now sees more than 100 million daily active users and says visitors have engaged in over half a billion chats. Plexamp, the music player originally incubated by the Labs division of media company Plex, is tapping into ChatGPT with its latest update. The new feature called “Sonic Sage,” powered by OpenAI’s ChatGPT, will build unique music playlists by scanning users’ libraries and leveraging their TIDAL subscription.\\n\\nMedia & Entertainment\\n\\nFintech\\n\\nYC-backed Kenyan fintech Fingo launched its neobanking app, developed in collaboration with Pan-African financial institution Ecobank Kenya. The company raised $4 million in seed funding after its YC S21 participation. Fingo offers users a bank account, paired with free peer-to-peer transactions and access to savings, financial education and smart spending analytics.\\n\\nThe company raised $4 million in seed funding after its YC S21 participation. Fingo offers users a bank account, paired with free peer-to-peer transactions and access to savings, financial education and smart spending analytics. The FDIC is looking into Tellus, an Andreessen Horowitz-backed fintech company that claims it can offer people higher yields on their savings balances by using that money to fund certain U.S. single-family-home loans. U.S. Senator Sherrod Brown, chairman of the Senate Banking, Housing, and Urban Affairs Committee, wrote a letter to FDIC Chairman Martin Gruenberg expressing concerns about Tellus, and asking the FDIC to review Tellus’s business practices which may put customers at risk.\\n\\nMessaging\\n\\nWhatsApp now lets users create single-vote polls and forward media with captions, Meta announced this week. Single-vote polls let users run a poll where people are only allowed to vote once, including multiple choice, as has been the default.\\n\\nMeta announced this week. Single-vote polls let users run a poll where people are only allowed to vote once, including multiple choice, as has been the default. Reddit’s latest update provides link previews for messaging apps. Now, when you share a Reddit link via a messaging app, it will include a visual preview of the content, the subreddit name, the total upvotes tally and the number of comments. The update also includes the ability to share directly to IG Stories and other tools for publishers.\\n\\nTravel & Transportation\\n\\nFollowing its acquisition by Via, Citymapper said it’s lowering the paywall for its premium features while also introducing a new subscription plan ($1.49/mo) purely for removing ads.\\n\\nwhile also introducing a new subscription plan ($1.49/mo) purely for removing ads. Uber reported a Q1 earnings beat with its revenue up 29% YoY to $8.82 billion, gross bookings up 19% YoY to $31.4 billion and adjusted EBITDA up 353% YoY to $761 million. It also reported a $157 million net loss.\\n\\ngross bookings up 19% YoY to $31.4 billion and adjusted EBITDA up 353% YoY to $761 million. It also reported a $157 million net loss. Uber Eats is also planning to offer support for Live Activities and Dynamic Island on iPhone and integrated with Alexa for order updates.\\n\\nfor order updates. Lyft shared worrisome Q2 guidance sending its stock down after Q1 earnings where it had reported a 14% YoY increase in revenue to $1 billion and a net loss drop of 5% to $187.6 million. Ridership was up 9.8% YoY to 19.5 million.\\n\\nGaming\\n\\nSnowman, the mobile game studio behind Alto’s Adventure and Alto’s Odyssey, launched its newest title, Laya’s Horizon, exclusively with Netflix. The wingsuit game sees players mastering the art of flying, diving off mountains, weaving across forests and gliding over rivers to unlock new abilities as they explore a vast and peaceful world.\\n\\nCross-platform game engine Unity announced layoffs of 8% of its workforce, or around 600 jobs, after laying off 500+ in January and last June.\\n\\nafter laying off 500+ in January and last June. Amazon announced that customers in the United States, Canada, Germany and the United Kingdom can now play Fortnite on their Fire TVs via its Amazon Luna cloud gaming service.\\n\\nCommerce & Food Delivery\\n\\nAmazon Inspire, the e-commerce giant’s in-app TikTok-like shopping feed has rolled out to all customers in the United States. The company had been experimenting since last year with the new feed, which features content creators by influencers.\\n\\nThe company had been experimenting since last year with the new feed, which features content creators by influencers. DoorDash revenue was up 40% YoY in Q1, reaching $2.04 billion, beating estimates of $1.93 billion. Its net loss also declined 3% to $162 million and orders were up 27% to 512 million.\\n\\nEtc.\\n\\nAmazon rolled out a Matter update for Alexa that includes support for Thread, setup on iOS, and a new version of its Works with Alexa program.\\n\\nand a new version of its Works with Alexa program. Match Group posted a Q1 earnings miss with revenue down by 1% YoY to $787 million and paying users down 3% to 15.9 million. The company, however, said it’s “very possible” the recent Apple-Epic court decision could result in App Store fee relief.\\n\\nMedtech startup Healthy.io, which provides urine analysis through a mobile app, is laying off a third of its staff, or around 70 people. The company had just raised $50 million in Series D funding.\\n\\nThe company had just raised $50 million in Series D funding. Airbnb announced Rooms, a feature that focuses on the ability to book single rooms averaging $67 per night as users complain about excessive fees, onerous checkout procedures and rising Airbnb prices.\\n\\naveraging $67 per night as users complain about excessive fees, onerous checkout procedures and rising Airbnb prices. Google’s smart home app, Google Home, added support for smart garage door openers.\\n\\nSecurity\\n\\nGoogle announced that passkeys are now rolling out to Google Account users globally. Passkey let users sign in to websites and apps using the same biometrics or screen-lock PIN they use to unlock their devices.\\n\\nPasskey let users sign in to websites and apps using the same biometrics or screen-lock PIN they use to unlock their devices. Google announced that in 2022, it prevented 1.43 million policy-violating apps from being published on Google Play “in part due to new and improved security features and policy enhancements.”\\n\\nGovernment, Policy and Lawsuits\\n\\nThe EU’s Digital Markets Act (DMA) became applicable on May 2, but enforcement is not expected until spring 2024. The act focused on gatekeepers like Apple, Google, Meta and Microsoft. It limits how they can use third-party data, bans self-preferencing, introduces interoperability requirements, bans tracking users for targeted ads without consent and more. It also says app stores can’t require the use of their own payment services and permits app sideloading.\\n\\nBipartisan U.S. lawmakers reintroduced the Kids Online Safety Act with updates aimed at fixing earlier issues. The bill says platforms have to take reasonable steps to stop the spread of posts that promote eating disorders, suicide, substance abuse and more and undergo independent analysis about their safety for minors. It now also includes protections for support services, like the National Suicide Hotline, substance abuse groups and LGBTQ+ youth centers. However, critics, including the ACLU, say the changes are not enough and they remain opposed to the increased surveillance of kids this bill would require and other matters.\\n\\nThe bill says platforms have to take reasonable steps to stop the spread of posts that promote eating disorders, suicide, substance abuse and more and undergo independent analysis about their safety for minors. It now also includes protections for support services, like the National Suicide Hotline, substance abuse groups and LGBTQ+ youth centers. However, critics, including the ACLU, say the changes are not enough and they remain opposed to the increased surveillance of kids this bill would require and other matters. France’s competition watchdog announced interim measures against Meta, saying it suspects Meta of abusing its dominant position in the French market for ads on social media and across the broader (non-search-related) online ads market.\\n\\nsaying it suspects Meta of abusing its dominant position in the French market for ads on social media and across the broader (non-search-related) online ads market. The U.S. Federal Trade Commission (FTC) says Meta has “repeatedly violated” privacy rules and proposed to tighten its 2020 privacy order against the company, which would completely bar it from monetizing data from anyone under 18 in any way, among other new restrictions. The FTC also accused Meta of COPPA, a children’s privacy law, by misrepresenting its Messenger Kids parental controls, which allowed group chats and group calls with unapproved contacts.\\n\\nFunding and M&A\\n\\nAmazon acquired a small audio-focused artificial intelligence firm called Snackable.AI in 2022, The Post reported. Deal terms weren’t disclosed but Mari Joller, the founder and CEO of Snackable, is now the artificial intelligence and machine learning product leader at Amazon.\\n\\nDownloads\\n\\nRTRO\\n\\nNew social networking startup RTRO launched its app this week with the goal of connecting brands, creators and their fans and followers in a more positive environment focused on human connections and communities, not algorithm-driven content. To accomplish this, RTRO divides its social experience into two parts — on one side, you can keep up with friends or family in RTRO’s “circles.” On the other side, users can switch over to see content from creators and brands in their own space, dubbed RTRO TV.\\n\\nDistroKid\\n\\nMusic distribution service DistroKid this week launched its first mobile app, initially only for iPhone. The new app lets artists upload new releases, receive instant payment alerts, access stats from Apple and Spotify, edit metadata and more from their phones. The company said the mobile app had been the number one request from DistroKid members.', metadata={'source': 'new_articles/05-06-this-week-in-apps-apple-and-google-team-up-on-trackers-google-i-o-preview-apps-hit-newfronts.txt'}))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "text = text_splitter.split_documents(document)"
      ],
      "metadata": {
        "id": "bsw-Ma2p7OWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text), text[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSF5nCpp8WUU",
        "outputId": "57a1cbe4-bead-46b5-d385-9c4f354a113b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80,\n",
              " Document(page_content='Welcome back to This Week in Apps, the weekly TechCrunch series that recaps the latest in mobile OS news, mobile applications and the overall app economy.\\n\\nThe app economy in 2023 hit a few snags, as consumer spending last year dropped for the first time by 2% to $167 billion, according to data.ai’s “State of Mobile” report. However, downloads are continuing to grow, up 11% year-over-year in 2022 to reach 255 billion. Consumers are also spending more time in mobile apps than ever before. On Android devices alone, hours spent in 2022 grew 9%, reaching 4.1 trillion.\\n\\nThis Week in Apps offers a way to keep up with this fast-moving industry in one place with the latest from the world of apps, including news, updates, startup fundings, mergers and acquisitions, and much more.\\n\\nDo you want This Week in Apps in your inbox every Saturday? Sign up here: techcrunch.com/newsletters\\n\\nTop Stories\\n\\nDorsey criticizes Twitter, Musk on the alternative social networks he’s backing', metadata={'source': 'new_articles/05-06-this-week-in-apps-apple-and-google-team-up-on-trackers-google-i-o-preview-apps-hit-newfronts.txt'}))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating ChromaDB"
      ],
      "metadata": {
        "id": "glV_-rzq8mBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import embeddings\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "persist_directory = 'db'\n",
        "\n",
        "embedding = OpenAIEmbeddings()\n",
        "\n",
        "vectordb = Chroma.from_documents(\n",
        "    documents=text,\n",
        "    embedding=embedding,\n",
        "    persist_directory=persist_directory\n",
        ")"
      ],
      "metadata": {
        "id": "sO_G_7v18lkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To persiste the data to disk\n",
        "vectordb.persist()"
      ],
      "metadata": {
        "id": "B3N67ATj9MHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb = None\n",
        "# Loading the persisted database from disk\n",
        "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)"
      ],
      "metadata": {
        "id": "4m-7AjWt9-tD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HREi_Mfb-LnF",
        "outputId": "342b82cf-67f1-4ff0-d9e5-86bb3cf72f78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_community.vectorstores.chroma.Chroma at 0x78d85f4af910>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrieval"
      ],
      "metadata": {
        "id": "EtSO9IhK-iZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectordb.as_retriever()"
      ],
      "metadata": {
        "id": "rfwX56TA-lL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = retriever.get_relevant_documents(\n",
        "    \"When did Google rolled out passkeys to Google Account users globally\"\n",
        ")\n",
        "\n",
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAEiAiUC-sHT",
        "outputId": "0cbea1a1-d434-4f0a-d75b-695f4eefe357"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='Google ditches passwords for passkeys: This week Google rolled out passkeys to Google Account users globally, roughly a year after the company — alongside Apple, Microsoft and the FIDO Alliance — announced a partnership to broadly advance passkey adoption. With passkeys, users’ authentication synchronizes across devices through the cloud using cryptographic key pairs, allowing them to sign in to websites and apps using the same biometrics or screen-lock PIN they use to unlock their devices.\\n\\nMicrosoft debuts Pegasus: Microsoft this week announced that it’ll extend the Startup Founders Hub, its self-service platform that provides founders with free resources, including Azure credits, with a new incubator program called the Pegasus Program. Pegasus will select startups with products that “fill a market need” and give them up to $350,000 in Azure, GitHub and LinkedIn credits plus backing from advisors, as well as “access to the best Microsoft tech,” Microsoft says.', metadata={'source': 'new_articles/05-06-amazon-launches-free-channels-check-marks-come-to-gmail-and-openai-raises-more-moolah.txt'}),\n",
              " Document(page_content='Google ditches passwords for passkeys: This week Google rolled out passkeys to Google Account users globally, roughly a year after the company — alongside Apple, Microsoft and the FIDO Alliance — announced a partnership to broadly advance passkey adoption. With passkeys, users’ authentication synchronizes across devices through the cloud using cryptographic key pairs, allowing them to sign in to websites and apps using the same biometrics or screen-lock PIN they use to unlock their devices.\\n\\nMicrosoft debuts Pegasus: Microsoft this week announced that it’ll extend the Startup Founders Hub, its self-service platform that provides founders with free resources, including Azure credits, with a new incubator program called the Pegasus Program. Pegasus will select startups with products that “fill a market need” and give them up to $350,000 in Azure, GitHub and LinkedIn credits plus backing from advisors, as well as “access to the best Microsoft tech,” Microsoft says.', metadata={'source': 'new_articles/05-06-amazon-launches-free-channels-check-marks-come-to-gmail-and-openai-raises-more-moolah.txt'}),\n",
              " Document(page_content='averaging $67 per night as users complain about excessive fees, onerous checkout procedures and rising Airbnb prices. Google’s smart home app, Google Home, added support for smart garage door openers.\\n\\nSecurity\\n\\nGoogle announced that passkeys are now rolling out to Google Account users globally. Passkey let users sign in to websites and apps using the same biometrics or screen-lock PIN they use to unlock their devices.\\n\\nPasskey let users sign in to websites and apps using the same biometrics or screen-lock PIN they use to unlock their devices. Google announced that in 2022, it prevented 1.43 million policy-violating apps from being published on Google Play “in part due to new and improved security features and policy enhancements.”\\n\\nGovernment, Policy and Lawsuits', metadata={'source': 'new_articles/05-06-this-week-in-apps-apple-and-google-team-up-on-trackers-google-i-o-preview-apps-hit-newfronts.txt'}),\n",
              " Document(page_content='averaging $67 per night as users complain about excessive fees, onerous checkout procedures and rising Airbnb prices. Google’s smart home app, Google Home, added support for smart garage door openers.\\n\\nSecurity\\n\\nGoogle announced that passkeys are now rolling out to Google Account users globally. Passkey let users sign in to websites and apps using the same biometrics or screen-lock PIN they use to unlock their devices.\\n\\nPasskey let users sign in to websites and apps using the same biometrics or screen-lock PIN they use to unlock their devices. Google announced that in 2022, it prevented 1.43 million policy-violating apps from being published on Google Play “in part due to new and improved security features and policy enhancements.”\\n\\nGovernment, Policy and Lawsuits', metadata={'source': 'new_articles/05-06-this-week-in-apps-apple-and-google-team-up-on-trackers-google-i-o-preview-apps-hit-newfronts.txt'})]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectordb.as_retriever(search_kwargs={\"k\":2})\n",
        "docs = retriever.get_relevant_documents(\n",
        "    \"What did Amazon CEO Andy Jassy during the company’s first-quarter earnings call\"\n",
        ")\n",
        "\n",
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bmZk2yX_CYD",
        "outputId": "afa4dbcb-cc80-470d-a047-474798407b06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='A new LLM for Alexa: Amazon is building a more “generalized and capable” large language model to power Alexa, said Amazon CEO Andy Jassy during the company’s first-quarter earnings call this week. He added that although Amazon has had an LLM powering Alexa, Amazon is working on one that’s more capable than the current one.\\n\\naudio', metadata={'source': 'new_articles/05-06-amazon-launches-free-channels-check-marks-come-to-gmail-and-openai-raises-more-moolah.txt'}),\n",
              " Document(page_content='A new LLM for Alexa: Amazon is building a more “generalized and capable” large language model to power Alexa, said Amazon CEO Andy Jassy during the company’s first-quarter earnings call this week. He added that although Amazon has had an LLM powering Alexa, Amazon is working on one that’s more capable than the current one.\\n\\naudio', metadata={'source': 'new_articles/05-06-amazon-launches-free-channels-check-marks-come-to-gmail-and-openai-raises-more-moolah.txt'})]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making a Chain"
      ],
      "metadata": {
        "id": "Rz1W-meADHuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI()\n",
        "llm"
      ],
      "metadata": {
        "id": "1B_98nswALHf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5deff13a-116f-4985-9e93-c0eaae90ae3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OpenAI(client=<openai.resources.completions.Completions object at 0x78d8651c86a0>, async_client=<openai.resources.completions.AsyncCompletions object at 0x78d8651cb610>, openai_api_key=SecretStr('**********'), openai_proxy='')"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True\n",
        ")"
      ],
      "metadata": {
        "id": "jh-X0KV5DtiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_llm_response(llm_response):\n",
        "  print(llm_response['result'])\n",
        "  print('\\nSources:')\n",
        "  for source in llm_response['source_documents']:\n",
        "    print(source.metadata[\"source\"])"
      ],
      "metadata": {
        "id": "UAR6vFu8ELuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usage Example\n",
        "query = \"What was the Apple and Google joint announcement?\"\n",
        "process_llm_response(qa_chain(query))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEb5RSFMEZoB",
        "outputId": "8ac8beb7-7f1f-44a3-ee63-33a7d3266f1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " They announced that they will be working together to draft a specification that would alert users in the case of unwanted tracking from Bluetooth devices.\n",
            "\n",
            "Sources:\n",
            "new_articles/05-06-this-week-in-apps-apple-and-google-team-up-on-trackers-google-i-o-preview-apps-hit-newfronts.txt\n",
            "new_articles/05-06-this-week-in-apps-apple-and-google-team-up-on-trackers-google-i-o-preview-apps-hit-newfronts.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Removing ChromaDB"
      ],
      "metadata": {
        "id": "nTnNTxUCHD2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Zipping to save the DB\n",
        "!zip -r db.zip ./db"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NN24SA89HIGe",
        "outputId": "3d97d71c-f94f-4750-f029-a56f2bad0086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: db/ (stored 0%)\n",
            "  adding: db/chroma.sqlite3 (deflated 45%)\n",
            "  adding: db/3b591d91-cf4f-4043-9482-ec2227d3efd2/ (stored 0%)\n",
            "  adding: db/3b591d91-cf4f-4043-9482-ec2227d3efd2/header.bin (deflated 61%)\n",
            "  adding: db/3b591d91-cf4f-4043-9482-ec2227d3efd2/link_lists.bin (stored 0%)\n",
            "  adding: db/3b591d91-cf4f-4043-9482-ec2227d3efd2/length.bin (deflated 84%)\n",
            "  adding: db/3b591d91-cf4f-4043-9482-ec2227d3efd2/data_level0.bin (deflated 100%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb.delete_collection()\n",
        "vectordb.persist()"
      ],
      "metadata": {
        "id": "_UDIlgLoHL6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrieval Augmented Generation (RAG)"
      ],
      "metadata": {
        "id": "_EuCaWra8AX_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RAG with Llama Index"
      ],
      "metadata": {
        "id": "IPUey0lX9HBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama_index"
      ],
      "metadata": {
        "id": "lETfH0cH8TBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://openreview.net/pdf?id=VtmBAGCN7o\" -O metagpt.pdf"
      ],
      "metadata": {
        "id": "T8J7tWWd8GwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "os.environ[\"OPENAI_MODEL_NAME\"] = 'gpt-3.5-turbo'\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrimE6qU8pTI",
        "outputId": "da3fe43e-8a7d-42a4-8a8b-9ca671eed108"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "hbfPTVjv8uJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Data**"
      ],
      "metadata": {
        "id": "4bi0RBvy87aH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "\n",
        "# load documents\n",
        "documents = SimpleDirectoryReader(input_files=[\"metagpt.pdf\"]).load_data()"
      ],
      "metadata": {
        "id": "n8-d7_n28OJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "\n",
        "splitter = SentenceSplitter(chunk_size=1024)\n",
        "nodes = splitter.get_nodes_from_documents(documents)"
      ],
      "metadata": {
        "id": "6gqN_XpM813n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define LLM and Embedding model**"
      ],
      "metadata": {
        "id": "VGE9nVss85ug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import Settings\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "\n",
        "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
        "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")"
      ],
      "metadata": {
        "id": "94Wrmuz28_UJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Summary Index and Vector Index over the Same Data**"
      ],
      "metadata": {
        "id": "6Mh0xD5h9FCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SummaryIndex, VectorStoreIndex\n",
        "\n",
        "summary_index = SummaryIndex(nodes)\n",
        "vector_index = VectorStoreIndex(nodes)"
      ],
      "metadata": {
        "id": "xm9rMWKB9CiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Query Engines and Set Metadata**"
      ],
      "metadata": {
        "id": "95pVh6or9mz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary_query_engine = summary_index.as_query_engine(\n",
        "    response_mode=\"tree_summarize\",\n",
        "    use_async=True,\n",
        ")\n",
        "vector_query_engine = vector_index.as_query_engine()"
      ],
      "metadata": {
        "id": "dLJXAqHt9nED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.tools import QueryEngineTool\n",
        "\n",
        "\n",
        "summary_tool = QueryEngineTool.from_defaults(\n",
        "    query_engine=summary_query_engine,\n",
        "    description=(\n",
        "        \"Useful for summarization questions related to MetaGPT\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "vector_tool = QueryEngineTool.from_defaults(\n",
        "    query_engine=vector_query_engine,\n",
        "    description=(\n",
        "        \"Useful for retrieving specific context from the MetaGPT paper.\"\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "mZZn271c9rB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Router Query Engine**"
      ],
      "metadata": {
        "id": "XE-nNCF098Kx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.query_engine.router_query_engine import RouterQueryEngine\n",
        "from llama_index.core.selectors import LLMSingleSelector\n",
        "\n",
        "\n",
        "query_engine = RouterQueryEngine(\n",
        "    selector=LLMSingleSelector.from_defaults(),\n",
        "    query_engine_tools=[\n",
        "        summary_tool,\n",
        "        vector_tool,\n",
        "    ],\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "x86aBOtq99Az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What is the summary of the document?\")\n",
        "print(str(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jS3TZmbJ9_Hr",
        "outputId": "9d1cd107-6735-4873-b3af-cafd280fbda1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;3;38;5;200mSelecting query engine 0: Useful for summarization questions related to MetaGPT.\n",
            "\u001b[0mThe document discusses MetaGPT, a meta-programming framework that utilizes Standardized Operating Procedures (SOPs) to enhance multi-agent systems based on Large Language Models (LLMs) in software development. It outlines the roles of various agents such as Product Manager, Architect, Project Manager, Engineer, and QA Engineer in the software development lifecycle. The framework emphasizes efficient workflows, structured communication interfaces, and an executable feedback mechanism to enhance code generation quality. It showcases state-of-the-art performance on benchmarks, details the development process of a software application named \"Drawing App\" using MetaGPT, and discusses the use of Python libraries for GUI creation and testing. The document also delves into the performance evaluation of MetaGPT in generating executable code, compares its performance with other models, and addresses limitations and ethical concerns related to its use in software development.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(response.source_nodes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAyvaHMQ-AU0",
        "outputId": "cdfcfe74-52f0-47e3-edcf-f1ea58addb5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\n",
        "    \"How do agents share information with other agents?\"\n",
        ")\n",
        "print(str(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ri_JID8h-Bq4",
        "outputId": "5178f81d-e894-4dee-dba6-a09a48a2163d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;3;38;5;200mSelecting query engine 1: This choice is more relevant as it focuses on retrieving specific context from the MetaGPT paper, which may provide insights on how agents share information with other agents..\n",
            "\u001b[0mAgents share information with other agents by utilizing a shared message pool. This shared message pool allows all agents to exchange messages directly. Agents publish their structured messages in the pool and can also access messages from other entities transparently. This system enables any agent to retrieve necessary information directly from the shared pool without having to inquire about other agents and wait for their responses, ultimately enhancing communication efficiency.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**put everything together**"
      ],
      "metadata": {
        "id": "KFxeQWls-IAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import get_router_query_engine\n",
        "\n",
        "query_engine = get_router_query_engine(\"metagpt.pdf\")"
      ],
      "metadata": {
        "id": "ksycmzv--JGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"Tell me about the ablation study results?\")\n",
        "print(str(response))"
      ],
      "metadata": {
        "id": "HrKasvO2-KHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agentic RAG\n",
        "\n"
      ],
      "metadata": {
        "id": "mwgMyk0s-xnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "os.environ[\"OPENAI_MODEL_NAME\"] = 'gpt-3.5-turbo'\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
      ],
      "metadata": {
        "id": "XfeLRkNF-2HP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "9hXvKAcf-5TG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define a Simple Tool**"
      ],
      "metadata": {
        "id": "fdsG3y6q-6QE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.tools import FunctionTool\n",
        "\n",
        "def add(x: int, y: int) -> int:\n",
        "    \"\"\"Adds two integers together.\"\"\"\n",
        "    return x + y\n",
        "\n",
        "def mystery(x: int, y: int) -> int:\n",
        "    \"\"\"Mystery function that operates on top of two numbers.\"\"\"\n",
        "    return (x + y) * (x + y)\n",
        "\n",
        "\n",
        "add_tool = FunctionTool.from_defaults(fn=add)\n",
        "mystery_tool = FunctionTool.from_defaults(fn=mystery)"
      ],
      "metadata": {
        "id": "MpaaSVlx-8qW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.openai import OpenAI\n",
        "\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
        "response = llm.predict_and_call(\n",
        "    [add_tool, mystery_tool],\n",
        "    \"Tell me the output of the mystery function on 2 and 9\",\n",
        "    verbose=True\n",
        ")\n",
        "print(str(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLvEdsNQ_A9u",
        "outputId": "ec28da94-e138-4789-c788-0392e6ccd0a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Calling Function ===\n",
            "Calling function: mystery with args: {\"x\": 2, \"y\": 9}\n",
            "=== Function Output ===\n",
            "121\n",
            "121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define an Auto-Retrieval Tool**"
      ],
      "metadata": {
        "id": "zHQQltfz_Q-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://openreview.net/pdf?id=VtmBAGCN7o\" -O metagpt.pdf"
      ],
      "metadata": {
        "id": "2gvY_2TN_S92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "# load documents\n",
        "documents = SimpleDirectoryReader(input_files=[\"metagpt.pdf\"]).load_data()"
      ],
      "metadata": {
        "id": "jnNYqv5M_Vnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "splitter = SentenceSplitter(chunk_size=1024)\n",
        "nodes = splitter.get_nodes_from_documents(documents)"
      ],
      "metadata": {
        "id": "AvUSz2eE_Xeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(nodes[0].get_content(metadata_mode=\"all\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghvf-EAq_aBS",
        "outputId": "8e9be8d9-1154-4606-d9f2-17f3c9d2b55b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_label: 1\n",
            "file_name: metagpt.pdf\n",
            "file_path: metagpt.pdf\n",
            "file_type: application/pdf\n",
            "file_size: 16911937\n",
            "creation_date: 2024-06-02\n",
            "last_modified_date: 2024-06-02\n",
            "\n",
            "Preprint\n",
            "METAGPT: M ETA PROGRAMMING FOR A\n",
            "MULTI -AGENT COLLABORATIVE FRAMEWORK\n",
            "Sirui Hong1∗, Mingchen Zhuge2∗, Jonathan Chen1, Xiawu Zheng3, Yuheng Cheng4,\n",
            "Ceyao Zhang4,Jinlin Wang1,Zili Wang ,Steven Ka Shing Yau5,Zijuan Lin4,\n",
            "Liyang Zhou6,Chenyu Ran1,Lingfeng Xiao1,7,Chenglin Wu1†,J¨urgen Schmidhuber2,8\n",
            "1DeepWisdom,2AI Initiative, King Abdullah University of Science and Technology,\n",
            "3Xiamen University,4The Chinese University of Hong Kong, Shenzhen,\n",
            "5Nanjing University,6University of Pennsylvania,\n",
            "7University of California, Berkeley,8The Swiss AI Lab IDSIA/USI/SUPSI\n",
            "ABSTRACT\n",
            "Remarkable progress has been made on automated problem solving through so-\n",
            "cieties of agents based on large language models (LLMs). Existing LLM-based\n",
            "multi-agent systems can already solve simple dialogue tasks. Solutions to more\n",
            "complex tasks, however, are complicated through logic inconsistencies due to\n",
            "cascading hallucinations caused by naively chaining LLMs. Here we introduce\n",
            "MetaGPT, an innovative meta-programming framework incorporating efficient\n",
            "human workflows into LLM-based multi-agent collaborations. MetaGPT en-\n",
            "codes Standardized Operating Procedures (SOPs) into prompt sequences for more\n",
            "streamlined workflows, thus allowing agents with human-like domain expertise\n",
            "to verify intermediate results and reduce errors. MetaGPT utilizes an assembly\n",
            "line paradigm to assign diverse roles to various agents, efficiently breaking down\n",
            "complex tasks into subtasks involving many agents working together. On col-\n",
            "laborative software engineering benchmarks, MetaGPT generates more coherent\n",
            "solutions than previous chat-based multi-agent systems. Our project can be found\n",
            "at https://github.com/geekan/MetaGPT.\n",
            "1 I NTRODUCTION\n",
            "Autonomous agents utilizing Large Language Models (LLMs) offer promising opportunities to en-\n",
            "hance and replicate human workflows. In real-world applications, however, existing systems (Park\n",
            "et al., 2023; Zhuge et al., 2023; Cai et al., 2023; Wang et al., 2023c; Li et al., 2023; Du et al., 2023;\n",
            "Liang et al., 2023; Hao et al., 2023) tend to oversimplify the complexities. They struggle to achieve\n",
            "effective, coherent, and accurate problem-solving processes, particularly when there is a need for\n",
            "meaningful collaborative interaction (Chen et al., 2024; Zhang et al., 2023; Dong et al., 2023; Zhou\n",
            "et al., 2023; Qian et al., 2023).\n",
            "Through extensive collaborative practice, humans have developed widely accepted Standardized\n",
            "Operating Procedures (SOPs) across various domains (Belbin, 2012; Manifesto, 2001; DeMarco &\n",
            "Lister, 2013). These SOPs play a critical role in supporting task decomposition and effective coor-\n",
            "dination. Furthermore, SOPs outline the responsibilities of each team member, while establishing\n",
            "standards for intermediate outputs. Well-defined SOPs improve the consistent and accurate exe-\n",
            "cution of tasks that align with defined roles and quality standards (Belbin, 2012; Manifesto, 2001;\n",
            "DeMarco & Lister, 2013; Wooldridge & Jennings, 1998). For instance, in a software company,\n",
            "Product Managers analyze competition and user needs to create Product Requirements Documents\n",
            "(PRDs) using a standardized structure, to guide the developmental process.\n",
            "Inspired by such ideas, we design a promising GPT -based Meta -Programming framework called\n",
            "MetaGPT that significantly benefits from SOPs. Unlike other works (Li et al., 2023; Qian et al.,\n",
            "2023), MetaGPT requires agents to generate structured outputs, such as high-quality requirements\n",
            "∗These authors contributed equally to this work.\n",
            "†Chenglin Wu (alexanderwu@fuzhi.ai) is the corresponding author, affiliated with DeepWisdom.\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "\n",
        "vector_index = VectorStoreIndex(nodes)\n",
        "query_engine = vector_index.as_query_engine(similarity_top_k=2)"
      ],
      "metadata": {
        "id": "0ytwQcS-_fjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.vector_stores import MetadataFilters\n",
        "\n",
        "query_engine = vector_index.as_query_engine(\n",
        "    similarity_top_k=2,\n",
        "    filters=MetadataFilters.from_dicts(\n",
        "        [\n",
        "            {\"key\": \"page_label\", \"value\": \"2\"}\n",
        "        ]\n",
        "    )\n",
        ")\n",
        "\n",
        "response = query_engine.query(\n",
        "    \"What are some high-level results of MetaGPT?\",\n",
        ")"
      ],
      "metadata": {
        "id": "3-sknqBX_oGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(str(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oq73khjG_rjA",
        "outputId": "be31d2ca-1e5d-4734-fc96-1888ebac19ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Some high-level results of MetaGPT include achieving a new state-of-the-art in code generation benchmarks with high Pass@1 scores, outperforming other popular frameworks in creating complex software projects, handling higher levels of software complexity effectively, offering extensive functionality, and demonstrating robustness and efficiency in task completion rates.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for n in response.source_nodes:\n",
        "    print(n.metadata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68cPodEM_xyw",
        "outputId": "31c54d2a-9705-4baa-d34e-cfacc54b0430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'page_label': '2', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-02', 'last_modified_date': '2024-06-02'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the Auto-Retrieval Tool**"
      ],
      "metadata": {
        "id": "i42QeKhx_2zN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from llama_index.core.vector_stores import FilterCondition\n",
        "\n",
        "\n",
        "def vector_query(\n",
        "    query: str,\n",
        "    page_numbers: List[str]\n",
        ") -> str:\n",
        "    \"\"\"Perform a vector search over an index.\n",
        "\n",
        "    query (str): the string query to be embedded.\n",
        "    page_numbers (List[str]): Filter by set of pages. Leave BLANK if we want to perform a vector search\n",
        "        over all pages. Otherwise, filter by the set of specified pages.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    metadata_dicts = [\n",
        "        {\"key\": \"page_label\", \"value\": p} for p in page_numbers\n",
        "    ]\n",
        "\n",
        "    query_engine = vector_index.as_query_engine(\n",
        "        similarity_top_k=2,\n",
        "        filters=MetadataFilters.from_dicts(\n",
        "            metadata_dicts,\n",
        "            condition=FilterCondition.OR\n",
        "        )\n",
        "    )\n",
        "    response = query_engine.query(query)\n",
        "    return response\n",
        "\n",
        "\n",
        "vector_query_tool = FunctionTool.from_defaults(\n",
        "    name=\"vector_tool\",\n",
        "    fn=vector_query\n",
        ")"
      ],
      "metadata": {
        "id": "ojrqTOJt_2H3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "response = llm.predict_and_call(\n",
        "    [vector_query_tool],\n",
        "    \"What are the high-level results of MetaGPT as described on page 2?\",\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mHSy6eU__I6",
        "outputId": "6949e50f-c65c-49ca-f3b7-f31ac5aa4e6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Calling Function ===\n",
            "Calling function: vector_tool with args: {\"query\": \"high-level results of MetaGPT\", \"page_numbers\": [\"2\"]}\n",
            "=== Function Output ===\n",
            "MetaGPT achieves a new state-of-the-art (SoTA) in code generation benchmarks with 85.9% and 87.7% in Pass@1. It stands out in handling higher levels of software complexity and offering extensive functionality, as demonstrated by achieving a 100% task completion rate in experimental evaluations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for n in response.source_nodes:\n",
        "    print(n.metadata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvsMG9eVAD3w",
        "outputId": "cc0c9f99-185a-489d-b0d5-25f684d72bcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'page_label': '2', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-02', 'last_modified_date': '2024-06-02'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's add some other tools!**"
      ],
      "metadata": {
        "id": "dTIyuHZgAIx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SummaryIndex\n",
        "from llama_index.core.tools import QueryEngineTool\n",
        "\n",
        "summary_index = SummaryIndex(nodes)\n",
        "summary_query_engine = summary_index.as_query_engine(\n",
        "    response_mode=\"tree_summarize\",\n",
        "    use_async=True,\n",
        ")\n",
        "summary_tool = QueryEngineTool.from_defaults(\n",
        "    name=\"summary_tool\",\n",
        "    query_engine=summary_query_engine,\n",
        "    description=(\n",
        "        \"Useful if you want to get a summary of MetaGPT\"\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "EJYHLuV6AJsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm.predict_and_call(\n",
        "    [vector_query_tool, summary_tool],\n",
        "    \"What are the MetaGPT comparisons with ChatDev described on page 8?\",\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiiSzPP-AK8R",
        "outputId": "255f9f6c-a9ac-4ff5-c373-17a87d2b9533"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Calling Function ===\n",
            "Calling function: vector_tool with args: {\"query\": \"MetaGPT comparisons with ChatDev\", \"page_numbers\": [\"8\"]}\n",
            "=== Function Output ===\n",
            "MetaGPT outperforms ChatDev on the challenging SoftwareDev dataset in nearly all metrics. For example, MetaGPT achieves a higher score in executability, takes less time to generate code, uses more tokens but requires fewer tokens to generate one line of code compared to ChatDev. Additionally, MetaGPT shows better performance in code statistics and human revision cost when compared to ChatDev.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for n in response.source_nodes:\n",
        "    print(n.metadata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4aMGDfMAMcT",
        "outputId": "b31554a7-fb44-4508-ba35-804ec25dc1ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'page_label': '8', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-02', 'last_modified_date': '2024-06-02'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm.predict_and_call(\n",
        "    [vector_query_tool, summary_tool],\n",
        "    \"What is a summary of the paper?\",\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxSKtHzEANMF",
        "outputId": "01767218-b42a-44b7-cc08-6180a76cf730"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Calling Function ===\n",
            "Calling function: summary_tool with args: {\"input\": \"The paper discusses the impact of climate change on biodiversity and ecosystems.\"}\n",
            "=== Function Output ===\n",
            "The paper does not discuss the impact of climate change on biodiversity and ecosystems.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agent Reasoning Loop"
      ],
      "metadata": {
        "id": "F9BDdFEmBKB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "os.environ[\"OPENAI_MODEL_NAME\"] = 'gpt-3.5-turbo'\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
      ],
      "metadata": {
        "id": "LHAFA7_9BLxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "K3Yb-R_ABPhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Requires vector_tool & summary_tool from previous chapter"
      ],
      "metadata": {
        "id": "wMis20s0Bb6n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setup Function Calling Agent**"
      ],
      "metadata": {
        "id": "J0xt51VxChqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.openai import OpenAI\n",
        "\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
      ],
      "metadata": {
        "id": "GtujtCf6BQxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.agent import FunctionCallingAgentWorker\n",
        "from llama_index.core.agent import AgentRunner\n",
        "\n",
        "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
        "    [vector_tool, summary_tool],\n",
        "    llm=llm,\n",
        "    verbose=True\n",
        ")\n",
        "agent = AgentRunner(agent_worker)"
      ],
      "metadata": {
        "id": "KaH_MrhTBm-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.query(\n",
        "    \"Tell me about the agent roles in MetaGPT, \"\n",
        "    \"and then how they communicate with each other.\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_wSqlbDBrHe",
        "outputId": "fe941ef2-7356-4ff2-a87c-450af7c13488"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added user message to memory: Tell me about the agent roles in MetaGPT, and then how they communicate with each other.\n",
            "=== Calling Function ===\n",
            "Calling function: summary_tool with args: {\"input\": \"agent roles in MetaGPT\"}\n",
            "=== Function Output ===\n",
            "The agent roles in MetaGPT include the Product Manager, Architect, Project Manager, Engineer, and QA Engineer. The Product Manager is responsible for creating the Product Requirement Document (PRD). The Architect designs technical specifications and system architecture diagrams. The Project Manager breaks down the project into tasks and assigns them to Engineers. Engineers implement development tasks based on technical specifications. The QA Engineer generates unit test code, reviews output from Engineers, and ensures high-quality software by identifying and fixing bugs.\n",
            "=== Calling Function ===\n",
            "Calling function: summary_tool with args: {\"input\": \"how agents communicate with each other in MetaGPT\"}\n",
            "=== Function Output ===\n",
            "Agents in MetaGPT communicate with each other through structured communication interfaces and a shared message pool. They publish structured messages in the shared pool and can subscribe to relevant messages based on their role profiles. This method enhances communication efficiency by enabling direct information exchange and access to necessary information without the need for one-on-one communication. Additionally, agents use role-specific interests to extract relevant information, ensuring they receive only task-related information and avoid distractions from irrelevant details.\n",
            "=== Calling Function ===\n",
            "Calling function: summary_tool with args: {\"input\": \"agent roles in MetaGPT\"}\n",
            "=== Function Output ===\n",
            "The agent roles in MetaGPT include Product Manager, Architect, Project Manager, Engineer, and QA Engineer. The Product Manager is responsible for creating the Product Requirement Document and conducting competitive analysis. The Architect designs the system architecture, interface definitions, and technical specifications. The Project Manager breaks down the project into tasks for execution. The Engineer implements the code based on the provided specifications. Lastly, the QA Engineer generates unit tests and reviews the code for quality assurance. Each role is essential in the software development process within the MetaGPT framework.\n",
            "=== Calling Function ===\n",
            "Calling function: summary_tool with args: {\"input\": \"how agents communicate with each other in MetaGPT\"}\n",
            "=== Function Output ===\n",
            "Agents in MetaGPT communicate with each other through structured communication interfaces and a shared message pool. They publish structured messages in the shared pool and can subscribe to relevant messages based on their role profiles. This approach enhances communication efficiency by allowing agents to exchange information directly and transparently. Additionally, agents utilize role-specific interests to extract relevant information, ensuring that they receive only task-related information and avoid distractions from irrelevant details.\n",
            "=== LLM Response ===\n",
            "In MetaGPT, the agent roles include the Product Manager, Architect, Project Manager, Engineer, and QA Engineer. Each role has specific responsibilities in the software development process. The Product Manager creates the Product Requirement Document, the Architect designs technical specifications, the Project Manager assigns tasks, the Engineer implements development tasks, and the QA Engineer ensures high-quality software by identifying and fixing bugs.\n",
            "\n",
            "Agents in MetaGPT communicate with each other through structured communication interfaces and a shared message pool. They publish structured messages in the shared pool and can subscribe to relevant messages based on their role profiles. This method enhances communication efficiency by enabling direct information exchange and access to necessary information without the need for one-on-one communication. Additionally, agents use role-specific interests to extract relevant information, ensuring they receive only task-related information and avoid distractions from irrelevant details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.source_nodes[0].get_content(metadata_mode=\"all\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLLOOj1zB5_n",
        "outputId": "6e1be34f-8cdc-4a40-bb40-82f80dfabc60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_label: 1\n",
            "file_name: metagpt.pdf\n",
            "file_path: metagpt.pdf\n",
            "file_type: application/pdf\n",
            "file_size: 16911937\n",
            "creation_date: 2024-06-02\n",
            "last_modified_date: 2024-06-02\n",
            "\n",
            "Preprint\n",
            "METAGPT: M ETA PROGRAMMING FOR A\n",
            "MULTI -AGENT COLLABORATIVE FRAMEWORK\n",
            "Sirui Hong1∗, Mingchen Zhuge2∗, Jonathan Chen1, Xiawu Zheng3, Yuheng Cheng4,\n",
            "Ceyao Zhang4,Jinlin Wang1,Zili Wang ,Steven Ka Shing Yau5,Zijuan Lin4,\n",
            "Liyang Zhou6,Chenyu Ran1,Lingfeng Xiao1,7,Chenglin Wu1†,J¨urgen Schmidhuber2,8\n",
            "1DeepWisdom,2AI Initiative, King Abdullah University of Science and Technology,\n",
            "3Xiamen University,4The Chinese University of Hong Kong, Shenzhen,\n",
            "5Nanjing University,6University of Pennsylvania,\n",
            "7University of California, Berkeley,8The Swiss AI Lab IDSIA/USI/SUPSI\n",
            "ABSTRACT\n",
            "Remarkable progress has been made on automated problem solving through so-\n",
            "cieties of agents based on large language models (LLMs). Existing LLM-based\n",
            "multi-agent systems can already solve simple dialogue tasks. Solutions to more\n",
            "complex tasks, however, are complicated through logic inconsistencies due to\n",
            "cascading hallucinations caused by naively chaining LLMs. Here we introduce\n",
            "MetaGPT, an innovative meta-programming framework incorporating efficient\n",
            "human workflows into LLM-based multi-agent collaborations. MetaGPT en-\n",
            "codes Standardized Operating Procedures (SOPs) into prompt sequences for more\n",
            "streamlined workflows, thus allowing agents with human-like domain expertise\n",
            "to verify intermediate results and reduce errors. MetaGPT utilizes an assembly\n",
            "line paradigm to assign diverse roles to various agents, efficiently breaking down\n",
            "complex tasks into subtasks involving many agents working together. On col-\n",
            "laborative software engineering benchmarks, MetaGPT generates more coherent\n",
            "solutions than previous chat-based multi-agent systems. Our project can be found\n",
            "at https://github.com/geekan/MetaGPT.\n",
            "1 I NTRODUCTION\n",
            "Autonomous agents utilizing Large Language Models (LLMs) offer promising opportunities to en-\n",
            "hance and replicate human workflows. In real-world applications, however, existing systems (Park\n",
            "et al., 2023; Zhuge et al., 2023; Cai et al., 2023; Wang et al., 2023c; Li et al., 2023; Du et al., 2023;\n",
            "Liang et al., 2023; Hao et al., 2023) tend to oversimplify the complexities. They struggle to achieve\n",
            "effective, coherent, and accurate problem-solving processes, particularly when there is a need for\n",
            "meaningful collaborative interaction (Chen et al., 2024; Zhang et al., 2023; Dong et al., 2023; Zhou\n",
            "et al., 2023; Qian et al., 2023).\n",
            "Through extensive collaborative practice, humans have developed widely accepted Standardized\n",
            "Operating Procedures (SOPs) across various domains (Belbin, 2012; Manifesto, 2001; DeMarco &\n",
            "Lister, 2013). These SOPs play a critical role in supporting task decomposition and effective coor-\n",
            "dination. Furthermore, SOPs outline the responsibilities of each team member, while establishing\n",
            "standards for intermediate outputs. Well-defined SOPs improve the consistent and accurate exe-\n",
            "cution of tasks that align with defined roles and quality standards (Belbin, 2012; Manifesto, 2001;\n",
            "DeMarco & Lister, 2013; Wooldridge & Jennings, 1998). For instance, in a software company,\n",
            "Product Managers analyze competition and user needs to create Product Requirements Documents\n",
            "(PRDs) using a standardized structure, to guide the developmental process.\n",
            "Inspired by such ideas, we design a promising GPT -based Meta -Programming framework called\n",
            "MetaGPT that significantly benefits from SOPs. Unlike other works (Li et al., 2023; Qian et al.,\n",
            "2023), MetaGPT requires agents to generate structured outputs, such as high-quality requirements\n",
            "∗These authors contributed equally to this work.\n",
            "†Chenglin Wu (alexanderwu@fuzhi.ai) is the corresponding author, affiliated with DeepWisdom.\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.chat(\n",
        "    \"Tell me about the evaluation datasets used.\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aKXszbDB7sZ",
        "outputId": "9277a84a-57f5-4904-9fa9-402d9163d0a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added user message to memory: Tell me about the evaluation datasets used.\n",
            "=== Calling Function ===\n",
            "Calling function: summary_tool with args: {\"input\": \"evaluation datasets in MetaGPT\"}\n",
            "=== Function Output ===\n",
            "The evaluation datasets used in MetaGPT include HumanEval, MBPP, and a self-generated SoftwareDev dataset. HumanEval consists of 164 handwritten programming tasks, while MBPP consists of 427 Python tasks. The SoftwareDev dataset comprises 70 representative software development tasks covering various scopes like mini-games, image processing algorithms, and data visualization. These datasets were used to evaluate the performance of MetaGPT in code generation tasks.\n",
            "=== LLM Response ===\n",
            "The evaluation datasets used in MetaGPT include HumanEval, MBPP, and a self-generated SoftwareDev dataset. HumanEval consists of 164 handwritten programming tasks, MBPP consists of 427 Python tasks, and the SoftwareDev dataset comprises 70 representative software development tasks covering various scopes like mini-games, image processing algorithms, and data visualization. These datasets were utilized to evaluate the performance of MetaGPT in code generation tasks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lower-Level: Debuggability and Control**"
      ],
      "metadata": {
        "id": "gKiBC2CeCOK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
        "    [vector_tool, summary_tool],\n",
        "    llm=llm,\n",
        "    verbose=True\n",
        ")\n",
        "agent = AgentRunner(agent_worker)"
      ],
      "metadata": {
        "id": "pNO1T4XiB9e1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task = agent.create_task(\n",
        "    \"Tell me about the agent roles in MetaGPT, \"\n",
        "    \"and then how they communicate with each other.\"\n",
        ")"
      ],
      "metadata": {
        "id": "GugyjDsFCPyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "step_output = agent.run_step(task.task_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eaQYu2tCQ95",
        "outputId": "1609651f-ea72-40ca-a2c3-f7ae1f4207c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added user message to memory: Tell me about the agent roles in MetaGPT, and then how they communicate with each other.\n",
            "=== Calling Function ===\n",
            "Calling function: summary_tool with args: {\"input\": \"agent roles in MetaGPT\"}\n",
            "=== Function Output ===\n",
            "The roles in MetaGPT include the Product Manager, Architect, Project Manager, Engineers, and QA Engineer. The Product Manager is responsible for creating the Product Requirement Document and competitive analysis. The Architect designs the system architecture, interface definitions, and technical specifications. The Project Manager breaks down the project into tasks for Engineers to work on. Engineers develop the code based on the specifications provided. The QA Engineer generates unit tests and reviews the code for bugs. Each role is crucial in the software development process within the MetaGPT framework.\n",
            "=== Calling Function ===\n",
            "Calling function: summary_tool with args: {\"input\": \"how agents communicate with each other in MetaGPT\"}\n",
            "=== Function Output ===\n",
            "Agents in MetaGPT communicate with each other through structured communication interfaces and a shared message pool. Each agent publishes structured messages in the shared pool and can subscribe to relevant messages based on their role profiles. This mechanism allows for efficient exchange of information among agents, enhancing communication efficiency and reducing information overload. Additionally, agents utilize role-specific interests to extract relevant information, ensuring that they receive only task-related information and avoid distractions from irrelevant details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completed_steps = agent.get_completed_steps(task.task_id)\n",
        "print(f\"Num completed for task {task.task_id}: {len(completed_steps)}\")\n",
        "print(completed_steps[0].output.sources[0].raw_output)"
      ],
      "metadata": {
        "id": "0gmoFFhRCUT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "upcoming_steps = agent.get_upcoming_steps(task.task_id)\n",
        "print(f\"Num upcoming steps for task {task.task_id}: {len(upcoming_steps)}\")\n",
        "upcoming_steps[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grp0Qc7kCVsx",
        "outputId": "9e5be5ba-3478-48f2-80ff-9a8914569eea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num upcoming steps for task 3669d303-f62e-486a-83e6-d4fa8b2c7f55: 1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TaskStep(task_id='3669d303-f62e-486a-83e6-d4fa8b2c7f55', step_id='f20d6cd5-3312-4bbf-be25-5b9da21680c4', input=None, step_state={}, next_steps={}, prev_steps={}, is_ready=True)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "step_output = agent.run_step(\n",
        "    task.task_id, input=\"What about how agents share information?\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnnGOU7RCWeo",
        "outputId": "0f934c43-ec36-42c8-b2a2-da54c333e0b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added user message to memory: What about how agents share information?\n",
            "=== Calling Function ===\n",
            "Calling function: summary_tool with args: {\"input\": \"how agents share information in MetaGPT\"}\n",
            "=== Function Output ===\n",
            "Agents in MetaGPT share information through a shared message pool where they publish structured messages and subscribe to relevant messages based on their profiles. This shared message pool allows all agents to exchange messages directly, enhancing communication efficiency. Additionally, agents utilize a subscription mechanism to extract relevant information based on their role profiles, ensuring they receive only task-related information and avoid distractions from irrelevant details. This structured communication approach helps streamline workflows and improve collaboration among agents in MetaGPT.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "step_output = agent.run_step(task.task_id)\n",
        "print(step_output.is_last)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjUPMIfHCXke",
        "outputId": "7e13912f-2b30-4ad7-bc28-34dd822f800e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== LLM Response ===\n",
            "Agents in MetaGPT share information through a shared message pool where they publish structured messages and subscribe to relevant messages based on their profiles. This shared message pool allows all agents to exchange messages directly, enhancing communication efficiency. Additionally, agents utilize a subscription mechanism to extract relevant information based on their role profiles, ensuring they receive only task-related information and avoid distractions from irrelevant details. This structured communication approach helps streamline workflows and improve collaboration among agents in MetaGPT.\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.finalize_response(task.task_id)"
      ],
      "metadata": {
        "id": "8GjAgbjoCYg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(str(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qx0xFN4RCZgG",
        "outputId": "b97b1eae-50ff-4651-b7f2-51258582c595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agents in MetaGPT share information through a shared message pool where they publish structured messages and subscribe to relevant messages based on their profiles. This shared message pool allows all agents to exchange messages directly, enhancing communication efficiency. Additionally, agents utilize a subscription mechanism to extract relevant information based on their role profiles, ensuring they receive only task-related information and avoid distractions from irrelevant details. This structured communication approach helps streamline workflows and improve collaboration among agents in MetaGPT.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating RAG"
      ],
      "metadata": {
        "id": "-s1Be-b-KktR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q llama_index llama-index-embeddings-huggingface trulens_eval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOnjR89lfe3t",
        "outputId": "94730a05-5618-45b6-feb9-bc16f579bd8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://wordpress.deeplearning.ai/wp-content/uploads/2022/10/eBook-How-to-Build-a-Career-in-AI.pdf -O eBook-How-to-Build-a-Career-in-AI.pdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jH_B2kfLDnLR",
        "outputId": "6ae4bc67-375c-4ac1-cdee-d93ec477abda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-02 20:47:37--  https://wordpress.deeplearning.ai/wp-content/uploads/2022/10/eBook-How-to-Build-a-Career-in-AI.pdf\n",
            "Resolving wordpress.deeplearning.ai (wordpress.deeplearning.ai)... 164.92.64.128\n",
            "Connecting to wordpress.deeplearning.ai (wordpress.deeplearning.ai)|164.92.64.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3717673 (3.5M) [application/pdf]\n",
            "Saving to: ‘eBook-How-to-Build-a-Career-in-AI.pdf’\n",
            "\n",
            "eBook-How-to-Build- 100%[===================>]   3.54M  10.9MB/s    in 0.3s    \n",
            "\n",
            "2024-06-02 20:47:37 (10.9 MB/s) - ‘eBook-How-to-Build-a-Career-in-AI.pdf’ saved [3717673/3717673]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "os.environ[\"OPENAI_MODEL_NAME\"] = 'gpt-3.5-turbo'\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42HRSgjGfl9N",
        "outputId": "0b0a69bb-36da-44e4-e6a2-782d13534f60"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Basic RAG pipeline**"
      ],
      "metadata": {
        "id": "hJ5H1p4TgcwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "\n",
        "documents = SimpleDirectoryReader(\n",
        "    input_files=[\"./eBook-How-to-Build-a-Career-in-AI.pdf\"]\n",
        ").load_data()"
      ],
      "metadata": {
        "id": "01gUXCjNfdc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(documents), \"\\n\")\n",
        "print(len(documents), \"\\n\")\n",
        "print(type(documents[0]))\n",
        "print(documents[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n42ecQhWgIFl",
        "outputId": "dba63091-6f1c-466b-bd0a-4cf3e6bba18f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> \n",
            "\n",
            "41 \n",
            "\n",
            "<class 'llama_index.core.schema.Document'>\n",
            "Doc ID: d9ca60e7-2260-4513-b233-443154fcaa47\n",
            "Text: PAGE 1Founder, DeepLearning.AICollected Insights from Andrew Ng\n",
            "How to  Build Your Career in AIA Simple Guide\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.core import ServiceContext\n",
        "from llama_index.llms.openai import OpenAI\n",
        "\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
        "service_context = ServiceContext.from_defaults(\n",
        "    llm=llm, embed_model=\"local:BAAI/bge-small-en-v1.5\"\n",
        ")\n",
        "index = VectorStoreIndex.from_documents(documents,\n",
        "                                        service_context=service_context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWGYiLKNgnv8",
        "outputId": "bc6e4dab-2614-4164-ac60-6fef8f132fd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-2d6d0c851acc>:6: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
            "  service_context = ServiceContext.from_defaults(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = index.as_query_engine()"
      ],
      "metadata": {
        "id": "1bJnEE_0hDWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\n",
        "    \"What are steps to take when finding projects to build your experience?\"\n",
        ")\n",
        "print(str(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuHAjjkRhEK9",
        "outputId": "646a9e17-4bc5-46dd-d61d-51eb282064d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Identify a business problem, brainstorm AI solutions, focus on an application area, join existing projects, keep reading and talking to people.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = query_engine.query(\n",
        "    \"How do you create your AI portfolio?\")\n",
        "output.response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "EKsxXFLJlrJS",
        "outputId": "baac01c7-b735-43de-9cf8-379c37278871"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'You create your AI portfolio by starting with small projects and gradually progressing to more complex undertakings. It is important to communicate effectively about your projects, explaining your thought process and the value of your work to others. Additionally, showcasing leadership skills, even in a non-managerial role, when working on larger AI projects is crucial for building a strong portfolio.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RAG Triad of metrics"
      ],
      "metadata": {
        "id": "VCw8sEvHj6xX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trulens_eval import Tru\n",
        "\n",
        "tru = Tru()\n",
        "tru.reset_database()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDo40Zw7iOug",
        "outputId": "4ac1b2fc-0c7b-450f-f042-37b8b8ebc7b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦑 Tru initialized with db url sqlite:///default.sqlite .\n",
            "🛑 Secret keys may be written to the database. See the `database_redact_keys` option of Tru` to prevent this.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feedback functions**"
      ],
      "metadata": {
        "id": "ypyRcCnkk3yH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "4NPi4Rr6k0XG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trulens_eval import OpenAI as fOpenAI\n",
        "\n",
        "provider = fOpenAI()"
      ],
      "metadata": {
        "id": "fM8A1MjLk2Km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Answer Relevance**"
      ],
      "metadata": {
        "id": "IpyZ9Zxuk5WT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trulens_eval import Feedback\n",
        "\n",
        "f_qa_relevance = Feedback(\n",
        "    provider.relevance_with_cot_reasons,\n",
        "    name=\"Answer Relevance\"\n",
        ").on_input_output()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtCDT_SFl6WN",
        "outputId": "e14d2c6e-7de9-4dfe-9397-f39a5fa26e90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
            "✅ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Context Relevance**"
      ],
      "metadata": {
        "id": "cxDXXwM3k5J7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trulens_eval import TruLlama\n",
        "\n",
        "context_selection = TruLlama.select_source_nodes().node.text"
      ],
      "metadata": {
        "id": "ueyblSb8mB2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "f_qs_relevance = (\n",
        "    Feedback(provider.qs_relevance,\n",
        "             name=\"Context Relevance\")\n",
        "    .on_input()\n",
        "    .on(context_selection)\n",
        "    .aggregate(np.mean)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8W2GxtnmByi",
        "outputId": "ecf1a52a-bb5a-4344-8152-c144e7081d48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
            "✅ In Context Relevance, input context will be set to __record__.app.query.rets.source_nodes[:].node.text .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "f_qs_relevance = (\n",
        "    Feedback(provider.qs_relevance_with_cot_reasons, # Chain-of-thougths reasoning\n",
        "             name=\"Context Relevance\")\n",
        "    .on_input()\n",
        "    .on(context_selection)\n",
        "    .aggregate(np.mean)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2BVyV22mBVX",
        "outputId": "11a42f1e-ebd3-4982-aba3-6bdee9d67fa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
            "✅ In Context Relevance, input context will be set to __record__.app.query.rets.source_nodes[:].node.text .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Groundedness**"
      ],
      "metadata": {
        "id": "U92ff7O1k43_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trulens_eval.feedback import GroundTruthAgreement\n",
        "\n",
        "grounded = GroundTruthAgreement(groundedness_provider=provider)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "collapsed": true,
        "id": "RSxCXcbykknG",
        "outputId": "74ffc345-0bfe-4253-d086-76b9a880c5a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "GroundTruthAgreement.__init__() missing 1 required positional argument: 'ground_truth'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-0b90de5a89c5>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtrulens_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeedback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGroundTruthAgreement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgrounded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGroundTruthAgreement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroundedness_provider\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprovider\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: GroundTruthAgreement.__init__() missing 1 required positional argument: 'ground_truth'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f_groundedness = (\n",
        "    Feedback(grounded.groundedness_measure_with_cot_reasons,\n",
        "             name=\"Groundedness\"\n",
        "            )\n",
        "    .on(context_selection)\n",
        "    .on_output()\n",
        "    .aggregate(grounded.grounded_statements_aggregator)\n",
        ")"
      ],
      "metadata": {
        "id": "mBweThsDmHsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation of the RAG application**"
      ],
      "metadata": {
        "id": "5KjK6EQysqjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trulens_eval import TruLlama\n",
        "from trulens_eval import FeedbackMode\n",
        "\n",
        "tru_recorder = TruLlama(\n",
        "    query_engine,\n",
        "    app_id=\"App_1\",\n",
        "    feedbacks=[\n",
        "        f_qa_relevance,\n",
        "        f_qs_relevance,\n",
        "        # f_groundedness\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "K_zqy-QOspyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_questions = ['What are the keys to building a career in AI?',\n",
        " 'How can teamwork contribute to success in AI?',\n",
        " 'What is the importance of networking in AI?',\n",
        " 'What are some good habits to develop for a successful career?',\n",
        " 'How can altruism be beneficial in building a career?',\n",
        " 'What is imposter syndrome and how does it relate to AI?',\n",
        " 'Who are some accomplished individuals who have experienced imposter syndrome?',\n",
        " 'What is the first step to becoming good at AI?',\n",
        " 'What are some common challenges in AI?',\n",
        " 'Is it normal to find parts of AI challenging?',\n",
        " 'How can I be successful in AI?']"
      ],
      "metadata": {
        "id": "4rRKdQFdss3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for question in eval_questions:\n",
        "    with tru_recorder as recording:\n",
        "        query_engine.query(question)"
      ],
      "metadata": {
        "id": "-Ry-Jjkhsvyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "records, feedback = tru.get_records_and_feedback(app_ids=[])\n",
        "records.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "1ZWNWMWUsyhb",
        "outputId": "ebceea55-107d-4490-d2c6-b5e6159e7e29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  app_id                                           app_json  \\\n",
              "0  App_1  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
              "1  App_1  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
              "2  App_1  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
              "3  App_1  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
              "4  App_1  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
              "\n",
              "                                                type  \\\n",
              "0  RetrieverQueryEngine(llama_index.core.query_en...   \n",
              "1  RetrieverQueryEngine(llama_index.core.query_en...   \n",
              "2  RetrieverQueryEngine(llama_index.core.query_en...   \n",
              "3  RetrieverQueryEngine(llama_index.core.query_en...   \n",
              "4  RetrieverQueryEngine(llama_index.core.query_en...   \n",
              "\n",
              "                                      record_id  \\\n",
              "0  record_hash_9e77ca610c5ce6358c3fb0813399eecc   \n",
              "1  record_hash_64f6761410536c1a79390fa1765a9db0   \n",
              "2  record_hash_23a29f1798e72b1ecc4f4d04965ee29f   \n",
              "3  record_hash_5a7cb0dbca78af51414dbeb08b7a7c09   \n",
              "4  record_hash_f1b725c7fc117c32ecd3dc3daa057b70   \n",
              "\n",
              "                                               input  \\\n",
              "0    \"What are the keys to building a career in AI?\"   \n",
              "1    \"How can teamwork contribute to success in AI?\"   \n",
              "2      \"What is the importance of networking in AI?\"   \n",
              "3  \"What are some good habits to develop for a su...   \n",
              "4  \"How can altruism be beneficial in building a ...   \n",
              "\n",
              "                                              output tags  \\\n",
              "0  \"The keys to building a career in AI involve l...    -   \n",
              "1  \"Teamwork can contribute to success in AI by e...    -   \n",
              "2  \"Networking in AI is crucial as it helps in bu...    -   \n",
              "3  \"Good habits to develop for a successful caree...    -   \n",
              "4  \"Altruism can be beneficial in building a care...    -   \n",
              "\n",
              "                                         record_json  \\\n",
              "0  {\"record_id\": \"record_hash_9e77ca610c5ce6358c3...   \n",
              "1  {\"record_id\": \"record_hash_64f6761410536c1a793...   \n",
              "2  {\"record_id\": \"record_hash_23a29f1798e72b1ecc4...   \n",
              "3  {\"record_id\": \"record_hash_5a7cb0dbca78af51414...   \n",
              "4  {\"record_id\": \"record_hash_f1b725c7fc117c32ecd...   \n",
              "\n",
              "                                           cost_json  \\\n",
              "0  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
              "1  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
              "2  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
              "3  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
              "4  {\"n_requests\": 1, \"n_successful_requests\": 1, ...   \n",
              "\n",
              "                                           perf_json  \\\n",
              "0  {\"start_time\": \"2024-06-02T20:57:42.711756\", \"...   \n",
              "1  {\"start_time\": \"2024-06-02T20:57:49.208609\", \"...   \n",
              "2  {\"start_time\": \"2024-06-02T20:57:57.379170\", \"...   \n",
              "3  {\"start_time\": \"2024-06-02T20:58:02.022181\", \"...   \n",
              "4  {\"start_time\": \"2024-06-02T20:58:06.613497\", \"...   \n",
              "\n",
              "                           ts  Answer Relevance  Context Relevance  \\\n",
              "0  2024-06-02T20:57:48.502243               0.8               0.85   \n",
              "1  2024-06-02T20:57:56.703892               0.9               0.65   \n",
              "2  2024-06-02T20:58:01.261125               0.9               0.80   \n",
              "3  2024-06-02T20:58:05.991335               0.9               0.80   \n",
              "4  2024-06-02T20:58:10.077221               0.9               0.85   \n",
              "\n",
              "                              Answer Relevance_calls  \\\n",
              "0  [{'args': {'prompt': 'What are the keys to bui...   \n",
              "1  [{'args': {'prompt': 'How can teamwork contrib...   \n",
              "2  [{'args': {'prompt': 'What is the importance o...   \n",
              "3  [{'args': {'prompt': 'What are some good habit...   \n",
              "4  [{'args': {'prompt': 'How can altruism be bene...   \n",
              "\n",
              "                             Context Relevance_calls  latency  total_tokens  \\\n",
              "0  [{'args': {'question': 'What are the keys to b...        5           666   \n",
              "1  [{'args': {'question': 'How can teamwork contr...        7          1002   \n",
              "2  [{'args': {'question': 'What is the importance...        3          1024   \n",
              "3  [{'args': {'question': 'What are some good hab...        3           648   \n",
              "4  [{'args': {'question': 'How can altruism be be...        3           812   \n",
              "\n",
              "   total_cost  \n",
              "0    0.001029  \n",
              "1    0.001555  \n",
              "2    0.001589  \n",
              "3    0.000995  \n",
              "4    0.001262  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1f3dadac-0f32-4b6e-8bb4-0de037992c60\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>app_id</th>\n",
              "      <th>app_json</th>\n",
              "      <th>type</th>\n",
              "      <th>record_id</th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "      <th>tags</th>\n",
              "      <th>record_json</th>\n",
              "      <th>cost_json</th>\n",
              "      <th>perf_json</th>\n",
              "      <th>ts</th>\n",
              "      <th>Answer Relevance</th>\n",
              "      <th>Context Relevance</th>\n",
              "      <th>Answer Relevance_calls</th>\n",
              "      <th>Context Relevance_calls</th>\n",
              "      <th>latency</th>\n",
              "      <th>total_tokens</th>\n",
              "      <th>total_cost</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>App_1</td>\n",
              "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
              "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
              "      <td>record_hash_9e77ca610c5ce6358c3fb0813399eecc</td>\n",
              "      <td>\"What are the keys to building a career in AI?\"</td>\n",
              "      <td>\"The keys to building a career in AI involve l...</td>\n",
              "      <td>-</td>\n",
              "      <td>{\"record_id\": \"record_hash_9e77ca610c5ce6358c3...</td>\n",
              "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
              "      <td>{\"start_time\": \"2024-06-02T20:57:42.711756\", \"...</td>\n",
              "      <td>2024-06-02T20:57:48.502243</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.85</td>\n",
              "      <td>[{'args': {'prompt': 'What are the keys to bui...</td>\n",
              "      <td>[{'args': {'question': 'What are the keys to b...</td>\n",
              "      <td>5</td>\n",
              "      <td>666</td>\n",
              "      <td>0.001029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>App_1</td>\n",
              "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
              "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
              "      <td>record_hash_64f6761410536c1a79390fa1765a9db0</td>\n",
              "      <td>\"How can teamwork contribute to success in AI?\"</td>\n",
              "      <td>\"Teamwork can contribute to success in AI by e...</td>\n",
              "      <td>-</td>\n",
              "      <td>{\"record_id\": \"record_hash_64f6761410536c1a793...</td>\n",
              "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
              "      <td>{\"start_time\": \"2024-06-02T20:57:49.208609\", \"...</td>\n",
              "      <td>2024-06-02T20:57:56.703892</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.65</td>\n",
              "      <td>[{'args': {'prompt': 'How can teamwork contrib...</td>\n",
              "      <td>[{'args': {'question': 'How can teamwork contr...</td>\n",
              "      <td>7</td>\n",
              "      <td>1002</td>\n",
              "      <td>0.001555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>App_1</td>\n",
              "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
              "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
              "      <td>record_hash_23a29f1798e72b1ecc4f4d04965ee29f</td>\n",
              "      <td>\"What is the importance of networking in AI?\"</td>\n",
              "      <td>\"Networking in AI is crucial as it helps in bu...</td>\n",
              "      <td>-</td>\n",
              "      <td>{\"record_id\": \"record_hash_23a29f1798e72b1ecc4...</td>\n",
              "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
              "      <td>{\"start_time\": \"2024-06-02T20:57:57.379170\", \"...</td>\n",
              "      <td>2024-06-02T20:58:01.261125</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.80</td>\n",
              "      <td>[{'args': {'prompt': 'What is the importance o...</td>\n",
              "      <td>[{'args': {'question': 'What is the importance...</td>\n",
              "      <td>3</td>\n",
              "      <td>1024</td>\n",
              "      <td>0.001589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>App_1</td>\n",
              "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
              "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
              "      <td>record_hash_5a7cb0dbca78af51414dbeb08b7a7c09</td>\n",
              "      <td>\"What are some good habits to develop for a su...</td>\n",
              "      <td>\"Good habits to develop for a successful caree...</td>\n",
              "      <td>-</td>\n",
              "      <td>{\"record_id\": \"record_hash_5a7cb0dbca78af51414...</td>\n",
              "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
              "      <td>{\"start_time\": \"2024-06-02T20:58:02.022181\", \"...</td>\n",
              "      <td>2024-06-02T20:58:05.991335</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.80</td>\n",
              "      <td>[{'args': {'prompt': 'What are some good habit...</td>\n",
              "      <td>[{'args': {'question': 'What are some good hab...</td>\n",
              "      <td>3</td>\n",
              "      <td>648</td>\n",
              "      <td>0.000995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>App_1</td>\n",
              "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
              "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
              "      <td>record_hash_f1b725c7fc117c32ecd3dc3daa057b70</td>\n",
              "      <td>\"How can altruism be beneficial in building a ...</td>\n",
              "      <td>\"Altruism can be beneficial in building a care...</td>\n",
              "      <td>-</td>\n",
              "      <td>{\"record_id\": \"record_hash_f1b725c7fc117c32ecd...</td>\n",
              "      <td>{\"n_requests\": 1, \"n_successful_requests\": 1, ...</td>\n",
              "      <td>{\"start_time\": \"2024-06-02T20:58:06.613497\", \"...</td>\n",
              "      <td>2024-06-02T20:58:10.077221</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.85</td>\n",
              "      <td>[{'args': {'prompt': 'How can altruism be bene...</td>\n",
              "      <td>[{'args': {'question': 'How can altruism be be...</td>\n",
              "      <td>3</td>\n",
              "      <td>812</td>\n",
              "      <td>0.001262</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f3dadac-0f32-4b6e-8bb4-0de037992c60')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1f3dadac-0f32-4b6e-8bb4-0de037992c60 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1f3dadac-0f32-4b6e-8bb4-0de037992c60');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9a1ba75c-0180-4c49-9c1c-d94bb3e3e958\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9a1ba75c-0180-4c49-9c1c-d94bb3e3e958')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9a1ba75c-0180-4c49-9c1c-d94bb3e3e958 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "records",
              "summary": "{\n  \"name\": \"records\",\n  \"rows\": 11,\n  \"fields\": [\n    {\n      \"column\": \"app_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"App_1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"app_json\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"{\\\"tru_class_info\\\": {\\\"name\\\": \\\"TruLlama\\\", \\\"module\\\": {\\\"package_name\\\": \\\"trulens_eval\\\", \\\"module_name\\\": \\\"trulens_eval.tru_llama\\\"}, \\\"bases\\\": [{\\\"name\\\": \\\"TruLlama\\\", \\\"module\\\": {\\\"package_name\\\": \\\"trulens_eval\\\", \\\"module_name\\\": \\\"trulens_eval.tru_llama\\\"}, \\\"bases\\\": null}, {\\\"name\\\": \\\"App\\\", \\\"module\\\": {\\\"package_name\\\": \\\"trulens_eval\\\", \\\"module_name\\\": \\\"trulens_eval.app\\\"}, \\\"bases\\\": null}, {\\\"name\\\": \\\"AppDefinition\\\", \\\"module\\\": {\\\"package_name\\\": \\\"trulens_eval.schema\\\", \\\"module_name\\\": \\\"trulens_eval.schema.app\\\"}, \\\"bases\\\": null}, {\\\"name\\\": \\\"WithClassInfo\\\", \\\"module\\\": {\\\"package_name\\\": \\\"trulens_eval.utils\\\", \\\"module_name\\\": \\\"trulens_eval.utils.pyschema\\\"}, \\\"bases\\\": null}, {\\\"name\\\": \\\"SerialModel\\\", \\\"module\\\": {\\\"package_name\\\": \\\"trulens_eval.utils\\\", \\\"module_name\\\": \\\"trulens_eval.utils.serial\\\"}, \\\"bases\\\": null}, {\\\"name\\\": \\\"BaseModel\\\", \\\"module\\\": {\\\"package_name\\\": \\\"pydantic\\\", \\\"module_name\\\": \\\"pydantic.main\\\"}, \\\"bases\\\": null}, {\\\"name\\\": \\\"WithInstrumentCallbacks\\\", \\\"module\\\": {\\\"package_name\\\": \\\"trulens_eval\\\", \\\"module_name\\\": \\\"trulens_eval.instruments\\\"}, \\\"bases\\\": null}, {\\\"name\\\": \\\"Hashable\\\", \\\"module\\\": {\\\"package_name\\\": \\\"collections\\\", \\\"module_name\\\": \\\"collections.abc\\\"}, \\\"bases\\\": null}, {\\\"name\\\": \\\"Generic\\\", \\\"module\\\": {\\\"package_name\\\": \\\"\\\", \\\"module_name\\\": \\\"typing\\\"}, \\\"bases\\\": null}, {\\\"name\\\": \\\"object\\\", \\\"module\\\": {\\\"package_name\\\": \\\"\\\", \\\"module_name\\\": \\\"builtins\\\"}, \\\"bases\\\": null}]}, \\\"app_id\\\": \\\"App_1\\\", \\\"tags\\\": \\\"-\\\", \\\"metadata\\\": {}, \\\"feedback_definitions\\\": [], \\\"feedback_mode\\\": \\\"with_app_thread\\\", \\\"root_class\\\": {\\\"name\\\": \\\"RetrieverQueryEngine\\\", \\\"module\\\": {\\\"package_name\\\": \\\"llama_index.core.query_engine\\\", \\\"module_name\\\": \\\"llama_index.core.query_engine.retriever_query_engine\\\"}, \\\"bases\\\": null}, \\\"app\\\": {\\\"__tru_non_serialized_object\\\": {\\\"cls\\\": {\\\"name\\\": \\\"RetrieverQueryEngine\\\", \\\"module\\\": {\\\"package_name\\\": \\\"llama_index.core.query_engine\\\", \\\"module_name\\\": \\\"llama_index.core.query_engine.retriever_query_engine\\\"}, \\\"bases\\\": null}, \\\"id\\\": 139578195407392, \\\"init_bindings\\\": null}}, \\\"initial_app_loader_dump\\\": null, \\\"app_extra_json\\\": {}, \\\"selector_check_warning\\\": false, \\\"selector_nocheck\\\": false}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"RetrieverQueryEngine(llama_index.core.query_engine.retriever_query_engine)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"record_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"record_hash_126e01e079f3cbd2d5c5073931690662\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"\\\"What is imposter syndrome and how does it relate to AI?\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"\\\"Imposter syndrome is when an individual doubts their accomplishments and has a persistent fear of being exposed as a fraud, despite evidence of their competence. In the field of AI, newcomers may experience imposter syndrome due to the technical complexity and the presence of highly capable individuals. It is common for individuals in the AI community, regardless of their success, to question their abilities and feel like they do not belong. However, it is emphasized that experiencing challenges and setbacks is a normal part of the learning process in AI, and it should not deter anyone from pursuing a career in the field.\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tags\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"-\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"record_json\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"{\\\"record_id\\\": \\\"record_hash_126e01e079f3cbd2d5c5073931690662\\\", \\\"app_id\\\": \\\"App_1\\\", \\\"cost\\\": {\\\"n_requests\\\": 1, \\\"n_successful_requests\\\": 1, \\\"n_classes\\\": 0, \\\"n_tokens\\\": 718, \\\"n_stream_chunks\\\": 0, \\\"n_prompt_tokens\\\": 603, \\\"n_completion_tokens\\\": 115, \\\"cost\\\": 0.0011345}, \\\"perf\\\": {\\\"start_time\\\": \\\"2024-06-02T20:58:10.411934\\\", \\\"end_time\\\": \\\"2024-06-02T20:58:13.812514\\\"}, \\\"ts\\\": \\\"2024-06-02T20:58:13.815153\\\", \\\"tags\\\": \\\"-\\\", \\\"meta\\\": null, \\\"main_input\\\": \\\"What is imposter syndrome and how does it relate to AI?\\\", \\\"main_output\\\": \\\"Imposter syndrome is when an individual doubts their accomplishments and has a persistent fear of being exposed as a fraud, despite evidence of their competence. In the field of AI, newcomers may experience imposter syndrome due to the technical complexity and the presence of highly capable individuals. It is common for individuals in the AI community, regardless of their success, to question their abilities and feel like they do not belong. However, it is emphasized that experiencing challenges and setbacks is a normal part of the learning process in AI, and it should not deter anyone from pursuing a career in the field.\\\", \\\"main_error\\\": null, \\\"calls\\\": [{\\\"call_id\\\": \\\"184ad0af-4ba6-4a13-abe1-d33d00ca3f54\\\", \\\"stack\\\": [{\\\"path\\\": \\\"app\\\", \\\"method\\\": {\\\"obj\\\": {\\\"cls\\\": {\\\"name\\\": \\\"RetrieverQueryEngine\\\", \\\"module\\\": {\\\"package_name\\\": \\\"llama_index.core.query_engine\\\", \\\"module_name\\\": \\\"llama_index.core.query_engine.retriever_query_engine\\\"}, \\\"bases\\\": null}, \\\"id\\\": 139578195407392, \\\"init_bindings\\\": null}, \\\"name\\\": \\\"query\\\"}}, {\\\"path\\\": \\\"app\\\", \\\"method\\\": {\\\"obj\\\": {\\\"cls\\\": {\\\"name\\\": \\\"RetrieverQueryEngine\\\", \\\"module\\\": {\\\"package_name\\\": \\\"llama_index.core.query_engine\\\", \\\"module_name\\\": \\\"llama_index.core.query_engine.retriever_query_engine\\\"}, \\\"bases\\\": null}, \\\"id\\\": 139578195407392, \\\"init_bindings\\\": null}, \\\"name\\\": \\\"retrieve\\\"}}, {\\\"path\\\": \\\"app._retriever\\\", \\\"method\\\": {\\\"obj\\\": {\\\"cls\\\": {\\\"name\\\": \\\"VectorIndexRetriever\\\", \\\"module\\\": {\\\"package_name\\\": \\\"llama_index.core.indices.vector_store.retrievers\\\", \\\"module_name\\\": \\\"llama_index.core.indices.vector_store.retrievers.retriever\\\"}, \\\"bases\\\": null}, \\\"id\\\": 139578195409456, \\\"init_bindings\\\": null}, \\\"name\\\": \\\"retrieve\\\"}}, {\\\"path\\\": \\\"app._retriever\\\", \\\"method\\\": {\\\"obj\\\": {\\\"cls\\\": {\\\"name\\\": \\\"VectorIndexRetriever\\\", \\\"module\\\": {\\\"package_name\\\": \\\"llama_index.core.indices.vector_store.retrievers\\\", \\\"module_name\\\": \\\"llama_index.core.indices.vector_store.retrievers.retriever\\\"}, \\\"bases\\\": null}, \\\"id\\\": 139578195409456, \\\"init_bindings\\\": null}, \\\"name\\\": \\\"_retrieve\\\"}}], \\\"args\\\": {\\\"query_bundle\\\": {\\\"query_str\\\": \\\"What is imposter syndrome and how does it relate to AI?\\\", \\\"image_path\\\": null, \\\"custom_embedding_strs\\\": null, \\\"embedding\\\": [-0.022138359025120735, 0.06330832839012146, -0.02178497612476349, 0.05808620527386665, -0.011336613446474075, -0.005612774286419153, 0.08911127597093582, 0.0030356543138623238, 0.05779843404889107, -0.0158709604293108, 0.043755464255809784, -0.04610735550522804, 0.041546400636434555, 0.04221899434924126, 0.010080059058964252, -0.007372432854026556, -0.012149561196565628, 0.010139614343643188, 0.023927219212055206, 0.0618598572909832, 0.002753077307716012, -0.02734963782131672, -0.026586217805743217, -0.05804353952407837, -0.05689089372754097, 0.025389932096004486, -0.02710329182446003, -0.030684951692819595, -0.06962019205093384, -0.12699782848358154, 0.010024623945355415, -0.030747653916478157, 0.07036616653203964, 0.03634142503142357, 0.023763809353113174, -0.029446573927998543, -0.06237635761499405, 0.028677452355623245, -0.0026431584265083075, -0.03701413795351982, -0.03109831176698208, -0.03169137239456177, 0.008376998826861382, -0.024873236194252968, 0.023566365242004395, 0.03139616549015045, -0.04141063243150711, 0.02061697654426098, -0.01121605560183525, -0.04815472289919853, -0.05840567871928215, -0.03434079512953758, -0.022948548197746277, 0.09036225080490112, -0.01924021728336811, 0.04285462573170662, 0.05470186471939087, 0.08362477272748947, -0.01492794044315815, 0.024841615930199623, 0.020555971190333366, 0.020025992766022682, -0.07407246530056, 0.10731633007526398, 0.0870477482676506, 0.021047256886959076, -0.04459372162818909, -0.06212715432047844, 0.00605186028406024, 0.0052450052462518215, -0.012020755559206009, -0.004519903101027012, -0.03384644165635109, 0.038123901933431625, 0.019433651119470596, 0.03789782151579857, 0.021288715302944183, 0.017243824899196625, 0.07020135968923569, 0.014117566868662834, 0.06357898563146591, -0.0064677344635128975, -0.05849508196115494, -0.019088268280029297, 0.01027615461498499, 0.0035970446188002825, 0.025662222877144814, -0.07794789224863052, 0.03695748373866081, -0.027840768918395042, -0.03499165177345276, -0.051770541816949844, 0.010811539366841316, 0.05399427190423012, 0.018361764028668404, -0.0067157866433262825, -0.03730263188481331, 0.0222349651157856, -0.07656251639127731, 0.33013853430747986, 0.029236525297164917, 0.001514303032308817, 0.06218745931982994, 0.0015199027257040143, -0.026270747184753418, -0.04608375206589699, 0.024223893880844116, 0.010248078033328056, -0.0752921774983406, 0.003555088071152568, -0.016446763649582863, -0.06423038989305496, 0.06408217549324036, 0.0414954274892807, 0.041121531277894974, -0.0035458658821880817, 0.06343093514442444, 0.03869159147143364, 0.031063418835401535, -0.007991282269358635, 0.0008135174284689128, 0.01949228160083294, -0.0003326743026264012, -0.002367552602663636, -0.06658053398132324, -0.027151096612215042, -0.04922632873058319, 0.08483787626028061, -0.056617144495248795, -0.08511564135551453, -0.0004727170744445175, 0.01962371915578842, -0.00859463308006525, -0.003877201583236456, 0.017960334196686745, 0.003219116711989045, -0.022798413410782814, -0.01940670982003212, 0.0073257810436189175, 0.03914864733815193, -0.038353364914655685, 0.04747907817363739, 0.01919323392212391, 0.04102756083011627, -0.028257502242922783, 0.03738253191113472, 0.015703555196523666, -0.01299336925148964, -0.020075581967830658, 0.019566604867577553, -0.021392663940787315, 0.00201755971647799, -0.09726795554161072, -0.07456518709659576, -0.0028769648633897305, -0.01575549691915512, 0.03440897911787033, -0.07228709012269974, -0.06267200410366058, -0.014082793146371841, -0.01460484229028225, -0.048231251537799835, -0.06281588226556778, 0.12147489190101624, 0.0880126878619194, -0.0606771782040596, -0.004004522692412138, -0.01554181706160307, -0.009473884478211403, 0.03531463071703911, 0.006306394003331661, -0.01354927383363247, -0.05453085899353027, 0.037171926349401474, 0.000934939191211015, -0.013814262114465237, -0.013664710335433483, 0.04010280966758728, -0.05416380241513252, 0.044868458062410355, 0.04724569991230965, -0.07873328030109406, -0.027704548090696335, 0.013921757228672504, 0.02553793415427208, -0.03706158697605133, -0.02916598878800869, -0.09766733646392822, 0.01947626657783985, -0.062387917190790176, -0.02831646427512169, 0.0067457156255841255, -0.08460460603237152, -0.0995142012834549, -0.016054866835474968, 0.028088662773370743, 0.057485997676849365, 0.0521850660443306, -0.018348874524235725, -0.029311131685972214, -0.02895592711865902, 0.05319276824593544, -0.024413008242845535, -0.046930667012929916, 0.01818789541721344, 0.03198171406984329, 0.01940084993839264, -0.01176284346729517, 0.05157820135354996, -0.01415332779288292, -0.014676016755402088, -0.017274275422096252, -0.015991754829883575, 0.003083337564021349, 0.010715456679463387, 0.026804542168974876, -0.033605191856622696, 0.0004534107865765691, -0.008858396671712399, -0.00928028579801321, -0.03359676152467728, -0.018838297575712204, -0.02760949172079563, -0.2535814344882965, -0.024165062233805656, -0.047418661415576935, -0.0125493835657835, -0.017373809590935707, -0.0388382151722908, -0.014610538259148598, 0.01423417218029499, 0.07930915057659149, 0.022359449416399002, 0.04189227148890495, 0.01480313390493393, -0.002080738777294755, 0.011763034388422966, -0.032442767173051834, 0.0392119437456131, 0.010166135616600513, 0.011189146898686886, -0.017394162714481354, -0.003022517077624798, -0.01676912046968937, 0.03419334068894386, 0.10458780080080032, -0.04781974479556084, -0.015625057741999626, 0.01153029315173626, 0.10123319178819656, 0.04090040549635887, 0.009774606674909592, 0.0324629470705986, -0.04235512763261795, 0.04105967655777931, 0.010661550797522068, -0.0838533565402031, 0.06761231273412704, -0.04992065951228142, 0.022016694769263268, -0.05823857709765434, -0.008222787640988827, 0.0035545474383980036, -0.10693804174661636, -0.005694338586181402, -0.005299585871398449, 0.0673288032412529, -0.059233054518699646, 0.07467004656791687, -0.016623474657535553, 0.04976487159729004, -0.028513558208942413, 0.1201036348938942, 0.0018306572455912828, -0.01473167259246111, -0.013808755204081535, 0.004389430396258831, -0.033403754234313965, -0.03186212480068207, -0.05654558911919594, -0.008508232422173023, -0.02997291274368763, -0.004388116300106049, 0.06433824449777603, 0.009878674522042274, -0.08721302449703217, -0.027398761361837387, 0.06771067529916763, 0.05710263177752495, -0.027601609006524086, 0.07307715713977814, 0.037535134702920914, 0.017999472096562386, -0.018361102789640427, 0.16629864275455475, -0.009966438636183739, -0.0064811911433935165, 0.0781630277633667, -0.02347560226917267, 0.007282616570591927, -0.07585280388593674, -0.020620226860046387, 0.055917929857969284, 0.03128000721335411, -0.016443993896245956, -0.013930227607488632, 0.03947686776518822, 0.020100127905607224, -0.014808209612965584, -0.0239152442663908, 0.004243770614266396, 0.10904030501842499, 0.056635886430740356, 0.017087917774915695, 0.08328763395547867, -0.0700441300868988, 0.0038121063262224197, 0.06441731750965118, -0.0031983586959540844, -0.2774692475795746, 0.016640212386846542, -0.03143422678112984, 0.047859594225883484, -0.0389234721660614, -0.0355895459651947, -0.012750927358865738, -0.04677576571702957, 0.014222712256014347, -0.07082463055849075, 0.0018205910455435514, -0.026118719950318336, -0.009636041708290577, 0.010927175171673298, -0.05170474946498871, 0.06983324885368347, 0.031764063984155655, -0.09643185138702393, -0.0271859560161829, -0.03655780479311943, -0.06585772335529327, 0.08345794677734375, 0.17869196832180023, 0.02623196318745613, -0.026039371266961098, -0.03584732115268707, 0.012415585108101368, 0.027818916365504265, 0.012372701428830624, -0.031115634366869926, 0.01597813330590725, -0.058284368366003036, 0.031048815697431564, -0.014511380344629288, 0.036379989236593246, 0.040107112377882004, -0.03885844349861145, 0.0642148107290268, 0.04553288221359253, -0.0032139429822564125, 0.0037294321227818727, 0.021384475752711296, 0.016061721369624138, 0.023716846480965614, 0.08300896733999252, 0.011103902943432331, 0.005610782187432051, 0.006257719360291958, -0.003271617693826556, 0.0017353056464344263, 0.004048414062708616, -0.03889920189976692, 0.0015362442936748266, -0.04101455211639404, 0.03691445663571358, 0.014115508645772934, -0.007408578880131245, -0.039914242923259735, 0.008639845997095108, -0.02662782184779644, -0.03573709353804588, 0.04430992156267166, 0.07191050797700882, 0.0472828708589077, -0.03748752549290657]}}, \\\"rets\\\": [{\\\"node\\\": {\\\"id_\\\": \\\"27cbf0f6-24f8-4d0f-b8d2-e9e7755b6538\\\", \\\"embedding\\\": null, \\\"metadata\\\": {\\\"page_label\\\": \\\"38\\\", \\\"file_name\\\": \\\"eBook-How-to-Build-a-Career-in-AI.pdf\\\", \\\"file_path\\\": \\\"eBook-How-to-Build-a-Career-in-AI.pdf\\\", \\\"file_type\\\": \\\"application/pdf\\\", \\\"file_size\\\": 3717673, \\\"creation_date\\\": \\\"2024-06-02\\\", \\\"last_modified_date\\\": \\\"2022-12-13\\\"}, \\\"excluded_embed_metadata_keys\\\": [\\\"file_name\\\", \\\"file_type\\\", \\\"file_size\\\", \\\"creation_date\\\", \\\"last_modified_date\\\", \\\"last_accessed_date\\\"], \\\"excluded_llm_metadata_keys\\\": [\\\"file_name\\\", \\\"file_type\\\", \\\"file_size\\\", \\\"creation_date\\\", \\\"last_modified_date\\\", \\\"last_accessed_date\\\"], \\\"relationships\\\": {\\\"1\\\": {\\\"node_id\\\": \\\"fc5ef969-90e7-4519-afc8-8fbed7897822\\\", \\\"node_type\\\": \\\"4\\\", \\\"metadata\\\": {\\\"page_label\\\": \\\"38\\\", \\\"file_name\\\": \\\"eBook-How-to-Build-a-Career-in-AI.pdf\\\", \\\"file_path\\\": \\\"eBook-How-to-Build-a-Career-in-AI.pdf\\\", \\\"file_type\\\": \\\"application/pdf\\\", \\\"file_size\\\": 3717673, \\\"creation_date\\\": \\\"2024-06-02\\\", \\\"last_modified_date\\\": \\\"2022-12-13\\\"}, \\\"hash\\\": \\\"8015b3d10bb297d165d3c19ad5322426807b464384d1e8ac1f2ebecd22daab11\\\"}}, \\\"text\\\": \\\"PAGE 38Before we dive into the final chapter of this book, I\\\\u2019d like to address the serious matter of \\\\nnewcomers to AI sometimes experiencing imposter syndrome, where someone \\\\u2014 regardless \\\\nof their success in the field \\\\u2014 wonders if they\\\\u2019re a fraud and really belong in the AI community. \\\\nI want to make sure this doesn\\\\u2019t discourage you or anyone else from growing in AI.\\\\nAn estimated 70 percent of people experience some form of imposter syndrome at some point. \\\\nMany talented people have spoken publicly about this experience, including former Facebook \\\\nCOO Sheryl Sandberg, U.S. first lady Michelle Obama, actor Tom Hanks, and Atlassian co-CEO \\\\nMike Cannon-Brookes. It happens in our community even among accomplished people. If you\\\\u2019ve \\\\nnever experienced this yourself, that\\\\u2019s great! I hope you\\\\u2019ll join me in encouraging and welcoming \\\\neveryone who wants to join our community.\\\\nAI is technically complex, and it has its fair share of smart and highly capable people. But it is \\\\neasy to forget that to become good at anything, the first step is to suck at it. If you\\\\u2019ve succeeded \\\\nat sucking at AI \\\\u2014 congratulations, you\\\\u2019re on your way!\\\\nI once struggled to understand the math behind linear regression. I was mystified when \\\\nlogistic regression performed strangely on my data, and it took me days to find a bug in my \\\\nimplementation of a basic neural network. Today, I still find many research papers challenging \\\\nto read, and I recently made an obvious mistake while tuning a neural network hyperparameter \\\\n(that fortunately a fellow engineer caught and fixed).\\\\nSo if you, too, find parts of AI challenging, it\\\\u2019s okay. We\\\\u2019ve all been there. I guarantee that everyone \\\\nwho has published a seminal AI paper struggled with similar technical challenges at some point.Let me be clear: If you want to be part of the AI \\\\ncommunity, then I welcome you with open arms. \\\\nIf you want to join us, you fully belong with us!Overcoming Imposter Syndrome\\\", \\\"start_char_idx\\\": 0, \\\"end_char_idx\\\": 1939, \\\"text_template\\\": \\\"{metadata_str}\\\\n\\\\n{content}\\\", \\\"metadata_template\\\": \\\"{key}: {value}\\\", \\\"metadata_seperator\\\": \\\"\\\\n\\\"}, \\\"score\\\": 0.8139902349518466}, {\\\"node\\\": {\\\"id_\\\": \\\"fcd8731f-ebd5-40af-be7a-6813e8b7645d\\\", \\\"embedding\\\": null, \\\"metadata\\\": {\\\"page_label\\\": \\\"37\\\", \\\"file_name\\\": \\\"eBook-How-to-Build-a-Career-in-AI.pdf\\\", \\\"file_path\\\": \\\"eBook-How-to-Build-a-Career-in-AI.pdf\\\", \\\"file_type\\\": \\\"application/pdf\\\", \\\"file_size\\\": 3717673, \\\"creation_date\\\": \\\"2024-06-02\\\", \\\"last_modified_date\\\": \\\"2022-12-13\\\"}, \\\"excluded_embed_metadata_keys\\\": [\\\"file_name\\\", \\\"file_type\\\", \\\"file_size\\\", \\\"creation_date\\\", \\\"last_modified_date\\\", \\\"last_accessed_date\\\"], \\\"excluded_llm_metadata_keys\\\": [\\\"file_name\\\", \\\"file_type\\\", \\\"file_size\\\", \\\"creation_date\\\", \\\"last_modified_date\\\", \\\"last_accessed_date\\\"], \\\"relationships\\\": {\\\"1\\\": {\\\"node_id\\\": \\\"771a3bb1-2b43-43f1-bb7e-1b16e94896e6\\\", \\\"node_type\\\": \\\"4\\\", \\\"metadata\\\": {\\\"page_label\\\": \\\"37\\\", \\\"file_name\\\": \\\"eBook-How-to-Build-a-Career-in-AI.pdf\\\", \\\"file_path\\\": \\\"eBook-How-to-Build-a-Career-in-AI.pdf\\\", \\\"file_type\\\": \\\"application/pdf\\\", \\\"file_size\\\": 3717673, \\\"creation_date\\\": \\\"2024-06-02\\\", \\\"last_modified_date\\\": \\\"2022-12-13\\\"}, \\\"hash\\\": \\\"293bf847843cd20f676eeffac711e0db3bde1207bf6eda80f52530f8692b41c5\\\"}}, \\\"text\\\": \\\"PAGE 37Overcoming Imposter \\\\nSyndromeCHAPTER 11\\\", \\\"start_char_idx\\\": 0, \\\"end_char_idx\\\": 46, \\\"text_template\\\": \\\"{metadata_str}\\\\n\\\\n{content}\\\", \\\"metadata_template\\\": \\\"{key}: {value}\\\", \\\"metadata_seperator\\\": \\\"\\\\n\\\"}, \\\"score\\\": 0.740083412837171}], \\\"error\\\": null, \\\"perf\\\": {\\\"start_time\\\": \\\"2024-06-02T20:58:10.968980\\\", \\\"end_time\\\": \\\"2024-06-02T20:58:11.071241\\\"}, \\\"pid\\\": 17076, \\\"tid\\\": 17076}, {\\\"call_id\\\": \\\"ee6a4c1d-b7e5-474f-be83-b2c237c8cc69\\\", \\\"stack\\\": [{\\\"path\\\": \\\"app\\\", \\\"method\\\": {\\\"obj\\\": {\\\"cls\\\": {\\\"name\\\": \\\"RetrieverQueryEngine\\\", \\\"module\\\": {\\\"package_name\\\": \\\"llama_index.core.query_engine\\\", \\\"module_name\\\": \\\"llama_index.core.query_engine.retriever_query_engine\\\"}, \\\"bases\\\": null}, \\\"id\\\": 139578195407392, \\\"init_bindings\\\": null}, \\\"name\\\": \\\"query\\\"}}, {\\\"path\\\": \\\"app\\\", \\\"method\\\": {\\\"obj\\\": {\\\"cls\\\": {\\\"name\\\": \\\"RetrieverQueryEngine\\\", \\\"module\\\": {\\\"package_name\\\": \\\"llama_index.core.query_engine\\\", \\\"module_name\\\": \\\"llama_index.core.query_engine.retriever_query_engine\\\"}, \\\"bases\\\": null}, \\\"id\\\": 139578195407392, \\\"init_bindings\\\": null}, \\\"name\\\": \\\"retrieve\\\"}}, {\\\"path\\\": \\\"app._retriever\\\", \\\"method\\\": {\\\"obj\\\": {\\\"cls\\\": {\\\"name\\\": \\\"VectorIndexRetriever\\\", \\\"module\\\": {\\\"package_name\\\": \\\"llama_index.core.indices.vector_store.retrievers\\\", \\\"module_name\\\": \\\"llama_index.core.indices.vector_store.retrievers.retriever\\\"}, \\\"bases\\\": null}, \\\"id\\\": 139578195409456, \\\"init_bindings\\\": null}, \\\"name\\\": \\\"retrieve\\\"}}], \\\"args\\\": {\\\"str_or_query_bundle\\\": {\\\"query_str\\\": \\\"What is imposter syndrome and how does it relate to AI?\\\", \\\"image_path\\\": null, \\\"custom_embedding_strs\\\": null, \\\"embedding\\\": [-0.022138359025120735, 0.06330832839012146, -0.02178497612476349, 0.05808620527386665, -0.011336613446474075, -0.005612774286419153, 0.08911127597093582, 0.0030356543138623238, 0.05779843404889107, -0.0158709604293108, 0.043755464255809784, -0.04610735550522804, 0.041546400636434555, 0.04221899434924126, 0.010080059058964252, -0.007372432854026556, -0.012149561196565628, 0.010139614343643188, 0.023927219212055206, 0.0618598572909832, 0.002753077307716012, -0.02734963782131672, -0.026586217805743217, -0.05804353952407837, -0.05689089372754097, 0.025389932096004486, -0.02710329182446003, -0.030684951692819595, -0.06962019205093384, -0.12699782848358154, 0.010024623945355415, -0.030747653916478157, 0.07036616653203964, 0.03634142503142357, 0.023763809353113174, -0.029446573927998543, -0.06237635761499405, 0.028677452355623245, -0.0026431584265083075, -0.03701413795351982, -0.03109831176698208, -0.03169137239456177, 0.008376998826861382, -0.024873236194252968, 0.023566365242004395, 0.03139616549015045, -0.04141063243150711, 0.02061697654426098, -0.01121605560183525, -0.04815472289919853, -0.05840567871928215, -0.03434079512953758, -0.022948548197746277, 0.09036225080490112, -0.01924021728336811, 0.04285462573170662, 0.05470186471939087, 0.08362477272748947, -0.01492794044315815, 0.024841615930199623, 0.020555971190333366, 0.020025992766022682, -0.07407246530056, 0.10731633007526398, 0.0870477482676506, 0.021047256886959076, -0.04459372162818909, -0.06212715432047844, 0.00605186028406024, 0.0052450052462518215, -0.012020755559206009, -0.004519903101027012, -0.03384644165635109, 0.038123901933431625, 0.019433651119470596, 0.03789782151579857, 0.021288715302944183, 0.017243824899196625, 0.07020135968923569, 0.014117566868662834, 0.06357898563146591, -0.0064677344635128975, -0.05849508196115494, -0.019088268280029297, 0.01027615461498499, 0.0035970446188002825, 0.025662222877144814, -0.07794789224863052, 0.03695748373866081, -0.027840768918395042, -0.03499165177345276, -0.051770541816949844, 0.010811539366841316, 0.05399427190423012, 0.018361764028668404, -0.0067157866433262825, -0.03730263188481331, 0.0222349651157856, -0.07656251639127731, 0.33013853430747986, 0.029236525297164917, 0.001514303032308817, 0.06218745931982994, 0.0015199027257040143, -0.026270747184753418, -0.04608375206589699, 0.024223893880844116, 0.010248078033328056, -0.0752921774983406, 0.003555088071152568, -0.016446763649582863, -0.06423038989305496, 0.06408217549324036, 0.0414954274892807, 0.041121531277894974, -0.0035458658821880817, 0.06343093514442444, 0.03869159147143364, 0.031063418835401535, -0.007991282269358635, 0.0008135174284689128, 0.01949228160083294, -0.0003326743026264012, -0.002367552602663636, -0.06658053398132324, -0.027151096612215042, -0.04922632873058319, 0.08483787626028061, -0.056617144495248795, -0.08511564135551453, -0.0004727170744445175, 0.01962371915578842, -0.00859463308006525, -0.003877201583236456, 0.017960334196686745, 0.003219116711989045, -0.022798413410782814, -0.01940670982003212, 0.0073257810436189175, 0.03914864733815193, -0.038353364914655685, 0.04747907817363739, 0.01919323392212391, 0.04102756083011627, -0.028257502242922783, 0.03738253191113472, 0.015703555196523666, -0.01299336925148964, -0.020075581967830658, 0.019566604867577553, -0.021392663940787315, 0.00201755971647799, -0.09726795554161072, -0.07456518709659576, -0.0028769648633897305, -0.01575549691915512, 0.03440897911787033, -0.07228709012269974, -0.06267200410366058, -0.014082793146371841, -0.01460484229028225, -0.048231251537799835, -0.06281588226556778, 0.12147489190101624, 0.0880126878619194, -0.0606771782040596, -0.004004522692412138, -0.01554181706160307, -0.009473884478211403, 0.03531463071703911, 0.006306394003331661, -0.01354927383363247, -0.05453085899353027, 0.037171926349401474, 0.000934939191211015, -0.013814262114465237, -0.013664710335433483, 0.04010280966758728, -0.05416380241513252, 0.044868458062410355, 0.04724569991230965, -0.07873328030109406, -0.027704548090696335, 0.013921757228672504, 0.02553793415427208, -0.03706158697605133, -0.02916598878800869, -0.09766733646392822, 0.01947626657783985, -0.062387917190790176, -0.02831646427512169, 0.0067457156255841255, -0.08460460603237152, -0.0995142012834549, -0.016054866835474968, 0.028088662773370743, 0.057485997676849365, 0.0521850660443306, -0.018348874524235725, -0.029311131685972214, -0.02895592711865902, 0.05319276824593544, -0.024413008242845535, -0.046930667012929916, 0.01818789541721344, 0.03198171406984329, 0.01940084993839264, -0.01176284346729517, 0.05157820135354996, -0.01415332779288292, -0.014676016755402088, -0.017274275422096252, -0.015991754829883575, 0.003083337564021349, 0.010715456679463387, 0.026804542168974876, -0.033605191856622696, 0.0004534107865765691, -0.008858396671712399, -0.00928028579801321, -0.03359676152467728, -0.018838297575712204, -0.02760949172079563, -0.2535814344882965, -0.024165062233805656, -0.047418661415576935, -0.0125493835657835, -0.017373809590935707, -0.0388382151722908, -0.014610538259148598, 0.01423417218029499, 0.07930915057659149, 0.022359449416399002, 0.04189227148890495, 0.01480313390493393, -0.002080738777294755, 0.011763034388422966, -0.032442767173051834, 0.0392119437456131, 0.010166135616600513, 0.011189146898686886, -0.017394162714481354, -0.003022517077624798, -0.01676912046968937, 0.03419334068894386, 0.10458780080080032, -0.04781974479556084, -0.015625057741999626, 0.01153029315173626, 0.10123319178819656, 0.04090040549635887, 0.009774606674909592, 0.0324629470705986, -0.04235512763261795, 0.04105967655777931, 0.010661550797522068, -0.0838533565402031, 0.06761231273412704, -0.04992065951228142, 0.022016694769263268, -0.05823857709765434, -0.008222787640988827, 0.0035545474383980036, -0.10693804174661636, -0.005694338586181402, -0.005299585871398449, 0.0673288032412529, -0.059233054518699646, 0.07467004656791687, -0.016623474657535553, 0.04976487159729004, -0.028513558208942413, 0.1201036348938942, 0.0018306572455912828, -0.01473167259246111, -0.013808755204081535, 0.004389430396258831, -0.033403754234313965, -0.03186212480068207, -0.05654558911919594, -0.008508232422173023, -0.02997291274368763, -0.004388116300106049, 0.06433824449777603, 0.009878674522042274, -0.08721302449703217, -0.027398761361837387, 0.06771067529916763, 0.05710263177752495, -0.027601609006524086, 0.07307715713977814, 0.037535134702920914, 0.017999472096562386, -0.018361102789640427, 0.16629864275455475, -0.009966438636183739, -0.0064811911433935165, 0.0781630277633667, -0.02347560226917267, 0.007282616570591927, -0.07585280388593674, -0.020620226860046387, 0.055917929857969284, 0.03128000721335411, -0.016443993896245956, -0.013930227607488632, 0.03947686776518822, 0.020100127905607224, -0.014808209612965584, -0.0239152442663908, 0.004243770614266396, 0.10904030501842499, 0.056635886430740356, 0.017087917774915695, 0.08328763395547867, -0.0700441300868988, 0.0038121063262224197, 0.06441731750965118, -0.0031983586959540844, -0.2774692475795746, 0.016640212386846542, -0.03143422678112984, 0.047859594225883484, -0.0389234721660614, -0.0355895459651947, -0.012750927358865738, -0.04677576571702957, 0.014222712256014347, -0.07082463055849075, 0.0018205910455435514, -0.026118719950318336, -0.009636041708290577, 0.010927175171673298, -0.05170474946498871, 0.06983324885368347, 0.031764063984155655, -0.09643185138702393, -0.0271859560161829, -0.03655780479311943, -0.06585772335529327, 0.08345794677734375, 0.17869196832180023, 0.02623196318745613, -0.026039371266961098, -0.03584732115268707, 0.012415585108101368, 0.027818916365504265, 0.012372701428830624, -0.031115634366869926, 0.01597813330590725, -0.058284368366003036, 0.031048815697431564, -0.014511380344629288, 0.036379989236593246, 0.040107112377882004, -0.03885844349861145, 0.0642148107290268, 0.04553288221359253, -0.0032139429822564125, 0.0037294321227818727, 0.021384475752711296, 0.016061721369624138, 0.023716846480965614, 0.08300896733999252, 0.011103902943432331, 0.005610782187432051, 0.006257719360291958, -0.003271617693826556, 0.0017353056464344263, 0.004048414062708616, -0.03889920189976692, 0.0015362442936748266, -0.04101455211639404, 0.03691445663571358, 0.014115508645772934, -0.007408578880131245, -0.039914242923259735, 0.008639845997095108, -0.02662782184779644, -0.03573709353804588, 0.04430992156267166, 0.07191050797700882, 0.0472828708589077, -0.03748752549290657]}}, \\\"rets\\\": [{\\\"node\\\": {\\\"id_\\\": \\\"27cbf0f6-24f8-4d0f-b8d2-e9e7755b6538\\\", \\\"embedding\\\": null, \\\"metadata\\\": {\\\"page_label\\\": \\\"38\\\", \\\"file_name\\\": \\\"eBook-How-to-Build-a-Career-in-AI.pdf\\\", \\\"file_path\\\": \\\"eBook-How-to-Build-a-Career-in-AI.pdf\\\", \\\"file_type\\\": \\\"application/pdf\\\", \\\"file_size\\\": 3717673, \\\"creation_date\\\": \\\"2024-06-02\\\", \\\"last_modified_date\\\": \\\"2022-12-13\\\"}, \\\"excluded_embed_metadata_keys\\\": [\\\"file_name\\\", \\\"file_type\\\", \\\"file_size\\\", \\\"creation_date\\\", \\\"last_modified_date\\\", \\\"last_accessed_date\\\"], \\\"excluded_llm_metadata_keys\\\": [\\\"file_name\\\", \\\"file_type\\\", \\\"file_size\\\", \\\"creation_date\\\", \\\"last_modified_date\\\", \\\"last_accessed_date\\\"], \\\"relationships\\\": {\\\"1\\\": {\\\"node_id\\\": \\\"fc5ef969-90e7-4519-afc8-8fbed7897822\\\", \\\"node_type\\\": \\\"4\\\", \\\"metadata\\\": {\\\"page_label\\\": \\\"38\\\", \\\"file_name\\\": \\\"eBook-How-to-Build-a-Career-in-AI.pdf\\\", \\\"file_path\\\": \\\"eBook-How-to-Build-a-Career-in-AI.pdf\\\", \\\"file_type\\\": \\\"application/pdf\\\", \\\"file_size\\\": 3717673, \\\"creation_date\\\": \\\"2024-06-02\\\", \\\"last_modified_date\\\": \\\"2022-12-13\\\"}, \\\"hash\\\": \\\"8015b3d10bb297d165d3c19ad5322426807b464384d1e8ac1f2ebecd22daab11\\\"}}, \\\"text\\\": \\\"PAGE 38Before we dive into the final chapter of this book, I\\\\u2019d like to address the serious matter of \\\\nnewcomers to AI sometimes experiencing imposter syndrome, where someone \\\\u2014 regardless \\\\nof their success in the field \\\\u2014 wonders if they\\\\u2019re a fraud and really belong in the AI community. \\\\nI want to make sure this doesn\\\\u2019t discourage you or anyone else from growing in AI.\\\\nAn estimated 70 percent of people experience some form of imposter syndrome at some point. \\\\nMany talented people have spoken publicly about this experience, including former Facebook \\\\nCOO Sheryl Sandberg, U.S. first lady Michelle Obama, actor Tom Hanks, and Atlassian co-CEO \\\\nMike Cannon-Brookes. It happens in our community even among accomplished people. If you\\\\u2019ve \\\\nnever experienced this yourself, that\\\\u2019s great! I hope you\\\\u2019ll join me in encouraging and welcoming \\\\neveryone who wants to join our community.\\\\nAI is technically complex, and it has its fair share of smart and highly capable people. But it is \\\\neasy to forget that to become good at anything, the first step is to suck at it. If you\\\\u2019ve succeeded \\\\nat sucking at AI \\\\u2014 congratulations, you\\\\u2019re on your way!\\\\nI once struggled to understand the math behind linear regression. I was mystified when \\\\nlogistic regression performed strangely on my data, and it took me days to find a bug in my \\\\nimplementation of a basic neural network. Today, I still find many research papers challenging \\\\nto read, and I recently made an obvious mistake while tuning a neural network hyperparameter \\\\n(that fortunately a fellow engineer caught and fixed).\\\\nSo if you, too, find parts of AI challenging, it\\\\u2019s okay. We\\\\u2019ve all been there. I guarantee that everyone \\\\nwho has published a seminal AI paper struggled with similar technical challenges at some point.Let me be clear: If you want to be part of the AI \\\\ncommunity, then I welcome you with open arms. \\\\nIf you want to join us, you fully belong with us!Overcoming Imposter Syndrome\\\", \\\"start_char_idx\\\": 0, \\\"end_char_idx\\\": 1939, \\\"text_template\\\": \\\"{metadata_str}\\\\n\\\\n{content}\\\", \\\"metadata_template\\\": \\\"{key}: {value}\\\", \\\"metadata_seperator\\\": \\\"\\\\n\\\"}, \\\"score\\\": 0.8139902349518466}, {\\\"node\\\": {\\\"id_\\\": \\\"fcd8731f-ebd5-40af-be7a-6813e8b7645d\\\", \\\"embedding\\\": null, \\\"metadata\\\": {\\\"page_label\\\": \\\"37\\\", \\\"file_name\\\": \\\"eBook-How-to-Build-a-Career-in-AI.pdf\\\", \\\"file_path\\\": \\\"eBook-How-to-Build-a-Career-in-AI.pdf\\\", \\\"file_type\\\": \\\"application/pdf\\\", \\\"file_size\\\": 3717673, \\\"creation_date\\\": \\\"2024-06-02\\\", \\\"last_modified_date\\\": \\\"2022-12-13\\\"}, \\\"excluded_embed_metadata_keys\\\": [\\\"file_name\\\", \\\"file_type\\\", \\\"file_size\\\", \\\"creation_date\\\", \\\"last_modified_date\\\", \\\"last_accessed_date\\\"], \\\"excluded_llm_metadata_keys\\\": [\\\"file_name\\\", \\\"file_type\\\", \\\"file_size\\\", \\\"creation_date\\\", \\\"last_modified_date\\\", \\\"last_accessed_date\\\"], \\\"relationships\\\": {\\\"1\\\": {\\\"node_id\\\": \\\"771a3bb1-2b43-43f1-bb7e-1b16e94896e6\\\", \\\"node_type\\\": \\\"4\\\", \\\"metadata\\\": {\\\"page_label\\\": \\\"37\\\", \\\"file_name\\\": \\\"eBook-How-to-Build-a-Career-in-AI.pdf\\\", \\\"file_path\\\": \\\"eBook-How-to-Build-a-Career-in-AI.pdf\\\", \\\"file_type\\\": \\\"application/pdf\\\", \\\"file_size\\\": 3717673, \\\"creation_date\\\": \\\"2024-06-02\\\", \\\"last_modified_date\\\": \\\"2022-12-13\\\"}, \\\"hash\\\": \\\"293bf847843cd20f676eeffac711e0db3bde1207bf6eda80f52530f8692b41c5\\\"}}, \\\"text\\\": \\\"PAGE 37Overcoming Imposter \\\\nSyndromeCHAPTER 11\\\", \\\"start_char_idx\\\": 0, \\\"end_char_idx\\\": 46, \\\"text_template\\\": \\\"{metadata_str}\\\\n\\\\n{content}\\\", \\\"metadata_template\\\": \\\"{key}: {value}\\\", \\\"metadata_seperator\\\": \\\"\\\\n\\\"}, \\\"score\\\": 0.740083412837171}], \\\"error\\\": null, \\\"perf\\\": {\\\"start_time\\\": \\\"2024-06-02T20:58:10.774426\\\", \\\"end_time\\\": \\\"2024-06-02T20:58:11.073810\\\"}, \\\"pid\\\": 17076, \\\"tid\\\": 17076}, {\\\"call_id\\\": \\\"c29edd73-89d0-4b3d-81df-48ea221524c0\\\", \\\"stack\\\": [{\\\"path\\\": \\\"app\\\", \\\"method\\\": {\\\"obj\\\": {\\\"cls\\\": {\\\"name\\\": \\\"RetrieverQueryEngine\\\", \\\"module\\\": {\\\"package_name\\\": \\\"llama_index.core.query_engine\\\", \\\"module_name\\\": \\\"llama_index.core.query_engine.retriever_query_engine\\\"}, \\\"bases\\\": null}, \\\"id\\\": 139578195407392, \\\"init_bindings\\\": null}, \\\"name\\\": \\\"query\\\"}}, {\\\"path\\\": \\\"app\\\", \\\"method\\\": {\\\"obj\\\": {\\\"cls\\\": {\\\"name\\\": \\\"RetrieverQueryEngine\\\", \\\"module\\\": {\\\"package_name\\\": \\\"llama_index.core.query_engine\\\", \\\"module_name\\\": \\\"llama_index.core.query_engine.retriever_query_engine\\\"}, \\\"bases\\\": null}, \\\"id\\\": 139578195407392, \\\"init_bindings\\\": null}, \\\"name\\\": \\\"retrieve\\\"}}], \\\"args\\\": {\\\"query_bundle\\\": {\\\"query_str\\\": \\\"What is imposter syndrome and how does it relate to AI?\\\", \\\"image_path\\\": null, \\\"custom_embedding_strs\\\": null, \\\"embedding\\\": [-0.022138359025120735, 0.06330832839012146, -0.02178497612476349, 0.05808620527386665, -0.011336613446474075, -0.005612774286419153, 0.08911127597093582, 0.0030356543138623238, 0.05779843404889107, -0.0158709604293108, 0.043755464255809784, -0.04610735550522804, 0.041546400636434555, 0.04221899434924126, 0.010080059058964252, -0.007372432854026556, -0.012149561196565628, 0.010139614343643188, 0.023927219212055206, 0.0618598572909832, 0.002753077307716012, -0.02734963782131672, -0.026586217805743217, -0.05804353952407837, -0.05689089372754097, 0.025389932096004486, -0.02710329182446003, -0.030684951692819595, -0.06962019205093384, -0.12699782848358154, 0.010024623945355415, -0.030747653916478157, 0.07036616653203964, 0.03634142503142357, 0.023763809353113174, -0.029446573927998543, -0.06237635761499405, 0.028677452355623245, -0.0026431584265083075, -0.03701413795351982, -0.03109831176698208, -0.03169137239456177, 0.008376998826861382, -0.024873236194252968, 0.023566365242004395, 0.03139616549015045, -0.04141063243150711, 0.02061697654426098, -0.01121605560183525, -0.04815472289919853, -0.05840567871928215, -0.03434079512953758, -0.022948548197746277, 0.09036225080490112, -0.01924021728336811, 0.04285462573170662, 0.05470186471939087, 0.08362477272748947, -0.01492794044315815, 0.024841615930199623, 0.020555971190333366, 0.020025992766022682, -0.07407246530056, 0.10731633007526398, 0.0870477482676506, 0.021047256886959076, -0.04459372162818909, -0.06212715432047844, 0.00605186028406024, 0.0052450052462518215, -0.012020755559206009, -0.004519903101027012, -0.03384644165635109, 0.038123901933431625, 0.019433651119470596, 0.03789782151579857, 0.021288715302944183, 0.017243824899196625, 0.07020135968923569, 0.014117566868662834, 0.06357898563146591, -0.0064677344635128975, -0.05849508196115494, -0.019088268280029297, 0.01027615461498499, 0.0035970446188002825, 0.025662222877144814, -0.07794789224863052, 0.03695748373866081, -0.027840768918395042, -0.03499165177345276, -0.051770541816949844, 0.010811539366841316, 0.05399427190423012, 0.018361764028668404, -0.0067157866433262825, -0.03730263188481331, 0.0222349651157856, -0.07656251639127731, 0.33013853430747986, 0.029236525297164917, 0.001514303032308817, 0.06218745931982994, 0.0015199027257040143, -0.026270747184753418, -0.04608375206589699, 0.024223893880844116, 0.010248078033328056, -0.0752921774983406, 0.003555088071152568, -0.016446763649582863, -0.06423038989305496, 0.06408217549324036, 0.0414954274892807, 0.041121531277894974, -0.0035458658821880817, 0.06343093514442444, 0.03869159147143364, 0.031063418835401535, -0.007991282269358635, 0.0008135174284689128, 0.01949228160083294, -0.0003326743026264012, -0.002367552602663636, -0.06658053398132324, -0.027151096612215042, -0.04922632873058319, 0.08483787626028061, -0.056617144495248795, -0.08511564135551453, -0.0004727170744445175, 0.01962371915578842, -0.00859463308006525, -0.003877201583236456, 0.017960334196686745, 0.003219116711989045, -0.022798413410782814, -0.01940670982003212, 0.0073257810436189175, 0.03914864733815193, -0.038353364914655685, 0.04747907817363739, 0.01919323392212391, 0.04102756083011627, -0.028257502242922783, 0.03738253191113472, 0.015703555196523666, -0.01299336925148964, -0.020075581967830658, 0.019566604867577553, -0.021392663940787315, 0.00201755971647799, -0.09726795554161072, -0.07456518709659576, -0.0028769648633897305, -0.01575549691915512, 0.03440897911787033, -0.07228709012269974, -0.06267200410366058, -0.014082793146371841, -0.01460484229028225, -0.048231251537799835, -0.06281588226556778, 0.12147489190101624, 0.0880126878619194, -0.0606771782040596, -0.004004522692412138, -0.01554181706160307, -0.009473884478211403, 0.03531463071703911, 0.006306394003331661, -0.01354927383363247, -0.05453085899353027, 0.037171926349401474, 0.000934939191211015, -0.013814262114465237, -0.013664710335433483, 0.04010280966758728, -0.05416380241513252, 0.044868458062410355, 0.04724569991230965, -0.07873328030109406, -0.027704548090696335, 0.013921757228672504, 0.02553793415427208, -0.03706158697605133, -0.02916598878800869, -0.09766733646392822, 0.01947626657783985, -0.062387917190790176, -0.02831646427512169, 0.0067457156255841255, -0.08460460603237152, -0.0995142012834549, -0.016054866835474968, 0.028088662773370743, 0.057485997676849365, 0.0521850660443306, -0.018348874524235725, -0.029311131685972214, -0.02895592711865902, 0.05319276824593544, -0.024413008242845535, -0.046930667012929916, 0.01818789541721344, 0.03198171406984329, 0.01940084993839264, -0.01176284346729517, 0.05157820135354996, -0.01415332779288292, -0.014676016755402088, -0.017274275422096252, -0.015991754829883575, 0.003083337564021349, 0.010715456679463387, 0.026804542168974876, -0.033605191856622696, 0.0004534107865765691, -0.008858396671712399, -0.00928028579801321, -0.03359676152467728, -0.018838297575712204, -0.02760949172079563, -0.2535814344882965, -0.024165062233805656, -0.047418661415576935, -0.0125493835657835, -0.017373809590935707, -0.0388382151722908, -0.014610538259148598, 0.01423417218029499, 0.07930915057659149, 0.022359449416399002, 0.04189227148890495, 0.01480313390493393, -0.002080738777294755, 0.011763034388422966, -0.032442767173051834, 0.0392119437456131, 0.010166135616600513, 0.011189146898686886, -0.017394162714481354, -0.003022517077624798, -0.01676912046968937, 0.03419334068894386, 0.10458780080080032, -0.04781974479556084, -0.015625057741999626, 0.01153029315173626, 0.10123319178819656, 0.04090040549635887, 0.009774606674909592, 0.0324629470705986, -0.04235512763261795, 0.04105967655777931, 0.010661550797522068, -0.0838533565402031, 0.06761231273412704, -0.04992065951228142, 0.022016694769263268, -0.05823857709765434, -0.008222787640988827, 0.0035545474383980036, -0.10693804174661636, -0.005694338586181402, -0.005299585871398449, 0.0673288032412529, -0.059233054518699646, 0.07467004656791687, -0.016623474657535553, 0.04976487159729004, -0.028513558208942413, 0.1201036348938942, 0.0018306572455912828, -0.01473167259246111, -0.013808755204081535, 0.004389430396258831, -0.033403754234313965, -0.03186212480068207, -0.05654558911919594, -0.008508232422173023, -0.02997291274368763, -0.004388116300106049, 0.06433824449777603, 0.009878674522042274, -0.08721302449703217, -0.027398761361837387, 0.06771067529916763, 0.05710263177752495, -0.027601609006524086, 0.07307715713977814, 0.037535134702920914, 0.017999472096562386, -0.018361102789640427, 0.16629864275455475, -0.009966438636183739, -0.0064811911433935165, 0.0781630277633667, -0.02347560226917267, 0.007282616570591927, -0.07585280388593674, -0.020620226860046387, 0.055917929857969284, 0.03128000721335411, -0.016443993896245956, -0.013930227607488632, 0.03947686776518822, 0.020100127905607224, -0.014808209612965584, -0.0239152442663908, 0.004243770614266396, 0.10904030501842499, 0.056635886430740356, 0.017087917774915695, 0.08328763395547867, -0.0700441300868988, 0.0038121063262224197, 0.06441731750965118, -0.0031983586959540844, -0.2774692475795746, 0.016640212386846542, -0.03143422678112984, 0.047859594225883484, -0.0389234721660614, -0.0355895459651947, -0.012750927358865738, -0.04677576571702957, 0.014222712256014347, -0.07082463055849075, 0.0018205910455435514, -0.026118719950318336, -0.009636041708290577, 0.010927175171673298, -0.05170474946498871, 0.06983324885368347, 0.031764063984155655, -0.09643185138702393, -0.0271859560161829, -0.03655780479311943, -0.06585772335529327, 0.08345794677734375, 0.17869196832180023, 0.02623196318745613, -0.026039371266961098, -0.03584732115268707, 0.012415585108101368, 0.027818916365504265, 0.012372701428830624, -0.031115634366869926, 0.01597813330590725, -0.058284368366003036, 0.031048815697431564, -0.014511380344629288, 0.036379989236593246, 0.040107112377882004, -0.03885844349861145, 0.0642148107290268, 0.04553288221359253, -0.0032139429822564125, 0.0037294321227818727, 0.021384475752711296, 0.016061721369624138, 0.023716846480965614, 0.08300896733999252, 0.011103902943432331, 0.005610782187432051, 0.006257719360291958, -0.003271617693826556, 0.0017353056464344263, 0.004048414062708616, -0.03889920189976692, 0.0015362442936748266, -0.04101455211639404, 0.03691445663571358, 0.014115508645772934, -0.007408578880131245, -0.039914242923259735, 0.008639845997095108, -0.02662782184779644, -0.03573709353804588, 0.04430992156267166, 0.07191050797700882, 0.0472828708589077, -0.03748752549290657]}}, \\\"rets\\\": [{\\\"node\\\": {\\\"id_\\\": \\\"27cbf0f6-24f8-4d0f-b8d2-e9e7755b6538\\\", \\\"embedding\\\": null, \\\"metadata\\\": {\\\"page_label\\\": \\\"38\\\", \\\"file_name\\\": \\\"eBook-How-to-Build-a-Career-in-AI.pdf\\\", \\\"file_path\\\": \\\"eBook-How-to-Build-a-Career-in-AI.pdf\\\", \\\"file_type\\\": \\\"application/pdf\\\", \\\"file_size\\\": 3717673, \\\"creation_date\\\": \\\"2024-06-02\\\", \\\"last_modified_date\\\": \\\"2022-12-13\\\"}, \\\"excluded_embed_metadata_keys\\\": [\\\"file_name\\\", \\\"file_type\\\", \\\"file_size\\\", \\\"creation_date\\\", \\\"last_modified_date\\\", \\\"last_accessed_date\\\"], \\\"excluded_llm_metadata_keys\\\": [\\\"file_name\\\", \\\"file_type\\\", \\\"file_size\\\", \\\"creation_date\\\", \\\"last_modified_date\\\", \\\"last_accessed_date\\\"], \\\"relationships\\\": {\\\"1\\\": {\\\"node_id\\\": \\\"fc5ef969-90e7-4519-afc8-8fbed7897822\\\", \\\"node_type\\\": \\\"4\\\", \\\"metadata\\\": {\\\"page_label\\\": \\\"38\\\", \\\"file_name\\\": \\\"eBook-How-to-Build-a-Career-in-AI.pdf\\\", \\\"file_path\\\": \\\"eBook-How-to-Build-a-Career-in-AI.pdf\\\", \\\"file_type\\\": \\\"application/pdf\\\", \\\"file_size\\\": 3717673, \\\"creation_date\\\": \\\"2024-06-02\\\", \\\"last_modified_date\\\": \\\"2022-12-13\\\"}, \\\"hash\\\": \\\"8015b3d10bb297d165d3c19ad5322426807b464384d1e8ac1f2ebecd22daab11\\\"}}, \\\"text\\\": \\\"PAGE 38Before we dive into the final chapter of this book, I\\\\u2019d like to address the serious matter of \\\\nnewcomers to AI sometimes experiencing imposter syndrome, where someone \\\\u2014 regardless \\\\nof their success in the field \\\\u2014 wonders if they\\\\u2019re a fraud and really belong in the AI community. \\\\nI want to make sure this doesn\\\\u2019t discourage you or anyone else from growing in AI.\\\\nAn estimated 70 percent of people experience some form of imposter syndrome at some point. \\\\nMany talented people have spoken publicly about this experience, including former Facebook \\\\nCOO Sheryl Sandberg, U.S. first lady Michelle Obama, actor Tom Hanks, and Atlassian co-CEO \\\\nMike Cannon-Brookes. It happens in our community even among accomplished people. If you\\\\u2019ve \\\\nnever experienced this yourself, that\\\\u2019s great! I hope you\\\\u2019ll join me in encouraging and welcoming \\\\neveryone who wants to join our community.\\\\nAI is technically complex, and it has its fair share of smart and highly capable people. But it is \\\\neasy to forget that to become good at anything, the first step is to suck at it. If you\\\\u2019ve succeeded \\\\nat sucking at AI \\\\u2014 congratulations, you\\\\u2019re on your way!\\\\nI once struggled to understand the math behind linear regression. I was mystified when \\\\nlogistic regression performed strangely on my data, and it took me days to find a bug in my \\\\nimplementation of a basic neural network. Today, I still find many research papers challenging \\\\nto read, and I recently made an obvious mistake while tuning a neural network hyperparameter \\\\n(that fortunately a fellow engineer caught and fixed).\\\\nSo if you, too, find parts of AI challenging, it\\\\u2019s okay. We\\\\u2019ve all been there. I guarantee that everyone \\\\nwho has published a seminal AI paper struggled with similar technical challenges at some point.Let me be clear: If you want to be part of the AI \\\\ncommunity, then I welcome you with open arms. \\\\nIf you want to join us, you fully belong with us!Overcoming Imposter Syndrome\\\", \\\"start_char_idx\\\": 0, \\\"end_char_idx\\\": 1939, \\\"text_template\\\": \\\"{metadata_str}\\\\n\\\\n{content}\\\", \\\"metadata_template\\\": \\\"{key}: {value}\\\", \\\"metadata_seperator\\\": \\\"\\\\n\\\"}, \\\"score\\\": 0.8139902349518466}, {\\\"node\\\": {\\\"id_\\\": \\\"fcd8731f-ebd5-40af-be7a-6813e8b7645d\\\", \\\"embedding\\\": null, \\\"metadata\\\": {\\\"page_label\\\": \\\"37\\\", \\\"file_name\\\": \\\"eBook-How-to-Build-a-Career-in-AI.pdf\\\", \\\"file_path\\\": \\\"eBook-How-to-Build-a-Career-in-AI.pdf\\\", \\\"file_type\\\": \\\"application/pdf\\\", \\\"file_size\\\": 3717673, \\\"creation_date\\\": \\\"2024-06-02\\\", \\\"last_modified_date\\\": \\\"2022-12-13\\\"}, \\\"excluded_embed_metadata_keys\\\": [\\\"file_name\\\", \\\"file_type\\\", \\\"file_size\\\", \\\"creation_date\\\", \\\"last_modified_date\\\", \\\"last_accessed_date\\\"], \\\"excluded_llm_metadata_keys\\\": [\\\"file_name\\\", \\\"file_type\\\", \\\"file_size\\\", \\\"creation_date\\\", \\\"last_modified_date\\\", \\\"last_accessed_date\\\"], \\\"relationships\\\": {\\\"1\\\": {\\\"node_id\\\": \\\"771a3bb1-2b43-43f1-bb7e-1b16e94896e6\\\", \\\"node_type\\\": \\\"4\\\", \\\"metadata\\\": {\\\"page_label\\\": \\\"37\\\", \\\"file_name\\\": \\\"eBook-How-to-Build-a-Career-in-AI.pdf\\\", \\\"file_path\\\": \\\"eBook-How-to-Build-a-Career-in-AI.pdf\\\", \\\"file_type\\\": \\\"application/pdf\\\", \\\"file_size\\\": 3717673, \\\"creation_date\\\": \\\"2024-06-02\\\", \\\"last_modified_date\\\": \\\"2022-12-13\\\"}, \\\"hash\\\": \\\"293bf847843cd20f676eeffac711e0db3bde1207bf6eda80f52530f8692b41c5\\\"}}, \\\"text\\\": \\\"PAGE 37Overcoming Imposter \\\\nSyndromeCHAPTER 11\\\", \\\"start_char_idx\\\": 0, \\\"end_char_idx\\\": 46, \\\"text_template\\\": \\\"{metadata_str}\\\\n\\\\n{content}\\\", \\\"metadata_template\\\": \\\"{key}: {value}\\\", \\\"metadata_seperator\\\": \\\"\\\\n\\\"}, \\\"score\\\": 0.740083412837171}], \\\"error\\\": null, \\\"perf\\\": {\\\"start_time\\\": \\\"2024-06-02T20:58:10.593917\\\", \\\"end_time\\\": \\\"2024-06-02T20:58:11.077978\\\"}, \\\"pid\\\": 17076, \\\"tid\\\": 17076}, {\\\"call_id\\\": \\\"12742b59-0338-4fe0-abd5-9ea551f0e6dc\\\", \\\"stack\\\": [{\\\"path\\\": \\\"app\\\", \\\"method\\\": {\\\"obj\\\": {\\\"cls\\\": {\\\"name\\\": \\\"RetrieverQueryEngine\\\", \\\"module\\\": {\\\"package_name\\\": \\\"llama_index.core.query_engine\\\", \\\"module_name\\\": \\\"llama_index.core.query_engine.retriever_query_engine\\\"}, \\\"bases\\\": null}, \\\"id\\\": 139578195407392, \\\"init_bindings\\\": null}, \\\"name\\\": \\\"query\\\"}}, {\\\"path\\\": \\\"app._response_synthesizer\\\", \\\"method\\\": {\\\"obj\\\": {\\\"cls\\\": {\\\"name\\\": \\\"CompactAndRefine\\\", \\\"module\\\": {\\\"package_name\\\": \\\"llama_index.core.response_synthesizers\\\", \\\"module_name\\\": \\\"llama_index.core.response_synthesizers.compact_and_refine\\\"}, \\\"bases\\\": null}, \\\"id\\\": 139578195410176, \\\"init_bindings\\\": null}, \\\"name\\\": \\\"get_response\\\"}}, {\\\"path\\\": \\\"app._response_synthesizer\\\", \\\"method\\\": {\\\"obj\\\": {\\\"cls\\\": {\\\"name\\\": \\\"Refine\\\", \\\"module\\\": {\\\"package_name\\\": \\\"llama_index.core.response_synthesizers\\\", \\\"module_name\\\": \\\"llama_index.core.response_synthesizers.refine\\\"}, \\\"bases\\\": null}, \\\"id\\\": 139578195410176, \\\"init_bindings\\\": null}, \\\"name\\\": \\\"get_response\\\"}}, {\\\"path\\\": \\\"app._response_synthesizer._llm\\\", \\\"method\\\": {\\\"obj\\\": {\\\"cls\\\": {\\\"name\\\": \\\"OpenAI\\\", \\\"module\\\": {\\\"package_name\\\": \\\"llama_index.llms.openai\\\", \\\"module_name\\\": \\\"llama_index.llms.openai.base\\\"}, \\\"bases\\\": null}, \\\"id\\\": 139578319484000, \\\"init_bindings\\\": null}, \\\"name\\\": \\\"chat\\\"}}], \\\"args\\\": {\\\"_self\\\": {\\\"callback_manager\\\": {\\\"__tru_non_serialized_object\\\": {\\\"cls\\\": {\\\"name\\\": \\\"CallbackManager\\\", \\\"module\\\": {\\\"package_name\\\": \\\"llama_index.core.callbacks\\\", \\\"module_name\\\": \\\"llama_index.core.callbacks.base\\\"}, \\\"bases\\\": null}, \\\"id\\\": 139578836106016, \\\"init_bindings\\\": null}}, \\\"system_prompt\\\": null, \\\"messages_to_prompt\\\": {\\\"__tru_non_serialized_object\\\": {\\\"cls\\\": {\\\"name\\\": \\\"function\\\", \\\"module\\\": {\\\"package_name\\\": \\\"\\\", \\\"module_name\\\": \\\"builtins\\\"}, \\\"bases\\\": null}, \\\"id\\\": 139581828912832, \\\"init_bindings\\\": null}}, \\\"completion_to_prompt\\\": {\\\"__tru_non_serialized_object\\\": {\\\"cls\\\": {\\\"name\\\": \\\"function\\\", \\\"module\\\": {\\\"package_name\\\": \\\"\\\", \\\"module_name\\\": \\\"builtins\\\"}, \\\"bases\\\": null}, \\\"id\\\": 139581829634304, \\\"init_bindings\\\": null}}, \\\"output_parser\\\": null, \\\"pydantic_program_mode\\\": \\\"default\\\", \\\"query_wrapper_prompt\\\": null, \\\"model\\\": \\\"gpt-3.5-turbo\\\", \\\"temperature\\\": 0.1, \\\"max_tokens\\\": null, \\\"logprobs\\\": null, \\\"top_logprobs\\\": 0, \\\"additional_kwargs\\\": {}, \\\"max_retries\\\": 3, \\\"timeout\\\": 60.0, \\\"default_headers\\\": null, \\\"reuse_client\\\": true, \\\"api_key\\\": \\\"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\\\", \\\"api_base\\\": \\\"https://api.openai.com/v1\\\", \\\"api_version\\\": \\\"\\\"}, \\\"messages\\\": [{\\\"role\\\": \\\"system\\\", \\\"content\\\": \\\"You are an expert Q&A system that is trusted around the world.\\\\nAlways answer the query using the provided context information, and not prior knowledge.\\\\nSome rules to follow:\\\\n1. Never directly reference the given context in your answer.\\\\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\\\", \\\"additional_kwargs\\\": {}}, {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"Context information is below.\\\\n---------------------\\\\npage_label: 38\\\\nfile_path: eBook-How-to-Build-a-Career-in-AI.pdf\\\\n\\\\nPAGE 38Before we dive into the final chapter of this book, I\\\\u2019d like to address the serious matter of \\\\nnewcomers to AI sometimes experiencing imposter syndrome, where someone \\\\u2014 regardless \\\\nof their success in the field \\\\u2014 wonders if they\\\\u2019re a fraud and really belong in the AI community. \\\\nI want to make sure this doesn\\\\u2019t discourage you or anyone else from growing in AI.\\\\nAn estimated 70 percent of people experience some form of imposter syndrome at some point. \\\\nMany talented people have spoken publicly about this experience, including former Facebook \\\\nCOO Sheryl Sandberg, U.S. first lady Michelle Obama, actor Tom Hanks, and Atlassian co-CEO \\\\nMike Cannon-Brookes. It happens in our community even among accomplished people. If you\\\\u2019ve \\\\nnever experienced this yourself, that\\\\u2019s great! I hope you\\\\u2019ll join me in encouraging and welcoming \\\\neveryone who wants to join our community.\\\\nAI is technically complex, and it has its fair share of smart and highly capable people. But it is \\\\neasy to forget that to become good at anything, the first step is to suck at it. If you\\\\u2019ve succeeded \\\\nat sucking at AI \\\\u2014 congratulations, you\\\\u2019re on your way!\\\\nI once struggled to understand the math behind linear regression. I was mystified when \\\\nlogistic regression performed strangely on my data, and it took me days to find a bug in my \\\\nimplementation of a basic neural network. Today, I still find many research papers challenging \\\\nto read, and I recently made an obvious mistake while tuning a neural network hyperparameter \\\\n(that fortunately a fellow engineer caught and fixed).\\\\nSo if you, too, find parts of AI challenging, it\\\\u2019s okay. We\\\\u2019ve all been there. I guarantee that everyone \\\\nwho has published a seminal AI paper struggled with similar technical challenges at some point.Let me be clear: If you want to be part of the AI \\\\ncommunity, then I welcome you with open arms. \\\\nIf you want to join us, you fully belong with us!Overcoming Imposter Syndrome\\\\n\\\\npage_label: 37\\\\nfile_path: eBook-How-to-Build-a-Career-in-AI.pdf\\\\n\\\\nPAGE 37Overcoming Imposter \\\\nSyndromeCHAPTER 11\\\\n---------------------\\\\nGiven the context information and not prior knowledge, answer the query.\\\\nQuery: What is imposter syndrome and how does it relate to AI?\\\\nAnswer: \\\", \\\"additional_kwargs\\\": {}}]}, \\\"rets\\\": {\\\"message\\\": {\\\"role\\\": \\\"assistant\\\", \\\"content\\\": \\\"Imposter syndrome is when an individual doubts their accomplishments and has a persistent fear of being exposed as a fraud, despite evidence of their competence. In the field of AI, newcomers may experience imposter syndrome due to the technical complexity and the presence of highly capable individuals. It is common for individuals in the AI community, regardless of their success, to question their abilities and feel like they do not belong. However, it is emphasized that experiencing challenges and setbacks is a normal part of the learning process in AI, and it should not deter anyone from pursuing a career in the field.\\\", \\\"additional_kwargs\\\": {}}, \\\"raw\\\": {\\\"id\\\": \\\"chatcmpl-9VmZHUKT8T1hEerJhHnoQXL2uoBaD\\\", \\\"choices\\\": [{\\\"finish_reason\\\": \\\"stop\\\", \\\"index\\\": 0, \\\"logprobs\\\": null, \\\"message\\\": {\\\"content\\\": \\\"Imposter syndrome is when an individual doubts their accomplishments and has a persistent fear of being exposed as a fraud, despite evidence of their competence. In the field of AI, newcomers may experience imposter syndrome due to the technical complexity and the presence of highly capable individuals. It is common for individuals in the AI community, regardless of their success, to question their abilities and feel like they do not belong. However, it is emphasized that experiencing challenges and setbacks is a normal part of the learning process in AI, and it should not deter anyone from pursuing a career in the field.\\\", \\\"role\\\": \\\"assistant\\\", \\\"function_call\\\": null, \\\"tool_calls\\\": null}}], \\\"created\\\": 1717361891, \\\"model\\\": \\\"gpt-3.5-turbo-0125\\\", \\\"object\\\": \\\"chat.completion\\\", \\\"system_fingerprint\\\": null, \\\"usage\\\": {\\\"completion_tokens\\\": 115, \\\"prompt_tokens\\\": 603, \\\"total_tokens\\\": 718}}, \\\"delta\\\": null, \\\"logprobs\\\": null, \\\"additional_kwargs\\\": {}}, \\\"error\\\": null, \\\"perf\\\": {\\\"start_time\\\": \\\"2024-06-02T20:58:11.548784\\\", \\\"end_time\\\": \\\"2024-06-02T20:58:13.810461\\\"}, \\\"pid\\\": 17076, \\\"tid\\\": 17076}, {\\\"call_id\\\": \\\"0e2a0932-f980-47be-bc98-1b791e5ce7b8\\\", \\\"stack\\\": [{\\\"path\\\": \\\"app\\\", \\\"method\\\": {\\\"obj\\\": {\\\"cls\\\": {\\\"name\\\": \\\"RetrieverQueryEngine\\\", \\\"module\\\": {\\\"package_name\\\": \\\"llama_index.core.query_engine\\\", \\\"module_name\\\": \\\"llama_index.core.query_engine.retriever_query_engine\\\"}, \\\"bases\\\": null}, \\\"id\\\": 139578195407392, \\\"init_bindings\\\": null}, \\\"name\\\": \\\"query\\\"}}, {\\\"path\\\": \\\"app._response_synthesizer\\\", \\\"method\\\": {\\\"obj\\\": {\\\"cls\\\": {\\\"name\\\": \\\"CompactAndRefine\\\", \\\"module\\\": {\\\"package_name\\\": \\\"llama_index.core.response_synthesizers\\\", \\\"module_name\\\": \\\"llama_index.core.response_synthesizers.compact_and_refine\\\"}, \\\"bases\\\": null}, \\\"id\\\": 139578195410176, \\\"init_bindings\\\": null}, \\\"name\\\": \\\"get_response\\\"}}, {\\\"path\\\": \\\"app._response_synthesizer\\\", \\\"method\\\": {\\\"obj\\\": {\\\"cls\\\": {\\\"name\\\": \\\"Refine\\\", \\\"module\\\": {\\\"package_name\\\": \\\"llama_index.core.response_synthesizers\\\", \\\"module_name\\\": \\\"llama_index.core.response_synthesizers.refine\\\"}, \\\"bases\\\": null}, \\\"id\\\": 139578195410176, \\\"init_bindings\\\": null}, \\\"name\\\": \\\"get_response\\\"}}], \\\"args\\\": {\\\"query_str\\\": \\\"What is imposter syndrome and how does it relate to AI?\\\", \\\"text_chunks\\\": [\\\"page_label: 38\\\\nfile_path: eBook-How-to-Build-a-Career-in-AI.pdf\\\\n\\\\nPAGE 38Before we dive into the final chapter of this book, I\\\\u2019d like to address the serious matter of \\\\nnewcomers to AI sometimes experiencing imposter syndrome, where someone \\\\u2014 regardless \\\\nof their success in the field \\\\u2014 wonders if they\\\\u2019re a fraud and really belong in the AI community. \\\\nI want to make sure this doesn\\\\u2019t discourage you or anyone else from growing in AI.\\\\nAn estimated 70 percent of people experience some form of imposter syndrome at some point. \\\\nMany talented people have spoken publicly about this experience, including former Facebook \\\\nCOO Sheryl Sandberg, U.S. first lady Michelle Obama, actor Tom Hanks, and Atlassian co-CEO \\\\nMike Cannon-Brookes. It happens in our community even among accomplished people. If you\\\\u2019ve \\\\nnever experienced this yourself, that\\\\u2019s great! I hope you\\\\u2019ll join me in encouraging and welcoming \\\\neveryone who wants to join our community.\\\\nAI is technically complex, and it has its fair share of smart and highly capable people. But it is \\\\neasy to forget that to become good at anything, the first step is to suck at it. If you\\\\u2019ve succeeded \\\\nat sucking at AI \\\\u2014 congratulations, you\\\\u2019re on your way!\\\\nI once struggled to understand the math behind linear regression. I was mystified when \\\\nlogistic regression performed strangely on my data, and it took me days to find a bug in my \\\\nimplementation of a basic neural network. Today, I still find many research papers challenging \\\\nto read, and I recently made an obvious mistake while tuning a neural network hyperparameter \\\\n(that fortunately a fellow engineer caught and fixed).\\\\nSo if you, too, find parts of AI challenging, it\\\\u2019s okay. We\\\\u2019ve all been there. I guarantee that everyone \\\\nwho has published a seminal AI paper struggled with similar technical challenges at some point.Let me be clear: If you want to be part of the AI \\\\ncommunity, then I welcome you with open arms. \\\\nIf you want to join us, you fully belong with us!Overcoming Imposter Syndrome\\\\n\\\\npage_label: 37\\\\nfile_path: eBook-How-to-Build-a-Career-in-AI.pdf\\\\n\\\\nPAGE 37Overcoming Imposter \\\\nSyndromeCHAPTER 11\\\"], \\\"prev_response\\\": null}, \\\"rets\\\": \\\"Imposter syndrome is when an individual doubts their accomplishments and has a persistent fear of being exposed as a fraud, despite evidence of their competence. In the field of AI, newcomers may experience imposter syndrome due to the technical complexity and the presence of highly capable individuals. It is common for individuals in the AI community, regardless of their success, to question their abilities and feel like they do not belong. However, it is emphasized that experiencing challenges and setbacks is a normal part of the learning process in AI, and it should not deter anyone from pursuing a career in the field.\\\", \\\"error\\\": null, \\\"perf\\\": {\\\"start_time\\\": \\\"2024-06-02T20:58:11.362133\\\", \\\"end_time\\\": \\\"2024-06-02T20:58:13.811928\\\"}, \\\"pid\\\": 17076, \\\"tid\\\": 17076}, {\\\"call_id\\\": \\\"393f534a-41bd-4dca-b4d7-138273d6c22b\\\", \\\"stack\\\": [{\\\"path\\\": \\\"app\\\", \\\"method\\\": {\\\"obj\\\": {\\\"cls\\\": {\\\"name\\\": \\\"RetrieverQueryEngine\\\", \\\"module\\\": {\\\"package_name\\\": \\\"llama_index.core.query_engine\\\", \\\"module_name\\\": \\\"llama_index.core.query_engine.retriever_query_engine\\\"}, \\\"bases\\\": null}, \\\"id\\\": 139578195407392, \\\"init_bindings\\\": null}, \\\"name\\\": \\\"query\\\"}}, {\\\"path\\\": \\\"app._response_synthesizer\\\", \\\"method\\\": {\\\"obj\\\": {\\\"cls\\\": {\\\"name\\\": \\\"CompactAndRefine\\\", \\\"module\\\": {\\\"package_name\\\": \\\"llama_index.core.response_synthesizers\\\", \\\"module_name\\\": \\\"llama_index.core.response_synthesizers.compact_and_refine\\\"}, \\\"bases\\\": null}, \\\"id\\\": 139578195410176, \\\"init_bindings\\\": null}, \\\"name\\\": \\\"get_response\\\"}}], \\\"args\\\": {\\\"query_str\\\": \\\"What is imposter syndrome and how does it relate to AI?\\\", \\\"text_chunks\\\": [\\\"page_label: 38\\\\nfile_path: eBook-How-to-Build-a-Career-in-AI.pdf\\\\n\\\\nPAGE 38Before we dive into the final chapter of this book, I\\\\u2019d like to address the serious matter of \\\\nnewcomers to AI sometimes experiencing imposter syndrome, where someone \\\\u2014 regardless \\\\nof their success in the field \\\\u2014 wonders if they\\\\u2019re a fraud and really belong in the AI community. \\\\nI want to make sure this doesn\\\\u2019t discourage you or anyone else from growing in AI.\\\\nAn estimated 70 percent of people experience some form of imposter syndrome at some point. \\\\nMany talented people have spoken publicly about this experience, including former Facebook \\\\nCOO Sheryl Sandberg, U.S. first lady Michelle Obama, actor Tom Hanks, and Atlassian co-CEO \\\\nMike Cannon-Brookes. It happens in our community even among accomplished people. If you\\\\u2019ve \\\\nnever experienced this yourself, that\\\\u2019s great! I hope you\\\\u2019ll join me in encouraging and welcoming \\\\neveryone who wants to join our community.\\\\nAI is technically complex, and it has its fair share of smart and highly capable people. But it is \\\\neasy to forget that to become good at anything, the first step is to suck at it. If you\\\\u2019ve succeeded \\\\nat sucking at AI \\\\u2014 congratulations, you\\\\u2019re on your way!\\\\nI once struggled to understand the math behind linear regression. I was mystified when \\\\nlogistic regression performed strangely on my data, and it took me days to find a bug in my \\\\nimplementation of a basic neural network. Today, I still find many research papers challenging \\\\nto read, and I recently made an obvious mistake while tuning a neural network hyperparameter \\\\n(that fortunately a fellow engineer caught and fixed).\\\\nSo if you, too, find parts of AI challenging, it\\\\u2019s okay. We\\\\u2019ve all been there. I guarantee that everyone \\\\nwho has published a seminal AI paper struggled with similar technical challenges at some point.Let me be clear: If you want to be part of the AI \\\\ncommunity, then I welcome you with open arms. \\\\nIf you want to join us, you fully belong with us!Overcoming Imposter Syndrome\\\", \\\"page_label: 37\\\\nfile_path: eBook-How-to-Build-a-Career-in-AI.pdf\\\\n\\\\nPAGE 37Overcoming Imposter \\\\nSyndromeCHAPTER 11\\\"]}, \\\"rets\\\": \\\"Imposter syndrome is when an individual doubts their accomplishments and has a persistent fear of being exposed as a fraud, despite evidence of their competence. In the field of AI, newcomers may experience imposter syndrome due to the technical complexity and the presence of highly capable individuals. It is common for individuals in the AI community, regardless of their success, to question their abilities and feel like they do not belong. However, it is emphasized that experiencing challenges and setbacks is a normal part of the learning process in AI, and it should not deter anyone from pursuing a career in the field.\\\", \\\"error\\\": null, \\\"perf\\\": {\\\"start_time\\\": \\\"2024-06-02T20:58:11.170025\\\", \\\"end_time\\\": \\\"2024-06-02T20:58:13.812052\\\"}, \\\"pid\\\": 17076, \\\"tid\\\": 17076}, {\\\"call_id\\\": \\\"04759190-64c8-4b1e-bc7d-973f3886d4c0\\\", \\\"stack\\\": [{\\\"path\\\": \\\"app\\\", \\\"method\\\": {\\\"obj\\\": {\\\"cls\\\": {\\\"name\\\": \\\"RetrieverQueryEngine\\\", \\\"module\\\": {\\\"package_name\\\": \\\"llama_index.core.query_engine\\\", \\\"module_name\\\": \\\"llama_index.core.query_engine.retriever_query_engine\\\"}, \\\"bases\\\": null}, \\\"id\\\": 139578195407392, \\\"init_bindings\\\": null}, \\\"name\\\": \\\"query\\\"}}], \\\"args\\\": {\\\"str_or_query_bundle\\\": \\\"What is imposter syndrome and how does it relate to AI?\\\"}, \\\"rets\\\": {\\\"response\\\": \\\"Imposter syndrome is when an individual doubts their accomplishments and has a persistent fear of being exposed as a fraud, despite evidence of their competence. In the field of AI, newcomers may experience imposter syndrome due to the technical complexity and the presence of highly capable individuals. It is common for individuals in the AI community, regardless of their success, to question their abilities and feel like they do not belong. However, it is emphasized that experiencing challenges and setbacks is a normal part of the learning process in AI, and it should not deter anyone from pursuing a career in the field.\\\", \\\"source_nodes\\\": [{\\\"node\\\": {\\\"id_\\\": \\\"27cbf0f6-24f8-4d0f-b8d2-e9e7755b6538\\\", \\\"embedding\\\": null, \\\"metadata\\\": {\\\"page_label\\\": \\\"38\\\", \\\"file_name\\\": \\\"eBook-How-to-Build-a-Career-in-AI.pdf\\\", \\\"file_path\\\": \\\"eBook-How-to-Build-a-Career-in-AI.pdf\\\", \\\"file_type\\\": \\\"application/pdf\\\", \\\"file_size\\\": 3717673, \\\"creation_date\\\": \\\"2024-06-02\\\", \\\"last_modified_date\\\": \\\"2022-12-13\\\"}, \\\"excluded_embed_metadata_keys\\\": [\\\"file_name\\\", \\\"file_type\\\", \\\"file_size\\\", \\\"creation_date\\\", \\\"last_modified_date\\\", \\\"last_accessed_date\\\"], \\\"excluded_llm_metadata_keys\\\": [\\\"file_name\\\", \\\"file_type\\\", \\\"file_size\\\", \\\"creation_date\\\", \\\"last_modified_date\\\", \\\"last_accessed_date\\\"], \\\"relationships\\\": {\\\"1\\\": {\\\"node_id\\\": \\\"fc5ef969-90e7-4519-afc8-8fbed7897822\\\", \\\"node_type\\\": \\\"4\\\", \\\"metadata\\\": {\\\"page_label\\\": \\\"38\\\", \\\"file_name\\\": \\\"eBook-How-to-Build-a-Career-in-AI.pdf\\\", \\\"file_path\\\": \\\"eBook-How-to-Build-a-Career-in-AI.pdf\\\", \\\"file_type\\\": \\\"application/pdf\\\", \\\"file_size\\\": 3717673, \\\"creation_date\\\": \\\"2024-06-02\\\", \\\"last_modified_date\\\": \\\"2022-12-13\\\"}, \\\"hash\\\": \\\"8015b3d10bb297d165d3c19ad5322426807b464384d1e8ac1f2ebecd22daab11\\\"}}, \\\"text\\\": \\\"PAGE 38Before we dive into the final chapter of this book, I\\\\u2019d like to address the serious matter of \\\\nnewcomers to AI sometimes experiencing imposter syndrome, where someone \\\\u2014 regardless \\\\nof their success in the field \\\\u2014 wonders if they\\\\u2019re a fraud and really belong in the AI community. \\\\nI want to make sure this doesn\\\\u2019t discourage you or anyone else from growing in AI.\\\\nAn estimated 70 percent of people experience some form of imposter syndrome at some point. \\\\nMany talented people have spoken publicly about this experience, including former Facebook \\\\nCOO Sheryl Sandberg, U.S. first lady Michelle Obama, actor Tom Hanks, and Atlassian co-CEO \\\\nMike Cannon-Brookes. It happens in our community even among accomplished people. If you\\\\u2019ve \\\\nnever experienced this yourself, that\\\\u2019s great! I hope you\\\\u2019ll join me in encouraging and welcoming \\\\neveryone who wants to join our community.\\\\nAI is technically complex, and it has its fair share of smart and highly capable people. But it is \\\\neasy to forget that to become good at anything, the first step is to suck at it. If you\\\\u2019ve succeeded \\\\nat sucking at AI \\\\u2014 congratulations, you\\\\u2019re on your way!\\\\nI once struggled to understand the math behind linear regression. I was mystified when \\\\nlogistic regression performed strangely on my data, and it took me days to find a bug in my \\\\nimplementation of a basic neural network. Today, I still find many research papers challenging \\\\nto read, and I recently made an obvious mistake while tuning a neural network hyperparameter \\\\n(that fortunately a fellow engineer caught and fixed).\\\\nSo if you, too, find parts of AI challenging, it\\\\u2019s okay. We\\\\u2019ve all been there. I guarantee that everyone \\\\nwho has published a seminal AI paper struggled with similar technical challenges at some point.Let me be clear: If you want to be part of the AI \\\\ncommunity, then I welcome you with open arms. \\\\nIf you want to join us, you fully belong with us!Overcoming Imposter Syndrome\\\", \\\"start_char_idx\\\": 0, \\\"end_char_idx\\\": 1939, \\\"text_template\\\": \\\"{metadata_str}\\\\n\\\\n{content}\\\", \\\"metadata_template\\\": \\\"{key}: {value}\\\", \\\"metadata_seperator\\\": \\\"\\\\n\\\"}, \\\"score\\\": 0.8139902349518466}, {\\\"node\\\": {\\\"id_\\\": \\\"fcd8731f-ebd5-40af-be7a-6813e8b7645d\\\", \\\"embedding\\\": null, \\\"metadata\\\": {\\\"page_label\\\": \\\"37\\\", \\\"file_name\\\": \\\"eBook-How-to-Build-a-Career-in-AI.pdf\\\", \\\"file_path\\\": \\\"eBook-How-to-Build-a-Career-in-AI.pdf\\\", \\\"file_type\\\": \\\"application/pdf\\\", \\\"file_size\\\": 3717673, \\\"creation_date\\\": \\\"2024-06-02\\\", \\\"last_modified_date\\\": \\\"2022-12-13\\\"}, \\\"excluded_embed_metadata_keys\\\": [\\\"file_name\\\", \\\"file_type\\\", \\\"file_size\\\", \\\"creation_date\\\", \\\"last_modified_date\\\", \\\"last_accessed_date\\\"], \\\"excluded_llm_metadata_keys\\\": [\\\"file_name\\\", \\\"file_type\\\", \\\"file_size\\\", \\\"creation_date\\\", \\\"last_modified_date\\\", \\\"last_accessed_date\\\"], \\\"relationships\\\": {\\\"1\\\": {\\\"node_id\\\": \\\"771a3bb1-2b43-43f1-bb7e-1b16e94896e6\\\", \\\"node_type\\\": \\\"4\\\", \\\"metadata\\\": {\\\"page_label\\\": \\\"37\\\", \\\"file_name\\\": \\\"eBook-How-to-Build-a-Career-in-AI.pdf\\\", \\\"file_path\\\": \\\"eBook-How-to-Build-a-Career-in-AI.pdf\\\", \\\"file_type\\\": \\\"application/pdf\\\", \\\"file_size\\\": 3717673, \\\"creation_date\\\": \\\"2024-06-02\\\", \\\"last_modified_date\\\": \\\"2022-12-13\\\"}, \\\"hash\\\": \\\"293bf847843cd20f676eeffac711e0db3bde1207bf6eda80f52530f8692b41c5\\\"}}, \\\"text\\\": \\\"PAGE 37Overcoming Imposter \\\\nSyndromeCHAPTER 11\\\", \\\"start_char_idx\\\": 0, \\\"end_char_idx\\\": 46, \\\"text_template\\\": \\\"{metadata_str}\\\\n\\\\n{content}\\\", \\\"metadata_template\\\": \\\"{key}: {value}\\\", \\\"metadata_seperator\\\": \\\"\\\\n\\\"}, \\\"score\\\": 0.740083412837171}], \\\"metadata\\\": {\\\"27cbf0f6-24f8-4d0f-b8d2-e9e7755b6538\\\": {\\\"page_label\\\": \\\"38\\\", \\\"file_name\\\": \\\"eBook-How-to-Build-a-Career-in-AI.pdf\\\", \\\"file_path\\\": \\\"eBook-How-to-Build-a-Career-in-AI.pdf\\\", \\\"file_type\\\": \\\"application/pdf\\\", \\\"file_size\\\": 3717673, \\\"creation_date\\\": \\\"2024-06-02\\\", \\\"last_modified_date\\\": \\\"2022-12-13\\\"}, \\\"fcd8731f-ebd5-40af-be7a-6813e8b7645d\\\": {\\\"page_label\\\": \\\"37\\\", \\\"file_name\\\": \\\"eBook-How-to-Build-a-Career-in-AI.pdf\\\", \\\"file_path\\\": \\\"eBook-How-to-Build-a-Career-in-AI.pdf\\\", \\\"file_type\\\": \\\"application/pdf\\\", \\\"file_size\\\": 3717673, \\\"creation_date\\\": \\\"2024-06-02\\\", \\\"last_modified_date\\\": \\\"2022-12-13\\\"}}}, \\\"error\\\": null, \\\"perf\\\": {\\\"start_time\\\": \\\"2024-06-02T20:58:10.411934\\\", \\\"end_time\\\": \\\"2024-06-02T20:58:13.812514\\\"}, \\\"pid\\\": 17076, \\\"tid\\\": 17076}]}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cost_json\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"{\\\"n_requests\\\": 1, \\\"n_successful_requests\\\": 1, \\\"n_classes\\\": 0, \\\"n_tokens\\\": 718, \\\"n_stream_chunks\\\": 0, \\\"n_prompt_tokens\\\": 603, \\\"n_completion_tokens\\\": 115, \\\"cost\\\": 0.0011345}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"perf_json\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"{\\\"start_time\\\": \\\"2024-06-02T20:58:10.411934\\\", \\\"end_time\\\": \\\"2024-06-02T20:58:13.812514\\\"}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ts\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"2024-06-02T20:58:13.815153\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answer Relevance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06466697906828632,\n        \"min\": 0.8,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Context Relevance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10067950951590718,\n        \"min\": 0.6,\n        \"max\": 0.8500000000000001,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.65\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answer Relevance_calls\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Context Relevance_calls\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"latency\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 2,\n        \"max\": 7,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_tokens\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 166,\n        \"min\": 636,\n        \"max\": 1087,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          718\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_cost\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0002544927575322403,\n        \"min\": 0.000971,\n        \"max\": 0.0016605,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.0011345\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\", None)\n",
        "records[[\"input\", \"output\"] + feedback]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 915
        },
        "id": "7euIdErxszo_",
        "outputId": "142d4384-d0c4-49cf-fa4b-6b7a91a36cef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                              input  \\\n",
              "0                                   \"What are the keys to building a career in AI?\"   \n",
              "1                                   \"How can teamwork contribute to success in AI?\"   \n",
              "2                                     \"What is the importance of networking in AI?\"   \n",
              "3                   \"What are some good habits to develop for a successful career?\"   \n",
              "4                            \"How can altruism be beneficial in building a career?\"   \n",
              "5                         \"What is imposter syndrome and how does it relate to AI?\"   \n",
              "6   \"Who are some accomplished individuals who have experienced imposter syndrome?\"   \n",
              "7                                  \"What is the first step to becoming good at AI?\"   \n",
              "8                                          \"What are some common challenges in AI?\"   \n",
              "9                                   \"Is it normal to find parts of AI challenging?\"   \n",
              "10                                                 \"How can I be successful in AI?\"   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             output  \\\n",
              "0                                                                                                                                                                                                                                                                                                                                    \"The keys to building a career in AI involve learning foundational technical skills, working on projects to deepen skills and create impact, and finding the right job that aligns with your career goals. These steps of learning, working on projects, and securing a job are essential for progressing in the field of AI.\"   \n",
              "1                                 \"Teamwork can contribute to success in AI by enabling individuals to work more effectively on large projects. Collaboration within a team allows for the sharing of ideas, expertise, and resources, leading to better problem-solving and innovation. Interpersonal and communication skills play a crucial role in teamwork, as they facilitate effective collaboration, influence, and the ability to be influenced by others. Building a strong professional network or community within the AI field can provide support, advice, and opportunities for growth, ultimately propelling individuals forward in their careers.\"   \n",
              "2                                          \"Networking in AI is crucial as it helps in building a strong professional community that can provide support, guidance, and opportunities. By connecting with others in the field, individuals can gain valuable insights, collaborate on projects, and stay updated on the latest trends and developments. Building a network in AI can also lead to mentorship opportunities, potential job referrals, and a sense of belonging within the industry. Ultimately, networking plays a significant role in advancing one's career in AI by fostering relationships that can open doors to new possibilities and growth.\"   \n",
              "3                                                                                                                                                                                                                                                                                                                                                                     \"Good habits to develop for a successful career include habits related to eating well, exercising, getting enough sleep, maintaining personal relationships, continuous learning, and self-care. These habits can help individuals move forward in their careers while also staying healthy.\"   \n",
              "4                                                                                                 \"Altruism can be beneficial in building a career by helping individuals lift others during their career journey, which often leads to achieving better outcomes for themselves. By aiming to support and encourage others while advancing in their own career, individuals can establish a positive reputation, gain recognition for their expertise, and foster a supportive community. This approach not only contributes to personal growth but also creates opportunities for collaboration, learning, and mutual advancement within the professional field.\"   \n",
              "5           \"Imposter syndrome is when an individual doubts their accomplishments and has a persistent fear of being exposed as a fraud, despite evidence of their competence. In the field of AI, newcomers may experience imposter syndrome due to the technical complexity and the presence of highly capable individuals. It is common for individuals in the AI community, regardless of their success, to question their abilities and feel like they do not belong. However, it is emphasized that experiencing challenges and setbacks is a normal part of the learning process in AI, and it should not deter anyone from pursuing a career in the field.\"   \n",
              "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \"Former Facebook COO Sheryl Sandberg, U.S. first lady Michelle Obama, actor Tom Hanks, and Atlassian co-CEO Mike Cannon-Brookes.\"   \n",
              "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \"The first step to becoming good at AI is to focus on learning technical skills that are essential for a successful career in AI.\"   \n",
              "8                                                                                                                                                                                                                                    \"Some common challenges in AI include identifying meaningful business problems to solve rather than just AI problems, determining appropriate metrics for success that go beyond just machine learning metrics, assessing the feasibility and value of potential solutions, budgeting for necessary resources, and being prepared for the iterative nature of project work where adjustments may be needed at various stages.\"   \n",
              "9                                                                                                                                                                                                                                                                                                          \"It is normal to find parts of AI challenging, as even accomplished individuals in the field have experienced difficulties and technical challenges at some point. The complexity of AI and the technical nature of the subject can make certain aspects challenging for individuals, but it is a common experience shared by many in the AI community.\"   \n",
              "10  \"To be successful in AI, you should focus on learning technical skills relevant to the field, such as coding and math. Additionally, it is important to identify real-world business problems that AI can help solve and work on projects that align with your career goals. Building a portfolio of projects that demonstrate your skill progression is crucial. Utilizing a simple framework for starting your AI job search and engaging in informational interviews to find the right job can also contribute to your success in the field. Overcoming imposter syndrome and making every day count are key aspects to building a successful career in AI.\"   \n",
              "\n",
              "    Context Relevance  Answer Relevance  \n",
              "0                0.85               0.8  \n",
              "1                0.65               0.9  \n",
              "2                0.80               0.9  \n",
              "3                0.80               0.9  \n",
              "4                0.85               0.9  \n",
              "5                0.60               0.9  \n",
              "6                0.60               1.0  \n",
              "7                0.85               0.8  \n",
              "8                0.80               0.8  \n",
              "9                0.85               0.8  \n",
              "10               0.80               0.9  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4a369a8f-3481-4b04-94d7-37b5d6561c5d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "      <th>Context Relevance</th>\n",
              "      <th>Answer Relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"What are the keys to building a career in AI?\"</td>\n",
              "      <td>\"The keys to building a career in AI involve learning foundational technical skills, working on projects to deepen skills and create impact, and finding the right job that aligns with your career goals. These steps of learning, working on projects, and securing a job are essential for progressing in the field of AI.\"</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"How can teamwork contribute to success in AI?\"</td>\n",
              "      <td>\"Teamwork can contribute to success in AI by enabling individuals to work more effectively on large projects. Collaboration within a team allows for the sharing of ideas, expertise, and resources, leading to better problem-solving and innovation. Interpersonal and communication skills play a crucial role in teamwork, as they facilitate effective collaboration, influence, and the ability to be influenced by others. Building a strong professional network or community within the AI field can provide support, advice, and opportunities for growth, ultimately propelling individuals forward in their careers.\"</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"What is the importance of networking in AI?\"</td>\n",
              "      <td>\"Networking in AI is crucial as it helps in building a strong professional community that can provide support, guidance, and opportunities. By connecting with others in the field, individuals can gain valuable insights, collaborate on projects, and stay updated on the latest trends and developments. Building a network in AI can also lead to mentorship opportunities, potential job referrals, and a sense of belonging within the industry. Ultimately, networking plays a significant role in advancing one's career in AI by fostering relationships that can open doors to new possibilities and growth.\"</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"What are some good habits to develop for a successful career?\"</td>\n",
              "      <td>\"Good habits to develop for a successful career include habits related to eating well, exercising, getting enough sleep, maintaining personal relationships, continuous learning, and self-care. These habits can help individuals move forward in their careers while also staying healthy.\"</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"How can altruism be beneficial in building a career?\"</td>\n",
              "      <td>\"Altruism can be beneficial in building a career by helping individuals lift others during their career journey, which often leads to achieving better outcomes for themselves. By aiming to support and encourage others while advancing in their own career, individuals can establish a positive reputation, gain recognition for their expertise, and foster a supportive community. This approach not only contributes to personal growth but also creates opportunities for collaboration, learning, and mutual advancement within the professional field.\"</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>\"What is imposter syndrome and how does it relate to AI?\"</td>\n",
              "      <td>\"Imposter syndrome is when an individual doubts their accomplishments and has a persistent fear of being exposed as a fraud, despite evidence of their competence. In the field of AI, newcomers may experience imposter syndrome due to the technical complexity and the presence of highly capable individuals. It is common for individuals in the AI community, regardless of their success, to question their abilities and feel like they do not belong. However, it is emphasized that experiencing challenges and setbacks is a normal part of the learning process in AI, and it should not deter anyone from pursuing a career in the field.\"</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>\"Who are some accomplished individuals who have experienced imposter syndrome?\"</td>\n",
              "      <td>\"Former Facebook COO Sheryl Sandberg, U.S. first lady Michelle Obama, actor Tom Hanks, and Atlassian co-CEO Mike Cannon-Brookes.\"</td>\n",
              "      <td>0.60</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>\"What is the first step to becoming good at AI?\"</td>\n",
              "      <td>\"The first step to becoming good at AI is to focus on learning technical skills that are essential for a successful career in AI.\"</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>\"What are some common challenges in AI?\"</td>\n",
              "      <td>\"Some common challenges in AI include identifying meaningful business problems to solve rather than just AI problems, determining appropriate metrics for success that go beyond just machine learning metrics, assessing the feasibility and value of potential solutions, budgeting for necessary resources, and being prepared for the iterative nature of project work where adjustments may be needed at various stages.\"</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>\"Is it normal to find parts of AI challenging?\"</td>\n",
              "      <td>\"It is normal to find parts of AI challenging, as even accomplished individuals in the field have experienced difficulties and technical challenges at some point. The complexity of AI and the technical nature of the subject can make certain aspects challenging for individuals, but it is a common experience shared by many in the AI community.\"</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>\"How can I be successful in AI?\"</td>\n",
              "      <td>\"To be successful in AI, you should focus on learning technical skills relevant to the field, such as coding and math. Additionally, it is important to identify real-world business problems that AI can help solve and work on projects that align with your career goals. Building a portfolio of projects that demonstrate your skill progression is crucial. Utilizing a simple framework for starting your AI job search and engaging in informational interviews to find the right job can also contribute to your success in the field. Overcoming imposter syndrome and making every day count are key aspects to building a successful career in AI.\"</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a369a8f-3481-4b04-94d7-37b5d6561c5d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4a369a8f-3481-4b04-94d7-37b5d6561c5d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4a369a8f-3481-4b04-94d7-37b5d6561c5d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-073a982c-bbcd-4e49-820c-70f582a680f1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-073a982c-bbcd-4e49-820c-70f582a680f1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-073a982c-bbcd-4e49-820c-70f582a680f1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"records[[\\\"input\\\", \\\"output\\\"] + feedback]\",\n  \"rows\": 11,\n  \"fields\": [\n    {\n      \"column\": \"input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"\\\"What is imposter syndrome and how does it relate to AI?\\\"\",\n          \"\\\"What are the keys to building a career in AI?\\\"\",\n          \"\\\"Is it normal to find parts of AI challenging?\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"\\\"Imposter syndrome is when an individual doubts their accomplishments and has a persistent fear of being exposed as a fraud, despite evidence of their competence. In the field of AI, newcomers may experience imposter syndrome due to the technical complexity and the presence of highly capable individuals. It is common for individuals in the AI community, regardless of their success, to question their abilities and feel like they do not belong. However, it is emphasized that experiencing challenges and setbacks is a normal part of the learning process in AI, and it should not deter anyone from pursuing a career in the field.\\\"\",\n          \"\\\"The keys to building a career in AI involve learning foundational technical skills, working on projects to deepen skills and create impact, and finding the right job that aligns with your career goals. These steps of learning, working on projects, and securing a job are essential for progressing in the field of AI.\\\"\",\n          \"\\\"It is normal to find parts of AI challenging, as even accomplished individuals in the field have experienced difficulties and technical challenges at some point. The complexity of AI and the technical nature of the subject can make certain aspects challenging for individuals, but it is a common experience shared by many in the AI community.\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Context Relevance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10067950951590718,\n        \"min\": 0.6,\n        \"max\": 0.8500000000000001,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.65,\n          0.6,\n          0.8500000000000001\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answer Relevance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06466697906828632,\n        \"min\": 0.8,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.8,\n          0.9,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tru.get_leaderboard(app_ids=[])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "kF4DXFhKs0iC",
        "outputId": "86901e4c-2b67-45c4-a392-ae956a3018b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Context Relevance  Answer Relevance   latency  total_cost\n",
              "app_id                                                           \n",
              "App_1            0.768182          0.872727  3.454545      0.0013"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-12abc78a-8e51-40d0-896b-ca1a88b7d7d9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Context Relevance</th>\n",
              "      <th>Answer Relevance</th>\n",
              "      <th>latency</th>\n",
              "      <th>total_cost</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>app_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>App_1</th>\n",
              "      <td>0.768182</td>\n",
              "      <td>0.872727</td>\n",
              "      <td>3.454545</td>\n",
              "      <td>0.0013</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12abc78a-8e51-40d0-896b-ca1a88b7d7d9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-12abc78a-8e51-40d0-896b-ca1a88b7d7d9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-12abc78a-8e51-40d0-896b-ca1a88b7d7d9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"tru\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"app_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"App_1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Context Relevance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.7681818181818183,\n        \"max\": 0.7681818181818183,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.7681818181818183\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answer Relevance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8727272727272727,\n        \"max\": 0.8727272727272727,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8727272727272727\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"latency\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 3.4545454545454546,\n        \"max\": 3.4545454545454546,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3.4545454545454546\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_cost\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0013003181818181818,\n        \"max\": 0.0013003181818181818,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0013003181818181818\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tru.run_dashboard()"
      ],
      "metadata": {
        "id": "3zZ4Rt8_s1M-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Auto-merging Retrieval"
      ],
      "metadata": {
        "id": "Ekyk-jRaEiqy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building the index**"
      ],
      "metadata": {
        "id": "wD5HIvMMEv60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from llama_index import (\n",
        "    ServiceContext,\n",
        "    StorageContext,\n",
        "    VectorStoreIndex,\n",
        "    load_index_from_storage,\n",
        ")\n",
        "from llama_index.node_parser import HierarchicalNodeParser\n",
        "from llama_index.node_parser import get_leaf_nodes\n",
        "from llama_index import StorageContext, load_index_from_storage\n",
        "from llama_index.retrievers import AutoMergingRetriever\n",
        "from llama_index.indices.postprocessor import SentenceTransformerRerank\n",
        "from llama_index.query_engine import RetrieverQueryEngine\n",
        "\n",
        "\n",
        "def build_automerging_index(\n",
        "    documents,\n",
        "    llm,\n",
        "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
        "    save_dir=\"merging_index\",\n",
        "    chunk_sizes=None,\n",
        "):\n",
        "    chunk_sizes = chunk_sizes or [2048, 512, 128]\n",
        "    node_parser = HierarchicalNodeParser.from_defaults(chunk_sizes=chunk_sizes)\n",
        "    nodes = node_parser.get_nodes_from_documents(documents)\n",
        "    leaf_nodes = get_leaf_nodes(nodes)\n",
        "    merging_context = ServiceContext.from_defaults(\n",
        "        llm=llm,\n",
        "        embed_model=embed_model,\n",
        "    )\n",
        "    storage_context = StorageContext.from_defaults()\n",
        "    storage_context.docstore.add_documents(nodes)\n",
        "\n",
        "    if not os.path.exists(save_dir):\n",
        "        automerging_index = VectorStoreIndex(\n",
        "            leaf_nodes, storage_context=storage_context, service_context=merging_context\n",
        "        )\n",
        "        automerging_index.storage_context.persist(persist_dir=save_dir)\n",
        "    else:\n",
        "        automerging_index = load_index_from_storage(\n",
        "            StorageContext.from_defaults(persist_dir=save_dir),\n",
        "            service_context=merging_context,\n",
        "        )\n",
        "    return automerging_index"
      ],
      "metadata": {
        "id": "0RL-KhGDEepN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining the retriever and running the query engine**"
      ],
      "metadata": {
        "id": "KV9Fy_CREtAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_automerging_query_engine(\n",
        "    automerging_index,\n",
        "    similarity_top_k=12,\n",
        "    rerank_top_n=6,\n",
        "):\n",
        "    base_retriever = automerging_index.as_retriever(similarity_top_k=similarity_top_k)\n",
        "    retriever = AutoMergingRetriever(\n",
        "        base_retriever, automerging_index.storage_context, verbose=True\n",
        "    )\n",
        "    rerank = SentenceTransformerRerank(\n",
        "        top_n=rerank_top_n, model=\"BAAI/bge-reranker-base\"\n",
        "    )\n",
        "    auto_merging_engine = RetrieverQueryEngine.from_args(\n",
        "        retriever, node_postprocessors=[rerank]\n",
        "    )\n",
        "    return auto_merging_engine"
      ],
      "metadata": {
        "id": "TIJddAu_En6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms import OpenAI\n",
        "\n",
        "index = build_automerging_index(\n",
        "    [document],\n",
        "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1),\n",
        "    save_dir=\"./merging_index\",\n",
        ")\n"
      ],
      "metadata": {
        "id": "ZiYq6hqJEefF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = get_automerging_query_engine(index, similarity_top_k=6)"
      ],
      "metadata": {
        "id": "TCeF33SXEg8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Serving LLMs"
      ],
      "metadata": {
        "id": "revomOFbe7lN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Generation"
      ],
      "metadata": {
        "id": "TnghqQQsfv96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer"
      ],
      "metadata": {
        "id": "qGcfb6SYfVgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"openai-community/gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "Nvb9HV4ve-wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2_g-vGefbj2",
        "outputId": "8f25932b-b4a8-4d99-97a9-40211b64ab38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT2LMHeadModel(\n",
            "  (transformer): GPT2Model(\n",
            "    (wte): Embedding(50257, 768)\n",
            "    (wpe): Embedding(1024, 768)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-11): 12 x GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"The quick brown fox jumped over the\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnu-8YzufqpS",
        "outputId": "8609e899-af20-4b5c-f7a0-43109e526be5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  464,  2068,  7586, 21831, 11687,   625,   262]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "logits = outputs.logits\n",
        "print(logits.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h25cBma9f2u0",
        "outputId": "00af0cde-1680-449c-976f-a2aef7af3606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 7, 50257])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "last_logits = logits[0, -1, :]\n",
        "next_token_id = last_logits.argmax()\n",
        "next_token_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gToZnCvof2sf",
        "outputId": "5099d463-c490-4cab-d63a-d84b7ef76dae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(13990)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(next_token_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "UeCMg7h4f2pj",
        "outputId": "418f3ae6-b7f8-41db-8579-c6a6b8f6801b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' fence'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_k = torch.topk(last_logits, k=10)\n",
        "tokens = [tokenizer.decode(tk) for tk in top_k.indices]\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jGYqRz-f2nR",
        "outputId": "76e3df05-6ac8-4620-935d-cec0bebaca19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' fence',\n",
              " ' edge',\n",
              " ' railing',\n",
              " ' wall',\n",
              " ' table',\n",
              " ' tree',\n",
              " ' top',\n",
              " ' counter',\n",
              " ' ground',\n",
              " ' side']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Concatenate the input and most likely tokens"
      ],
      "metadata": {
        "id": "QyljVNuuf-L4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "next_inputs = {\n",
        "    \"input_ids\": torch.cat(\n",
        "        [inputs[\"input_ids\"], next_token_id.reshape((1, 1))],\n",
        "        dim=1\n",
        "    ),\n",
        "    \"attention_mask\": torch.cat(\n",
        "        [inputs[\"attention_mask\"], torch.tensor([[1]])],\n",
        "        dim=1\n",
        "    ),\n",
        "}"
      ],
      "metadata": {
        "id": "zC56Kn0yf2jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(next_inputs[\"input_ids\"],\n",
        "      next_inputs[\"input_ids\"].shape)\n",
        "print(next_inputs[\"attention_mask\"],\n",
        "      next_inputs[\"attention_mask\"].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZR9evM1vf0-4",
        "outputId": "5c8f3f59-ee78-4f42-f3f0-a699f8bee06b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  464,  2068,  7586, 21831, 11687,   625,   262, 13990]]) torch.Size([1, 8])\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1]]) torch.Size([1, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text generation helper function**"
      ],
      "metadata": {
        "id": "edi636Lvgf0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_token(inputs):\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    last_logits = logits[0, -1, :]\n",
        "    next_token_id = last_logits.argmax()\n",
        "    return next_token_id"
      ],
      "metadata": {
        "id": "x9_awDmCgghs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_tokens = []\n",
        "next_inputs = inputs\n",
        "durations_s = []\n",
        "for _ in range(10):\n",
        "    t0 = time.time()\n",
        "    next_token_id = generate_token(next_inputs)\n",
        "    durations_s += [time.time() - t0]\n",
        "\n",
        "    next_inputs = {\n",
        "        \"input_ids\": torch.cat(\n",
        "            [next_inputs[\"input_ids\"], next_token_id.reshape((1, 1))],\n",
        "            dim=1),\n",
        "        \"attention_mask\": torch.cat(\n",
        "            [next_inputs[\"attention_mask\"], torch.tensor([[1]])],\n",
        "            dim=1),\n",
        "    }\n",
        "\n",
        "    next_token = tokenizer.decode(next_token_id)\n",
        "    generated_tokens.append(next_token)\n",
        "\n",
        "print(f\"{sum(durations_s)} s\")\n",
        "print(generated_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkVsLL-jggnv",
        "outputId": "6a41cf00-02a6-4b20-9575-e302b7b01b56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.5023064613342285 s\n",
            "[' fence', ' and', ' ran', ' to', ' the', ' other', ' side', ' of', ' the', ' fence']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot token generation time\n",
        "- The x-axis here is the token number\n",
        "- The y-axis is the time to generate a token in millisenconds (ms)"
      ],
      "metadata": {
        "id": "CfwB3mnpglJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(durations_s)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "_9gsJzslggkt",
        "outputId": "b6896ae6-c1a9-40bf-eaa6-ec0e601089d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimizing text generation with KV-caching\n",
        "\n",
        "KV-caching is a technique to speed up token generation by storing some of the tensors in the attention head for use in subsequent generation steps\n",
        "- Modify the generate helper function to return the next token and the key/value tensors"
      ],
      "metadata": {
        "id": "1lj8HSS1gwsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_token_with_past(inputs):\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    last_logits = logits[0, -1, :]\n",
        "    next_token_id = last_logits.argmax()\n",
        "    return next_token_id, outputs.past_key_values"
      ],
      "metadata": {
        "id": "QEBV6nkagxL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_tokens = []\n",
        "next_inputs = inputs\n",
        "durations_cached_s = []\n",
        "for _ in range(10):\n",
        "    t0 = time.time()\n",
        "    next_token_id, past_key_values = generate_token_with_past(next_inputs)\n",
        "    durations_cached_s += [time.time() - t0]\n",
        "\n",
        "    next_inputs = {\n",
        "        \"input_ids\": next_token_id.reshape((1, 1)),\n",
        "        \"attention_mask\": torch.cat(\n",
        "            [next_inputs[\"attention_mask\"], torch.tensor([[1]])],\n",
        "            dim=1),\n",
        "        \"past_key_values\": past_key_values,\n",
        "    }\n",
        "\n",
        "    next_token = tokenizer.decode(next_token_id)\n",
        "    generated_tokens.append(next_token)\n",
        "\n",
        "print(f\"{sum(durations_cached_s)} s\")\n",
        "print(generated_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSGC5KtlhaO7",
        "outputId": "14120120-cc8f-4adb-aa06-adae2400fbba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6952714920043945 s\n",
            "[' fence', ' and', ' ran', ' to', ' the', ' other', ' side', ' of', ' the', ' fence']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Compare the execution time for the KV-cache function with the original helper function"
      ],
      "metadata": {
        "id": "yLaHNmKnhfga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(durations_s)\n",
        "plt.plot(durations_cached_s)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "Nz3XF9xlhfxd",
        "outputId": "2b951c5a-00f8-4e87-f000-e5f6cf47b5fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batching"
      ],
      "metadata": {
        "id": "XxoSxWcQi-wj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "YdAvAOF7jH_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"openai-community/gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "OLfJ-I-NjH_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reuse KV-cache text generation"
      ],
      "metadata": {
        "id": "ZV4_D1yMjRiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"The quick brown fox jumped over the\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "\n",
        "def generate_token_with_past(inputs):\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    last_logits = logits[0, -1, :]\n",
        "    next_token_id = last_logits.argmax()\n",
        "    return next_token_id, outputs.past_key_values\n",
        "\n",
        "\n",
        "def generate(inputs, max_tokens):\n",
        "    generated_tokens = []\n",
        "    next_inputs = inputs\n",
        "    for _ in range(max_tokens):\n",
        "        next_token_id, past_key_values = \\\n",
        "        generate_token_with_past(next_inputs)\n",
        "        next_inputs = {\n",
        "            \"input_ids\": next_token_id.reshape((1, 1)),\n",
        "            \"attention_mask\": torch.cat(\n",
        "                [next_inputs[\"attention_mask\"], torch.tensor([[1]])],\n",
        "                dim=1\n",
        "            ),\n",
        "            \"past_key_values\": past_key_values,\n",
        "        }\n",
        "\n",
        "        next_token = tokenizer.decode(next_token_id)\n",
        "        generated_tokens.append(next_token)\n",
        "    return \"\".join(generated_tokens)\n",
        "\n",
        "\n",
        "tokens = generate(inputs, max_tokens=10)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "add309e5-7d47-422c-898a-4d0b878cfd24",
        "id": "BNQcALdijH_n"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " fence and ran to the other side of the fence\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Add padding tokens to the model to prepare batches of prompts**"
      ],
      "metadata": {
        "id": "CXpJ28QZjXQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define PAD Token = EOS Token = 50256\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model.config.pad_token_id = model.config.eos_token_id"
      ],
      "metadata": {
        "id": "qIkHTObjjZvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pad on the left so we can append new tokens on the right\n",
        "tokenizer.padding_side = \"left\"\n",
        "tokenizer.truncation_side = \"left\""
      ],
      "metadata": {
        "id": "0SJ09-IqjAuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Tokenize list of prompts\n",
        "- Add padding so that all prompts have the same number of tokens as the longest prompt"
      ],
      "metadata": {
        "id": "fhYyN2bYkCi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# multiple prompts of varying lengths to send\n",
        "# to the model at once\n",
        "prompts = [\n",
        "    \"The quick brown fox jumped over the\",\n",
        "    \"The rain in Spain falls\",\n",
        "    \"What comes up must\",\n",
        "]\n",
        "\n",
        "# note: padding=True ensures the padding token\n",
        "# will be inserted into the tokenized tensors\n",
        "inputs = tokenizer(prompts, padding=True, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "uONrOg9AkCJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"input_ids:\", inputs[\"input_ids\"])\n",
        "print(\"shape:\", inputs[\"input_ids\"].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-bSxYhIkJAo",
        "outputId": "f9431d70-3089-45a9-9362-70713c94a0e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids: tensor([[  464,  2068,  7586, 21831, 11687,   625,   262],\n",
            "        [50256, 50256,   464,  6290,   287,  8602,  8953],\n",
            "        [50256, 50256, 50256,  2061,  2058,   510,  1276]])\n",
            "shape: torch.Size([3, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"attention_mask:\", inputs[\"attention_mask\"])\n",
        "print(\"shape:\", inputs[\"attention_mask\"].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljehqNPEkKpl",
        "outputId": "a8702a87-340b-4f1d-9c8c-68db2f365d68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attention_mask: tensor([[1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 1, 1, 1, 1]])\n",
            "shape: torch.Size([3, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Add position ids to track original order of tokens in each prompt\n",
        "- Padding tokens are set to `1` and then first real token starts with position `0`"
      ],
      "metadata": {
        "id": "0AEj1yB0kpPI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# position_ids tell the transformer the ordinal position\n",
        "# of each token in the input sequence\n",
        "# for single input inference, this is just [0 .. n]\n",
        "# for n tokens, but for batch inference,\n",
        "# we need to 0 out the padding tokens at the start of the sequence\n",
        "attention_mask = inputs[\"attention_mask\"]\n",
        "position_ids = attention_mask.long().cumsum(-1) - 1\n",
        "position_ids.masked_fill_(attention_mask == 0, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rm1S-uWXkpt0",
        "outputId": "7bdf56bf-79e8-4ccf-ae98-05b26015e9ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1, 2, 3, 4, 5, 6],\n",
              "        [1, 1, 0, 1, 2, 3, 4],\n",
              "        [1, 1, 1, 0, 1, 2, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# same as before, but include the position_ids\n",
        "with torch.no_grad():\n",
        "    outputs = model(position_ids=position_ids, **inputs)\n",
        "logits = outputs.logits"
      ],
      "metadata": {
        "id": "3D024qlik7ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_logits = logits[:, -1, :]\n",
        "next_token_ids = last_logits.argmax(dim=1)\n",
        "\n",
        "print(next_token_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0V9K9kEWlDdn",
        "outputId": "4c9067bc-8d27-4d75-f43e-d424b10872ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([13990,   319,   307])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next_tokens = tokenizer.batch_decode(next_token_ids)\n",
        "next_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbDGRcN0lIe1",
        "outputId": "7e476b27-3895-42a0-d6d7-5328bbc23e5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' fence', ' on', ' be']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**put it all together**"
      ],
      "metadata": {
        "id": "099lvQpslRlp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_batch_tokens_with_past(inputs):\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    last_logits = logits[:, -1, :]\n",
        "    next_token_ids = last_logits.argmax(dim=1)\n",
        "    return next_token_ids, outputs.past_key_values"
      ],
      "metadata": {
        "id": "mLaWaj9wlT2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_batch(inputs, max_tokens):\n",
        "    # create a list of tokens for every input in the batch\n",
        "    generated_tokens = [\n",
        "        [] for _ in range(inputs[\"input_ids\"].shape[0])\n",
        "    ]\n",
        "\n",
        "    attention_mask = inputs[\"attention_mask\"]\n",
        "    position_ids = attention_mask.long().cumsum(-1) - 1\n",
        "    position_ids.masked_fill_(attention_mask == 0, 1)\n",
        "\n",
        "    next_inputs = {\n",
        "        \"position_ids\": position_ids,\n",
        "        **inputs\n",
        "    }\n",
        "\n",
        "    for _ in range(max_tokens):\n",
        "        next_token_ids, past_key_values = \\\n",
        "            generate_batch_tokens_with_past(next_inputs)\n",
        "\n",
        "        next_inputs = {\n",
        "            \"input_ids\": next_token_ids.reshape((-1, 1)),\n",
        "            \"position_ids\": next_inputs[\"position_ids\"][:, -1].unsqueeze(-1) + 1,\n",
        "            \"attention_mask\": torch.cat([\n",
        "                next_inputs[\"attention_mask\"],\n",
        "                torch.ones((next_token_ids.shape[0], 1)),\n",
        "            ], dim=1),\n",
        "            \"past_key_values\": past_key_values,\n",
        "        }\n",
        "\n",
        "        next_tokens = tokenizer.batch_decode(next_token_ids)\n",
        "        for i, token in enumerate(next_tokens):\n",
        "            generated_tokens[i].append(token)\n",
        "    return [\"\".join(tokens) for tokens in generated_tokens]"
      ],
      "metadata": {
        "id": "Kkp-ITlDlTv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_tokens = generate_batch(inputs, max_tokens=10)"
      ],
      "metadata": {
        "id": "qm2iuVAilZzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for prompt, generated in zip(prompts, generated_tokens):\n",
        "    print(prompt, f\"\\x1b[31m{generated}\\x1b[0m\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rRaW4C4lbGD",
        "outputId": "17c3587a-27d5-4e6c-9ae1-368054185a9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The quick brown fox jumped over the \u001b[31m fence and ran to the other side of the fence\u001b[0m\n",
            "\n",
            "The rain in Spain falls \u001b[31m on the first day of the month, and the\u001b[0m\n",
            "\n",
            "What comes up must \u001b[31m be a good idea.\n",
            "\n",
            "\"I think\u001b[0m\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Throughput vs Latency\n",
        "\n",
        "> **Throughput**: the number of tokens we can generate at the same time\n",
        "\n",
        "> **Latency**: How long it takes to generate each token\n",
        "\n",
        "- Explore the effect of batching on latency (how long it takes to generate each token).\n",
        "- Observe the fundamental tradeoff that exists between throughput and latency."
      ],
      "metadata": {
        "id": "l5kHfIoDoMwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# constants\n",
        "max_tokens = 10\n",
        "\n",
        "# observations\n",
        "durations = []\n",
        "throughputs = []\n",
        "latencies = []\n",
        "\n",
        "batch_sizes = [2**p for p in range(8)]\n",
        "for batch_size in batch_sizes:\n",
        "    print(f\"bs= {batch_size}\")\n",
        "\n",
        "    # generate tokens for batch and record duration\n",
        "    t0 = time.time()\n",
        "    batch_prompts = [\n",
        "        prompts[i % len(prompts)] for i in range(batch_size)\n",
        "    ]\n",
        "    inputs = tokenizer(\n",
        "        batch_prompts, padding=True, return_tensors=\"pt\"\n",
        "    )\n",
        "    generated_tokens = generate_batch(inputs, max_tokens=max_tokens)\n",
        "    duration_s = time.time() - t0\n",
        "\n",
        "    ntokens = batch_size * max_tokens\n",
        "    throughput = ntokens / duration_s\n",
        "    avg_latency = duration_s / max_tokens\n",
        "    print(\"duration\", duration_s)\n",
        "    print(\"throughput\", throughput)\n",
        "    print(\"avg latency\", avg_latency)\n",
        "    print()\n",
        "\n",
        "    durations.append(duration_s)\n",
        "    throughputs.append(throughput)\n",
        "    latencies.append(avg_latency)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpCnmOpIoT7C",
        "outputId": "cc0e3aac-7408-4a2c-f4d6-06fa492232f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bs= 1\n",
            "duration 0.7290999889373779\n",
            "throughput 13.715539914593107\n",
            "avg latency 0.0729099988937378\n",
            "\n",
            "bs= 2\n",
            "duration 1.1314568519592285\n",
            "throughput 17.676325849605345\n",
            "avg latency 0.11314568519592286\n",
            "\n",
            "bs= 4\n",
            "duration 1.228811264038086\n",
            "throughput 32.55178494096245\n",
            "avg latency 0.12288112640380859\n",
            "\n",
            "bs= 8\n",
            "duration 1.7085089683532715\n",
            "throughput 46.82445423573466\n",
            "avg latency 0.17085089683532714\n",
            "\n",
            "bs= 16\n",
            "duration 2.3915843963623047\n",
            "throughput 66.90125602231156\n",
            "avg latency 0.23915843963623046\n",
            "\n",
            "bs= 32\n",
            "duration 3.4378533363342285\n",
            "throughput 93.08134137601546\n",
            "avg latency 0.34378533363342284\n",
            "\n",
            "bs= 64\n",
            "duration 4.508948564529419\n",
            "throughput 141.9399646814987\n",
            "avg latency 0.4508948564529419\n",
            "\n",
            "bs= 128\n",
            "duration 9.249368906021118\n",
            "throughput 138.38782007783803\n",
            "avg latency 0.9249368906021118\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's plot the throughput and latency observations against the batch size**"
      ],
      "metadata": {
        "id": "ps-ne0MtsEkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def render_plot(x, y1, y2, x_label, y1_label, y2_label):\n",
        "    # Create a figure and a set of subplots\n",
        "    fig, ax1 = plt.subplots()\n",
        "\n",
        "    # Plot the first line (throughput)\n",
        "    color = 'tab:red'\n",
        "    ax1.set_xlabel(x_label)\n",
        "    ax1.set_ylabel(y1_label, color=color)\n",
        "    ax1.plot(x, y1, color=color)\n",
        "    ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "    # Set the x-axis to be log-scaled\n",
        "    ax1.set_xscale('log', base=2)\n",
        "\n",
        "    # Instantiate a second axes that shares the same x-axis\n",
        "    ax2 = ax1.twinx()\n",
        "    color = 'tab:blue'\n",
        "    ax2.set_ylabel(y2_label, color=color)  # we already handled the x-label with ax1\n",
        "    ax2.plot(x, y2, color=color)\n",
        "    ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "PDt0ppeasFSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "render_plot(\n",
        "    batch_sizes,\n",
        "    throughputs,\n",
        "    latencies,\n",
        "    \"Batch Size\",\n",
        "    \"Throughput\",\n",
        "    \"Latency\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "niWPkHj4sHQ6",
        "outputId": "1296ae34-d971-43a6-a2f3-60fc153f4276"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm4AAAG1CAYAAABAuXhiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB0QklEQVR4nO3dd3gU5cLG4d+WZNN7b4QivYogiB27YsN6PHos2LtiARWsYD0ee8Pu+ewdyxFFsVAUld5rCukhPdnN7s73RyASqYEks5t97uvKpZndnTyzQPLknXnfsRiGYSAiIiIiPs9qdgARERER2TMqbiIiIiJ+QsVNRERExE+ouImIiIj4CRU3ERERET+h4iYiIiLiJ1TcRERERPyEipuIiIiIn7CbHcAXuN1u/vzzT5KTk7Fa1WVFRET8gdfrpaioiCFDhmC3B0alCYyj3I0///yT4cOHmx1DRERE9sKvv/7KsGHDzI7RIVTcgOTkZKDpDz41NdXkNCIiIrInCgoKGD58ePPP8UCg4gbNp0dTU1PJyMgwOY2IiIi0RiBd5hQ4RyoiIiLi51TcRERERPyEipuIiIiIn1BxExEREfETKm4iIiIifkLFTURERMRPqLiJiIiI+AkVNxERERE/oeImIiIi4idU3ERERET8hIqbiIiIiJ9QcRMREZF2YxiG2RE6Fd1kXkREpJ14Kioomvog2GwEd+nS9JHdheCsLKxhYWbH6xBX/98f2K1Wrhu9Hz2SIsyO4/dU3ERERNpJyTPPUvnppzt8zJ6U9FeR69KFoK3FLisLa0hIBydtH+W1Lv63tAiP1+CGo/YzO06nYGpxq/vtN8pefoWGpUtxl5SQ8fRTRB511A6fWzD5birefZfkCbcT969/NW/3VFRQeP8D1Hz/PVitRB5zNCkTJ2IND++owxAREdlOY1ERFe++C0DsP/6Bp6Ya18aNNG7YiKeyEndxMe7iYup++63lCy0W7Ckpf43QbVvuMjOxBgebcDR756slBXi8Bv3To+iWqNG2tmBqcfPW1+Po3YvosaeTf+11O31e1YwZ1C9ciD0pabvH8m+5FXdJCVmvvIzhdrNp4kQKJk0m/bFH2zO6iIjILpW9+BKGy0Xo0KEk33UnFoul+TFPRQWujRubPjZs/Ov/N27EW12Nu6AAd0EBdXPnttyp1UpQauqOR+oyMrAEBXXwUe7aZws2AXDyoDSTk3Qepha3iEMPJeLQQwHI38lzGouKKLr/AbKmvUTu5Ve0eMy5di21P/1E9vvvEzqgPwApd95J7mWXk3TrrQQlb1/0RERE2ltjUREV770HQOK117QobQC2mBhCY2IIHTSoxXbDMPBs3rxNmdvQXOgaN2zEW1dHY34+jfn51M6e3fKL2mwEpafveKQuLQ2LvWN/5BdWNvDrhnIAThyo4tZWfPoaN8PrZdOttxF/ycU49tv+3Hj9ggVYo6KaSxtA+MiRYLVSv2ghQUcfvcP9Op1OnE5n8+fV1dVtH15ERAJW2QsvYjQ2EnbAAYQdeOAev85isWCPi8MeF0fY/kNaPGYYBp7S0h2P1OXkYNTX05iTQ2NODrU//dRyx0FBBG8tddnbjNJ1ySYoNQWLzdYWh93CF4sLMAw4oEss6TGhbb7/QOXTxa3spWlYbDZizz9/h4+7S0qxx8W12Gax27FFR+MpLd3pfqdOnco999zTpllFREQAGgsKqHj/fQASrtl+tG1vWSwW7ImJ2BMTCTvggBaPGYaBu7h4S5nbZpRuY05TqXM6cW3YgGvDBpj1t/0GBRGUlbXDkTp7cjIW696tHPb5wqbTpGN0mrRN+Wxxq1+ylPI336Trhx+22V/6rSZMmMBNN93U/Hl+fj59+/Zt068hIiKBqfTFLaNtw4YRPmLPR9v2hcViISg5maDkZMIPHN7iMcPrxV1UtMPr6RpzcjAaG3GtXYtr7drt9xsSQnBm5vbX03XJxp6UuNOfzzlldSzIrcBqgRMGpLbLMQcq3y1uv8/HU1bGmiOP/Gujx0PRQw9T/vob9Jj5HfbEBNzl5S1eZ7jdeCorsSUk7HTfDocDh8PR/HlVVVWb5xcRkcDTuGkTFR98CEDCtdeYnKaJZcuEhqDUVMJHjGjxmOHx0FhQ2DxK17htucvLw2howLl6Nc7Vq7ffb1gYwTsZqft88WYADuqeQGKkY7vXyt7z2eIWdfLJhI0c2WJb7rhLiT7lZKJPOx2A0MGD8VZVUb9kKaH9+wFQO3ceeL2EDhy03T5FRETaU+mLL0JjI2EHHkj48OG7f4HJLDYbwRnpBGekw6hRLR4z3G4aN23a8Uhdfj5GXR3OFStwrlix3X4/GD0eIlM4eMWPFD8xl+AuXYg47DDssbEddWidlrnLgdTW4srJaf7clZdHw/Ll2KKjCUpL2+4P2GK3Y09IwNGtKwCO7t0JP+QQCibdRerdd2O43RTddx9RJ5ygGaUiItKhGvPzqfjwIwASr7na5DT7zmK3N42oZWXBIYe0eMxwuXDl5/81SrdNuVtT7WZ9ZAp2r5v9//c2ZY31AHT99BMVtzZganGrX7KUnG0W0y1+8CEAok89lbQHp+7RPtIfeZjC++4n58KLtizAewwpd0xsl7wiIiI7U/rCltG2ESMIGzbM7DjtyhIcjKNrVxxdu2732KdfL4cf1jEqKZjuN17bPEoXnJVlQtLOx9TiFn7gcPqsWL7Hz+8x87vtttliYrTYroiImMqVl0/FR1tG23zk2jYzGIbB9CVFAJw2eiDxQ443OVHns3dzfEVERKRZ2QvPg9tN+EEjCRs61Ow4plm6qYr1pbWEBFk5um+y2XE6JRU3ERGRfeDKy6Pi408ASLjmWnPDmGzr2m2jeycT7vDZ+Y9+TcVNRERkH5Q+v2W0bdSo7e52EEi8XoPpiwoAGDNIa7e1FxU3ERGRveTKzaWyebTN/2eS7os/czeTX1FPhMPO4b20skN7UXETERHZS6XPPQ8eD+EHH0zYkMAdbQP4bEHTadJj+iYTEtT29z6VJipuIiIie8G1cSOVn34KBPZMUgC3x8sXi7ecJh2se5O2JxU3ERGRvVD6/AtNo22HHkLooMC+W8+89eWU1riICQvi4B47v+Wk7DsVNxERkVZybdxI5WefAZB4TWCPtsFfs0mP759KkE3Voj3p3RUREWml0mefaxptO+xQQgcONDuOqVxuL18tKQQ0m7QjqLiJiIi0gnP9eio//xzQaBvAT6tLqKxvJCnSwYFd482O0+mpuImIiLRC6XPPgddLxOGHEzpggNlxTLf1NOmJA1OxWS0mp+n8VNxERET2kHPdeqqmfwFAgkbbqHd5mLGs6d6kYwZpNmlHUHETERHZQ82jbUceSWj/fmbHMd33K4updXlIjwllSGaM2XECgoqbiIjIHnCuW0fVF1tG266+yuQ0vmHradIxg9KwWHSatCOouImIiOyB0meebRptGz2a0H4abatuaOS7FcUAnKzTpB1GxU1ERGQ3nGvWUPXllwAkBvg9SbeasawIl9tL98Rw+qRGmh0nYKi4iYiI7Ebps8+BYRB59FGE9OljdhyfoNOk5lBxExER2QXn6tVUffUVAAlXa7QNYHOti59WlwJw0kCdJu1IKm4iIiK7UPLss1tG244mpHdvs+P4hK+WFOL2GvRNjaJHUoTZcQKKipuIiMhONKxaRfXX/wMgQde2Ndt6mvTkwRpt62gqbiIiIjtR+syW0bZjjyWkVy+z4/iE4qoG5q4vA+DEAbo3aUdTcRMREdmBhpWrqP7f/8Bi0bpt2/hicQGGAftnxZAZF2Z2nICj4iYiIrIDpc88A0DkcccS0rOnyWl8x7azSaXjqbiJiIj8TcOKFVR/8w1YLCRepdG2rXLL6/gjpwKrRadJzaLiJiIi8jdbR9uijj8Ox377mZzGd0xfVADAiG7xJEWFmJwmMKm4iYiIbKNh+XKqZ3zbdG2bRtta0GlS86m4iYiIbKNk62jbCSfg6NHD5DS+Y01xDcsKqrBbLRzXL8XsOAFLxU1ERGSLhmXLqPn2O80k3YHpi5pG2w7ZL4HY8GCT0wQuFTcREZEtSp7eMtp24ok4unUzOY3vMAyDz7Tork9QcRMREQHqlyylZuZMsFp1bdvfLCuoYl1JLQ67laP6JJsdJ6CpuImIiAClTz8NQNRJJ+Lo1tXkNL7l84VNs0mP7J1EZEiQyWkCm4qbiIgEvPrFS6j54Yem0bYrrzQ7jk8xDEOzSX2IipuIiAS8raNt0WPG4Oiq0bZt/ZlbQX5FPeHBNo7snWR2nICn4iYiIgGtftEiambNApuNhCuvMDuOz/lsQdNo2zH9UggJspmcRuxmBxARETFTyTajbcHZ2eaG8TEer8EXi5uubxszqHPc4uqNORt4YdY6Smqc9EmN4p6T+zE4M2anz3/55/X8d+5G8ivqiQsP5vj+qdx6XC/TSqxG3EREJGDVL1hA7Y8/NY22XaVr2/5u3voySqqdRIcGcXCPRLPj7LPPF27i/unLuf6o/fji2oPpmxrJBS/Po7TGucPnf7ogn4e+XsH1R+3HtzcdxkNjBzJ90SYe+d/KDk7+FxU3EREJWCXPPAtA9CmnEJyVZXIa37N1Nunx/VMItvt/ZZj283rOGZ7JWQdksl9yJA+cOoDQYBvvzc/d4fN/37iZA7rEcsrgdDLjwji0ZyInD0pjYW5Fxwbfhv//KYiIiOyFuj//pPann3Rt2040erx8tWTraVLfnk1aXV1NVVVV84fTuf0ImsvtZUl+JaN6JDRvs1otjOqRwB8bK3a436FdYlmcX8mCLUUtp6yO71cWc4SJkzR0jZuIiASk0i13SYg+9RSCMzNNTuN7fl5dSkVdIwkRDkZ0izc7zi717du3xeeTJ0/m7rvvbrFtc50Lj9cgIcLRYntihIO1JbU73O8pg9Mpr3Vx5vOzMQxwew3OOzCLq48w7x62Km4iIhJw6v74k9pffgG7Xeu27cTWtdtOGpiKzWoxOc2uLVu2jPT09ObPHQ7HLp695+asLeOZ79dy3yn9GZwVw4bSOu79fClPfrea60bv1yZfo7VU3EREJOCUPv0UADGnnUpwRobJaXxPQ6OHb5YVAf4xmzQyMpKoqKhdPic2LBib1bLdRISSGieJETsuev+esZLT90/nnOFN1z/2TomivtHNhI8Wc80RPbCaUGh1jZuIiASUut9/p3b2HLDbib9c17btyA8ri6lxukmPCWVIZqzZcdpEsN1K//RoZq8pbd7m9RrMXlPG/l1idvia+kYPlr91M+uWDUZ7Bd0NU0fc6n77jbKXX6Fh6VLcJSVkPP0UkUcdBYDR2EjJE09QM+tHXHl52CIiCD9oJIk33UxQ8l8XBXoqKii8/wFqvv8erFYijzmalIkTsYaHm3VYIiLiw7au2xZz+ukEZ6Tv5tmB6bNtTpOaMarUXsYd3JWb31/IgIwYBmdG8/LPG6hzuTlzaNM1jje9u4Dk6BBuO643AKN7J/Pyz+vplxbNkMwYNpTV8u8ZqxjdJ9m008emFjdvfT2O3r2IHns6+dde1/KxhgYali0j4aorcfTqjbeqksIpU8m76iq6fvhB8/Pyb7kVd0kJWa+8jOF2s2niRAomTSb9sUc7+nBERMTH1c2fT92cuRAURMLll5kdxyfVON18t7wY8P3ZpK01ZlAa5bUuHp+xipJqJ33Sonj94uEkRjadKs2vqMeyzRDbtUf2wGKBx75ZSWFlA/HhwYzuk8z4Y3uZdQjmFreIQw8l4tBDAcj/22O2yEiyXnmlxbaUu+5kw5ln0bhpE0FpaTjXrqX2p5/Ifv99Qgf0b3rOnXeSe9nlJN16a4uRORERkZKn/hptC0rXaNuOfLusCKfbS7eEcPql7fq6MX/0r4Oy+ddB2Tt87N3LR7b43G6zcsNRPbnhqJ4dkGzP+NU1bt7qarBYsG65ALF+wQKsUVHNpQ0gfORIsFqpX7Rwp/txOp0t1nuprq5u9+wiImKu2l9/pW7ePI227UbzbNJBaS1Gn8Q3+E1x8zqdFD/6GFEnnogtIgIAd0kp9ri4Fs+z2O3YoqPxlJbuaDcATJ06lejo6OaPv6//IiIinc/WddtizhhLUFrnOgXYVirqXPy4ugSAk/1gNmkg8oviZjQ2kn/DjRgYpNw9eZ/3N2HCBCorK5s/li1b1gYpRUTEV9XO+5W6X3/FEhREwmUabduZr5cU0ugx6JMaRY+kSLPjyA74/DpuRmMjeTfeSOOmTWS99mrzaBuAPTEBd3l5y+e73XgqK7ElJPx9V80cDkeLxfmqqqraPriIiPgEwzAofWrLum1nnkFQqkaSdubzRU2nSf1h7bZA5dMjbs2lbeNGsl59BXtsy7VkQgcPxltVRf2Spc3baufOA6+X0IGDOjquiIj4oLp586ibPx9LUBDxGm3bqeLqBuasLQNgzECdSvZV5i4HUluLKyen+XNXXh4Ny5dji47GnphI3vU30LBsGZnPPwceD+6SpvPutuhoLMHBOLp3J/yQQyiYdBepd9+N4XZTdN99RJ1wgmaUiogIhmH8NZP0rLMISkkxOZHv+mpxIV4DBmfGkBkXZnYc2QlTi1v9kqXk/OtfzZ8XP/gQANGnnkrCNddQM3MmAOtPPa3F67Jef53wA4cDkP7IwxTedz85F160ZQHeY0i5Y2IHHYGIiPiyurlzqf/9dyzBwRpt242ts0k729ptnY2pxS38wOH0WbF8p4/v6rGtbDExWmxXRES202K07eyzdSZmF/Ir6pm/cTMWS9PdEsR3+fQ1biIiInurdvZs6v/4A4vDQfy4cWbH8WnTt4y2Hdg1juSoEJPTyK6ouImISKfTNJN062jbWRpt242/ZpPqNKmvU3ETEZFOp/bnX6hfsECjbXtgXUkNS/KrsFktHN9fp0l9nYqbiIh0KoZhUPp002hb7DnnEJSk0bZdmb6oAICDeyQQFx5schrZHRU3ERHpVGp//pn6hQuxhIQQP+4Ss+P4NMMw+GzL9W0n6zSpX1BxExGRTmPbmaSx55yDPTHR5ES+bUVhNWuKawi2Wzm6X7LZcWQPqLiJiEinUfvjjzQsWqTRtj20de22I3olEhUSZHIa2RMqbiIi0im0GG37xz+w7+Ke1dL0fmk2qf9RcRMRkU6hZtYsGpYswRIaSvwlF5sdx+ctzKskt7yesGAbo3vrNKm/UHETERG/1zST9BkA4s77B/b4eJMT+b7PFjSNth3dN5nQYJvJaWRPqbiJiIjfq/n+h6bRtrAw4i7WaNvueLwG07eeJh2o06T+RMVNRET82rbrtsWd9w/scXEmJ/J9v20op7jaSVSInUN66lpAf6LiJiIifq1m5kwali3DqtG2PbZ1Nulx/VNw2HWa1J+ouImIiN8yDIOSLde2xf7zn9hjY01O5PsaPV6+XNx0t4STB6WbnEZaS8VNRET8Vs133+FcvrxptO2iC82O4xd+WVPK5rpGEiKCGdFNp5X9jYqbiIj4JcPr/Wu07fzzNdq2hz5f2DTadsKAVOw21QB/oz8xERHxS9XffotzxQqs4eHEa7RtjzQ0evhmaSGgRXf9lYqbiIj4HcPrbV63LfaC87HFxJgbyE/MWlVCtdNNanQIQ7M0QumPVNxERMTvVM/4FueqVVgjIoi/8EKz4/iNzxb+dYsrq9VichrZGypuIiLiV5pG27as23bBBdiio01O5B9qnW6+W14EaNFdf6biJiIifqX6m29wrl6NNTKSuH9dYHYcv/Ht8iIaGr1kx4fRPz3K7Diyl1TcRETEbxheL6XPbLknqUbbWmXrbNIxg9KwWHSa1F+puImIiN+o/vprnKvXaLStlSrrGpm1qhjQbFJ/p+ImIiJ+wfB4KHn2WQDiLvwXtiid7ttT/1taSKPHoHdKJD2TI82OI/tAxU1ERPxC1ddf41qzFmtUFHEXaLStNT5f9NdsUvFvKm4iIuLzDI+H0me2GW2L1KjRniqtcfLLmlIAThqYanIa2VcqbiIi4vOqvvwK17p1WKOjNdrWSl8tLsBrwKCMaLrEh5sdR/aRipuIiPg0w+OhdMu1bfEXXYgtIsLkRP5l29mk4v9U3ERExKdVffklrvXrsUVHE/vPf5odx69sqqjn1w3lWCxwkhbd7RRU3ERExGcZbvdf17ZdfLFG21rpi0VNo23DsuNIiQ4xOY20BRU3ERHxWVVffIFrwwZsMTHEnnee2XH8jmaTdj4qbiIi4pMMt/uvddsuvhhbhC6sb40NpbUsyqvEZrVwQv8Us+NIG1FxExERn1T5+XQaN+Zgi40l7rx/mB3H70zfMto2qkcC8REOk9NIW1FxExERn2O43ZQ+9xwA8ZdcjDVco22t9dnCLadJtXZbp6LiJiIiPqfys89pzGkabYv9h0bbWmtlYTWrimoItlk5pp9Ok3YmKm4iIuJTjMbGv0bbxl2CNSzM5ET+5/Mto22H9UokOjTI5DTSllTcRETEp1R+9hmNubnY4uOJPfdcs+P4HcMwNJu0E1NxExERn9E02vY8APGXaLRtbyzKq2RjWR2hQTaO6pNkdhxpYypuIiLiMyo//ZTGvDxsCQnEnnuO2XH80tbTpEf1TSYs2G5yGmlrKm4iIuITDJfrr9G2cZdgDQ01OZH/8XoNpm+5W4Jmk3ZOKm4iIuITKj75hMb8/KbRtrPPNjuOX5q/cTOFVQ1Ehtg5rFei2XGkHZha3Op++43cK65k9SGHsrx3H6q//bbF44ZhUPLkk6w65BBWDBrMxosuwrVhQ4vneCoqyB9/CyuHHsDKYcPZdMcdeGtrO/AoRERkXxkuF6XPN422JVw6TqNte2nradJj+6XgsNtMTiPtwdTi5q2vx9G7F8mT7trh42XTplH+5luk3n032e+9izU0jJxxl+J1Opufk3/LrTjXrCHrlZfJfP456ubPp2DS5I46BBERaQMVH32Me1MB9sREYjTatlfcHi9fLm46TXqyZpN2WqYWt4hDDyXphhuIOvro7R4zDIPyN94g4YoriBw9mpBevUh76EHcxcXNI3POtWup/eknUu+7j9BBgwgbOpSUO++k6ssvaSwq7ujDERGRvWC4XJS+8AIA8ZdeijUkxORE/mn22jLKal3EhQdzUPd4s+NIO/HZa9wa8/LwlJQSftDI5m22yEhCBw6kfsFCAOoXLMAaFUXogP7NzwkfORKsVuoXLdzpvp1OJ1VVVc0f1dXV7XcgIiKySxUffYS7YOto21lmx/FbW0+TnjAgBbvNZ3+8yz7y2T9Zd0kpALb4lr812BIScJeWND/HHhfX4nGL3Y4tOhpPaelO9z116lSio6ObP/r27dvG6UVEZE94XS5Kn98y2nbZZVgduhn63nC6PXy9tBCAMQN1mrQz89ni1p4mTJhAZWVl88eyZcvMjiQiEpAqPvgAd2Eh9uRkYs460+w4fuvHVaVUN7hJiQphWHbc7l8gfstnV+azJyYA4CkrIyjpr5WfPaWlOPr0aX6Ou7y8xesMtxtPZSW2hISd7tvhcODY5re6qqqqtowuIiJ7wOt0UvbCiwDEX3apRtv2wWdbTpOeNDAVq9VichppTz474haUkYEtMYHaOXObt3lqaqhftIjQwYMACB08GG9VFfVLljY/p3buPPB6CR04qMMzi4jInqv44APcRUXYU1KIOVOjbXurzuXm22VFgO5NGghMHXHz1tbiyslp/tyVl0fD8uXYoqMJSksj7oILKH3+eYKzuxCUnkHJk09iT0oi8qijAHB07074IYdQMOkuUu++G8Ptpui++4g64QSCknV/NhERX7XtaFvC5ZdhDQ42OZH/+m55MfWNHrLiwhiYEW12HGlnpha3+iVLyfnXv5o/L37wIQCiTz2VtAenEj9uHEZ9PQWTJuOtqiJ06P5kvvRii+H09EcepvC++8m58CKwWok85hhS7pjY4cciIiJ7ruK993EXF2NPTSV67Fiz4/i1rbNJxwxKxWLRadLOztTiFn7gcPqsWL7Txy0WC4nXXUfiddft9Dm2mBjSH3u0PeKJiEg78DY0UPaiRtvaQlVDIz+sbFpp4eRB6SankY7gs9e4iYhI51Tx3nu4S0qwp6USc/rpZsfxa/9bUojL46VncgS9UiLNjiMdQMVNREQ6jLehgdKXXgIg4fIrsGi0bZ98vqjpFldauy1wqLiJiEiHqXj3XTwlpQSlpRFz2qlmx/FrZTVOflnTtNj8SZpNGjBU3EREpEN46+spfWkaAPFXXK7Rtn301ZJCPF6DAenRdE0INzuOdBAVNxER6RCb33kXT2kpQenpxJx2mtlx/N7W2aQna7QtoKi4iYhIu/PW1VE2rWm0LeHKK7AEBZmcyL8VVjbw64amOwedODDV5DTSkVTcRESk3W1+592mWxhmZhJ9yilmx/F70xdtwjBgWHYsaTGhZseRDuSz9yoVEZHOocVo2xUabWsLzbNJdZq01d6Ys4EXZq2jpMZJn9Qo7jm5H4MzY3b6/Mr6Rh7930q+XlpIZV0j6bGhTDqpL0f0NucOTSpuIiLSrja//Tae8vKm0baTx5gdx+/llNWxMLcCqwWO76/TpK3x+cJN3D99Ofef1p8hmTG88st6Lnh5HjPHH05ChGO757vcXs5/eR7x4cE8d97+JEeFkF9RT1SIeb98qLiJiEi78dbWUjbtZQASrrxSo21t4PNFTZMSRvVIIDFy+7IhOzft5/WcMzyTsw7IBOCBUwcwc0Ux783P5arDe2z3/Pfm51JR18iHVx5EkK3p6rLMuLAOzfx3Km4iItJuyt98C8/mzQR1ydJoWxtpvjepFt1tVl1dTVVVVfPnDocDh6NlqXW5vSzJr+Sqw7s3b7NaLYzqkcAfGyt2uN9vlxexf1YMkz5dwoxlRcSFB3PK4HSuOKw7Nqs594XV5AQREWkX1d9+S8lTTwFbRtvsGivYV6uKqllRWE2QzcKx/VLMjuMz+vbtS3R0dPPH1KlTt3vO5joXHq+x3SnRxAgHJTXOHe43p7yOL7esl/fqhcO59sj9eOmndTw1c3W7HMeeaPW/oopPPiHqhBO2uymw4XJR+eWXxJx6altlExERP1U7Zw75N94EHg/Rp51G9Mknmx2pU5i+ZbTtsJ6JRIfptPNWy5YtIz09vfnzv4+27S3DgITwYKaePhCb1cKAjGiKqhp44cd13HBUzzb5Gq3V6hG3gol34K2u3m67p7aWgol3tEkoERHxX3V//knu1ddgNDYSefTRpN53LxarTvDsK8MwNJt0JyIjI4mKimr+2FFxiw0Lxma1UPq30bWSGieJO5iYAJAY6aBrYniL06LdkyIoqXbicnvb9iD2UOv/JRkGWLY/r+suKsIaGdkWmURExE81rFxJ7uVXYNTVET5qFGmPPapTpG1kSX4V60trCQmyclSfZLPj+J1gu5X+6dHM3nJ/VwCv12D2mjL27xKzw9cc0CWWDaV1eL1G87b1JbUkRToItpvzy8ge/2tad9rpYAEsFnIuvAjstr8e9HhpzMsj/JBD2iGiiIj4A9eGDeRcMg5vVRWhQ4aQ8dST211WI3tv62zS0X2SCXeoDO+NcQd35eb3FzIgI4bBmdG8/PMG6lxuzhzaNMv0pncXkBwdwm3H9QbgnyO68Macjdzz+VL+dVA2G8pqefaHNVx4ULZpx7DHf/KRo0cD4Fy+gvCDD8Ya9td0WEtQEEHp6UQdc3TbJxQREZ/XWFDAxosvxlNaiqNPHzJfeL7FzwnZN16v0Xx9m2aT7r0xg9Ior3Xx+IxVlFQ76ZMWxesXD29eViW/oh7LNmcV02JCef3i4dw3fRnHPfETKVEhXDSqK1cc1n1nX6LdWQzDMHb/tL9UfPwJUSccj7WNLvzzBXl5eWRmZpKbm0tGRobZcURE/Iq7rIyN/zwf1/r1BGdn0+W/b2GPjzc7Vqcyf0M5Zzw/hwiHnfl3HkVIkG33LwoAgfjzu9VjrTGnndoOMURExB95qqrIGXcprvXrsaelkvXqKypt7WDr2m3H9EtWaQtwrS5uy/v03eHkhK36LFu6T4FERMQ/eOvqyL3iSpzLl2OLjyfr5ZcJStUtmNqa2+Pli8VNs0lP1mzSgNfq4pbx1JMtipvR6KZh+XIqP/mExGuvadNwIiLim7wuF3nXXkf9H39gjYoi65WXcXTtanasTmnuunJKa1zEhgUxqkeC2XHEZK0ubpFHHbXdtqjjjsXRowdVX31FzBlntEkwERHxTYbbzabxt1D7yy9YQkPJfOF5Qnr1MjtWp7X1NOnxA1Kb75cpgavN/gaEDh5E7dy5bbU7ERHxQYbXS8Fdk6j+5hssQUFkPvM0YUOGmB2r03K5vXy1ZMuiu5pNKrRRcfM2NFD+5psEJSW1xe5ERMQHGYZB0YMPUvnxx2Czkfbvxwg/6CCzY3VqP60uoarBTXKUg+Fd48yOIz6g1adKVw4/sOXkBMPAW1uLNSSEtEcebstsIiLiQ0qffobNb7wJQOoD9xN1tNbubG+fbTlNeuKAtBa3XZLA1eriljxhQovPLVYLtrg4QgcOxBYd3WbBRETEd5S99hqlzzwDQPKddxJz6qnmBgoA9S4PM5YVATBmkGbrShOt4yYiIrtU8eGHFD/4EACJN1xP3D/PMzlRYJi5opg6l4eM2FAGZ8aYHUd8xF7d7MxTWUnFBx/iXLcWAEf3HsScfhq2mJi2zCYiIiar+vprCu6aBEDcxRcTf/nlJicKHFtnk44ZlNbiNkziX96bn8uYgWmEBrfNwsmtnpxQ99tvrBl9FOVvvYW3qgpvVRXlb73JmqOOpu6339oklIiImK/mp5/Iv+VW8HqJOfNMkm4ZrwLRQaobGpm5shjQorv+7uGvVzDsgW+59YOF/L6xfJ/31+oRt8J77yPq+ONJuXsyFltTezQ8HgrvuZfCe++j2+ef7XMoERExV938+eRdex00NhJ1wpbv+SptHeabpUW43F56JEXQOyXS7DiyD+ZOGM23y4v54Pc8znlxLplxYZw5NJOxQ9NJigxp9f5aXdxcOTmkP/FEc2kDsNhsxF14Ies//bTVAURExLfUL11K7hVXYjQ0EH7YoaQ9+GCL7/nS/j5ftOU06UCdJvV3dpuV4/qncFz/FEqqnXzyZz4f/pHHv2es5LCeiZx1QCZH9UnGuoezhlt9qjSkb19cW65t25Zr3VocvbVytoiIP3OuXUvuuEvx1tQQdsABZDzxBJbgYLNjBZTyWhc/ry4F4CTNJu1UEiMdHJAdy5CsWCwWCysKq7n5/YUc+sj3zFlbtkf7aPWIW9z5/6RwyhRcG3MIHTwIgPoFC9n8f/9H0s030bByZfNzdQsUERH/4crLJ+fiS/Bs3kxIv35kPP8c1pDWn8qRffP1kkLcXoN+aVF0T4wwO460gZJqJx//mcf78/PIKa/jmH4pvPKvYRy8XwJ1LjdPfLea8e8v5Jfbj9ztvlpd3PJvHg9A8aOP7vgxiwUMAywW+ixb2trdi4iICRqLi8m5+GLcRUUE9+hO5rSXsEWoNJjhs4X5gCYldBaXvPYbP64uoWtCOOcMz2Ls/unEhP01ih0WbOfSQ7rx4o/r9mh/rS5uPb6d0dqXiIiID/NUVJB7yTgac3IIysgg6+WXscfGmh0rIBVVNTBvfdPMwxMH6jRpZxAfEcw7l41kaJed/5uKDw/mp1uP2KP9tbq4BaWnt/YlIiLiozw1teRcdjnO1auxJyaS9eorBCUnmx0rYH2xqADDgKFdYsmIDTM7jrSBh88YtNvnWCyWPf7z3qsFeF0bNlA771c85WUYXm+LxxKvvnpvdikiIh3M63SSd801NCxahC06mqxXXiY4M9PsWAHtr9mkGm3rLO7+bCld4sO4aFTXFttfn72BDWW1TB7Tr1X7a3Vx2/zeexTecy+22FjsCQktbzhvUXETEfEHRmMj+TfeRN3cuVjDwsic9hKO/fYzO1ZAyy2v48+cCqwWOEHFrdP4akkB0y4Ytt32oV1iee6Hte1f3Eqff57EG64n4dJLW/tSERHxAYbXy6aJd1AzcyYWh4OM554jdMAAs2MFvK2jbSO7x+/VwqzimzbXNRIZsn3dinDYKa9ztXp/rV7HzVtZRdRxx7X6C4mIiPkMw6Dwvvuo+vxzsNtJf+I/hB843OxYAny+sABoWnRXOo/s+DBmrSrZbvsPK4vJimv9dYytHnGLPO5Yan/5heBzzmn1FxMREXOVPP4fKt5+BywW0h58kMjDDzc7kgBriqtZXlCF3WrhuP4pZseRNjTu4G5M+mwJZbUuDuoeD8DsNaW89NN6Jo3p2+r97VFxK3/jzeb/D87qQskTT1K/YCGOnj2x2FvuIu6C81sdQkRE2l/pSy9R9uKLAKTcfTfRJ51ociLZauto26E9E1us8SX+76xhmTg9Xp6ZuYanZq4GICM2lPtP7c/YoRmt3t+eFbfXX2/xuTUsjLrffqPut99aPtFiadPiZng8lDz9NFWffY67tBR7UhLRp51KwpVXNt+7zTAMSp96is3vv4+3qprQ/YeQOnkywdnZbZZDRMTfbX7nHUoe+zcASbeMJ/bss0xOJFsZhtF8fZsW3e2czh/RhfNHdKGsxklIkI1wx14t6gHsYXHr8d23e/0F9kXZS9OoePsdUh+ciqPHfjQsWULBxInYIiKbC2LZtGmUv/kWaQ9OJSgjg5InniRn3KV0+2I6VofDlNwiIr6k8vPpFN5zLwDxl19O/CWXmJxItrV0UxXrSmpx2K0c1Vdr6HVm8RH73kv2vvJ1gPo//yRi9JHN12AEZ6RT9cUX1C9eDDT9llL+xhskXHEFkaNHA5D20IOsHnUw1d9+S/SJOg0gIoGteub3bLr9djAMYv/xDxJvuN7sSPI3W0fbRvdJImIfRmLEN5VUO5ny5XJ+WVNKWa0LwzBaPL5uauu6Sqv/hhRNfXDHD1gsWBwOgrOyiBx9JLaYmNbuejuhQ4ZQ8d57ONevx9G1Kw0rVlD3xx8k334bAI15eXhKSgk/aGTza2yRkYQOHEj9goU7LW5OpxOn09n8eXV19T5nFRHxNbVz55F/ww3g8RB18hiS77yj+TIT8Q2GYTBds0k7tfHvL2RTRT3Xjt6PpEgH+/ovsNXFrWH5chqWLcPwenFsuY7MtWED2GwEd+vK5rffpujhh8n+71s4evTYp3Dxl12Kt7aGdSecCDYbeDwk3nAD0WPGAOAuKQXAFh/f4nW2hATcpdtPvd1q6tSp3HPPPfuUTUTEl9UvWkTeVVdhuFxEjB5N2pQpWKytXgFK2tkfORXkV9QT4bBzRO8ks+NIO5i/oZz3rhhJv7ToNtlfq/8VR44+kvCRI9nvx1l0/ehDun70IT1m/UD4QQcRfeKJ7DfrB8IOOGDnI3OtUPXVV1R+Pp20Rx+h64cfkvbgVMpfeYWKjz/Zp/1OmDCBysrK5o9ly5btc1YREV/RsGoVOZdehreujrCRI0j/92PbrQAgvuHzhU2nSY/pm0xIkM3kNNIeUmNC+dvZ0X3S6uJW9vIrJF5/HbaIiOZttshIEq+5mrJpL2MNDSXhqitpWLp0n8MVP/Io8ZeOI/rEEwnp1ZPoU04h7sJ/NU9ntycmAOApK2vxOk9pKfaExJ3u1+FwEBUV1fwRGRm5z1lFRHyBKyeHnEsuwVtZSciggWQ+/bQmavkoj9fgi8VbTpNqNmmnNemkvjz09Qpyy+vaZH+t/hXMU1ODu6wcx9/OgrrLN+OtqQHAFhWF0di4z+GM+vrth/atNthyY/ugjAxsiQnUzplLSJ8+zfnqFy0i5lwtECwigaWxqIiciy7GU1KKo2dPsl54AWt4uNmxZCfmrSujpNpJTFgQo3okmB1H2sk1//cHDY1eDnvke0KDbNhtLXvNwsnHtGp/rb9zwpFHUnDHHSTddmvzve3qFy+m+OFHiDiqaWZn/aJFbbKOWsQRR1D6/AvYU1OblgNZvozy114jZuzpAFgsFuIuuIDS558nOLsLQekZlDz5JPakJCKPOmqfv76IiL9wl5eTc/ElNObnE9Qli6yXp7XJJDFpP1tnkx7fP4Vgu64/7KwmtfIm8rvT6uKWes/dFD34IJtuuhnD4wHAYrMRfeqpJE+4HQBHt26k3n/fPodLvvNOSp58gsJ778VTVo49KYmYs88i8aqrmp8TP24cRn09BZMm462qInTo/mS+9KJODYhIwPBUV5M77lJca9diT0mhyyuvYE/c+eUiYj6X28tXSwoBzSbt7M7Yi7sj7IrF+PuCInvIW1uLKy8PgOCMDL8ejs/LyyMzM5Pc3FwyMtr2DRYRaU/e+npyLr2U+vm/Y4uLo8tbb+Lo1s3sWLIb368o5qLXfiMx0sHcCaOxWbVMy97wl5/fG8tqeX9+HhvL65g8pi8JEQ6+X1lMekwoPZNbd539Xo/NWsPDCenVi5Bevfy6tImI+CvD5SLv+uupn/871ogIsqa9pNLmJz7bMpv0xAGpKm2d3Nx1ZRz7nx9ZkFvB/5YUUudsOlu5vKCKx2esavX+Wn2qdOMF/4JdLODY5fXXWh1CRERax/B4yL/tNmp//AlLSAiZLzxPSN++ZseSPdDQ6OGbpVtOk2o2aaf30NcrGH9ML8Yd0o1+k75u3n5Q9wTemL2x1ftrdXEL6dO7xedGo5uGFStwrl5N9KmntjqAiIi0jmEYFN59N9VffQ1BQWQ89RRhQ4eaHUv20Pcriql1eUiPCWX/rBiz40g7W1lYzZPnDNlue3x4MOV1rlbvr9XFLXnChB1uL3nqabx1bbNGiYiI7JhhGBQ/9DAV738AVivpjzxCxCEHmx1LWmHrbNKTBqXqFmQBICokiOLqBjLjwlpsX7qpipSokFbvr83mH0efPIaKjz5qq92JiMgOlD3/POWvvQZA6n33EXXcseYGklapbmjku+XFAJys06QBYcygVB78agXF1Q1YLBa8hsH8DeVM+XI5p++f3ur9tdk9UOoXLMAaHNxWuxMRkb8pf+NNSp54EoDkiROa17QU//Ht8iKcbi/dEsPpmxpldhzpALcc25tJny7hoKkz8RgGRz8+C4/X4JTB6Vx75H6t3l+ri1vetde2+NwwDNwlJTQsWUrClVe2OoCIiOxexcefUDRlCgAJ11xD3AUXmJxI9sbnC7fc4mpgmk6TBohgu5UHxw7kutH7sbKwmlqXm35p0XRN2LsVOVpd3KwRf1tvxGrB0bUriddeR8TBo/YqhIiI7FzVN99QcMcdAMT96wISrr5qN68QX1RR5+LHVSWAZpMGkie+Xc1lh3YjLSaUtJjQ5u0NjR5emLWO649q3ahbq4tb2tQprX2JiIjspZqffyH/5vHg9RI99nSSbr9dIzV+6uslhbi9Bn1To+iRFGF2HOkgT3y3ivNGZBEabGuxvd7l4YnvVrV/cWv+gkuW4lq3FgBHjx5aP0hEpI3V/fFn0+UpjY1EHnssqffeq9Lmx7YuuqvRtsBiADv6V7u8oIqYsNbPDWh1cXOXlZF/083U/for1qimCyu9VVWEHXgg6f9+DHtcXKtDiIhISw3Ll5N7+eUY9fWEH3II6Y88jMVm2/0LxScVVzUwZ10ZACcNTDU5jXSEgXf/D4vFggU44tEfWvzS5fUa1LrcnHdgl1bvt9XFrfD++/HW1tJt+uc4uncHwLlmDZtun0DR/Q+Q/u/HWh1CRET+4ly/npxLxuGtriZ06FAynnwCi2bt+7UvFxdgGDAkK2a79bykc5o0ph+GYXDrh4u48eieRIYENT8WZLOQERvG0C6xrd5vq4tb7U8/k/XqK82lDZpOlaZMuoucS8a1OoCIiPylcdMmci6+BE95OY6+fch8/jmsoaG7f6H4tM8X/TWbVALDGUObbnqfGddU0IJsbbN0buuvcfN6sdi3f5nFbgevty0yiYgEJHdpKTkXXYy7oIDgbt3ImjYNW2Tk7l8oPi1vcx2/b9yMxaLTpIFoRLf45v9vaPTQ6GnZlbYdidsTrS5uYSNGUPTAFNIee4yg5CQAGouKKJr6IGEjR7R2dyIiAngqK8kZdymujRsJSksj65WXdc1wJzF9y2jbiK7xJO3FLY7Ev9W7PEz9ajlfLCpg8w7uTbpu6omt2l+rx+1S7roTT20ta446ijVHH9P0cdTReGprSLnzztbuTkQk4Hlra8m9/AqcK1ZgS0gg65WXCUpJMTuWtJHPNZs0oE35cjmz15Zx/6n9mxfjvfGoniRHhfDvswa3en+tHnELSk2l60cfUjt7Nq516wFwdO9G+EEHtfqLi4gEOq/LRd611zbdNjA6mqyXXyY4O9vsWNJG5qwtY+mmKuxWC8f1VxkPRN8tL+KxswYzsns8t3ywiOHZcWQnhJMeG8onC/I5dUjr7lfaquJmNDayYvAQun78ERGjRsEo3SlBRGRvGW43m26+mdrZc7CEhZH1wvOE9OppdixpA/UuD499s5JXfmka4BjdJ4m4cM0MDkQV9Y1kxTfNJI5w2KmobwRgWHYcd36ypNX7a9WpUktQEEGpqZqEICKyjwyvl4I77qR6xrdYgoPJfPYZQgcPNjuWtIG568o47okfmfbzerwGnL5/Og+PHWR2LDFJVlwYueV1AHRPCueLRU2nzr9dXkRkSOvniLb6FQlXXE7x44+T/tBD2GJiWv0FRUQCnWEYFE2ZSuWnn4LNRvrj/yZ8hCZ3+bsap5uHvlrBm3M3ApAaHcKU0wZwRO8kk5OJmc4YmsHygipGdIvnysN6cMnrv/H6nI24PV7uPLH1d51qdXEr/+//0bhxI6sPPYygtDQsYS3XF+r20UetDiEiEkhKnnySzW+9BTTd/zly9GiTE8m++nFVCRM+Wkx+RT0A5w7PYsIJvYlq5VIP0vmMO6Rb8/8fvF8C3918GEvyK4kNC+aTBfmt3l+ri5u+wYiI7L2yl1+h7LnnAUiedBfRJ59sciLZF5X1jTzwxTLem58HQGZcKA+ePpBRPRJMTia+KiM2jIzYMJZtquLd33KZevrAVr2+1cUt8ZqrW/sSEREBNr/3HsWPPAJA4o03EvePf5icSPbFjGVF3PHxYoqrnVgscOFB2dxybC/Cglt/3ZLIntrrv12Gy4W7vHy7iQpBaVqnRkTk76q+/JLCyXcDED/uEuIvu9TcQLLXymtd3P3ZUj7bsj5bt4RwHj5jIAdka8FkaX+tLm7O9espuPMu6v/8s+UDhgEWC32WLW2rbCIinULNrFnk33obGAYxZ59N4s03Y7FYzI4lrWQYBl8sLmDyp0spq3VhtcBlh3bnhqP2IyTIZnY8CRCtLm4FE+/AYrOR+fxz2BMTQd98RER2qu6338i77npwu4k66SRSJt2l0uaHiqsauOvTJfxvaREAvZIjefiMgQzKjDE3mPisy9+cv8vHq+rde7XfVhe3hhUr6PrhBzi6ddv9k0VEAlj1Dz+w6aabMZxOIg4/nLSpU7DYNDLjTwzD4KM/8rl3+jIq6xuxWy1cfUQPrj6iB8H2Vt81UgLI7m4eHxkSxOmxGa3eb6uLm6N7dzybN7f6C4mIBArDMCibNo2Sfz8OhkHYyBGk/+dxLEFaGsKfbKqoZ+LHi/lhZQkAA9KjefiMgfRJjTI5mfiDR89sn0WX96i4eWpqmv8/afzNFD/yKIk33oij537bfSOyRUS0bUIRET/ira+n4M67qPriCwBizj6blDsmYgnW7Y78hddr8PZvOUz9cgU1TjfBdis3HtWTSw/pit2mUTYx1x4Vt1XDhre8ls0wyLnoopZP0uQEEQlwjYWF5F19DQ1Ll4LdTsodE4k991yzY0kr5JTVcduHi5izrgyA/bNiePiMQfRI0qCE+IY9Km5Zr7/WzjFERPxb3R9/knfddXhKS7HFxpL+xH8IHz7c7Fiyhzxeg9dnb+CR/62kvtFDaJCNW47txb8OysZm1WQS8R17VNzChw+n5JlniL/4Yqyhobt/gYhIAKn48EMK7r4HGhtx9OpFxjPPEJyRbnYs2UNrimu47cNF/L6x6frtkd3ieWjsQLLiw0xOJrK9PZ6cUPrMs8Sec46Km4jIFobbTdFDD7P5zTcBiDzmGNKmTsEaHm5yMtkTbo+Xl35az+PfrsLl9hLhsDPxhD6cMywTq0bZxEft+axSw2jHGCIi/sW9eTP5N91E3Zy5ACRcew0JV16JxaqL1/3B8oIqbv1gEYvzKwE4vFciU04bQFqMBic6uzfmbOCFWesoqXHSJzWKe07ux+A9WI/vs4WbuO7tPzm6bzIvXXBA+wfdidYtB6JFI0VEcK5eTe5VV9OYm4slLIy0hx4k6uijzY4le8Dl9vLM92t45vs1uL0GUSF2Jo/px+n7p2th5ADw+cJN3D99Ofef1p8hmTG88st6Lnh5HjPHH05ChGOnr8str2PKF8sZ7gO3NWtVcVt73PG7LW+95s3dp0AiIr6s+rvv2HTLrXjr6gjKyCDjmWcI6dXT7FiyBxblVXDrB4tYUVgNwLH9krnvlP4kRYWYnEw6yrSf13PO8EzOOiATgAdOHcDMFcW8Nz+Xqw7vscPXeLwGN7y7gBuP3o9f12+mqqGxIyNvp1XFLfGaa7BGRrZXFhERn2UYBmUvvEDJf54AIOzAA0n/z+PYY2NNTia709Do4T/frubFH9fiNSA+PJh7TunHiQNSNcrWSVRXV1NVVdX8ucPhwOFoOYLmcntZkl/JVYd3b95mtVoY1SOBPzZW7HTfT3y3mvjwYM4elsWv682/AUGrilvUiSdgj49vrywiIj7JW1fHpol3UP311wDEnnceybffpjsh+IH5G8q59cNFrCupBeDkQWlMHtOX+F2cFhP/07dv3xafT548mbvvvrvFts11LjxeY7tTookRDtZu+fvxd79tKOe933L58vpD2jTvvtjz4qbfSkQkADXm55N7zbU4ly+HoCBS7rqT2LPOMjuW7Eady83DX6/k9TkbMAxIinTwwGkDOLpvstnRpB0sW7aM9PS/luD5+2jb3qhxurnx3QVMHTuAuHDfufOJZpWKiOxE3fz55F13PZ7ycmxxcWQ89SRhQ4eaHUt2Y/aaUm77aBG55fUAnHVABnec2JfoUI2QdlaRkZFERe36HrKxYcHYrBZKa5wttpfUOEncwQjsxrJa8jbXM+71+c3bvFu6UPeJXzLz5sPoEt/xS//scXHrs3xZe+YQEfEpm999j8L77gO3G0ffPmQ+/TRBaWlmx5JdqGpoZOqXK3j71xwA0mNCmXr6AA7tmWhyMvEFwXYr/dOjmb2mlGP7pQBN96WdvaaMCw7qst3zuydG8L8bDm2x7dFvVlLrdDN5TD9So81ZOqZ1y4GYoLGoiOJHH6P2xx/xNjQQnJVF6pQphA7oDzRdMFz61FNsfv99vFXVhO4/hNTJkwnOzjY3uIj4JaOxkaKpU9n8f28DEHn8caRNmaLFx33c9yuKmfjxYgoqGwA4f0QXbju+NxEOn/8xJx1o3MFdufn9hQzIiGFwZjQv/7yBOpebM4c2zTK96d0FJEeHcNtxvQkJstErpeWEzKiQplHbv2/vSD79N9pTWcnGc/9B2IEHkvnSi9ji4nBt2Igt+q/h0LJp0yh/8y3SHpxKUEYGJU88Sc64S+n2xXSsbXCOW0QCh3vzZvKvv4G6X38Fi4XE668n/vLLNPPQh1XUubh3+jI++iMfgC7xYTw0diAjumkinWxvzKA0ymtdPD5jFSXVTvqkRfH6xcNJjGzqC/kV9T7/791iGL578VrxY49R98efZP/3rR0+bhgGqw89lPgLLyL+kosB8FRXs3rUwaROnUL0iSfu0dfJy8sjMzOT3NxcMjIy2iy/iPiPhpUrybvqahrz87GGhZH26KNEHnmE2bFkF75eUsCdnyyltMaJ1QKXHNyVm47uRWiwzexo0kEC8ee3T4+4Vc/8noiDR5F3/Q3U/fYb9uRkYs89p3lGV2NeHp6SUsIPGtn8GltkJKEDB1K/YOFOi5vT6cTp/OvixOrq6vY9EBHxaVXffMOm2ydg1NURlJVF5jNP49hvP7NjyU6U1jiZ/OlSvlhcAECPpAgePmMg+2dpTT3p/Hy6uDXm5rL57XeIu/BCEi6/jPrFSyh6YAqWoGBiTjsVd0kpALa/rS1nS0jAXVqy0/1OnTqVe+65p12zi4jvM7xeSp95ltJnngEg/KCRpP/739hiYswNJjtkGAafLdzE3Z8tZXNdIzarhSsP6861o3vgsGuUTQKDTxc3wzAI7dePpJtuBCCkb1+cq1dT8c47xJx26l7vd8KECdx0003Nn+fn52+3eJ+IdG7e2lo23X471TO+BSDuXxeQdMstWOw+/W0xYBVWNnDnJ4v5dnkxAH1So3jkjIH0T482OZlIx/Lp71D2xASCe3Rvsc3RvRvV33zT/DiAp6yMoKSk5ud4Sktx9Omz0/3+/VYY294mQ0Q6P1deHnlXXY1z1SosQUGk3H03MWNPNzuW7IBhGLw/P4/7vlhGdYObIJuF647cjysO706QzWp2PJEO59PFLWzI/rjWb2ixzbVhQ/NaSkEZGdgSE6idM5eQLUXNU1ND/aJFxJx7TkfHFRE/UDt3Hvk33ICnogJbQkLTorpDhpgdS3Ygt7yOiR8v5qfVTZfFDMqM4ZEzBtIzWffMlsDl08Ut7sJ/seHcf1D6/AtEHX8c9YsWs/m990m9t+n6NIvFQtwFF1D6/PMEZ3chKD2DkiefxJ6URORRR5mcXkR8iWEYbH77bYoemAIeDyH9+pHxzNMEpaSYHU3+xus1eGveRh78agV1Lg8Ou5Xxx/Ti4oO7YrP69lINIu3Np4tb6IABZDz1JCX/fpzSZ58lKCOD5Am3Ez1mTPNz4seNw6ivp2DSZLxVVYQO3Z/Ml17UGm4i0sxwuSi8/wEq3nsPgKiTTiL1/vuwhoSYnEz+bn1pLbd9sIhfN5QDMDw7jofOGEjXhI6/tZCIL/Lpddw6SiCuAyMSKNxlZeRddz31v/8OFgtJN99E3CWX+Pwim4HG4zV45ef1PPrNSpxuL2HBNm4/vjf/PLALVo2yyU4E4s9vnx5xExHZFw3LlpF7zTW4NxVgjYgg/bFHiTjsMLNjyd+sKqrmlg8WsTC3AoCDeyQw9fQBZMaFmRtMxAepuIlIp1T11VdsmjARo6GB4OxsMp59Bke3bmbHkm00ery8MGstT363BpfHS2SInTtP7MNZB2RqRFRkJ1TcRKRTMbxeSp58krLnXwAg/OCDSf/3Y9iionbzSulIS/IrufWDRSwraFqOaXTvJB44bQAp0bruUGRXVNxEpNPw1NSw6dbbqJk5E4C4iy8m6eabsNi0qr6vcLo9PPXdGp6btRaP1yA2LIi7T+7HyYPSNMomsgdU3ESkU3Dl5JB71VW41qzFEhxM6n33En3KKWbHkm38mbOZWz9YxOriGgBOHJDKPaf0IyFCqwCI7CkVNxHxe7WzZ5N34014KyuxJyaS8czThA4caHYs2aLe5eHfM1by8s/r8RqQEOHgvlP6cfyAVLOjifgdFTcR8VuGYbD5zbcoeuihpkV1Bw4k46mnCEpO2v2LpUPMXVfG7R8uYkNZHQCn75/OpJP6EhMWbHIyEf+k4iYifsnrclF4zz1UfvgRANGnnELKvfdo8W0fUVnfyINfLeftX3MBSI0OYcppAziit0q1yL5QcRMRv+MuKSHv2uuoX7AArFaSbrmFuAv/pYvbfcTXSwqZ9OkSiqudAJw7PIsJJ/QmKiTI5GQi/k/FTUT8Sv3iJeRdey3uwkKsUVGkP/YYEYccbHYsAYqqGpj86VK+XloIQLeEcKaePoADu8WbnEyk81BxExG/Ufn5dAruvBPD6SS4WzcynnkaR9euZscKeF6vwTu/5TL1q+VUN7ixWy1ceXh3rj6iByFBWopFpC2puImIzzM8Hkr+8x/KXpoGQMRhh5H26CPYIiNNTibrSmqY8NFi5q1vuin8oMwYHho7gN4pWvBYpD2ouImIT/NUV5M/fjy1s34EIP7SS0m84XotqmuyRo+XF39cxxPfrcbl9hIaZGP8sb248KBsbLopvEi7UXETEZ/lXL+evKuvwbVuHRaHg9QHHiD6pBPNjhXwFuZWcNuHi1hRWA3AoT0TeeDU/ropvEgHUHETEZ9U89PP5N90E97qauzJyWQ8/TShA/qbHSug1bncPPbNKl79pWkh3diwICaP6ccpg3W7KpGOouImIj7FMAzKX32N4kcfBa+X0MGDyXjqSeyJiWZHC2izVpVwx8eLydtcD8BpQ9K588Q+xOt2VSIdSsVNRHyG1+mkcNIkKj/9DIDosaeTMnky1mCtsm+W8loX909fxkd/5gOQHhPKA6f15/BeWkhXxAwqbiLiExqLism79loaFi0Cm43k224j9vx/6hScSQzD4LOFm7jn82WU17qwWOCig7py8zE9CXfoR4eIWfSvT0RMV79wIXnXXIu7pARrdDQZ/3mc8JEjzY4VsPI213HnJ0v4YWUJAL2SI3lw7ACGZMWanExEVNxExFQVn3xC4aTJGC4Xjv16kPHMMwRnZZkdKyB5vAZvzNnAI/9bSZ3LQ7DNynWje3DZod0JtlvNjiciqLiJiEkMt5vix/5N+auvAhBx5JGkPfwwtohwk5MFppWF1dz24SIW5FYAMDw7jimnD6BHUoS5wUSkBRU3EelwnspK8m8eT+3PPwMQf+UVJF57LRarRnU6mtPt4ZmZa3hu1loaPQaRDju3n9Cbc4dlYdVCuiI+R8VNRDqUc9068q68CtfGjVhCQkh7cCpRxx1ndqyA9NuGcm7/cBFrS2oBOLpvMved0p+U6BCTk4nIzqi4iUiHqZk1i/ybx+OtqcGemkrmM08T0rev2bECTlVDIw9/vYK35uYAkBjp4N6T+3Fc/xTN4hXxcSpuItLuDMOgbNo0Sv79OBgGoUOHkvHkE9jj482OFnBmLCvirk+WUFjVAMA5wzKZcHwfosOCTE4mIntCxU1E2pW3oYGCO++iavp0AGLOOouUO+/AokV1O1RxdQP3fLaMLxYXAJAdH8aU0wdwUPcEk5OJSGuouIlIu3Hl5pJ/w400LF0KdjvJEycQe+65Oh3XgQzD4P35edz/xTKqGtzYrBYuO7Qb14/ej5Agm9nxRKSVVNxEpM156+ooffFFyl95FcPlwhYTQ/oTTxB+4HCzowWUDaW1TPhoMXPWlQEwID2aB8cOoF9atMnJRGRvqbiJSJsxDIOq6dMpfvQx3EVFAISNGEHq/fcRnJFhcrrA4fZ4mfbzeh6fsQqn20tIkJWbj+7FRaOysdu05IqIP1NxE5E2Ub94CUVTplD/558ABGVkkHTbrUQedZROjXagJfmV3PbhIpZuqgLg4B4JTDltAFnxYSYnE5G2oOImIvvEXVpK8eOPU/nRx2AYWEJDSbj8cuIuuhCrw2F2vIBR7/Lw+LermPbTOrwGRIcGcddJfRm7f7qKs0gnouImInvFcLkof/MtSp99Fm9t0wKuUWPGkDT+ZoKSk01OF1h+WVPKhI8Wk1NeB8CYQWlMOqkviZEqziKdjYqbiLRa9Q8/UDz1QVwbNwIQ0r8/yRMnErb/EJOTBZaKOhf3f7GcD37PAyA1OoT7T+3P6D4qziKdlYqbiOwx57r1FD04ldoffwLAlpBA0o03En3aqbrPaAcyDIPpiwq45/OllNa4sFjgghFduOW43kQ49G1dpDPTv3AR2S1PdTWlzzxL+VtvgdsNQUHEnX8+CVddiS0iwux4AWVTRT2TPl3Ct8uLAeiRFMFDYwcwtEucyclEpCOouInIThkeD5Uff0zx4//BU9a0FljEYYeRdPttOLp2NTldYPF6Dd6at5GHvlpBrctDkM3C1Uf04MrDu+OwayFdkUCh4iYiO1T3xx8U3f8ADcuWARDctSvJE24n4tBDTU4WeFYXVXP7R4v5feNmAPbPiuGhsQPZLznS5GQi0tFU3ESkhcbCQoofeZSqL74AwBoRQcLVVxN33j90f9EO5nR7eO6HtTz7/VpcHi/hwTZuO743/zywC1arlvgQCUQqbiICNN0MvvzVVyl98SWM+nqwWIg5YyyJN9yAPT7e7HgB5/eNm7n9w0WsLq4BYHTvJO47tT9pMaEmJxMRM6m4iQQ4wzCo/mYGxQ8/TGN+PgCh++9P8h0TCe3Xz+R0gafG6eaRr1fwxtyNGAYkRAQzeUw/ThqYqoV0RUTFTSSQNaxcRdGUKdTNmweAPSWFpPHjiTrxBJUEE8xcUcQdHy+hoLIBgDOGZnDniX2ICdMpahFp4lfFrfTFlyj597+JveB8UiZOBMDrdFL80ENUffEl3sZGIkaNImXyJOwJCSanFfFd7s2bKX3qKTa/8y54vViCg4kfdwnx48ZhDdM9LTtaaY2Tez5fxucLNwGQGRfK1NMGcvB++j4mIi35TXGrX7yYinffxdGrV4vtRVOnUjPrR9Kf+A/WiEiK7ruPvGuvI/vt/zMpqYjvMtxuNr/zLiVPPYW3shKAyGOOIenWWwnOSDc5XeAxDIMP/8jn/i+WUVHXiNUClx7SjRuO6klosJb4EJHt+UVx89bWsmn8LaTedy+lzz3fvN1TXU3Fhx+R/sgjhI8YAUDq1CmsO+FE6hcsIHTwYJMSi/ie2rlzKXpgCs7VqwFw9OxJ8sSJhI840ORkgSmnrI6JHy/m5zWlAPRNjeKhsQMZkBFtcjIR8WV+UdwK772PiMMPI/ygg1oUt4alS6GxkfCDRjZvc3Trhj0tlbpdFDen04nT6Wz+vLq6ut2yi5jNlZdH8UMPUT3jWwBs0dEk3nA9MWeeicXuF98COhW3x8urv2zgsRkraWj04rBbueGonow7pCtBNt02TER2zee/a1d+8QUNy5aR/cH72z3mLinFEhSELSqqxXZ7fAKe0tKd7nPq1Kncc889bZ5VxJd4a2spffElyl99FcPlApuN2HPOIfHaa7DFxJgdLyAt3VTJ7R8uZnF+02nqkd3imXr6ALITwk1OJiL+wqeLW2NBAUVTppL1ystYHY422++ECRO46aabmj/Pz8+nb9++bbZ/ETMZhkHV9OkUP/Io7uKm+1mGjRxB8oQJhPTsaXK6wNTQ6OGJ71bz4o/r8HgNokLs3HliX848IEOzd0WkVXy6uDUsXYqnrIz1p4/9a6PHQ938+Wz+7/+RNe0ljMZGPFVVLUbd3GWl2HYxq9ThcODYpghWVVW1S36Rjla/eAlFDzxA/YIFAARlZJB8+21EjB6tgmACwzCYvbaMOz5ezIayOgBOHJDK5JP7khQZYnI6EfFHPl3cwkaMpOtnn7bYVjDxDoK7dSV+3DiCUlMhKIjaOXOJOvYYAJzr1uPeVECYJiZIAHGXlFD8+H+o/PhjMAwsYWEkXHYZcRdd2Kaj1bJn6l0ePl+4idfnbGDppqZfDJOjHNx3Sn+O6ZdicjoR8Wc+XdxsEeHY/nZqxxoaii0mpvmUT8zY0yl66EFs0dFYIyIouv9+QgcP1oxSCQiGy0X5m29R+uyzeGtrAYg6eQxJN99MUHKyyekCz8ayWt6au5H35udRWd8IQLDdyjnDMhl/bC+iQoJMTigi/s6ni9ueSJ4wAYvVSt7112O4XEQcPIqUSZPMjiXS7qp/+IHiqQ/i2rgRgJD+/Um+YyJhQ4aYnCyweLwGs1YV88acjcxaVYJhNG3PiA3lnyO6cNYBmcSF684HItI2LIax9dtM4MrLyyMzM5Pc3FwyMjLMjiOyS8516yl6cCq1P/4EgC0hgaQbbyT6tFOxWLWcREfZXOvivfm5vDVvI7nl9c3bD++VyPkjunB4ryRsVl1XKNKeAvHnt9+PuIkECk91NaXPPEv5W2+B2w1BQcRdcD4JV16JLSLC7HgBY1FeBW/M2cjnCzfhdHsBiAqxc9YBmfxzRBct7SEi7UrFTcTHGR4PlR9/TPHj/8FTVgZAxGGHkXT7bTi6djU5XWBoaPTwxaIC3pi7kYW5Fc3b+6VFccHILpw8KF23qBKRDqHiJuLD6v74g6L7H6Bh2TIAgrt2JXnC7UQceqjJyQJDbnkd/52Xw3vzcymvdQEQbLNywoAUzh+Zzf5ZMVpmRUQ6lIqbiA9qLCyk+JFHqfriCwCsEREkXH01cef9A0uwLnRvT16vwc9rSnljzkZmrijCu+Uq4LToEM4b0YWzh2WSEKElVkTEHCpuIj7E29BA+auvUvriSxj19WCxEHPGWBJvuAF7fLzZ8Tq1yrpGPvgjj7fmbmR9aW3z9oN7JHD+yC6M7p2EXfcSFRGTqbiJ+ADDMKj+ZgbFDz9MY34+AKH770/yHRMJ7dfP5HSd27JNVbw5dwMf/5lPQ2PTZINIh52xQzP454gu9EjSxA8R8R0qbiIma1i5kqIpU6mbNw8Ae0oKSePHE3XiCbp+qp243F6+WlLAm3M2Mn/j5ubtvVMiOX9kF04dnE64Q98eRcT36DuTiEncmzdT+tRTbH7nXfB6sTgcxF9yMfHjxmENCzM7XqdUUFnP/83L4e1fcymtcQJgt1o4tn8K/xqZzbDsWJVlEfFpKm4iHcxwu9n8zruUPPUU3spKACKPPZakW24hOCPd5HSdj2EYzFlbxhtzNjJjeRGeLbMNkiId/OPALP4xPIukKN3wXSRQvDFnAy/MWkdJjZM+qVHcc3I/BmfG7PC5b/+aw0d/5LGysBqAARnR3HJs750+vyOouIl0oNq5cyl6YArO1asBcPTsSfLEiYSPONDkZJ1PdUMjH/2Rz5tzN7KmuKZ5+4Fd47hgZDbH9EsmSJMNRALK5ws3cf/05dx/Wn+GZMbwyi/rueDlecwcf/gOZ4vPXVfGyYPS2P/kWBx2G8/PWsv5L89jxo2HkRJtzi98Km4iHcCVl0fxQw9RPeNbAGzR0STecD0xZ56Jxa5/hm1pVVE1b8zZwMd/5FPr8gAQFmzj9P3TOX9ENr1SIk1OKCJmmfbzes4ZnslZB2QC8MCpA5i5opj35udy1eE9tnv+E+e0vPfzQ2MH8vWSQn5ZU8rYoebcYks/MUTakbe2ltIXX6L81VcxXC6w2Yg991wSr7kaW0yM2fE6jUaPl2+WFvHGnA3MW1/evL17YjgXjMzm9P3TiQwJMjGhiLSn6upqqqqqmj93OBw4HC1H0FxuL0vyK7nq8O7N26xWC6N6JPDHxoo9+jr1jR4aPV5iwsz7fqLiJtIODMOg+n//o2jqg7iLigAIGzmC5AkTCOnZ0+R0nUdxVQNv/5rL//26kaKqpskGNquFo/skc8HILozsHq/JBiIBoG/fvi0+nzx5MnfffXeLbZvrXHi8xnanRBMjHKwtqWVPPPjVcpKjQhjVI2Gf8u4LFTeRNuZct56i+++ndvZsAIIyMki+/TYiRo9WiWgDhmHw24bNvDFnA18vKcS9ZbJBQkQw5w7P4h8HZpEaHWpyShHpSMuWLSM9/a/JXX8fbWsLz/6whs8XFvDOZSMICTLv3sQqbiJtxFtfT+nzL1D2yivQ2IglOJj4Sy8l/tJxWEM0a3Ff1TrdfLIgnzfnbGTFlhleAEO7xHLByC4c3z+VYLsmG4gEosjISKKionb5nNiwYGxWS/NSQFuV1DhJ3M1t7F78cS3P/bCW/447kD6pu/467U3FTWQfGYZBzcyZFD0whcZNmwAIP/QQUu64g+AuXUxO5//WltTw5pyNfPh7HtVONwAhQVZOHZzO+SO70C8t2uSEIuIPgu1W+qdHM3tNKcf2SwGa7k08e00ZFxy08+/Vz89ayzMz1/D6JcMZmBHTQWl3TsVNZB+4cnMpuv8BambNAsCemkryxAlEHnWUTovuA7fHy3crinlzzkZ+XlPavD07Pox/jujCmUMziTbx4mAR8U/jDu7Kze8vZEBGDIMzo3n55w3UudycObRplulN7y4gOTqE247rDcBzP6zl8RmreOKcwWTEhlJc3QBAeLDdtLurqLiJ7AWv00nZtGmUvfgShtMJQUHEX3ghCVdeobse7IPSGifv/pbLf+duZFNl0zdIiwVG907i/JHZHNIjAatVhVhE9s6YQWmU17p4fMYqSqqd9EmL4vWLh5MY2XSqNL+ivsUv3W/N3YjL4+XK//7RYj/Xj96PG482Z6KZxTAMw5Sv7EPy8vLIzMwkNzeXjAxz1mUR/1Hz008U3nc/jTk5AISNGEHKpLtwdOtmcjL/ZBgGf+RU8OacDXy5uBCXp+lG77FhQZw9LIvzDswiM05lWES2F4g/vzXiJrKHGjdtomjqg1TPmAGAPTGRpNtvI+oE3Qx+b9S7PHy+cBOvz9nA0k1/rb80KDOGC0Z04cSBqabO3BIR8UUqbiK7YbhclL32OqXPPYdRXw82G3H//CcJ116DLSLC7Hh+Z0NpLf+dt5H35udRWd8INF00fPKgNC4Y2cUnLv4VEfFVKm4iu1A7dy6F996Ha906AEKHDiVl0iRCemkR3dbweA1mrSrmjTkb+WFlSfP2jNhQ/jmiC2cdkElceLCJCUVE/IOKm8gONBYVU/zQQ1R9+SUAtvh4km4ZT/Qpp+i0aCtsqqjn84WbeGveRnLL65u3H9YzkQtGduHwXknYNNlARGSPqbiJbMNwuyl/6y1Kn3oab20tWK3EnnMOiTdcj203iztK0zIef+ZWMHNFMd+vKG6xUG5UiJ2zDsjknyO6kJ0QbmJKERH/peImskXd779TeM+9OFetAiBk0EBSJk0itF8/k5P5too6F7NWlTBzRTGzVpVQUdfY/JjVAvtnxXLmARmcPCid0GBNNhAR2RcqbhLw3KWlFD/6GJWffAKALTqaxPE3EzN2LBarbqH0d4ZhsLKomu+WN42q/ZGzGe82iwpFhwZxWM9EjuydxGE9E4nVtWsiIm1GxU0CluHxsPmddyj5zxN4q5tO6cWceSaJN92IPTbW5HS+pd7lYfba0uZToFsXx92qV3IkR/RO4sjeSeyfFYPdpsIrItIeVNwkINUvXEjhPffSsGwZAI6+fUidPJnQQYNMTuY78jbX8f2KYmauKGb22jKcbm/zYw67lVE9EjiidxJH9EokI1YL5IqIdAQVNwko7s2bKfn341R88AEYBtbISBJvuJ7Yc87BYgvs66/cHi+/b9zMzJVNo2qrimpaPJ4eE8oRvZtOgY7slqDr1URETKDiJgHB8Hqp+PBDSh77N56KCgCiTzmFpFvGY09IMDecicprXcxaVczMFSXMWllMVYO7+TGrBYZ2iW0+BdorOVJLoYiImEzFTTq9hmXLKLznXuoXLgTAsd9+pEyeRNgBB5icrOMZhsHygmpmrihi5opi/sytYNu7FceEBXF4z0SO2DKxICZMEwtERHyJipt0Wp6qKkqeeJLNb78NXi/WsDASrr2WuH+ehyUoyOx4HabO5eaXNWXMXFHMDyuLKfjbxILeKZEcuWVUbUhWrBbEFRHxYSpu0ukYhkHlp59S/MijeMrKAIg64XiSbruNoORkk9N1jNzyOmauKOa7FcXMXVeGa5uJBSFBVkZ13zKxoHcS6TGhJiYVEZHWUHGTTqVh1SoK772X+vm/AxDctSspk+4ifORIk5O1r0aPl/kbNvP9yqZZoGuKW04syIgN5cgtRW1kt3hCgjSxQETEH6m4Safgqaml9OmnKX/zTfB4sISGknDllcRf+C8swZ3zOq2yGic/rCxh5spiflxVQvU2EwtsVgtDu8RyZO8kRvdOokdShCYWiIh0Aipu4tcMw6D6q68oevAh3MXFAEQefRTJEyYQlJZmcrq2ZRgGSzdVMXPL2moL81pOLIgNC+LwXk3Xqh26XyLRYYFzHZ+ISKBQcRO/5Vy3nqL776N29hwAgrKySLnzDiIOPdTkZG2n1unm5zWlfL+imO9XFlNU5WzxeN/UqOZToIMzYzSxQESkk1NxE7/jrauj9PkXKHv1VWhsxBIcTPxllxF/6TisDofZ8fbZxrLa5lG1eevKcXn+mlgQGmRjVI+ELWUtkdRoTSwQEQkkKm7iNwzDoPrbbymaOhX3pgIAwg87lJQ77iA4K8vkdHvP5fYyf0N5U1lbWcy6ktoWj2fGhTK6dzJH9E7iwK5xmlggIhLAVNzEL7hycii8/35qf/wJAHtaKikTJxIxerRfXnRfUu3kh5VNpz9/XFVKjfOviQV2q4UDsmOb11brnqiJBSIi0kTFTXyat6GBspemUfbSSxguFwQFEX/RRSRccTnWMP+5sbnX2zSx4LsVRXy/opiFeZUtHo8PD+awXomM7p3MIT0TiArRxAIREdmeipv4rJpZsyi8/wEac3MBCBs5gpS77sLRrZvJyVoyDIP6Rg/VDW6q6hupanBT3dDY9HlDIwtzK/h+ZQkl1S0nFvRPj+LIXk0TCwZlxGDVxAIREdkNny5upS+8SPWMGbjWrcMSEkLokCEk3Xwzjm5dm5/jdTopfughqr74Em9jIxGjRpEyeVJA3zjc3zXm51M4dSo1334HgD0pieTbbyPy+OPb5ZRhw5bStW3ZavF5cxnb+tjWx/96rsdr7PbrhAXbOLh5YkESyVEhbX4sIiLSufl0cav77Tdi//EPQgf0x/B4KH78cXLGXUL36dObT5MVTZ1KzawfSX/iP1gjIim67z7yrr2O7Lf/z+T00lqGy0XZq69R+txzGA0NYLMRd8EFJFx9NbaI8B2+ptHj3a50VdW7d1Cuti9b1Q1NhWzb20HtC6sFIkOCiAyxE7Xlv5EhQWTFhXFE70SGd43DYdfEAhER2Xs+Xdyypr3U4vO0qVNZfdAoGpYuJWzYMDzV1VR8+BHpjzxC+IgRAKROncK6E06kfsECQgcPNiG17CmP16DG2VSgiubOJ+fl16koraAuoS+u7r2wjD6G+ohoqr5Z2zziVd3QSFX9XyWsvtHTZnkiHfbmshUVam8uYX8VsW0+Dw0iKsTeoqiFBds0iUBERNqVTxe3v/NWVwNgjY4GoGHpUmhsJPygv+5D6ejWDXtaKnW7KG5OpxOn86/rjaq37FfaTlFVA3PXlbEgt4LyWleLsrV1pGvbmZQA9Dgdemzz+R9lQNkefb2wYFtz6fr7iFfUlqK1tXRFOoJafh4SRITDrsVrRUTE5/lNcTO8XoqmTCV0//0J6dkTAHdJKZagIGxRUS2ea49PwFNautN9TZ06lXvuuadd8waa/Ip65q0rY966cuatL2NDWd0evzbI00hEYwORoUHEpCQQFR7SNOLlCNrlCNjWchYRYifIZm3HoxMREfENflPcCu+9F+fq1XT5v//u874mTJjATTfd1Px5fn4+ffv23ef9BgrDMMjbXM/cdWXMW99U1HLL61s8x2qBvmlRDMuOIz0mtMUIWNC6VThffJag1SsJc9cTPaA/KZMnEaI/AxERkV3yi+JWeO991Pwwiy5vvUlQSkrzdntiAkZjI56qqhajbu6yUmy7mFXqcDhwbHNrpKqqqvYJ3kkYhsGGsrqmEbX15cxbV8amyoYWz7FZLfRPj2ZE1zgO7BbHAdlx261F5i4tpfiRR6j89LOm18TEkDT+bqJPPx2LVSNmIiIiu+PTxc0wDIruu5/qb7+lyxuvE5yR0eLxkH79ICiI2jlziTr2GKDpxuPuTQWEaWLCXjMMg7UlNcxdV95c1Ir/tgZZkM3CwIwYDuwax4Hd4hnaJZYIx47/OhluN5vfeZeSJ55ouk7RYiHmzDNJvPEG7LGxHXFIIiIinYJPF7fCe++lavoXZDzzNNbwcNwlJQBYIyOxhoRgi4wkZuzpFD30ILboaKwRERTdfz+hgwdrRmkreL0Gq4qrm69P+3V9OaU1rhbPCbZZGZwZw4Hd4hjRLZ79s2IJDd710haGYVD/5wIK77sP5/LlAIT07UvK3ZMJHTiw3Y5HRESks/Lp4lbx9jsA5FzwrxbbU6dMIeb00wBInjABi9VK3vXXY7hcRBw8ipRJkzo8qz/xeA1WFFY1jaitK+O3DeVsrmts8RyH3cr+WbEc2C2OA7vGMyQrZqc3Nze8Xhrz83GuXYtr7bot/12Lc926v2YCR0WReMP1xJ59Nhab1jITERHZGxbDMHa/5Hsnl5eXR2ZmJrm5uWT87XRsZ+D2eFlWUNViRK2qoeVSHKFBNg7Ijm0+9TkwI3q7xWINlwtXTg7ONWtxrttS0tatw7VuHYaz5anUZjYb0WPGkHTLeOzx8e11iCIiEoA6+8/vHfHpETfZO40eL4vzK5uL2vwNm7dbMy3CYd9S1OI5sFscA9Kjm5fU8NbV4Vyxgsp1a3GuXYdr3Vqca9biyskBz44XvLUEBRGcnU1wj+44unXH0b0bwd27E5ydjXWbiSAiIiKy91TcOgGn28OivMrmWZ+/b9xMnatlwYoMsTM8O675GrW+qVFYqqtwrluHc94flK9pOrXpWruWxk2bdvq1rGFhBHfvjqNbUzFz9Gj6/6CMDCx2/XUSERFpT/pJ64caGj38mVPBvPVNC97+kbMZ59/utxkTFtRU1LrGMTTGQreqTbjXrcT5/Vpc09axbu1aPGU7vyuBLTaW4O7dcHTv0TR6tmUUzZ6Sots6iYiImETFzQ/Uuzz8kbO5acHbdeUsyK3A5WlZ1OLDgxmWEsKQoHoG1RWQkbOSxi+arkPz1tSQv5N921NTt4yedWs6xdmjO8Hdu2uZDhERER+k4uaDapxuft+4ufnU56K8Cho9LeeQJAbDEHsNA6vy6JezhJSVf8K291/d9slWK8GZmQT36PFXSeveneCu3bBFhHfMQYmIiMg+U3HzAVUNjczfUM68deXMXV/OkvxKPN6WRS3JW8+Aihz65y5mQPEa0mpL+fsJS0twMMFdu/51arNHd4K7dWuaIBAc3HEHJCIiIu1Cxc0EFXUufl3fdFeCuauLWV5Ui/dvz0muLWdA2VoGlK5jQOlaUurKm4uaNTyc4EED/5q9uaWkBaWna400ERGRTkzFrQOUVjcwZ+EG5i7N49dNtaxx2jD+Nl6WVlPSVNK2lLWk+gps8fFNpzYPOvqvSQLdu2NPStIEARERkQCk4tZOPF6DW+98lfkNDjYGx2zzSNNbnlFdzMDStQwoXctgey3pWSk4BnUjuPspTdefdeumCQIiIiLSgopbO7FZLcyvC2JjSAwAXaoKGeQqYWiEm2HpUaQflE1wt+E4umZjDdcEAREREdk9Fbd2dO3+CVgtMHJwV1J6HY1FEwRERERkH6i4taMzLjje7AgiIiLSiVjNDiAiIiIie0bFTURERMRPqLiJiIiI+AkVNxERERE/oeImIiIi4idU3ERERET8hIqbiIiIiJ9QcRMRERHxEypuIiIiIn5CxU1ERETET6i4iYiIiPgJFTcRERERP6HiJiIiIuIn7GYH8AVerxeAgoICk5OIiIjIntr6c3vrz/FAoOIGFBUVATB8+HCTk4iIiEhrFRUVkZWVZXaMDmExDMMwO4TZ3G43f/75J8nJyVitbXf2uLq6mr59+7Js2TIiIyPbbL/+JNDfAx1/YB8/6D0I9OMHvQftefxer5eioiKGDBmC3R4YY1Eqbu2oqqqK6OhoKisriYqKMjuOKQL9PdDxB/bxg96DQD9+0HsQ6Mff1jQ5QURERMRPqLiJiIiI+AkVt3bkcDiYPHkyDofD7CimCfT3QMcf2McPeg8C/fhB70GgH39b0zVuIiIiIn5CI24iIiIifkLFTURERMRPqLiJiIiI+AkVNxERERE/oeImIiIi4idU3DrI9OnT6dWrF/vttx/Tpk0zO44pTjvtNGJjYznjjDPMjtLhcnNzOfzww+nbty8DBw7k/fffNztSh6qoqOCAAw5g8ODB9O/fn5deesnsSKapq6ujS5cujB8/3uwoHS47O5uBAwcyePBgjjjiCLPjdLj169dzxBFH0LdvXwYMGEBtba3ZkTrUypUrGTx4cPNHaGgon3zyidmx/I6WA+kAbrebvn378v333xMdHc3QoUOZPXs28fHxZkfrUD/88APV1dW8/vrrfPDBB2bH6VAFBQUUFRUxePBgCgsLGTp0KKtWrSI8PNzsaB3C4/HgdDoJCwujtraW/v37M3/+/ID7NwBwxx13sGbNGjIzM3n00UfNjtOhsrOzWbJkCREREWZHMcVhhx3G/fffzyGHHEJ5eTlRUVEBc3/Nv6upqSE7O5uNGzcGzPfBtqIRtw7w66+/0q9fP9LT04mIiOD444/nm2++MTtWhzv88MMD8gbLAKmpqQwePBiAlJQUEhISKC8vNzdUB7LZbISFhQHgdDoxDINA/J1x9erVrFixguOPP97sKNLBli5dSlBQEIcccggAcXFxAVvaAD777DNGjx6t0rYXVNzayNSpUxk2bBiRkZEkJSVx6qmnsnLlSgA2bdpEenp683PT09PJz883K2q72dV7EAj29Ph///13PB4PmZmZJqRsP7s7/oqKCgYNGkRGRga33HILCQkJJqZtH7t7D8aPH8/UqVNNTNi+dnf8FouFww47jGHDhvHf//7XxKTtY1fHv3r1aiIiIhgzZgz7778/U6ZMMTlt+9jT74PvvfceZ599tgkJ/Z+KWxuZNWsWV199NXPnzmXGjBk0NjZyzDHHBNQ1DIH+HuzJ8ZeXl3PBBRfw4osvmpi0fezu+GNiYli4cCHr16/n//7v/ygqKjI5cdvb1Xvw6aef0rNnT3r27Gl2zHazu78DP//8M7///jufffYZU6ZMYdGiRSYnblu7On63281PP/3Es88+y5w5c5gxYwYzZswwO3Kb25Pvg1VVVcyePZsTTjjBxKR+zJB2UVxcbADGrFmzjF9++cU49dRTmx+7/vrrjf/+978mpusY274HW33//ffG2LFjTUzVcf5+/A0NDcYhhxxivPHGGyYn6xg7+vPf6sorrzTef/99E1J1rG3fg9tvv93IyMgwunTpYsTHxxtRUVHGPffcY3bEdrWrvwPjx483Xn311Y4P1YG2Pf7Zs2cbxxxzTPNjDz/8sPHwww+bmK5j7OjvwBtvvGGcd955JqbybxpxayeVlZVA03UMw4cPZ8mSJeTn51NTU8NXX33Fsccea3LC9rftexCItj1+wzC48MILOfLIIzn//PNNTtYxtj3+oqIiqqurm7f/+OOP9OrVy8x4HWLb92Dq1Knk5uayYcMGHn30US699FImTZpkcsL2te3x19bWNv8dqKmpYebMmfTr18/MeO1u2+MfNmwYxcXFbN68Ga/Xy48//kifPn1MTtj+dvRzQKdJ95HZzbEz8ng8xoknnmiMGjWqedunn35q7Lfffkb37t2NF154wcR0HWNH78Ho0aONhIQEIzQ01EhPTzdmz55tYsL29ffj/+mnnwyLxWIMGjSo+WPRokUmp2w/fz/+efPmGYMGDTIGDhxoDBgwwHj++edNTtj+dvRvYKtXX33VuPnmm01I1XH+fvxr1641Bg4caAwcONDo16+f8Z///MfkhO1rR3/+X375pdG/f3+jX79+xo033mhiuo6xo/egoqLCSEpKMpxOp4nJ/JuKWzu44oorjC5duhi5ublmRzFNoL8HOv7APn7D0Hug4w/s4zcMvQftRcWtjV199dVGRkaGsW7dOrOjmCbQ3wMdf2Afv2HoPdDxB/bxG4beg/ak4tZGvF6vcfXVVxtpaWnGqlWrzI5jikB/D3T8gX38hqH3QMcf2MdvGHoPOkLgrv7Xxq6++mr+7//+j08//ZTIyEgKCwsBiI6OJjQ01OR0HSPQ3wMdf2AfP+g90PEH9vGD3oMOYXZz7CyAHX509unu2wr090DHH9jHbxh6D3T8gX38hqH3oCPoXqUiIiIifkLruImIiIj4CRU3ERERET+h4iYiIiLiJ1TcRERERPyEipuIiIiIn1BxExEREfETKm4iIiIifkLFTURERMRPqLiJSKfy2muvERMT0+b7vfvuuxk8eHCb71dEpDVU3ESkzV144YVYLJbmj/j4eI477jgWLVrUqv10ZFn6+OOPGTFiBNHR0URGRtKvXz9uuOGG5sfHjx/Pd9991yFZRER2RsVNRNrFcccdR0FBAQUFBXz33XfY7XZOOukks2Pt0HfffcfZZ5/N2LFj+fXXX/n999954IEHaGxsbH5OREQE8fHxJqYUEVFxE5F24nA4SElJISUlhcGDB3P77beTm5tLSUlJ83Nuu+02evbsSVhYGN26deOuu+5qLkuvvfYa99xzDwsXLmweuXvttdcAqKio4PLLLyc5OZmQkBD69+/P9OnTW3z9//3vf/Tp04eIiIjmErkzn3/+OaNGjeKWW26hV69e9OzZk1NPPZVnnnmm+Tl/H/3bdkRx60d2dnbz40uWLOH4448nIiKC5ORkzj//fEpLS/fhHRURUXETkQ5QU1PDW2+9RY8ePVqMWkVGRvLaa6+xbNkynnjiCV566SUef/xxAM4++2xuvvlm+vXr1zxyd/bZZ+P1ejn++OP55ZdfeOutt1i2bBkPPvggNputeb91dXU8+uijvPnmm/z444/k5OQwfvz4neZLSUlh6dKlLFmyZI+PaWumgoIC1qxZQ48ePTj00EOBpmJ55JFHMmTIEObPn8/XX39NUVERZ511VmvfOhGRFuxmBxCRzmn69OlEREQAUFtbS2pqKtOnT8dq/ev3xTvvvLP5/7Ozsxk/fjzvvPMOt956K6GhoURERGC320lJSWl+3jfffMOvv/7K8uXL6dmzJwDdunVr8bUbGxt5/vnn6d69OwDXXHMN9957706zXnvttfz0008MGDCALl26MGLECI455hjOO+88HA7HDl+zNZNhGIwdO5bo6GheeOEFAJ5++mmGDBnClClTmp//yiuvkJmZyapVq5pzi4i0lkbcRKRdHHHEESxYsIAFCxbw66+/cuyxx3L88cezcePG5ue8++67jBo1ipSUFCIiIrjzzjvJycnZ5X4XLFhARkbGLstPWFhYc2kDSE1Npbi4eKfPDw8P54svvmDNmjXceeedREREcPPNNzN8+HDq6up2mWfixInMmTOHTz/9lNDQUAAWLlzI999/T0RERPNH7969AVi7du0u9ycisisqbiLSLsLDw+nRowc9evRg2LBhTJs2jdraWl566SUA5syZw3nnnccJJ5zA9OnT+fPPP7njjjtwuVy73O/WcrQrQUFBLT63WCwYhrHb13Xv3p1x48Yxbdo0/vjjD5YtW8a777670+e/9dZbPP7443z88cekp6c3b6+pqWHMmDHNxXXrx+rVq5tPp4qI7A2dKhWRDmGxWLBardTX1wMwe/ZsunTpwh133NH8nG1H4wCCg4PxeDwttg0cOJC8vLx2P+WYnZ1NWFgYtbW1O3x8zpw5jBs3jhdeeIERI0a0eGz//ffnww8/JDs7G7td32ZFpO1oxE1E2oXT6aSwsJDCwkKWL1/Otdde2zwSBbDffvuRk5PDO++8w9q1a3nyySf5+OOPW+wjOzub9evXs2DBAkpLS3E6nRx22GEceuihjB07lhkzZrB+/Xq++uorvv76673Oevfdd3Prrbfyww8/sH79ev78808uvvhiGhsbOfroo7d7fmFhIaeddhrnnHMOxx57bPNxbp0xe/XVV1NeXs65557Lb7/9xtq1a/nf//7HRRddtF0RFRFpDRU3EWkXX3/9NampqaSmpnLggQfy22+/8f7773P44YcDcPLJJ3PjjTdyzTXXMHjwYGbPns1dd93VYh9jx47luOOO44gjjiAxMZG3334bgA8//JBhw4Zx7rnn0rdvX2699dZ9KkSHHXYY69at44ILLqB3794cf/zxFBYW8s0339CrV6/tnr9ixQqKiop4/fXXm48xNTWVYcOGAZCWlsYvv/yCx+PhmGOOYcCAAdxwww3ExMS0mJwhItJaFmNPLvwQEREREdPpVz8RERERP6HiJiIiIuInVNxERERE/ISKm4iIiIifUHETERER8RMqbiIiIiJ+QsVNRERExE+ouImIiIj4CRU3ERERET+h4iYiIiLiJ1TcRERERPyEipuIiIiIn/h/StF5b1YZDKwAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Continuous Batching\n",
        "\n",
        "- The key idea behind continuous batching is constantly swap out requests from the batch that have completed generation for requests in the queue that are waiting to be processed."
      ],
      "metadata": {
        "id": "M6VLBm8Wtom0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer"
      ],
      "metadata": {
        "id": "G1DF2YeauLAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_next_inputs(batch, next_token_ids, past_key_values, next_tokens):\n",
        "    return {\n",
        "        # '-1' here means the remaining elements for this dim\n",
        "        \"input_ids\": next_token_ids.reshape((-1, 1)),\n",
        "        # increment last, discard the rest\n",
        "        \"position_ids\": batch[\"position_ids\"][:, -1].unsqueeze(-1) + 1,\n",
        "        # concatenate vector of 1's with shape [batch_size]\n",
        "        \"attention_mask\": torch.cat([\n",
        "            batch[\"attention_mask\"],\n",
        "            torch.ones((next_token_ids.shape[0], 1)),\n",
        "        ], dim=1),\n",
        "        \"past_key_values\": past_key_values,\n",
        "        \"responses\": [\n",
        "            r1 + r2 for r1, r2\n",
        "            in zip(batch[\"responses\"], next_tokens)],\n",
        "        \"tokens_remaining\": [\n",
        "            v - 1 for v in batch[\"tokens_remaining\"]],\n",
        "    }\n",
        "\n",
        "\n",
        "def init_batch(requests):\n",
        "    prompts = [r[0] for r in requests]\n",
        "    inputs = tokenizer(prompts, padding=True, return_tensors=\"pt\")\n",
        "\n",
        "    attention_mask = inputs[\"attention_mask\"]\n",
        "    position_ids = attention_mask.long().cumsum(-1) - 1\n",
        "    position_ids.masked_fill_(attention_mask == 0, 1)\n",
        "\n",
        "    return {\n",
        "        \"position_ids\": position_ids,\n",
        "        \"responses\": copy.copy(prompts),\n",
        "        \"tokens_remaining\": [r[1] for r in requests],\n",
        "        **inputs\n",
        "    }\n",
        "\n",
        "\n",
        "def generate_next_token(batch):\n",
        "    inputs = copy.copy(batch)\n",
        "    inputs.pop(\"responses\")\n",
        "    inputs.pop(\"tokens_remaining\")\n",
        "\n",
        "    next_token_ids, past_key_values = \\\n",
        "        generate_batch_tokens_with_past(inputs)\n",
        "    next_tokens = tokenizer.batch_decode(next_token_ids)\n",
        "    return get_next_inputs(\n",
        "        batch, next_token_ids, past_key_values, next_tokens)\n",
        "\n",
        "\n",
        "def merge_batches(batch1, batch2):\n",
        "    # first find the max sequence length of the two batches\n",
        "    # this can be obtained from the second dimension\n",
        "    # of the attention mask\n",
        "    attn_mask1 = batch1[\"attention_mask\"]\n",
        "    attn_mask2 = batch2[\"attention_mask\"]\n",
        "    max_seq_len = max(attn_mask1.shape[1], attn_mask2.shape[1])\n",
        "\n",
        "    # pad each mask (on the left) to the max sequence length\n",
        "    # attention mask uses 0 for padding\n",
        "    padding1 = max_seq_len - attn_mask1.shape[1]\n",
        "    padding2 = max_seq_len - attn_mask2.shape[1]\n",
        "    attn_mask1 = F.pad(attn_mask1, (padding1, 0), \"constant\", 0)\n",
        "    attn_mask2 = F.pad(attn_mask2, (padding2, 0), \"constant\", 0)\n",
        "\n",
        "    # because we only append batches post decoding,\n",
        "    # we don't need to pad input_ids\n",
        "    # or position_ids. these are always length 1\n",
        "    # in the sequence dimension\n",
        "    # however, we do need to pad the\n",
        "    # past_key_values, which have shape:\n",
        "    # [batch_size, num_heads, sequence_length, head_dim]\n",
        "    past_kv1 = batch1[\"past_key_values\"]\n",
        "    past_kv2 = batch2[\"past_key_values\"]\n",
        "\n",
        "    padded_kv1 = []\n",
        "    for i in range(len(past_kv1)):\n",
        "        k, v = past_kv1[i]\n",
        "        k = F.pad(k, (0, 0, padding1, 0), \"constant\", 0)\n",
        "        v = F.pad(v, (0, 0, padding1, 0), \"constant\", 0)\n",
        "        padded_kv1.append((k, v))\n",
        "\n",
        "    padded_kv2 = []\n",
        "    for i in range(len(past_kv2)):\n",
        "        k, v = past_kv2[i]\n",
        "        k = F.pad(k, (0, 0, padding2, 0), \"constant\", 0)\n",
        "        v = F.pad(v, (0, 0, padding2, 0), \"constant\", 0)\n",
        "        padded_kv2.append((k, v))\n",
        "\n",
        "    # now that everything has been padded to have\n",
        "    # consistent shapes, let's merge\n",
        "    input_ids = torch.concat(\n",
        "        [batch1[\"input_ids\"], batch2[\"input_ids\"]], dim=0)\n",
        "    position_ids = torch.concat(\n",
        "        [batch1[\"position_ids\"], batch2[\"position_ids\"]], dim=0)\n",
        "    attn_mask = torch.concat([attn_mask1, attn_mask2], dim=0)\n",
        "\n",
        "    past_kv = []\n",
        "    for i in range(len(padded_kv1)):\n",
        "        k1, v1 = padded_kv1[i]\n",
        "        k2, v2 = padded_kv2[i]\n",
        "        k = torch.concat([k1, k2], dim=0)\n",
        "        v = torch.concat([v1, v2], dim=0)\n",
        "        past_kv.append((k, v))\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"position_ids\": position_ids,\n",
        "        \"attention_mask\": attn_mask,\n",
        "        \"past_key_values\": past_kv,\n",
        "        \"responses\": batch1[\"responses\"] + batch2[\"responses\"],\n",
        "        \"tokens_remaining\": batch1[\"tokens_remaining\"] + batch2[\"tokens_remaining\"],\n",
        "    }\n",
        "\n",
        "\n",
        "def filter_batch(batch):\n",
        "    # mark all rows with 0 tokens remaining for removal\n",
        "    remove_indices = []\n",
        "    for i, tokens_remaining in enumerate(batch[\"tokens_remaining\"]):\n",
        "        if tokens_remaining <= 0:\n",
        "            remove_indices.append(i)\n",
        "\n",
        "    # first, define a mask used to subselect the indices to keep\n",
        "    # from each tensor, given the indices to remove\n",
        "    batch_size = batch[\"input_ids\"].size(0)\n",
        "    mask = torch.ones(batch_size, dtype=torch.bool)\n",
        "    mask[remove_indices] = False\n",
        "\n",
        "    # index into the tensors using the mask to remove rows\n",
        "    input_ids = batch[\"input_ids\"][mask]\n",
        "    position_ids = batch[\"position_ids\"][mask]\n",
        "    attention_mask = batch[\"attention_mask\"][mask]\n",
        "    responses = [\n",
        "        r\n",
        "        for i, r in enumerate(batch[\"responses\"])\n",
        "        if i not in remove_indices\n",
        "    ]\n",
        "    tokens_remaining = [\n",
        "        v\n",
        "        for i, v in enumerate(batch[\"tokens_remaining\"])\n",
        "        if i not in remove_indices\n",
        "    ]\n",
        "\n",
        "    past_key_values = batch[\"past_key_values\"]\n",
        "    new_past_key_values = []\n",
        "    for i in range(len(past_key_values)):\n",
        "        k, v = past_key_values[i]\n",
        "        k = k[mask]\n",
        "        v = v[mask]\n",
        "        new_past_key_values.append((k, v))\n",
        "    past_key_values = new_past_key_values\n",
        "\n",
        "    if input_ids.size(0) > 0:\n",
        "        # next, as an optimization to avoid wasting\n",
        "        # compute cycles on padding tokens,\n",
        "        # we will left truncate the attention_mask\n",
        "        # and past_key_values to the longest\n",
        "        # remaining sequence length\n",
        "        # we obtain the longest sequence length by\n",
        "        # looking for the min first non-zero index\n",
        "        # of the attention mask\n",
        "        # cumprod ensures we stop accumulating when we see a 1\n",
        "        zero_mask = attention_mask == 0\n",
        "        cumprod = zero_mask.cumprod(dim=1)\n",
        "        leading_zeros_count = cumprod.sum(dim=1)\n",
        "        min_leading_zeros = torch.min(leading_zeros_count)\n",
        "        truncation_offset = min_leading_zeros.item()\n",
        "\n",
        "        # do the trunction\n",
        "        attention_mask = attention_mask[:, truncation_offset:]\n",
        "        past_key_values = past_key_values\n",
        "        new_past_key_values = []\n",
        "        for i in range(len(past_key_values)):\n",
        "            k, v = past_key_values[i]\n",
        "            k = k[:, :, truncation_offset:, :]\n",
        "            v = v[:, :, truncation_offset:, :]\n",
        "            new_past_key_values.append((k, v))\n",
        "        past_key_values = new_past_key_values\n",
        "\n",
        "    # return the new batch\n",
        "    return {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"position_ids\": position_ids,\n",
        "        \"attention_mask\": attention_mask,\n",
        "        \"past_key_values\": past_key_values,\n",
        "        \"responses\": responses,\n",
        "        \"tokens_remaining\": tokens_remaining,\n",
        "    }, remove_indices"
      ],
      "metadata": {
        "id": "x5ov2hCMulbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"openai-community/gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "A_9MmtdVu4ST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Add padding tokens to the model to prepare batches of prompts**"
      ],
      "metadata": {
        "id": "7U-tRkXTu8V6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define PAD Token = EOS Token = 50256\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model.config.pad_token_id = model.config.eos_token_id\n",
        "\n",
        "# pad on the left so we can append new tokens on the right\n",
        "tokenizer.padding_side = \"left\"\n",
        "tokenizer.truncation_side = \"left\""
      ],
      "metadata": {
        "id": "j-1bgXdYu9MD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# multiple prompts of varying lengths to send to the model at once\n",
        "prompts = [\n",
        "    \"The quick brown fox jumped over the\",\n",
        "    \"The rain in Spain falls\",\n",
        "    \"What comes up must\",\n",
        "]\n",
        "\n",
        "# note: padding=True ensures the padding token will be inserted into the tokenized tensors\n",
        "inputs = tokenizer(prompts, padding=True, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "x8CFr46hu9h3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define needed functions for batching**"
      ],
      "metadata": {
        "id": "uOzK2hyEvB9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_batch_tokens_with_past(inputs):\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    last_logits = logits[:, -1, :]\n",
        "    next_token_ids = last_logits.argmax(dim=1)\n",
        "    return next_token_ids, outputs.past_key_values\n",
        "\n",
        "\n",
        "def generate_batch(inputs, max_tokens):\n",
        "    # create a list of tokens for every input in the batch\n",
        "    generated_tokens = [[] for _ in range(inputs[\"input_ids\"].shape[0])]\n",
        "\n",
        "    attention_mask = inputs[\"attention_mask\"]\n",
        "    position_ids = attention_mask.long().cumsum(-1) - 1\n",
        "    position_ids.masked_fill_(attention_mask == 0, 1)\n",
        "\n",
        "    next_inputs = {\n",
        "        \"position_ids\": position_ids,\n",
        "        **inputs\n",
        "    }\n",
        "    for _ in range(max_tokens):\n",
        "        next_token_ids, past_key_values = generate_batch_tokens_with_past(next_inputs)\n",
        "        next_inputs = {\n",
        "            \"input_ids\": next_token_ids.reshape((-1, 1)),  # '-1' here means the remaining elements for this dim\n",
        "            \"position_ids\": next_inputs[\"position_ids\"][:, -1].unsqueeze(-1) + 1,  # increment last, discard the rest\n",
        "            \"attention_mask\": torch.cat([\n",
        "                next_inputs[\"attention_mask\"],\n",
        "                torch.ones((next_token_ids.shape[0], 1)),  # concatenate vector of 1's with shape [batch_size]\n",
        "            ], dim=1),\n",
        "            \"past_key_values\": past_key_values,\n",
        "        }\n",
        "\n",
        "        next_tokens = tokenizer.batch_decode(next_token_ids)\n",
        "        for i, token in enumerate(next_tokens):\n",
        "            generated_tokens[i].append(token)\n",
        "    return [\"\".join(tokens) for tokens in generated_tokens]"
      ],
      "metadata": {
        "id": "ZPlZE6Ryu9a-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the requests to be processed**"
      ],
      "metadata": {
        "id": "Xtk4tIA_vFwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# seed the random number generator so our results are deterministic\n",
        "random.seed(42)\n",
        "\n",
        "# constants\n",
        "queue_size = 32\n",
        "batch_size = 8\n",
        "\n",
        "# requests waiting to be processed\n",
        "# requests are tuples (prompt, max_tokens)\n",
        "request_queue = [\n",
        "    (prompts[0], 100 if i % batch_size == 0 else 10)\n",
        "    for i in range(queue_size)\n",
        "]"
      ],
      "metadata": {
        "id": "VBl6EVa_u9X2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "request_queue[:8]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ab2G8KymvGbu",
        "outputId": "92cbace0-996f-4311-b982-5506e933f743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The quick brown fox jumped over the', 100),\n",
              " ('The quick brown fox jumped over the', 10),\n",
              " ('The quick brown fox jumped over the', 10),\n",
              " ('The quick brown fox jumped over the', 10),\n",
              " ('The quick brown fox jumped over the', 10),\n",
              " ('The quick brown fox jumped over the', 10),\n",
              " ('The quick brown fox jumped over the', 10),\n",
              " ('The quick brown fox jumped over the', 10)]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batches = [\n",
        "    request_queue[i:i + batch_size]\n",
        "    for i in range(0, len(request_queue), batch_size)\n",
        "]"
      ],
      "metadata": {
        "id": "ajR2_IeIvGhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(batches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhLbMO9LvGeu",
        "outputId": "89262081-b5de-415b-bccc-a9929837ca14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batches[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrcA1W2ivJsQ",
        "outputId": "a5d9412e-7027-4e6f-c559-9aae046b73f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The quick brown fox jumped over the', 100),\n",
              " ('The quick brown fox jumped over the', 10),\n",
              " ('The quick brown fox jumped over the', 10),\n",
              " ('The quick brown fox jumped over the', 10),\n",
              " ('The quick brown fox jumped over the', 10),\n",
              " ('The quick brown fox jumped over the', 10),\n",
              " ('The quick brown fox jumped over the', 10),\n",
              " ('The quick brown fox jumped over the', 10)]"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Processing batches**"
      ],
      "metadata": {
        "id": "n_dnXqvFvMal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate tokens for all batches and record duration\n",
        "t0 = time.time()\n",
        "with tqdm(total=len(batches), desc=f\"bs={batch_size}\") as pbar:\n",
        "    for i, batch in enumerate(batches):\n",
        "        # to accommodate all the requests with our\n",
        "        # current implementation, we take the max of\n",
        "        # all the tokens to generate among the requests\n",
        "        batch_max_tokens = [b[1] for b in batch]\n",
        "        max_tokens = max(batch_max_tokens)\n",
        "        pbar.set_postfix({'max_tokens': max_tokens})\n",
        "\n",
        "        batch_prompts = [b[0] for b in batch]\n",
        "        inputs = tokenizer(\n",
        "            batch_prompts, padding=True, return_tensors=\"pt\")\n",
        "        generate_batch(inputs, max_tokens=max_tokens)\n",
        "\n",
        "        pbar.update(1)\n",
        "\n",
        "duration_s = time.time() - t0\n",
        "print(\"duration\", duration_s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPTXplYWvJpX",
        "outputId": "bf95b542-0e61-45a7-a34c-33e7043501dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "bs=8: 100%|██████████| 4/4 [00:49<00:00, 12.41s/it, max_tokens=100]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "duration 49.65493988990784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's try continuous batching**\n",
        "\n",
        "- This time, rather than processing each batch to completion, you will use continuous batching to dynamically swap in and out inputs from the queue."
      ],
      "metadata": {
        "id": "ipqeWxw-vPid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# seed the random number generator so our results are deterministic\n",
        "random.seed(42)\n",
        "\n",
        "# constants\n",
        "queue_size = 32\n",
        "batch_size = 8\n",
        "\n",
        "# requests waiting to be processed\n",
        "# this time requests are tuples (prompt, max_tokens)\n",
        "request_queue = [\n",
        "    (prompts[0], 100 if i % batch_size == 0 else 10)\n",
        "    for i in range(queue_size)\n",
        "]\n",
        "\n",
        "t0 = time.time()\n",
        "with tqdm(total=len(request_queue), desc=f\"bs={batch_size}\") as pbar:\n",
        "    # first, let's seed the initial cached_batch\n",
        "    # with the first `batch_size` inputs\n",
        "    # and run the initial prefill step\n",
        "    batch = init_batch(request_queue[:batch_size])\n",
        "    cached_batch = generate_next_token(batch)\n",
        "    request_queue = request_queue[batch_size:]\n",
        "\n",
        "    # continue until both the request queue is\n",
        "    # fully drained and every input\n",
        "    # within the cached_batch has completed generation\n",
        "    while (\n",
        "        len(request_queue) > 0 or\n",
        "        cached_batch[\"input_ids\"].size(0) > 0\n",
        "    ):\n",
        "        batch_capacity = (\n",
        "            batch_size - cached_batch[\"input_ids\"].size(0)\n",
        "        )\n",
        "        if batch_capacity > 0 and len(request_queue) > 0:\n",
        "            # prefill\n",
        "            new_batch = init_batch(request_queue[:batch_capacity])\n",
        "            new_batch = generate_next_token(new_batch)\n",
        "            request_queue = request_queue[batch_capacity:]\n",
        "\n",
        "            # merge\n",
        "            cached_batch = merge_batches(cached_batch, new_batch)\n",
        "\n",
        "        # decode\n",
        "        cached_batch = generate_next_token(cached_batch)\n",
        "\n",
        "        # remove any inputs that have finished generation\n",
        "        cached_batch, removed_indices = filter_batch(cached_batch)\n",
        "        pbar.update(len(removed_indices))\n",
        "\n",
        "duration_s = time.time() - t0\n",
        "print(\"duration\", duration_s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31Qxkb11vJma",
        "outputId": "2832d8e1-5cbf-4d1a-ed7d-07f1f0b46a90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "bs=8: 100%|██████████| 32/32 [00:18<00:00,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "duration 18.821728467941284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantization"
      ],
      "metadata": {
        "id": "MPwF3Y_PV3T0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from transformers.models.gpt2.modeling_gpt2 import GPT2Model"
      ],
      "metadata": {
        "id": "nvJkvP9CV5yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"openai-community/gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "FVkXyultV9YL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_batch_tokens_with_past(model, inputs):\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    last_logits = logits[:, -1, :]\n",
        "    next_token_ids = last_logits.argmax(dim=1)\n",
        "    return next_token_ids, outputs.past_key_values\n",
        "\n",
        "def init_batch(tokenizer, requests):\n",
        "    prompts = [r[0] for r in requests]\n",
        "    inputs = tokenizer(prompts, padding=True, return_tensors=\"pt\")\n",
        "\n",
        "    attention_mask = inputs[\"attention_mask\"]\n",
        "    position_ids = attention_mask.long().cumsum(-1) - 1\n",
        "    position_ids.masked_fill_(attention_mask == 0, 1)\n",
        "\n",
        "    return {\n",
        "        \"position_ids\": position_ids,\n",
        "        \"responses\": copy.copy(prompts),\n",
        "        \"tokens_remaining\": [r[1] for r in requests],\n",
        "        **inputs\n",
        "    }\n",
        "\n",
        "def filter_batch(batch):\n",
        "    # mark all rows with 0 tokens remaining for removal\n",
        "    remove_indices = []\n",
        "    for i, tokens_remaining in enumerate(batch[\"tokens_remaining\"]):\n",
        "        if tokens_remaining <= 0:\n",
        "            remove_indices.append(i)\n",
        "\n",
        "    completed_responses = [\n",
        "        r\n",
        "        for i, r in enumerate(batch[\"responses\"])\n",
        "        if i in remove_indices\n",
        "    ]\n",
        "\n",
        "    # first, define a mask used to subselect the indices to keep\n",
        "    # from each tensor, given the indices to remove\n",
        "    batch_size = batch[\"input_ids\"].size(0)\n",
        "    mask = torch.ones(batch_size, dtype=torch.bool)\n",
        "    mask[remove_indices] = False\n",
        "\n",
        "    # index into the tensors using the mask to remove rows\n",
        "    input_ids = batch[\"input_ids\"][mask]\n",
        "    position_ids = batch[\"position_ids\"][mask]\n",
        "    attention_mask = batch[\"attention_mask\"][mask]\n",
        "    responses = [\n",
        "        r\n",
        "        for i, r in enumerate(batch[\"responses\"])\n",
        "        if i not in remove_indices\n",
        "    ]\n",
        "    tokens_remaining = [\n",
        "        v\n",
        "        for i, v in enumerate(batch[\"tokens_remaining\"])\n",
        "        if i not in remove_indices\n",
        "    ]\n",
        "\n",
        "    past_key_values = batch[\"past_key_values\"]\n",
        "    new_past_key_values = []\n",
        "    for i in range(len(past_key_values)):\n",
        "        k, v = past_key_values[i]\n",
        "        k = k[mask]\n",
        "        v = v[mask]\n",
        "        new_past_key_values.append((k, v))\n",
        "    past_key_values = new_past_key_values\n",
        "\n",
        "    if input_ids.size(0) > 0:\n",
        "        # next, as an optimization to avoid wasting compute cycles on padding tokens,\n",
        "        # we will left truncate the attention_mask and past_key_values to the longest\n",
        "        # remaining sequence length\n",
        "        # we obtain the longest sequence length by looking for the min first non-zero index\n",
        "        # of the attention mask\n",
        "        zero_mask = attention_mask == 0\n",
        "        cumprod = zero_mask.cumprod(dim=1)  # cumprod ensures we stop accumulating when we see a 1\n",
        "        leading_zeros_count = cumprod.sum(dim=1)\n",
        "        min_leading_zeros = torch.min(leading_zeros_count)\n",
        "        truncation_offset = min_leading_zeros.item()\n",
        "\n",
        "        # do the trunction\n",
        "        attention_mask = attention_mask[:, truncation_offset:]\n",
        "        past_key_values = past_key_values\n",
        "        new_past_key_values = []\n",
        "        for i in range(len(past_key_values)):\n",
        "            k, v = past_key_values[i]\n",
        "            k = k[:, :, truncation_offset:, :]\n",
        "            v = v[:, :, truncation_offset:, :]\n",
        "            new_past_key_values.append((k, v))\n",
        "        past_key_values = new_past_key_values\n",
        "\n",
        "    # return the new batch\n",
        "    return {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"position_ids\": position_ids,\n",
        "        \"attention_mask\": attention_mask,\n",
        "        \"past_key_values\": past_key_values,\n",
        "        \"responses\": responses,\n",
        "        \"tokens_remaining\": tokens_remaining,\n",
        "    }, remove_indices, completed_responses\n",
        "\n",
        "def generate_next_token(model, tokenizer, batch):\n",
        "    inputs = copy.copy(batch)\n",
        "    inputs.pop(\"responses\")\n",
        "    inputs.pop(\"tokens_remaining\")\n",
        "\n",
        "    next_token_ids, past_key_values = generate_batch_tokens_with_past(model, inputs)\n",
        "    next_tokens = tokenizer.batch_decode(next_token_ids)\n",
        "    return get_next_inputs(batch, next_token_ids, past_key_values, next_tokens)\n",
        "\n",
        "def generate(model, tokenizer, requests):\n",
        "    # seed the random number generator so our results are deterministic\n",
        "    random.seed(42)\n",
        "\n",
        "    # constants\n",
        "    batch_size = 8\n",
        "    request_queue = copy.copy(requests)\n",
        "\n",
        "    responses = [None] * len(requests)\n",
        "\n",
        "    # and run the initial prefill step\n",
        "    batch = init_batch(tokenizer, request_queue[:batch_size])\n",
        "    cached_batch = generate_next_token(model, tokenizer, batch)\n",
        "    request_queue = request_queue[batch_size:]\n",
        "\n",
        "    # continue until both the request queue is fully drained and every input\n",
        "    # within the cached_batch has completed generation\n",
        "    while len(request_queue) > 0 or cached_batch[\"input_ids\"].size(0) > 0:\n",
        "        batch_capacity = batch_size - cached_batch[\"input_ids\"].size(0)\n",
        "        if batch_capacity > 0 and len(request_queue) > 0:\n",
        "            # prefill\n",
        "            new_batch = init_batch(tokenizer, request_queue[:batch_capacity])\n",
        "            new_batch = generate_next_token(model, tokenizer, new_batch)\n",
        "            request_queue = request_queue[batch_capacity:]\n",
        "\n",
        "            # merge\n",
        "            cached_batch = merge_batches(cached_batch, new_batch)\n",
        "\n",
        "        # decode\n",
        "        cached_batch = generate_next_token(model, tokenizer, cached_batch)\n",
        "\n",
        "        # remove any inputs that have finished generation\n",
        "        cached_batch, removed_indices, completed_responses = filter_batch(cached_batch)\n",
        "\n",
        "        for idx, resp in zip(removed_indices, completed_responses):\n",
        "            responses[idx] = resp\n",
        "\n",
        "    return responses"
      ],
      "metadata": {
        "id": "TKy0xqMRWTYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define PAD Token = EOS Token = 50256\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model.config.pad_token_id = model.config.eos_token_id\n",
        "\n",
        "# pad on the left so we can append new tokens on the right\n",
        "tokenizer.padding_side = \"left\"\n",
        "tokenizer.truncation_side = \"left\""
      ],
      "metadata": {
        "id": "pimqk25XWXdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define a Float 32 type**"
      ],
      "metadata": {
        "id": "DbQxW8YwV5fQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fix dtype post quantization to \"pretend\" to be fp32\n",
        "def get_float32_dtype(self):\n",
        "    return torch.float32\n",
        "GPT2Model.dtype = property(get_float32_dtype)"
      ],
      "metadata": {
        "id": "z-zBXj3NW0gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_memory_footprint()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGrwwir_W0Gp",
        "outputId": "873872d5-454f-4da0-d0e4-730666bece6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "510342192"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define a quantization function**"
      ],
      "metadata": {
        "id": "qTntNIyIW1EH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def quantize(t):\n",
        "    # obtain range of values in the tensor to map between 0 and 255\n",
        "    min_val, max_val = t.min(), t.max()\n",
        "\n",
        "    # determine the \"zero-point\", or value in the tensor to map to 0\n",
        "    scale = (max_val - min_val) / 255\n",
        "    zero_point = min_val\n",
        "\n",
        "    # quantize and clamp to ensure we're in [0, 255]\n",
        "    t_quant = (t - zero_point) / scale\n",
        "    t_quant = torch.clamp(t_quant, min=0, max=255)\n",
        "\n",
        "    # keep track of scale and zero_point for reversing quantization\n",
        "    state = (scale, zero_point)\n",
        "\n",
        "    # cast to uint8 and return\n",
        "    t_quant = t_quant.type(torch.uint8)\n",
        "    return t_quant, state"
      ],
      "metadata": {
        "id": "wSUvIYQqW1X-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = model.transformer.h[0].attn.c_attn.weight.data\n",
        "print(t, t.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eKqI82mW1qs",
        "outputId": "61dc450e-2861-4529-851d-eb5209cf8750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4738, -0.2614, -0.0978,  ...,  0.0513, -0.0584,  0.0250],\n",
            "        [ 0.0874,  0.1473,  0.2387,  ..., -0.0525, -0.0113, -0.0156],\n",
            "        [ 0.0039,  0.0695,  0.3668,  ...,  0.1143,  0.0363, -0.0318],\n",
            "        ...,\n",
            "        [-0.2592, -0.0164,  0.1991,  ...,  0.0095, -0.0516,  0.0319],\n",
            "        [ 0.1517,  0.2170,  0.1043,  ...,  0.0293, -0.0429, -0.0475],\n",
            "        [-0.4100, -0.1924, -0.2400,  ..., -0.0046,  0.0070,  0.0198]]) torch.Size([768, 2304])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_q, state = quantize(t)\n",
        "print(t_q, t_q.min(), t_q.max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwtUYdwQW-d1",
        "outputId": "9223bcd4-1a08-4813-807f-3cf5c57104ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[107, 116, 124,  ..., 130, 125, 129],\n",
            "        [132, 135, 139,  ..., 126, 128, 127],\n",
            "        [128, 131, 145,  ..., 133, 130, 127],\n",
            "        ...,\n",
            "        [116, 127, 137,  ..., 129, 126, 130],\n",
            "        [135, 138, 133,  ..., 129, 126, 126],\n",
            "        [110, 119, 117,  ..., 128, 128, 129]], dtype=torch.uint8) tensor(0, dtype=torch.uint8) tensor(255, dtype=torch.uint8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define a dequantization function**"
      ],
      "metadata": {
        "id": "57V7M14QW_FN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dequantize(t, state):\n",
        "    scale, zero_point = state\n",
        "    return t.to(torch.float32) * scale + zero_point"
      ],
      "metadata": {
        "id": "wg_fxSPlXBMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_rev = dequantize(t_q, state)\n",
        "print(t_rev)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wFjyvA4XCyN",
        "outputId": "6c5e0ed6-7efc-4942-d8ba-50096ca15477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4774, -0.2783, -0.1014,  ...,  0.0313, -0.0793,  0.0092],\n",
            "        [ 0.0755,  0.1419,  0.2303,  ..., -0.0572, -0.0129, -0.0351],\n",
            "        [-0.0129,  0.0534,  0.3630,  ...,  0.0976,  0.0313, -0.0351],\n",
            "        ...,\n",
            "        [-0.2783, -0.0351,  0.1861,  ...,  0.0092, -0.0572,  0.0313],\n",
            "        [ 0.1419,  0.2082,  0.0976,  ...,  0.0092, -0.0572, -0.0572],\n",
            "        [-0.4110, -0.2120, -0.2562,  ..., -0.0129, -0.0129,  0.0092]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.abs(t - t_rev)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_eBIh6EXDnz",
        "outputId": "f1a299ea-9962-475b-9ea3-dc87ddae7b88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0035, 0.0170, 0.0036,  ..., 0.0200, 0.0209, 0.0158],\n",
              "        [0.0119, 0.0055, 0.0084,  ..., 0.0046, 0.0017, 0.0195],\n",
              "        [0.0168, 0.0161, 0.0038,  ..., 0.0167, 0.0050, 0.0032],\n",
              "        ...,\n",
              "        [0.0191, 0.0187, 0.0131,  ..., 0.0004, 0.0056, 0.0006],\n",
              "        [0.0098, 0.0088, 0.0067,  ..., 0.0202, 0.0143, 0.0097],\n",
              "        [0.0010, 0.0196, 0.0162,  ..., 0.0084, 0.0199, 0.0107]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_expected = generate(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    [(\"The quick brown fox jumped over the\", 10)]\n",
        ")[0]\n",
        "response_expected"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "IaYS8d4NXEhT",
        "outputId": "73b69b24-d60f-4c9a-f196-1d37540d8687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The quick brown fox jumped over the fence and ran to the other side of the fence'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's apply the quantization technique to the entire model**"
      ],
      "metadata": {
        "id": "yxqtoruQXHJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def quantize_model(model):\n",
        "    states = {}\n",
        "    for name, param in model.named_parameters():\n",
        "        param.requires_grad = False\n",
        "        param.data, state = quantize(param.data)\n",
        "        states[name] = state\n",
        "    return model, states"
      ],
      "metadata": {
        "id": "Srdig9CgXHwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quant_model, states = quantize_model(model)"
      ],
      "metadata": {
        "id": "G060ZHJtXIKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quant_model.get_memory_footprint()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRTKQdKEXIFH",
        "outputId": "a192bc8b-58df-4ece-9d3f-2e434800108b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "137022768"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def size_in_bytes(t):\n",
        "    return t.numel() * t.element_size()"
      ],
      "metadata": {
        "id": "AUJBKnHvXICP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum([\n",
        "    size_in_bytes(v[0]) + size_in_bytes(v[1])\n",
        "    for v in states.values()\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szk9fDCWXH_h",
        "outputId": "3d5197a1-f4b1-42f7-d697-3abb1fabca5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1184"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dequantize_model(model, states):\n",
        "    for name, param in model.named_parameters():\n",
        "        state = states[name]\n",
        "        param.data = dequantize(param.data, state)\n",
        "    return model"
      ],
      "metadata": {
        "id": "qEiMbBRRXH76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dequant_model = dequantize_model(quant_model, states)"
      ],
      "metadata": {
        "id": "kugDZMfuXODO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dequant_model.get_memory_footprint()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xehRqGaFXOAk",
        "outputId": "676ffb0d-32c3-439a-999d-b8929f207f19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "510342192"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_expected = generate(\n",
        "    dequant_model,\n",
        "    tokenizer,\n",
        "    [(\"The quick brown fox jumped over the\", 10)]\n",
        ")[0]\n",
        "response_expected"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "lRpz2QZUXN90",
        "outputId": "ee08ce38-d9cf-425a-8429-16a6259bb5ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The quick brown fox jumped over the fence.\\n\\nThe fox jumped over the fence'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tuning"
      ],
      "metadata": {
        "id": "s8tRQu9eS9Yv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameter-Efficient Fine-Tuning (PEFT)"
      ],
      "metadata": {
        "id": "-WFpUVghVoad"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **PEFT**: Parameter-Efficient Fine-Tuning of billion-scale models on low-resource hardware. It freezes most parameters of a pre-trained\n",
        "\n"
      ],
      "metadata": {
        "id": "rOPTk5ixVpI5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adapter Tuning\n",
        "\n",
        "Fine-tuning involves copying the weights from a pre-trained network and tuning them on the downstream task (a new set of weights for each task).\n",
        "\n",
        "Multi-task learning requires simultaneous access to all tasks (memory intense).\n",
        "\n",
        "\n",
        "**Adapters** yield \"**parameter-efficient tuning**\" for NLP.\n",
        "It permits training on tasks **sequentially**!\n",
        "\n",
        "Tuning with adapter modules involves adding a small number of new parameters to a model, which are trained on the downstream task.\n",
        "\n",
        "In **adapter-tuning**, the parameters of the original network are **frozen** and therefore may be shared by many tasks."
      ],
      "metadata": {
        "id": "8T4beGTiWInB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AdapterFusion\n",
        "\n",
        "Sequential fine-tuning and multi-task learning are methods aiming to incorporate knowledge from multiple tasks; however, they suffer from **catastrophic forgetting and difficulties in dataset balancing**. To address these shortcomings, AdapterFusion, a new two stage learning algorithm that leverages knowledge from multiple tasks was proposed.\n",
        "\n",
        "Example, if you have 100 dataset, and 100 tasks, after lots of sequential fine-tuning the model might overwrite what it has learned.\n",
        "\n",
        "In this appraoch, each dataset has its own adapters. And there's one AdapterFusion layer for all.\n",
        "\n",
        "![adapterfusion architecture#](https://voicelab.ai/wp-content/uploads/obraz9.png)"
      ],
      "metadata": {
        "id": "p0rZtDfybRt8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Low-Rank Adaptation (LoRA)\n",
        "\n",
        "Goal: Loading a large model into a GPU with lower VRAM and being able to do calculations.\n",
        "\n",
        "\n",
        "\n",
        "> **LoRA**: Low-Rank Adaptation, a random projection to a smaller subspace. Freezes pre-trained model weights and injects trainable rank decomposition matrices inot each layer of Transformer"
      ],
      "metadata": {
        "id": "ssTHZig_CFSb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**LoRA**\n",
        "\n",
        "$$\n",
        "W_0 + \\Delta W = W_o + BA\n",
        "$$\n",
        "\n",
        "Where:\n",
        "- $W_0$ Original untouch model weights\n",
        "- $B$ Low rank matrix, $B \\in R^{dxr}$, $B$ is set to zero\n",
        "- $A$ Low rank matrix, $A \\in R^{rxk}$, $A$ is sampled from Normal Distribution\n",
        "  - rank r << min(d,k)\n",
        "\n",
        "In the Forward Pass:\n",
        "\n",
        "$$\n",
        "h = W_0x+\\Delta Wx = W_0x+ BAx \\\\\n",
        "$$"
      ],
      "metadata": {
        "id": "o0E47CuMTjHx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BA is acheived through SVD compression\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "M &= USV^T \\\\\n",
        "&= (US)V^T \\\\\n",
        "&= LR^T, \\text{ where} \\\\\n",
        "L &= (US), \\text{ and} \\\\\n",
        "R &= V\n",
        "\\end{align*}\n",
        "$$"
      ],
      "metadata": {
        "id": "WNJhQZdPxonl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "def regular_forward_matmul(x, W):\n",
        "  h = x @ W\n",
        "  return h\n",
        "\n",
        "def lora_forward_matmul(x, W, W_A, W_B):\n",
        "  h = x @ W # regular matrix multiplication\n",
        "  h += x @ (W_A @ W_B)*alpha # use scaled LoRA weights\n",
        "  return h\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "9Jmkp6KIDeak"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$BA$ is scaled by $\\frac{\\alpha}{r}$\n",
        "\n",
        "- $r$: The intrinsic dimension, which means to what extent we want to decompose the matrices. Typical numbers range from 1 to 64, and express the amount of compression on the weights.\n",
        "\n",
        "- $\\alpha$: Scaling factor. It controls the amount of change that is added to the original model weights. Using zero will output the original model, and using 1 will output the fully fine-tuned model, and anything larger will be amplifying it's effect."
      ],
      "metadata": {
        "id": "mK6-zqGZERSa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementing LoRA"
      ],
      "metadata": {
        "id": "nUppikWVgfwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "YX7vbJ8wgo2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set the seed so we get the same results from here on for each run\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpP5uEAsgsTH",
        "outputId": "f4e0e400-d1fa-42e3-8b06-4d31755b4256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x78ee5023d790>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create a test Model**"
      ],
      "metadata": {
        "id": "nmtkx277guJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TestModel(torch.nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super().__init__()\n",
        "        self.embedding = torch.nn.Embedding(10, hidden_size)\n",
        "        self.linear = torch.nn.Linear(hidden_size, hidden_size)\n",
        "        self.lm_head = torch.nn.Linear(hidden_size, 10)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        x = self.embedding(input_ids)\n",
        "        x = self.linear(x)\n",
        "        x = self.lm_head(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "kRkhkhKQgvPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set a reasonably large hidden size to illustrate the small fraction of\n",
        "# params needed to be added for LoRA\n",
        "hidden_size = 1024\n",
        "model = TestModel(hidden_size)"
      ],
      "metadata": {
        "id": "z-N3zpNygwJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dummy inputs\n",
        "input_ids = torch.LongTensor([[0, 1, 2, 3, 4, 5, 6, 7]])"
      ],
      "metadata": {
        "id": "B8jhj6_MgxG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# toy example of a detokenizer.\n",
        "# The vocabulary only consists of 10 words (different colors)\n",
        "detokenizer = [\n",
        "    \"red\",\n",
        "    \"orange\",\n",
        "    \"yellow\",\n",
        "    \"green\",\n",
        "    \"blue\",\n",
        "    \"indigo\",\n",
        "    \"violet\",\n",
        "    \"magenta\",\n",
        "    \"marigold\",\n",
        "    \"chartreuse\",\n",
        "]"
      ],
      "metadata": {
        "id": "nSuDXOeXgyOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is the same generation step as we saw in lesson 2 (batching)\n",
        "def generate_token(model, **kwargs):\n",
        "    with torch.no_grad():\n",
        "        logits = model(**kwargs)\n",
        "    last_logits = logits[:, -1, :]\n",
        "    next_token_ids = last_logits.argmax(dim=1)\n",
        "\n",
        "    return [detokenizer[token_id] for token_id in next_token_ids]"
      ],
      "metadata": {
        "id": "YhRXw6iDgz-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate one token\n",
        "next_token = generate_token(model, input_ids=input_ids)[0]\n",
        "next_token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "w6aVMVNVg1Ob",
        "outputId": "6269e4c2-66b7-41c1-956e-797d10ed4c21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'magenta'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dummy input tensor\n",
        "# shape: (batch_size, sequence_length, hidden_size)\n",
        "X = torch.randn(1, 8, 1024)"
      ],
      "metadata": {
        "id": "i2z8curWg19h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's set up the LoRA computation¶**"
      ],
      "metadata": {
        "id": "lkUPJxpQg3g_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LoRA A and B tensors\n",
        "# A has shape (hidden_size, rank)\n",
        "# B has shape (rank, hidden_size)\n",
        "R=2 # hyperparameter rank\n",
        "lora_a = torch.randn(1024, R)\n",
        "lora_b = torch.randn(R, 1024)"
      ],
      "metadata": {
        "id": "c1yOnlIEg4eA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W = model.linear.weight"
      ],
      "metadata": {
        "id": "PWQ1PMiOg5QN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W89PWw9Og6Eq",
        "outputId": "84685e91-613a-45ed-9023-10d27ac9a926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1024, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W2 = lora_a @ lora_b"
      ],
      "metadata": {
        "id": "18dnESJTg67r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBntMY5eg71N",
        "outputId": "96d73225-1ef3-4f9c-e231-f0a15d701a68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1024, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare number of elements of A and B with number of elements of W\n",
        "# W here has shape (hidden_size, hidden_size)\n",
        "lora_numel = lora_a.numel() + lora_b.numel()\n",
        "base_numel = W.numel()\n",
        "print(\"|A+B| / |W|:\", lora_numel / base_numel)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7xenaUHg80E",
        "outputId": "95d9f85d-3c5a-4a4e-a3da-9d13c40a801c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|A+B| / |W|: 0.00390625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's run the LoRA computation"
      ],
      "metadata": {
        "id": "pxAcSa15g_v-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the output of X @ W (the original linear layer)\n",
        "base_output = model.linear(X)\n",
        "\n",
        "# compute the output of X @ A @ B (the added lora adapter)\n",
        "lora_output = X @ lora_a @ lora_b\n",
        "\n",
        "# sum them together\n",
        "total_output = base_output + lora_output\n",
        "\n",
        "# output should have the same shape as the original output:\n",
        "# (batch_size, sequence_length, hidden_size)\n",
        "total_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aWFfCqeg_Yd",
        "outputId": "92d8d13d-feb2-4682-c175-5fcadcd0bfd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LoraLayer(torch.nn.Module):\n",
        "    def __init__(self, base_layer, r):\n",
        "        super().__init__()\n",
        "        self.base_layer = base_layer\n",
        "\n",
        "        d_in, d_out = self.base_layer.weight.shape\n",
        "        self.lora_a = torch.randn(d_in, r)\n",
        "        self.lora_b = torch.randn(r, d_out)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y1 = self.base_layer(x)\n",
        "        y2 = x @ self.lora_a @ self.lora_b\n",
        "        return y1 + y2"
      ],
      "metadata": {
        "id": "pRyFXvE7hDg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wrap the linear layer of our toy model, use rank 2\n",
        "lora_layer = LoraLayer(model.linear, 2)\n",
        "lora_layer(X).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1ivmlz3hFNq",
        "outputId": "89600745-f162-4def-e831-aa27f4c76825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.linear = lora_layer"
      ],
      "metadata": {
        "id": "R0IbG82PhF-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sadii3J6hGuT",
        "outputId": "88353c01-b34f-4a26-ab8b-9cdbf08eeec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TestModel(\n",
              "  (embedding): Embedding(10, 1024)\n",
              "  (linear): LoraLayer(\n",
              "    (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1024, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's try the generate token after adding the LoRA layer**"
      ],
      "metadata": {
        "id": "RRx7_jFthIEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "next_token = generate_token(model, input_ids=input_ids)\n",
        "next_token[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "upfDqShUhJE8",
        "outputId": "7db42739-ab3b-4208-83e7-d050ad718935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'chartreuse'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementing Multi-LoRA"
      ],
      "metadata": {
        "id": "lnFGYyZskYxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "dMHBK7TlkdFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's create a new model**\n",
        "\n",
        "It has a custom helper function for computing the LoRA layer step with multiple LoRAs per batch."
      ],
      "metadata": {
        "id": "OUlrcpNekiQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AbstractMultiLoraModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # hidden_size = 10\n",
        "        # set this so low to ensure we are not\n",
        "        # compute-bound by the linear layer\n",
        "        # this is only an issue when running on CPU,\n",
        "        # for GPUs we can set this much\n",
        "        # higher and still avoid being compute bound\n",
        "        self.embedding = torch.nn.Embedding(10, 10)\n",
        "        self.linear = torch.nn.Linear(10, 10)\n",
        "        self.lm_head = torch.nn.Linear(10, 10)\n",
        "\n",
        "    def linear_lora(\n",
        "        self,\n",
        "        x: torch.Tensor,                 # (batch_size, seq_len, in_features)\n",
        "        loras_a: torch.Tensor,           # (num_loras, in_features, rank)\n",
        "        loras_b: torch.Tensor,           # (num_loras, rank, out_features)\n",
        "        lora_indices: torch.LongTensor,  # (batch_size,)\n",
        "    ) -> torch.Tensor:\n",
        "        # y[i] = x[i] @ loras_a[lora_idx] @ loras_b[lora_idx]\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def forward(self, input_ids, loras_a, loras_b, lora_indices):\n",
        "        x = self.embedding(input_ids)\n",
        "        x = self.linear_lora(x, loras_a, loras_b, lora_indices)\n",
        "        x = self.lm_head(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "y68kAcRdkdCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using a loop**\n",
        "\n",
        "Our first attempt to infer across multiple LoRAs will be straightforward: just loop over every row in the batch and apply the correct LoRA using an index mapping: `batch_index --> lora_index`."
      ],
      "metadata": {
        "id": "wcSpUg9wktW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LoopMultiLoraModel(AbstractMultiLoraModel):\n",
        "    def linear_lora(\n",
        "        self,\n",
        "        x: torch.Tensor,                 # (batch_size, seq_len, in_features)\n",
        "        loras_a: torch.Tensor,           # (num_loras, in_features, lora_rank)\n",
        "        loras_b: torch.Tensor,           # (num_loras, lora_rank, out_features)\n",
        "        lora_indices: torch.LongTensor,  # (batch_size,)\n",
        "    ) -> torch.Tensor:\n",
        "        y = self.linear(x)\n",
        "        for batch_idx, lora_idx in enumerate(lora_indices.numpy()):\n",
        "            lora_a = loras_a[lora_idx]\n",
        "            lora_b = loras_b[lora_idx]\n",
        "            y[batch_idx] += x[batch_idx] @ lora_a @ lora_b\n",
        "        return y"
      ],
      "metadata": {
        "id": "x-3hXibokc_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# toy example of a detokenizer. The vocabular only consists of 10 words (different colors)\n",
        "detokenizer = [\n",
        "    \"red\",\n",
        "    \"orange\",\n",
        "    \"yellow\",\n",
        "    \"green\",\n",
        "    \"blue\",\n",
        "    \"indigo\",\n",
        "    \"violet\",\n",
        "    \"magenta\",\n",
        "    \"marigold\",\n",
        "    \"chartreuse\",\n",
        "]"
      ],
      "metadata": {
        "id": "EEZMjEBLkc8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dummy inputs\n",
        "input_ids = torch.LongTensor([[0, 1, 2, 3, 4, 5, 6, 7]])"
      ],
      "metadata": {
        "id": "fz768s51kc5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8J3WHuJkc2G",
        "outputId": "04a1a9fc-4860-4644-a133-af9aa773f763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x78ee5023d790>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_token(model, **kwargs):\n",
        "    with torch.no_grad():\n",
        "        logits = model(**kwargs)\n",
        "    last_logits = logits[:, -1, :]\n",
        "    next_token_ids = last_logits.argmax(dim=1)\n",
        "\n",
        "    return [detokenizer[token_id] for token_id in next_token_ids]"
      ],
      "metadata": {
        "id": "SHOAkWsmkplD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LoopMultiLoraModel()"
      ],
      "metadata": {
        "id": "YL4_gRDukpi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's try it!**\n",
        "\n",
        "We will try this over a few random LoRAs using a fixed tensor of input_ids. If our multi-LoRA generation process is working as designed, we should see a variety of different outputs generated as we randomly iterate over the LoRAs."
      ],
      "metadata": {
        "id": "Nmlb5Lojkx-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# constants\n",
        "bs = 1\n",
        "num_loras = 64\n",
        "h = 10\n",
        "r = 2\n",
        "\n",
        "# create contiguous blocks for 64 random LoRA weights\n",
        "loras_a = torch.randn(num_loras, h, r)\n",
        "loras_b = torch.randn(num_loras, r, h)\n",
        "\n",
        "for i in range(10):\n",
        "    # randomize the LoRAs each iteration\n",
        "    lora_indices = torch.randint(num_loras, (bs,), dtype=torch.long)\n",
        "    next_token = generate_token(\n",
        "        model,\n",
        "        input_ids=input_ids,\n",
        "        loras_a=loras_a,\n",
        "        loras_b=loras_b,\n",
        "        lora_indices=lora_indices,\n",
        "    )\n",
        "    print(next_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hf3eHH96k0B6",
        "outputId": "44a6b33f-2a64-4334-d5ae-fa50fa9675c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['orange']\n",
            "['red']\n",
            "['chartreuse']\n",
            "['yellow']\n",
            "['marigold']\n",
            "['yellow']\n",
            "['red']\n",
            "['orange']\n",
            "['violet']\n",
            "['red']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's benchmark our multi-LoRA system!**\n",
        "\n",
        "We will measure the average latency to generate a single token as the batch size increases and each element within the batch can have a different LoRA adapter (chosen randomly)."
      ],
      "metadata": {
        "id": "cLfLyCQlk18r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# constants\n",
        "seq_len = 8\n",
        "vocab_size = 10\n",
        "nsamples = 500\n",
        "max_batch_size = 64\n",
        "\n",
        "\n",
        "def benchmark(model):\n",
        "    avg_latencies = []\n",
        "    for bs in range(1, max_batch_size + 1):\n",
        "        latencies = []\n",
        "        for _ in range(nsamples):\n",
        "            # randomize the inputs and LoRA indices\n",
        "            input_ids = torch.randint(\n",
        "                vocab_size, (bs, seq_len), dtype=torch.long)\n",
        "            lora_indices = torch.randint(\n",
        "                num_loras, (bs,), dtype=torch.long)\n",
        "\n",
        "            # measure the end-to-end latency for\n",
        "            # generating a single token\n",
        "            t0 = time.time()\n",
        "            next_token = generate_token(\n",
        "                model,\n",
        "                input_ids=input_ids,\n",
        "                loras_a=loras_a,\n",
        "                loras_b=loras_b,\n",
        "                lora_indices=lora_indices,\n",
        "            )\n",
        "            latencies.append(time.time() - t0)\n",
        "\n",
        "        # average the latency across all the samples\n",
        "        latency_s = sum(latencies) / len(latencies)\n",
        "        avg_latencies.append(latency_s)\n",
        "        print(bs, latency_s)\n",
        "    return avg_latencies"
      ],
      "metadata": {
        "id": "SiTOpE8Fk38C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_latencies_loop = benchmark(model)"
      ],
      "metadata": {
        "id": "IXq8cXM2k35P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's visualize it!**"
      ],
      "metadata": {
        "id": "Px-0gJ9Ek7SU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = list(range(1, max_batch_size + 1))\n",
        "plt.plot(x, avg_latencies_loop, label=\"loop\")\n",
        "\n",
        "plt.xlabel('Batch Size')\n",
        "plt.ylabel('Avg Latency (s)')\n",
        "plt.title('Multi-LoRA latency w.r.t. batch size')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "NCxfb4NEk3eO",
        "outputId": "390b284a-61f0-4e2e-81b2-bf46063c8868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's vectorize the LoRA computation**\n",
        "\n",
        "We will vectorize the LoRA computation by:\n",
        "\n",
        "1. Gather the LoRA weight for each batch into a single tensor using `torch.index_select`.\n",
        "2. Apply LoRA computation once for the entire input tensor."
      ],
      "metadata": {
        "id": "NlTH7jF9k-d2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GatheredMultiLoraModel(AbstractMultiLoraModel):\n",
        "    def linear_lora(\n",
        "        self,\n",
        "        x: torch.Tensor,                 # (batch_size, seq_len, in_features)\n",
        "        loras_a: torch.Tensor,           # (num_loras, in_features, lora_rank)\n",
        "        loras_b: torch.Tensor,           # (num_loras, lora_rank, out_features)\n",
        "        lora_indices: torch.LongTensor,  # (batch_size,)\n",
        "    ) -> torch.Tensor:\n",
        "        y = self.linear(x)\n",
        "\n",
        "        # gather the LoRA weights into a new tensor and apply\n",
        "        lora_a = torch.index_select(loras_a, 0, lora_indices) # (batch_size, in_features, lora_rank)\n",
        "        lora_b = torch.index_select(loras_b, 0, lora_indices) # (batch_size, lora_rank, out_features)\n",
        "        y += x @ lora_a @ lora_b\n",
        "        return y"
      ],
      "metadata": {
        "id": "EwBEM1eJlAni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GatheredMultiLoraModel()"
      ],
      "metadata": {
        "id": "YLQw5tCklCwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_latencies_gathered = benchmark(model)"
      ],
      "metadata": {
        "id": "8usyKGhFlDwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's visualize it!**"
      ],
      "metadata": {
        "id": "9SQDHFqelFU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = list(range(1, max_batch_size + 1))\n",
        "plt.plot(x, avg_latencies_loop, label=\"loop\")\n",
        "plt.plot(x, avg_latencies_gathered, label=\"gathered\")\n",
        "\n",
        "plt.xlabel('Batch Size')\n",
        "plt.ylabel('Avg Latency (s)')\n",
        "plt.title('Multi-LoRA latency w.r.t. batch size')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "AoBfz1OulGQi",
        "outputId": "65d23716-cced-452e-e9d6-9d34a7b2fad2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlEAAAHHCAYAAACfqw0dAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACWmElEQVR4nOzdd3iTVfvA8W+SjnQXugulLXsPC9QCgmi1KIh1sBH0RVF/qCBuZSrKK4jiQHG8KipbFBURGaKsUmTvXWbponTv5Pn98ZBA6KAtKem4P9eVq82Tk+c5SQu5e8597qNRFEVBCCGEEEJUiNbWHRBCCCGEqIkkiBJCCCGEqAQJooQQQgghKkGCKCGEEEKISpAgSgghhBCiEiSIEkIIIYSoBAmihBBCCCEqQYIoIYQQQohKkCBKCCGEEKISJIgSoopNmTIFjUZTrrbffvstGo2GU6dOVW2nbOjUqVNoNBq+/fZbW3dFVIJGo+GZZ56xdTfMbr/9dtq2bVtl55ffV1EWCaJEnWYKWjQaDZs2bSr2uKIoBAUFodFo6Nevn9Wu+84777B8+fIbOkdISIjV+nT77beb3weNRoOTkxPt27dn9uzZGI3GUp/XtWtXNBoNn332mVX6cT1btmxhypQppKWl3ZTr1TbW+L2ztoMHDzJlypRa/YeDqL0kiBIC0Ov1LFiwoNjxf/75h3PnzuHo6GjV65X2YfbII4+Qm5tLcHCwVa9XHg0bNuT777/n+++/Z/r06ej1ep5//nkmTpxYYvtjx47x77//EhISwvz5829KH7ds2cLUqVMliKqk6hpETZ06tdoGUcHBweTm5vLII4/YuiuiGpIgSgjg3nvvZenSpRQVFVkcX7BgAWFhYfj7+9+Ufuh0OvR6fbmn/6zJw8OD4cOHM3z4cMaNG8eGDRsIDg7m448/xmAwFGv/ww8/4Ovry6xZs9iyZUu1/RCsi7Kzs23dhVpDo9Gg1+vR6XS27oqohiSIEgIYMmQIFy9eZM2aNeZjBQUF/PjjjwwdOrRY+7///huNRsPff/9tcbw8+RMajYbs7GzmzZtnnj579NFHAevnRBUVFfHWW2/RpEkTHB0dCQkJ4fXXXyc/P/+6z9Xr9XTp0oXMzEySkpKKPb5gwQIefvhh+vXrh4eHR4kjeeW1d+9eHn30URo3boxer8ff35///Oc/XLx40dxmypQpvPTSSwCEhoaa37ur36sffviBsLAwnJycqF+/PoMHD+bs2bMW1zLl0Bw8eJDevXvj7OxMgwYNmDFjRrF+5eXlMWXKFJo3b45erycgIIAHH3yQEydOoCgKISEh3H///SU+z8PDgyeffLLU1/zggw9yyy23WBy777770Gg0/Prrr+ZjsbGxaDQa/vjjjxLP8+ijj+Lq6sqJEye49957cXNzY9iwYcXalfV7Vxnz58+nRYsW6PV6wsLC2LBhg8Xjp0+f5v/+7/9o0aIFTk5OeHl5MWDAAIuf17fffsuAAQMA6N27t7lfV/+7+uOPP+jVqxdubm64u7vTpUuXEn/XyvPzLMmaNWvo0aMHnp6euLq60qJFC15//XXz49f+mzb92y/pFhISYnHuP/74g9tuuw0XFxfc3Nzo27cvBw4cKFe/RM0gQZQQqPlFERERLFy40Hzsjz/+ID09ncGDB1v1Wt9//z2Ojo7cdttt5umzsj5sb8Tjjz/OpEmTuOWWW/jggw/o1asX06dPL/drMn2AeHp6WhyPjY3l+PHjDBkyBAcHBx588MEbmtJbs2YNJ0+e5LHHHuPjjz9m8ODBLFq0iHvvvRdFUQA16BgyZAgAH3zwgfm98/HxAeDtt99mxIgRNGvWjPfff59x48axbt06evbsWWz679KlS/Tp04cOHTowa9YsWrZsySuvvGIRqBgMBvr168fUqVMJCwtj1qxZjB07lvT0dPbv349Go2H48OH88ccfpKamWpz/t99+IyMjg+HDh5f6mm+77Tb27NlDRkYGoObfbd68Ga1Wy8aNG83tNm7ciFarpXv37qWeq6ioiKioKHx9fXnvvfd46KGHirWx5u/dP//8w7hx4xg+fDhvvvkmFy9epE+fPuzfv9/c5t9//2XLli0MHjyYjz76iKeeeop169Zx++23k5OTA0DPnj157rnnAHj99dfN/WrVqhWgBll9+/YlNTWV1157jf/+97907NiRVatWWfSnPD/Pkhw4cIB+/fqRn5/Pm2++yaxZs+jfvz+bN28u9TmtWrUy99N0+/jjj7G3t8fX19fc7vvvv6dv3764urry7rvvMnHiRA4ePEiPHj1k1LY2UYSow7755hsFUP7991/lk08+Udzc3JScnBxFURRlwIABSu/evRVFUZTg4GClb9++5uetX79eAZT169dbnC8uLk4BlG+++cZ8bPLkycq1/9RcXFyUkSNHltqfuLi46/b92j5da/fu3QqgPP744xbHX3zxRQVQ/vrrL/OxXr16KS1btlSSk5OV5ORk5fDhw8pLL72kACVe45lnnlGCgoIUo9GoKIqirF69WgGUXbt2XbffJb1Hpvf8agsXLlQAZcOGDeZjM2fOLPH9OXXqlKLT6ZS3337b4vi+ffsUOzs7i+O9evVSAOW7774zH8vPz1f8/f2Vhx56yHzs66+/VgDl/fffL9Y30+s+cuSIAiifffaZxeP9+/dXQkJCzO1K8u+//yqAsnLlSkVRFGXv3r0KoAwYMEAJDw+3OFenTp1KPc/IkSMVQHn11VdLbWNS2u9dRQAKoGzfvt187PTp04per1ceeOAB87GSfqYxMTHF3vulS5eW+G8pLS1NcXNzU8LDw5Xc3FyLx65+X8v78yzJBx98oABKcnJyqW1K+n29ti/9+vVTXF1dlQMHDiiKoiiZmZmKp6en8sQTT1i0TUhIUDw8PIodFzWXjEQJcdnAgQPJzc1lxYoVZGZmsmLFihKn8mqKlStXAjB+/HiL4y+88AIAv//+u8Xxw4cP4+Pjg4+PDy1btmTmzJn079+/2NRkUVERixcvZtCgQebcrTvuuANfX99Kj0Y5OTmZv8/LyyMlJYVbb70VgJ07d173+T/99BNGo5GBAweSkpJivvn7+9OsWTPWr19v0d7V1dVilMjBwYGuXbty8uRJ87Fly5bh7e3Ns88+W+x6ptfdvHlzwsPDLV53amoqf/zxB8OGDSszt61Tp064urqap8E2btxIw4YNGTFiBDt37iQnJwdFUdi0aRO33Xbbdd+Dp59++rptrCUiIoKwsDDz/UaNGnH//ffz559/mvPnrv6ZFhYWcvHiRZo2bYqnp2e5fqZr1qwhMzOTV199Fb1eb/HYte9reX6eJTGNsP7yyy9lrkIty1tvvcWKFSv49ttvad26tbnvaWlpDBkyxOL3UafTER4eXuz3UdRcEkQJcZmPjw+RkZEsWLCAn376CYPBwMMPP2zTPqWnp5OQkGC+XTttVJbTp0+j1Wpp2rSpxXF/f388PT05ffq0xfGQkBDWrFnDn3/+yaeffkqDBg1ITk4u9gG2evVqkpOT6dq1K8ePH+f48ePExcXRu3dvFi5cWKkPo9TUVMaOHYufnx9OTk74+PgQGhpqfg+u59ixYyiKQrNmzcyBoOl26NChYjldDRs2LPZBXK9ePS5dumS+f+LECVq0aIGdnV2Z1x4xYgSbN282v59Lly6lsLDwuqu5dDodERER5qm7jRs3ctttt9GjRw8MBgNbt27l4MGDpKamXjeIsrOzo2HDhmW2saZmzZoVO9a8eXNycnJITk4GIDc3l0mTJhEUFISjoyPe3t74+PiQlpZWrp/piRMnAMpVA6o8P8+SDBo0iO7du/P444/j5+fH4MGDWbJkSbl/h1etWsXUqVN57bXXLKZQjx07Bqh/XFz7+7h69eoScwxFzVT2/w5C1DFDhw7liSeeICEhgXvuuadYLpBJaSMMJa1iuxFjx45l3rx55vu9evUqlsx+PeVd6efi4kJkZKT5fvfu3bnlllt4/fXX+eijj8zHTaMuAwcOLPE8//zzD717965QHwcOHMiWLVt46aWX6NixI66urhiNRvr06VOuDzSj0WhOvi5pFZWrq6vF/dJWWimX868qYvDgwTz//PPMnz+f119/nR9++IHOnTvTokWL6z63R48evP322+Tl5bFx40beeOMNPD09adu2LRs3bsTPzw/gukGUo6MjWm31+pv42Wef5ZtvvmHcuHFERETg4eGBRqNh8ODBlR71KU1lf55OTk5s2LCB9evX8/vvv7Nq1SoWL17MHXfcwerVq8tckRcXF8ewYcO46667mDZtmsVjptf3/fffl7iy93qBuag55CcpxFUeeOABnnzySbZu3crixYtLbVevXj2AYgnL147ulKa8gc3LL79sMU1hum55BAcHYzQaOXbsmDlRFyAxMZG0tLTr1qJq3749w4cP5/PPP+fFF1+kUaNGZGdn88svvzBo0KASR+mee+455s+fX6Eg6tKlS6xbt46pU6cyadIk83HTX/NXK+19a9KkCYqiEBoaSvPmzct97bI0adKE2NhYCgsLsbe3L7Vd/fr16du3L/Pnz2fYsGFs3ryZ2bNnl+sat912GwUFBSxcuJDz58+bg6WePXuag6jmzZubg6kbZa3SGSX9bI4ePYqzs7M50f/HH39k5MiRzJo1y9wmLy+v2L+Zsn6mAPv37y82mmpNWq2WO++8kzvvvJP333+fd955hzfeeIP169db/FFxtdzcXB588EE8PT1ZuHBhsQDW1HdfX99SzyFqh+r1p4sQNubq6spnn33GlClTuO+++0ptFxwcjE6nK7as+9NPPy3XdVxcXMpVMLJ169ZERkaab1fnoVzPvffeC1DsA/39998HoG/fvtc9x8svv0xhYaH5OT///DPZ2dmMGTOGhx9+uNitX79+LFu2rFwlFExMf+1fO2pQUiDi4uICFA9eH3zwQXQ6HVOnTi12HkVRLEollNdDDz1ESkoKn3zySbHHrr3GI488wsGDB3nppZfQ6XTlXv0YHh6Ovb097777LvXr16dNmzaAGlxt3bqVf/75x2IU6sKFCxw+fJjCwsLrnvvw4cOcOXPG4lhpv3c5OTkcPnyYlJSUcvU7JibGIq/p7Nmz/PLLL9x9993mn6dOpyv2PpVUc6y0n+ndd9+Nm5sb06dPJy8vz+KxyowYlqSk6fGOHTsClPk7/NRTT3H06FF+/vnnEv+wiYqKwt3dnXfeeafEn5VpylPUfDISJcQ1Ro4ced02Hh4eDBgwgI8//hiNRkOTJk1YsWJFuXMdwsLCWLt2Le+//z6BgYGEhoYSHh5e4b4eP3682FQCqEnLffv2ZeTIkXzxxRekpaXRq1cvtm3bxrx584iOji7XaFHr1q259957+eqrr5g4cSLz58/Hy8uLbt26ldi+f//+fPnll/z+++88+OCD5XoN7u7u9OzZkxkzZlBYWEiDBg1YvXo1cXFxxdqagsg33niDwYMHY29vz3333UeTJk2YNm0ar732GqdOnSI6Oho3Nzfi4uL4+eefGT16NC+++GK5+mMyYsQIvvvuO8aPH8+2bdu47bbbyM7OZu3atfzf//2fRX2ovn374uXlxdKlS7nnnnsslrqXxdnZmbCwMLZu3WquEQXqSFR2djbZ2dkWQdRrr73GvHnziIuLK1aT6FqtWrUqNv1b2u/dtm3b6N27N5MnT2bKlCnX7Xfbtm2Jioriueeew9HR0fzHw9SpU81t+vXrx/fff4+HhwetW7cmJiaGtWvX4uXlZXGujh07otPpePfdd0lPT8fR0dG8UOGDDz7g8ccfp0uXLgwdOpR69eqxZ88ecnJyLKa5K+vNN99kw4YN9O3bl+DgYJKSkvj0009p2LAhPXr0KPE5v//+O9999x0PPfQQe/fuZe/evebHXF1diY6Oxt3dnc8++4xHHnmEW265hcGDB+Pj48OZM2f4/fff6d69e4nBuaiBbLQqUIhq4eoSB2UpqZxAcnKy8tBDDynOzs5KvXr1lCeffFLZv39/uUocHD58WOnZs6fi5OSkAOZl5xUtccDl5ebX3kaNGqUoiqIUFhYqU6dOVUJDQxV7e3slKChIee2115S8vDyLc/Xq1Utp06ZNidf5+++/FUB5+umnFTs7O+WRRx4ptU85OTmKs7OzxVL3a5W0ZPzcuXPKAw88oHh6eioeHh7KgAEDlPj4eAVQJk+ebPH8t956S2nQoIGi1WqLvVfLli1TevToobi4uCguLi5Ky5YtlTFjxihHjhy57msdOXKkEhwcXOz1vPHGG+b3z9/fX3n44YeVEydOFHv+//3f/ymAsmDBglJfe0lMpSTeffddi+NNmzZVAItrmcoZXP2aR44cqbi4uBQ7L6D06tXL4lhpv3emkh3XvtclAZQxY8YoP/zwg9KsWTPF0dFR6dSpU7ESBZcuXVIee+wxxdvbW3F1dVWioqKUw4cPK8HBwcXKLHz55ZdK48aNFZ1OV6zcwa+//qp069ZNcXJyUtzd3ZWuXbsqCxcuND9ekZ/ntdatW6fcf//9SmBgoOLg4KAEBgYqQ4YMUY4ePWpuc+3vq+nfaEm3a6+3fv16JSoqSvHw8FD0er3SpEkT5dFHH7UoDyFqNo2iWGlcVAgh6rDnn3+e//3vfyQkJODs7Gzr7gghbgLJiRJCiBuUl5fHDz/8wEMPPSQBlBB1iORECSFEJSUlJbF27Vp+/PFHLl68yNixY23dJSHETSRBlBBCVNLBgwcZNmwYvr6+fPTRR+aVXUKIukFyooQQQgghKkFyooQQQgghKkGCKCGEEEKISpCcqCpkNBqJj4/Hzc3NatstCCGEEKJqKYpCZmYmgYGBZe5LKUFUFYqPjycoKMjW3RBCCCFEJZw9e5aGDRuW+rgEUVXIzc0NUH8I7u7uNu6NEEIIIcojIyODoKAg8+d4aSSIqkKmKTx3d3cJooQQQoga5nqpOJJYLoQQQghRCRJECSGEEEJUggRRQgghhBCVIDlRNmYwGCgsLLR1N0QF2dvbo9PpbN0NIYQQNiRBlI0oikJCQgJpaWm27oqoJE9PT/z9/aUGmBBC1FESRNmIKYDy9fXF2dlZPohrEEVRyMnJISkpCYCAgAAb90gIIYQtSBBlAwaDwRxAeXl52bo7ohKcnJwASEpKwtfXV6b2hBCiDpLEchsw5UA5OzvbuCfiRph+fpLTJoQQdZMEUTYkU3g1m/z8hBCibpMgSgghhBCiEiSIEhVy++23M27cOFt3QwghhLA5CaKEEEIIISpBgighhBBC1DjHk7I4kZxl0z5IECUq7dKlS4wYMYJ69erh7OzMPffcw7FjxyzaLFu2jDZt2uDo6EhISAizZs2yeDwkJIS33nqLIUOG4OLiQoMGDZgzZ87NfBlCCCFqmCMJmQz+IoahX27lzMUcm/VDgqhqQlEUcgqKbHJTFKVSfX700UfZvn07v/76KzExMSiKwr333mte8r9jxw4GDhzI4MGD2bdvH1OmTGHixIl8++23FueZOXMmHTp0YNeuXbz66quMHTuWNWvW3OhbKoQQohbafz6dwV/EkJJVgJeLI65625W8lGKb1URuoYHWk/60ybUPvhmFs0PFfhWOHTvGr7/+yubNm+nWrRsA8+fPJygoiOXLlzNgwADef/997rzzTiZOnAhA8+bNOXjwIDNnzuTRRx81n6t79+68+uqr5jabN2/mgw8+4K677rLOCxRCCFEr7DmbxiP/iyUjr4gODT347j/heDjb26w/1WIkas6cOYSEhKDX6wkPD2fbtm1ltl+6dCktW7ZEr9fTrl07Vq5cafG4oihMmjSJgIAAnJyciIyMLDbN1L9/fxo1aoRerycgIIBHHnmE+Ph48+OnTp1Co9EUu23dutV6L7wGO3ToEHZ2doSHh5uPeXl50aJFCw4dOmRu0717d4vnde/enWPHjmEwGMzHIiIiLNpERESYzyGEEEIA7DidyrCv1AAqLLgePzxu2wAKqsFI1OLFixk/fjxz584lPDyc2bNnExUVxZEjR/D19S3WfsuWLQwZMoTp06fTr18/FixYQHR0NDt37qRt27YAzJgxg48++oh58+YRGhrKxIkTiYqK4uDBg+j1egB69+7N66+/TkBAAOfPn+fFF1/k4YcfZsuWLRbXW7t2LW3atDHfr6ptWpzsdRx8M6pKzl2eawshhBDV1daTF/nPt/+SU2Dg1sb1+d/ILrg42jyEAcXGunbtqowZM8Z832AwKIGBgcr06dNLbD9w4EClb9++FsfCw8OVJ598UlEURTEajYq/v78yc+ZM8+NpaWmKo6OjsnDhwlL78csvvygajUYpKChQFEVR4uLiFEDZtWtXZV+akp6ergBKenq6xfHc3Fzl4MGDSm5ubqXPbSu9evVSxo4dqxw9elQBlM2bN5sfS0lJUZycnJSlS5cqiqIoQ4cOVe666y6L57/00ktKmzZtzPeDg4OVe+65x6LN4MGDix2rjmryz1EIIWqKjUeTlRYTVirBr6xQhn+1VcnJL6rya5b2+X0tm07nFRQUsGPHDiIjI83HtFotkZGRxMTElPicmJgYi/YAUVFR5vZxcXEkJCRYtPHw8CA8PLzUc6ampjJ//ny6deuGvb3l0GD//v3x9fWlR48e/Prrr2W+nvz8fDIyMixutVWzZs24//77eeKJJ9i0aRN79uxh+PDhNGjQgPvvvx+AF154gXXr1vHWW29x9OhR5s2bxyeffMKLL75oca7NmzczY8YMjh49ypw5c1i6dCljx461xcsSQghRjaw/nMR/5v1LXqGR3i18+HJEZ5wcqs/siU2DqJSUFAwGA35+fhbH/fz8SEhIKPE5CQkJZbY3fS3POV955RVcXFzw8vLizJkz/PLLL+bHXF1dmTVrFkuXLuX333+nR48eREdHlxlITZ8+HQ8PD/MtKCjoOu9AzfbNN98QFhZGv379iIiIQFEUVq5caQ5Eb7nlFpYsWcKiRYto27YtkyZN4s0337RIKgc12Nq+fTudOnVi2rRpvP/++0RF2WZqUwghhO0pisLXm+IY/f12CoqM3N3aj7mPhKGvZukn1WBC0XZeeuklRo0axenTp5k6dSojRoxgxYoVaDQavL29GT9+vLltly5diI+PZ+bMmfTv37/E87322msWz8nIyKh1gdTff/9t/r5evXp89913ZbZ/6KGHeOihh8ps4+7uzpIlS6zRPSGEEDVcek4hL/24h9UHEwG4v2Mg7w3ogL2uWqyFs2DTIMrb2xudTkdiYqLF8cTERPz9/Ut8jr+/f5ntTV8TExMJCAiwaNOxY8di1/f29qZ58+a0atWKoKAgtm7dWmy1mEl4eHiZ9YscHR1xdHQs9XEhhBBClG732TSeWbCTc5dycdBpmdCvFY/cGoxGo7F110pk07DOwcGBsLAw1q1bZz5mNBpZt25dqYFMRESERXuANWvWmNuHhobi7+9v0SYjI4PY2NhSz2m6Lqh5TaXZvXu3RWAmhBBCiBunKAr/2xTHgLlbOHcpl0b1nVn2dDdGRIRU2wAKqsF03vjx4xk5ciSdO3ema9euzJ49m+zsbB577DEARowYQYMGDZg+fToAY8eOpVevXsyaNYu+ffuyaNEitm/fzhdffAGARqNh3LhxTJs2jWbNmplLHAQGBhIdHQ1AbGws//77Lz169KBevXqcOHGCiRMn0qRJE3OgNW/ePBwcHOjUqRMAP/30E19//TVfffXVTX6HardTp07ZugtCCCFsKD2nkBd/3MOay9N397bz578Ptcddb9saUOVh8yBq0KBBJCcnM2nSJBISEujYsSOrVq0yJ4afOXMGrfbKgFm3bt1YsGABEyZM4PXXX6dZs2YsX77cXCMK4OWXXyY7O5vRo0eTlpZGjx49WLVqlblGlLOzMz/99BOTJ08mOzubgIAA+vTpw4QJEyym49566y1Onz6NnZ0dLVu2ZPHixTz88MM36Z0RQgghardL2QX0+3gT59NqxvTdtTSKUsmN08R1ZWRk4OHhQXp6Ou7u7ubjeXl5xMXFERoaag7sRM0jP0chhLgxi7ad4dWf9uHvruerkZ1p28DD1l0CSv/8vlb1S3UXQgghRJ1wKUfdsL57U+9qE0BVhARRQgghhLCJtNwCADxtvAdeZUkQJYQQQgibyMhVR6I8nCSIEkIIIYQot7TL03kyEiXEDbr99tsZN26crbthNmXKlGIFWoUQQliPKYiSkSghyunvv/9Go9GQlpZm664IIYSwoXSZzhOi+iooKLB1F4QQQpTCFER5OjvYuCeVI0GUqLDMzEyGDRuGi4sLAQEBfPDBBxZTcd9//z2dO3fGzc0Nf39/hg4dSlJSEqBWKO/duzegbmCs0Wh49NFHzec2Go28/PLL1K9fH39/f6ZMmWJx7bS0NB5//HF8fHxwd3fnjjvuYM+ePebHTVNwX331lUX9pus9D+C///0vfn5+uLm5MWrUKPLy8qz8zgkhhLhaWo76h66MRIkboyhQkG2bWwXrrY4fP57Nmzfz66+/smbNGjZu3MjOnTvNjxcWFvLWW2+xZ88eli9fzqlTp8yBUlBQEMuWLQPgyJEjXLhwgQ8//ND83Hnz5uHi4kJsbCwzZszgzTfftNj0ecCAASQlJfHHH3+wY8cObrnlFu68805SU1PNbY4fP86yZcv46aef2L17d7met2TJEqZMmcI777zD9u3bCQgI4NNPP63Q+yKEEKL8Cg1GsgsMAHjW0CDK5tu+iMsKc+CdQNtc+/V4cHApV9PMzEzmzZvHggULuPPOOwH45ptvCAy80vf//Oc/5u8bN27MRx99RJcuXcjKysLV1ZX69esD4Ovri6enp8X527dvz+TJkwFo1qwZn3zyCevWreOuu+5i06ZNbNu2jaSkJPP2PO+99x7Lly/nxx9/ZPTo0YA6hffdd9/h4+MDUK7nzZ49m1GjRjFq1CgApk2bxtq1a2U0SgghqohpKg/AvYYGUTISJSrk5MmTFBYW0rVrV/MxDw8PWrRoYb6/Y8cO7rvvPho1aoSbmxu9evUC1H0Qr6d9+/YW9wMCAsxTgXv27CErKwsvLy9cXV3Nt7i4OE6cOGF+TnBwsDmAKu/zDh06RHh4uMW1TZtRCyGEsD7Tyjw3vR06bc3YK+9aMhJVXdg7qyNCtrq2lWRnZxMVFUVUVBTz58/Hx8eHM2fOEBUVVa4kb3t7y79GNBoNRqMRgKysLAICAvj777+LPe/qES0XF8tRtfI+TwghxM1zJam8Zo5CgQRR1YdGU+4pNVtq3Lgx9vb2/PvvvzRq1AiA9PR0jh49Ss+ePTl8+DAXL17kv//9L0FBQQBs377d4hwODuoqDIPBUKFr33LLLSQkJGBnZ0dISIhVn9eqVStiY2MZMWKE+djWrVsr1D8hhBDll27a8sWpZq7MA5nOExXk5ubGyJEjeemll1i/fj0HDhxg1KhRaLVaNBoNjRo1wsHBgY8//piTJ0/y66+/8tZbb1mcIzg4GI1Gw4oVK0hOTiYrK6tc146MjCQiIoLo6GhWr17NqVOn2LJlC2+88UaxQK2izxs7dixff/0133zzDUePHmXy5MkcOHCg8m+UEEKIMtX0QpsgQZSohPfff5+IiAj69etHZGQk3bt3p1WrVuj1enx8fPj2229ZunQprVu35r///S/vvfeexfMbNGjA1KlTefXVV/Hz8+OZZ54p13U1Gg0rV66kZ8+ePPbYYzRv3pzBgwdz+vRp/Pz8buh5gwYNYuLEibz88suEhYVx+vRpnn766cq/SUIIIcpkLrRZg6fzNIpSwfXtotwyMjLw8PAgPT0dd3d38/G8vDzi4uIs6hjVZNnZ2TRo0IBZs2aZV7fVBbXt5yiEEDfTB2uO8uG6YwwLb8TbD7SzdXcslPb5fS3JiRIVtmvXLg4fPkzXrl1JT0/nzTffBOD++++3cc+EEELUFDV9yxeQIEpU0nvvvceRI0dwcHAgLCyMjRs34u3tbetuCSGEqCFkdZ6okzp16sSOHTts3Q0hhBA1mGnLF1mdJ4QQQghRAaaRqJparRwkiLIpyemv2eTnJ4QQlZdWC6bzJIiyAVNV7pycHBv3RNwI08/v2irrQgghri89p+YHUZITZQM6nQ5PT0/znnDOzs5oNDVz36C6SFEUcnJySEpKwtPTE51OZ+suCSFEjaIoiqzOE5Xn7+8PYA6kRM3j6elp/jkKIYQov+wCA0VGNSWiJieWSxBlIxqNhoCAAHx9fSksLLR1d0QF2dvbywiUEEJUkmllnoOdFr19zc0skiDKxnQ6nXwYCyGEqFOunsqryeksNTf8E0IIIUSNZE4qr8H5UCBBlBBCCCFusrRakFQOEkQJIYQQ4iarDVu+gARRQgghhLjJ0nJMI1E1d2UeSBAlhBBCiJssLVddnSfTeUIIIYQQFZAh03lCCCGEEBWXVgu2fAEJooQQQghxk13JiZIgSgghhBCi3GrDvnkgQZQQQgghbrIrJQ5kdZ4QQgghRLnJSJQQQgghRAUVGoxk5RcBsu2LEEIIIUS5mUahANwliLpxc+bMISQkBL1eT3h4ONu2bSuz/dKlS2nZsiV6vZ527dqxcuVKi8cVRWHSpEkEBATg5OREZGQkx44ds2jTv39/GjVqhF6vJyAggEceeYT4+HiLNnv37uW2225Dr9cTFBTEjBkzrPOChRBCiDrKFES56e3QaTU27s2NsXkQtXjxYsaPH8/kyZPZuXMnHTp0ICoqiqSkpBLbb9myhSFDhjBq1Ch27dpFdHQ00dHR7N+/39xmxowZfPTRR8ydO5fY2FhcXFyIiooiLy/P3KZ3794sWbKEI0eOsGzZMk6cOMHDDz9sfjwjI4O7776b4OBgduzYwcyZM5kyZQpffPFF1b0ZQgghRC1XW2pEAaDYWNeuXZUxY8aY7xsMBiUwMFCZPn16ie0HDhyo9O3b1+JYeHi48uSTTyqKoihGo1Hx9/dXZs6caX48LS1NcXR0VBYuXFhqP3755RdFo9EoBQUFiqIoyqeffqrUq1dPyc/PN7d55ZVXlBYtWpT7taWnpyuAkp6eXu7nCCGEELXZukMJSvArK5R+H220dVdKVd7Pb5uORBUUFLBjxw4iIyPNx7RaLZGRkcTExJT4nJiYGIv2AFFRUeb2cXFxJCQkWLTx8PAgPDy81HOmpqYyf/58unXrhr29vfk6PXv2xMHhyvLLqKgojhw5wqVLl0o8T35+PhkZGRY3IYQQQlxRW1bmgY2n81JSUjAYDPj5+Vkc9/PzIyEhocTnJCQklNne9LU853zllVdwcXHBy8uLM2fO8Msvv1z3Oldf41rTp0/Hw8PDfAsKCiqxnRBCCFFXmauV14LpPJvnRNnSSy+9xK5du1i9ejU6nY4RI0agKEqlz/faa6+Rnp5uvp09e9aKvRVCCCFqvtqy5QuAnS0v7u3tjU6nIzEx0eJ4YmIi/v7+JT7H39+/zPamr4mJiQQEBFi06dixY7Hre3t707x5c1q1akVQUBBbt24lIiKi1OtcfY1rOTo64ujoeJ1XLYQQQtRd5mrltSCIsulIlIODA2FhYaxbt858zGg0sm7dOiIiIkp8TkREhEV7gDVr1pjbh4aG4u/vb9EmIyOD2NjYUs9pui6oeU2m62zYsIHCwiv1LNasWUOLFi2oV69eBV+pEEIIIeDqLV8kiLph48eP58svv2TevHkcOnSIp59+muzsbB577DEARowYwWuvvWZuP3bsWFatWsWsWbM4fPgwU6ZMYfv27TzzzDMAaDQaxo0bx7Rp0/j111/Zt28fI0aMIDAwkOjoaABiY2P55JNP2L17N6dPn+avv/5iyJAhNGnSxBxoDR06FAcHB0aNGsWBAwdYvHgxH374IePHj7+5b5AQQghRi6TlFAAynWcVgwYNIjk5mUmTJpGQkEDHjh1ZtWqVOYn7zJkzaLVXYr1u3bqxYMECJkyYwOuvv06zZs1Yvnw5bdu2Nbd5+eWXyc7OZvTo0aSlpdGjRw9WrVqFXq8HwNnZmZ9++onJkyeTnZ1NQEAAffr0YcKECebpOA8PD1avXs2YMWMICwvD29ubSZMmMXr06Jv47gghhBC1y5XVeTV782EAjXIjmdSiTBkZGXh4eJCeno67u7utuyOEEELY3B2z/uZkcjaLRt/KrY29bN2dEpX389vm03lCCCGEqDvSa9HqPAmihBBCCHFTKIoiieVCCCGEEBWVXWCgyKhmEXnWgpwoCaKEEEIIcVOYVuY56LTo7Wt+CFLzX4EQQgghagTzyjxnezQajY17c+MkiBJCCCHETWFKKq8N1cpBgighhBBC3CRXakRJECWEEEIIUW5ptWhlHkgQJYQQQoibJC2n9lQrBwmihBBCCHGTyHSeEEIIIUQlpOeqJQ5kOk8IIYQQogLSatGWLyBBlBBCCCFuktq05QtIECWEEEKIm0RGooQQQgghKkESy4UQQgghKuHKdJ6UOBBCCCGEKJdCg5Gs/CJAtn0RQgghhCg30ygUgLsEUUIIIYQQ5WMKotz0dui0Ghv3xjokiBJCCCFElTOtzKst5Q1AgighhBBC3ASmauW1ZWUeSBAlhBBCiJvAvDKvlmw+DBJECSGEEOImMBfalOk8IYQQQojyq22FNkGCKCGEEELcBObEcgmihBBCCCHKr7ZtPgwSRAkhhBDiJpDpPCGEEEKISkjLMZU4kNV5QgghhBDllibTeUIIIYQQFZch03lCCCFE3aMoChuOJnP6Yratu1IjKYpSK7d9sbN1B4QQQojqbt/5dEZ8vQ17nYYxvZvy9O1NcLTT2bpbNUZ2gYEiowLISJQQQghRpxxLzAKg0KAwe+0x+n60iR2nU23cq5rDtDLPQafFyb72BJ8SRAkhhBDXEZ+WC0DrAHe8XR04npTFw3NjmLh8P5l5hTbuXfVnXpnnbI9Go7Fxb6xHgighhBDiOuLT8wC4q7Ufa8f3YmDnhigKfL/1NHe9v4E1BxNt3MPqLT2n9iWVgwRRQgghxHVdSFdHogI99Xg6OzDj4Q4seDycYC9nEjLyeOK77bz9+0Eb97L6MlcrlyBKCCGEqFtM03mBnk7mY92aevPnuJ482bMxAF9tiqPQYLRJ/6q72lgjCiSIEkIIIa7rQpo6nRfg4WRxXG+v45U+LdFpNSgKXMwqsEX3qj1TeQN3GYmyvjlz5hASEoJeryc8PJxt27aV2X7p0qW0bNkSvV5Pu3btWLlypcXjiqIwadIkAgICcHJyIjIykmPHjpkfP3XqFKNGjSI0NBQnJyeaNGnC5MmTKSgosGij0WiK3bZu3WrdFy+EEKJay8grJDO/CFCn866l1WrwdlW3MknJyr+pfasprkzn1Z4tX6AaBFGLFy9m/PjxTJ48mZ07d9KhQweioqJISkoqsf2WLVsYMmQIo0aNYteuXURHRxMdHc3+/fvNbWbMmMFHH33E3LlziY2NxcXFhaioKPLy1L8kDh8+jNFo5PPPP+fAgQN88MEHzJ07l9dff73Y9dauXcuFCxfMt7CwsKp5I4QQQlRLplEoT2d7nB1KLq/o4+YIQHKmBFElSc9VBylkOs/K3n//fZ544gkee+wxWrduzdy5c3F2dubrr78usf2HH35Inz59eOmll2jVqhVvvfUWt9xyC5988gmgjkLNnj2bCRMmcP/999O+fXu+++474uPjWb58OQB9+vThm2++4e6776Zx48b079+fF198kZ9++qnY9by8vPD39zff7O1r1y+AEEKIssVfTiq/dirvat6uEkSVJb0WbvkCNg6iCgoK2LFjB5GRkeZjWq2WyMhIYmJiSnxOTEyMRXuAqKgoc/u4uDgSEhIs2nh4eBAeHl7qOQHS09OpX79+seP9+/fH19eXHj168Ouvv1bo9QkhhKj5TCNRgR7Fp/JMfExBlEznlag2bvkCNt72JSUlBYPBgJ+fn8VxPz8/Dh8+XOJzEhISSmyfkJBgftx0rLQ21zp+/Dgff/wx7733nvmYq6srs2bNonv37mi1WpYtW0Z0dDTLly+nf//+JZ4nPz+f/Pwr/4AyMjJKbCeEEKLmMK3MCyghH8pEpvPKllZL60TV+b3zzp8/T58+fRgwYABPPPGE+bi3tzfjx4833+/SpQvx8fHMnDmz1CBq+vTpTJ06tcr7LIQQ4uaJTy9e3uBaEkSVTabzqoC3tzc6nY7ERMtKr4mJifj7+5f4HH9//zLbm76W55zx8fH07t2bbt268cUXX1y3v+Hh4Rw/frzUx1977TXS09PNt7Nnz173nEIIIaq3K9N5EkRVlnl1nrOszrMaBwcHwsLCWLdunfmY0Whk3bp1RERElPiciIgIi/YAa9asMbcPDQ3F39/fok1GRgaxsbEW5zx//jy33347YWFhfPPNN2i1138rdu/eTUBAQKmPOzo64u7ubnETQghRs11JLJecqMooNBjJulwiorZVLLf5dN748eMZOXIknTt3pmvXrsyePZvs7Gwee+wxAEaMGEGDBg2YPn06AGPHjqVXr17MmjWLvn37smjRIrZv324eSdJoNIwbN45p06bRrFkzQkNDmThxIoGBgURHRwNXAqjg4GDee+89kpOTzf0xjVbNmzcPBwcHOnXqBMBPP/3E119/zVdffXWz3hohhBA2pigKFy7vmyfTeZWTkXtlg+baVmzT5kHUoEGDSE5OZtKkSSQkJNCxY0dWrVplTgw/c+aMxShRt27dWLBgARMmTOD111+nWbNmLF++nLZt25rbvPzyy2RnZzN69GjS0tLo0aMHq1atQq9X/4pYs2YNx48f5/jx4zRs2NCiP4qimL9/6623OH36NHZ2drRs2ZLFixfz8MMPV+XbIYQQohq5mF1AQZERjQb8yxqJuhxEZeUXkVtgwMlBd7O6WO2Ztnxx09uh02ps3Bvr0ihXRw3CqjIyMvDw8CA9PV2m9oQQogbaey6N/p9sxtfNkW1vRJbaTlEUWk1aRV6hkY0v9yaovvNN7GX1tuP0JR76bAsN6zmx6ZU7bN2dcinv57fNi20KIYQQ1VV82vWn8kBNJTEV3EySKT0LGbV082GQIEoIIYQo1QVzeYPSp/JMJC+qZGmmLV9q2b55IEGUEEIIUSpzoc0yyhuYyAq9ktXWQpsgQZQQQghRqvhyrMwzkZGokpkLbdbC6bwKr87Lz88nNjaW06dPk5OTg4+PD506dSI0NLQq+ieEEELYzIXLI1Fl7ZtnIkFUyU4mZwMQ4H7997CmKXcQtXnzZj788EN+++03CgsL8fDwwMnJidTUVPLz82ncuDGjR4/mqaeews3NrSr7LIQQQtwUpsTyABmJqrS959IA6BDkadN+VIVyTef179+fQYMGERISwurVq8nMzOTixYucO3eOnJwcjh07xoQJE1i3bh3NmzdnzZo1Vd1vIYQQokoVGYwkZZqm88oxEnU5JypFcqLM0nIKOHUxB4D2DT1s3BvrK9dIVN++fVm2bBn29iXPZzZu3JjGjRszcuRIDh48yIULF6zaSSGEEOJmS8zMx6iAvU6Dt4vjddvLSFRxe8+lAxDi5Vzr9s2DcgZRTz75ZLlP2Lp1a1q3bl3pDgkhhBDVgWllnr+HHm05Km17X7U6T1EUNJraVZ27MvacTQOgfUNPm/ajqlR4dd7Zs2c5d+6c+f62bdsYN26cee86IYQQojaINyeVXz8fCq6MRBUUGcnIK6qyftUkey6PRNXGfCioRBA1dOhQ1q9fD0BCQgJ33XUX27Zt44033uDNN9+0egeFEEIIWyjPxsNX09vrcNOrEzwypaduhbPHlFReC/OhoBJB1P79++natSsAS5YsoW3btmzZsoX58+fz7bffWrt/QgghhE1cKbRZ/qX5khd1RUJGHsmZ+ei0GtoEShAFQGFhIY6O6i/J2rVr6d+/PwAtW7aUhHIhhBC1Rnn3zbuaVC2/wpQP1dzPDScHnW07U0UqHES1adOGuXPnsnHjRtasWUOfPn0AiI+Px8vLy+odFEIIIWyhIvvmmchI1BWmfKiOQbVzFAoqEUS9++67fP7559x+++0MGTKEDh06APDrr7+ap/mEEEKImq4i++aZSBB1RW1fmQeV2Pbl9ttvJyUlhYyMDOrVq2c+Pnr0aJydna3aOSGEEMIWcgsMXLq8cW6FpvPcpOAmgNGosM+0Mk+CKEs6nc4igAIICQmxRn+EEEIImzNN5bk46HDXl/+j0pwTVcdHok6mZJOZX4TeXktzP1dbd6fKlGs6r0+fPmzduvW67TIzM3n33XeZM2fODXdMCCGEsBVTeYMAT6cKFc30luk84Mp+eW0DPbDTVThzqMYoV3g9YMAAHnroITw8PLjvvvvo3LkzgYGB6PV6Ll26xMGDB9m0aRMrV66kb9++zJw5s6r7LYQQQlSZ86ZCmxWYygNZnWdSF/KhoJxB1KhRoxg+fDhLly5l8eLFfPHFF6Snq3OdGo2G1q1bExUVxb///kurVq2qtMNCCCFEVbtgKm9QgRpRAL6XR6IuZuVjMCroyrFdTG10pVJ57V2ZBxXIiXJ0dGT48OEMHz4cgPT0dHJzc/Hy8ip1Y2IhhBCiJjLlRFVkZR5AfRcHNBowKpCaXWBONK9LCoqMHIzPAGp3UjlUosSBiYeHB/7+/hJACSGEqHWuTOdVbCTKTqfFy8UBqLt5UUcSMikwGPFwsifYq3av2q+92V5CCCFEJVV037yredfxvKjdl5PK2zf0qFBSfk0kQZQQQlRDpy9m8/i8f9l+KtXWXalzFEXhQiX2zTMx14qqZSNRB+Mz+GX3eRRFKbPd3stJ5R2DPKu+UzZWqTpRQgghqtaCbWdYeygJN709nUPq27o7dUpGbhHZBQag4jlRcFXV8lo0EnUiOYuBn8eQlV+ERqOhf4fAUtvuMY9Eed6cztmQjEQJIUQ1ZKr2XNcrX9tC/OWk8vouDpXaOLe2bf2SlV/Ek9/vICu/CIDZa45SZDCW2vZYUhYAHRrW7pV5UIkgauTIkWzYsKEq+iKEEAJ1OmnfeTWIupRTYOPe1D1XVuZVfCoPalfVckVReHHJHo4nZeHn7kh9FwdOpmTz087zJbbffz4dRVHfO1/3yr1/NUmFg6j09HQiIyNp1qwZ77zzDufPl/xGCiGEqJzTF3PIzFP/6k/NkiDqZjt/uUZUZabyoHaNRH32zwlWHUjAXqfhs+FhPN2rCQAfrjtGfpGhWHtTpfLaXtrApMJB1PLlyzl//jxPP/00ixcvJiQkhHvuuYcff/yRwsLCquijEELUKaZRKIBUGYm66UxJ5Q0qWN7ApLZULd9wNJn3/jwCwNT+bbmlUT0eiQjGz92R82m5LNp2tthz9pxVf3fb1/IimyaVyony8fFh/Pjx7Nmzh9jYWJo2bcojjzxCYGAgzz//PMeOHbN2P4UQos64OojKKzSSU1Bkw97UPVfvm1cZtWEk6mxqDs8t2oVRgUGdgxjSNQgAvb2OZ+5oBsAn64+TW2A5GmVKKu8oI1HXd+HCBdasWcOaNWvQ6XTce++97Nu3j9atW/PBBx9Yq49CCFGnmJLKTVKzZTTqZjp/A+UN4EoQlZ5bWOKUV3WXW2Dgye93kJZTSIeGHky9v41FvadBnYNoWM+J5Mx85sWcMh+/mJXPuUvqe9e2DiSVQyWCqMLCQpYtW0a/fv0IDg5m6dKljBs3jvj4eObNm8fatWtZsmQJb775ZlX0VwghajWjUWH/edPepOqxS9mSKnEzmRLLG1RyJMrDyR57nfrDS6lhOW2KovDGz/s4eCEDLxcHPhseht7ecoWig52W5yObAzD3nxNk5Km/n3svB/9NfFxw19eN3UwqHEQFBATwxBNPEBwczLZt29i+fTtPPfUU7u7u5ja9e/fG09PTmv0UQog64XRqDpn5RTjaaWnm6wrAxeyaOy1U0xiNCgk3OJ2n0WjMeVE1reDmvC2n+GnXeXRaDZ8MvaXUiu3RnRrQ1NeVtJxC/rcxDoDdl4tsdqgDRTZNKhxEffDBB8THxzNnzhw6duxYYhtPT0/i4uJutG9CCFHnmFY3tQpwx9dNnU6SMgc3T0pWPoUGBa0G/G5g8+CamBeVml3AO38cBuC1e1oS0cSr1LY6rYbxd6mjUf/bFMel7II6tzIPKhFE9e/fn5ycnGLHU1NTycjIsEqnhBCirjJN5bVv6EG9yxvZXqxhU0I1WfzlUSg/dz12usqnDdfE/fN+2nmOgiIjbQLdGdUj9Lrt+7Txp02gO1n5Rcz95wR7Lk/nyUhUGQYPHsyiRYuKHV+yZAmDBw+2SqeEEKKuMuWVtG3ggdflIEpGom6eG9kz72o1bSRKURQWbjsDwNDwRuXaOFir1fDi3S0AdTQqNbsAe52GVgFuVdrX6qTCQVRsbCy9e/cudvz2228nNjbWKp0SQoi6yGhUOBCvjui3b+hBPWc1iEqVxPKbxrwyr5L5UCY1LYjafvoSJ5KzcbLXlbkv3rVub+FDWHA9iozqpsStAtxxtKv4Vjk1VYWDqPz8fIqKitcsKSwsJDc31yqdEkKIuijuYjZZ+UXo7bU09XGlvqspiKoZH8S1galGVGVX5pnUtCDKNAp1X4cA3Cqwsk6juTIaBWrwX5dUOIjq2rUrX3zxRbHjc+fOJSwszCqdEkKIushUH6p1gDt2Oi31L49ESYmDm+dG980zqUlVy9NzCvl97wUABndtVOHnRzTxoldzHwC6N/G2at+quwoHUdOmTeOrr76iZ8+eTJ06lalTp9KzZ0++/vpr3nnnnUp1Ys6cOYSEhKDX6wkPD2fbtm1ltl+6dCktW7ZEr9fTrl07Vq5cafG4oihMmjSJgIAAnJyciIyMtKiifurUKUaNGkVoaChOTk40adKEyZMnU1BgmXewd+9ebrvtNvR6PUFBQcyYMaNSr08IIcpjnzmp3BOAei7qiICUOLh5bnTfPJOaNBK1fPd58ouMtPR3o1Mlk8I/G34LC54Ip09bf+t2rpqrcBDVvXt3YmJiCAoKYsmSJfz22280bdrUHHBU1OLFixk/fjyTJ09m586ddOjQgaioKJKSkkpsv2XLFoYMGcKoUaPYtWsX0dHRREdHs3//fnObGTNm8NFHHzF37lxiY2NxcXEhKiqKvDz1H8fhw4cxGo18/vnnHDhwgA8++IC5c+fy+uuvm8+RkZHB3XffTXBwMDt27GDmzJlMmTKlxFE4IYSwhn1XJZUDeLmoH8SXcmQk6ma5sm+edYKolGo+EnV1QvngLkHlSigvibODHd2aeFf6+TWWYmNdu3ZVxowZY75vMBiUwMBAZfr06SW2HzhwoNK3b1+LY+Hh4cqTTz6pKIqiGI1Gxd/fX5k5c6b58bS0NMXR0VFZuHBhqf2YMWOGEhoaar7/6aefKvXq1VPy8/PNx1555RWlRYsW5X5t6enpCqCkp6eX+zlCiLqpyGBUWk/8Qwl+ZYVyJCFDURRFSczIVYJfWaGEvLpCKTIYbdzD2i+/0KCEvLpCCX5lhZKcmXdD58rKK1SCX1HPlZVXaKUeWt/O06lK8CsrlOZvrFTSsgts3Z1qo7yf35UqgmE0Gjl69CibNm1iw4YNFreKKCgoYMeOHURGRpqPabVaIiMjiYmJKfE5MTExFu0BoqKizO3j4uJISEiwaOPh4UF4eHip5wRIT0+nfv36Ftfp2bMnDg4OFtc5cuQIly5dKvEc+fn5ZGRkWNyEEKI84lKyyC4w4GSvo4mPWqnctDpPUdR92ETVSszIQ1HUbU1M5SUqy8XRDhcHdZVadZ7SW7TtLAD3tgvAw7lubNViTXYVfcLWrVsZOnQop0+fRlEUi8c0Gg0GQ/k3W0xJScFgMODn52dx3M/Pj8OHD5f4nISEhBLbJyQkmB83HSutzbWOHz/Oxx9/zHvvvWdxndBQy2JjpnMmJCRQr169YueZPn06U6dOLfEaQghRFlM+VJtAd3RadUrEXqfFXW9HRl4RqdkF1L/BD3ZRtvjLU3mBHnqrTEt5uzmSfTGH5Kx8Qrxdbvh81paVX8Rve+MBGFKJhHJRiZyop556is6dO7N//35SU1O5dOmS+ZaamloVfaxS58+fp0+fPgwYMIAnnnjihs712muvkZ6ebr6dPXvWSr0UQtR2e6/JhzIxBU6p2VJws6qZyhvcaFK5iXmFXjUdifp1dzw5BQaa+LjQJaT4wIC4vgqPRB07dowff/yRpk2b3vDFvb290el0JCYmWhxPTEzE37/kDH9/f/8y25u+JiYmEhAQYNHm2r3+4uPj6d27N926dSuWMF7ada6+xrUcHR1xdKz8XktCiLrr6u1erlbfxYFTF3MkiLoJdp5RUzUa+1hn1Ki6r9C7klBevgrlorgKj0SFh4dz/Phxq1zcwcGBsLAw1q1bZz5mNBpZt24dERERJT4nIiLCoj3AmjVrzO1DQ0Px9/e3aJORkUFsbKzFOc+fP8/tt99OWFgY33zzDVqt5VsRERHBhg0bKCy8koewZs0aWrRoUeJUnhBCVJbBqLD/vJpD2U5GomxCURTWHVJXhfdu4WuVc1bnIGr/+XT2nU/HXqfhwVsa2Lo7NVaFR6KeffZZXnjhBRISEmjXrh329paJaO3bt6/Q+caPH8/IkSPp3LkzXbt2Zfbs2WRnZ/PYY48BMGLECBo0aMD06dMBGDt2LL169WLWrFn07duXRYsWsX37dvNIkkajYdy4cUybNo1mzZoRGhrKxIkTCQwMJDo6GrgSQAUHB/Pee++RnJxs7o9plGno0KFMnTqVUaNG8corr7B//34+/PBDPvjgg4q+ZUIIUaaTyVnkFhpwdtDR+HJSuUl92T/vpjh0IZPzabno7bV0b2qdgpHVeTpv0b/qKNTdbfzxcpUZlMqqcBD10EMPAfCf//zHfEyj0aAoSoUTywEGDRpEcnIykyZNIiEhgY4dO7Jq1SpzEveZM2csRom6devGggULmDBhAq+//jrNmjVj+fLltG3b1tzm5ZdfJjs7m9GjR5OWlkaPHj1YtWoVer1agXbNmjUcP36c48eP07BhQ4v+mJLlPTw8WL16NWPGjCEsLAxvb28mTZrE6NGjK/T6hBDiesz5UIEe5qRyk3oyEnVTrD2kpmv0aOqDk4N19n4zj0RVs1pROQVFLN+lJpQPlYTyG1LhICouLs7qnXjmmWd45plnSnzs77//LnZswIABDBgwoNTzaTQa3nzzTd58880SH3/00Ud59NFHr9uv9u3bs3Hjxuu2E0KIG2FamXdtUjlgXmovQVTVWnc5iIpsZZ2pPKi+BTdX7L1AVn4Rjeo7E9HYy9bdqdEqHEQFBwdXRT+EEKLO2ldKUjlcqRUlQVTVSczIY8/l0cA7qiCIutnTeQVFRmJOXiQ9t9CiFJHp2283nwJgUJcgtFpJKL8RFQ6iAL7//nvmzp1LXFwcMTExBAcHM3v2bEJDQ7n//vut3UchhKi1igxGDsSXPhIlieVV76/DakJ5hyBPfN1ubOPhq109EmU0KlUesJxNzWHhtjMs2X6WlKyyf190Wg0DwhqW2UZcX4WDqM8++4xJkyYxbtw43n77bXMOlKenJ7Nnz5YgSgghKuBEcjZ5hUZcHHQ0LqEgowRRVW/tQXUq7y4rjkLBlb0PCw0K6bmF5vw2ayoyGFl/JJn5saf552iyebTJx82RZr7qIgVT9QINGvP9u9v44+tuvYCxrqpwEPXxxx/z5ZdfEh0dzX//+1/z8c6dO/Piiy9atXNCCFHb7T2XBkCbBh4ljlRIEFW1cgsMbDqeAsCdrfyu07piHOy0eDrbk5ZTSHJWvlWCqJyCIs6m5nImNYd959JYsv0cCRl55sdva+bNsPBG3NnKD3tdpXZ2ExVQqcTyTp06FTvu6OhIdna2VTolhBB1hbnIZglTeXAliMotNJBbYLDayjGh2nQ8hfwiIw08nWjp72b18/u4OqpBVGY+zf0qdv7U7ALmbz3NyZRszqTmcCY1p8T8qvouDgzo3JAhXRpVy+1larMKB1GhoaHs3r27WIL5qlWraNWqldU6JoQQdcHey0FUuxKSygFcHe2w12koNChcyinAycE6W5IIlWlV3l2t/aqkarePmyPHkrIqnFxeaDAy8utt5kUHV/NwsqdRfWcaeTlzd2s/+rT1x9FOgmtbqHAQNX78eMaMGUNeXh6KorBt2zYWLlzI9OnT+eqrr6qij0IIUSsVGYwcjC+5UrmJRqOhnrMDSZn5pGYXEOgpQZS1GI0Kay9XKb/TyvlQJpVdoffxX8fZdz4dDyd7nuzVmOD6LmrgVN8ZD2f7659A3BQVDqIef/xxnJycmDBhAjk5OQwdOpTAwEA+/PBDBg8eXBV9FEKIWulYUhb5RUbcHO0I8Sp9Gqa+y5UgSljP3vPppGTl4+poR3ho1dRLMlUtr0itqN1n05izXt1ebVp0W+7rEFglfRM3rlIlDoYNG8awYcPIyckhKysLX9+qieCFEKI2M03VtGngXubyd0kurxqmVXm9mvvgYFc1SdgVHYnKLTAwfsluDEaF/h0CJYCq5ir8W3PHHXeQlpYGgLOzszmAysjI4I477rBq54QQojb7+4g6ldS+oWeZ7SSIqhqmrV4iW1fdQEBFt355d9VhTiZn4+fuyJv3t6myfgnrqHAQ9ffff1NQUPwfcl5enmyRIoQQ5fTngQRW7ktAq4F+7QPKbCubEFvf2dQcDidkotXA7c2rLojyrsAmxJuPp/DtllMAzHi4A57O1q8rJayr3NN5e/fuNX9/8OBBEhISzPcNBgOrVq2iQYMG1u2dEELUQhez8nnj530APNmryXVHokxbv1yUkSirMa3K6xxSv0qKYJqUdzovPbeQF5fuAWD4rY3o1dynyvokrKfcQVTHjh3RaDRoNJoSp+2cnJz4+OOPrdo5IYSobRRFYcLy/aRkFdDCz41xkc2u+xwv18sjURJEWc26y1u93GXlApvXMgVRqTkFFBqMpRbAnPrrAS6k5xHi5czr90q5oJqi3EFUXFwciqLQuHFjtm3bho/PlSjZwcEBX19fdDqpUyGEEGX5dU88f+xPwE6rYdbADuWq7yMjUdaVmVfI1pMXgaorbWBSz9kBnVaDwagw6PMY7mjpy+0tfGkdcGUxwR/7LvDTrvNoNTBrYEecHSq15kvYQLl/Uqbimkajsco6I4QQtVliRh6TfjkAwLN3NCtxw+GSeLnISJQ1bTiaQqFBobGPC419XKv0WjqthvvaB7B8dzw7z6Sx80wa760+irerI72a+9CtiRfTfj8IwNO3NyEsuF6V9kdYV6XD3YMHD3LmzJliSeb9+/e/4U4JIURtoygKry7bS3puIe0aePB/vZuU+7n1ZHVehZU1dWZelVfFU3kmswd34qU+Lfn7SBJ/H0lm8/EUUrLyWbbzHMt2ngOgVYA7Y+9sflP6I6ynwkHUyZMneeCBB9i3bx8ajQbl8pbRpnL5BoPBuj0UQohaYOn2c6w/koyDnZZZAztUaHNYr6tW5xmNSpk1peq6S9kFPL9kN/8cTaapjysRTbzo1sSL8FAv6rk4UGQwsv5yaYmbFUQBNPB0Ylh4MMPCg8kvMrD91CVzUJWVX8TsQR2rrFaVqDoVDqLGjh1LaGgo69atIzQ0lG3btnHx4kVeeOEF3nvvvarooxBC1GjnLuXw5gp1yubFu5tXeCNa01J3owIZeYWy9L0UB+LTefL7HZy7lAuoFeGPJWXxXcxpNBpo6e9OM19X0nIK8XS255ZGnjbpp6Odju5Nvene1Js3+tqkC8JKKhxExcTE8Ndff+Ht7Y1Wq0Wr1dKjRw+mT5/Oc889x65du6qin0IIUSMZjQov/7iXrPwiOgfXY1SPxhU+h4OdFjdHOzLzi7iYXSBBVAl+2X2eV5btJa/QSLCXM7MGdCA5M5+YkxeJOXGRY0lZHLqQwaEL6l6Fd7Twxa4Co4FClKTCQZTBYMDNTf0rytvbm/j4eFq0aEFwcDBHjhyxegeFEKImmx97mi0nLuJkr+O9AR3QVXIqrr6rA5n5RWpyuZQQMisyGPnvH4f5alMcoG7h8tHgTuZNeu9ppxYyTcrMY+vJVGJOXORsag5P3V7+nDQhSlPhIKpt27bs2bOH0NBQwsPDmTFjBg4ODnzxxRc0blzxv7CEEKI2W7jtLAAvRrUgxLv0TYavp56zA6cv5kiZg6tczMrn2YW72HJCLVcwpncTxt/VosRA1ddNT/8OgfSXveiEFVU4iJowYQLZ2dkAvPnmm/Tr14/bbrsNLy8vFi1aZPUOCiFETWU0KsSlqP9f3tHyxuoRSZkDSwfi0xn93Q7Op+Xi7KBj1oAO5lEnIW6WCgdRUVFR5u+bNm3K4cOHSU1NpV69euYVekIIISAxM4/cQgN2Wg0N6znd0LnMZQ5k/zzyiwyM+nY7CRlqhe8vRnSucLK+ENZglay6+vXrc+TIEZo3lxoXQghhEpesjkI1qu9coZIGJTFtQpyaJUHUL7viScjIw8/dkV+e6SEBlLAZqy1NyM/P58SJE9Y6nRBC1HgnL0/lhd5ALpRJfRmJAtQp0s83qJ81o3qE4uFkb+MeibpM1ncKIUQVibNmEOUsVctB3Tj4RHI2bo52DOnayNbdEXWcBFFCCFFFzEGUj/VGoup6YvkXl0ehht7aCDe9jEIJ25IgSgghqog1R6JMieV1ucTBjtOX+PfUJex1Gv7TPdTW3RGi/Kvzrrf6rqioyCodEkKI2qDQYORsag4Ajb1db/h8MhJ1ZRTqgU4N8HPX27g3QlQgiJo9e3YVdkMIIWqXc5dyKTIqONnr8HN3vOHzmYKo7AIDeYUG9Pa6Gz5nTXIiOYvVBxMBGN1TCjuL6qHcQdTIkSOrsh9CCFGrxKVkARDi7WKVGnruejvstBqKjAqXcgoI8LixulM1zVcbT6IoENnKl6a+UtJAVA+SEyWEEFXg5OUaUY2tkA8FoNForhTcrGNTekmZeSzbeR6AJ3vJnnei+pAgSgghqoA1k8pN6mqZg3lbTlFQZKRTI086B9ezdXeEMJMgSgghqkCVBFF1cCQqO7+I72NOA/BkzyayvZioViSIEkKIKmDNGlEmdTGIWvTvWTLyimjs7cJdrf1s3R0hLEgQJYQQVpZTUMSF9DzAejlRAPVc1OKSdaXMQaHByNeb4gB4/LbG6LQyCiWql3KvzjMZP358icc1Gg16vZ6mTZty//33U79+/RvunBBC1ESnUtT6UPWc7fG8nMdkDfVd1FIJdWX/vN/3XuB8Wi7erg48eEsDW3dHiGIqHETt2rWLnTt3YjAYaNGiBQBHjx5Fp9PRsmVLPv30U1544QU2bdpE69atrd5hIYSo7qoiHwqgvrM6ElXbp/Oy84tYeyiR99ccBeDRbiF1ri6WqBkqHESZRpm++eYb3N3dAUhPT+fxxx+nR48ePPHEEwwdOpTnn3+eP//80+odFkKI6s5UIyrUCpXKr1bf9fJIVC0MovIKDfx9JJnf9saz7lAieYVGQM0DG35rsI17J0TJKpwTNXPmTN566y1zAAXg4eHBlClTmDFjBs7OzkyaNIkdO3aU63xz5swhJCQEvV5PeHg427ZtK7P90qVLadmyJXq9nnbt2rFy5UqLxxVFYdKkSQQEBODk5ERkZCTHjh2zaPP222/TrVs3nJ2d8fT0LPE6Go2m2G3RokXlek1CiLot7vJ0Xqi3s1XPWxtLHGw5kcILS/bQZdpanvphB7/vvUBeoZEQL2eeu6Mpvz7T3apTokJYU4WDqPT0dJKSkoodT05OJiMjAwBPT08KCq7/j3zx4sWMHz+eyZMns3PnTjp06EBUVFSJ5wfYsmULQ4YMYdSoUezatYvo6Giio6PZv3+/uc2MGTP46KOPmDt3LrGxsbi4uBAVFUVeXp65TUFBAQMGDODpp58us3/ffPMNFy5cMN+io6Ov+5qEEKKqRqJMieWp2YVWPa8t5BUaeOPnfQz9MpZlO8+RmV9EgIee0T0b89szPVj/4u2Mv7sFDetZNxAVwqqUCho6dKgSGhqq/PTTT8rZs2eVs2fPKj/99JPSuHFjZfjw4YqiKMrChQuVsLCw656ra9euypgxY8z3DQaDEhgYqEyfPr3E9gMHDlT69u1rcSw8PFx58sknFUVRFKPRqPj7+yszZ840P56WlqY4OjoqCxcuLHa+b775RvHw8CjxWoDy888/X/c1lCU9PV0BlPT09Bs6jxCiZuk49U8l+JUVyoHz1v23fyEtVwl+ZYXS+LXfFaPRaNVz30ynUrKUez/coAS/skIJeXWF8sqPe5RtcRcVg6HmviZRu5T387vCI1Gff/45d955J4MHDyY4OJjg4GAGDx7MnXfeydy5cwFo2bIlX331VZnnKSgoYMeOHURGRpqPabVaIiMjiYmJKfE5MTExFu0BoqKizO3j4uJISEiwaOPh4UF4eHip5yzLmDFj8Pb2pmvXrnz99dcoilJm+/z8fDIyMixuQoi65VJ2AZdy1JGiECtP55lGogxGhYzcIque+3oKDUYS0vMwGsv+f/B6Vu2/QL+PNnEgPoP6Lg58+1hX/vtQe7qE1EcrJQxEDVPhxHJXV1e+/PJLPvjgA06ePAlA48aNcXW9MmzdsWPH654nJSUFg8GAn59l8TQ/Pz8OHz5c4nMSEhJKbJ+QkGB+3HSstDbl9eabb3LHHXfg7OzM6tWr+b//+z+ysrJ47rnnSn3O9OnTmTp1aoWuI4SoXeIuqivzAjz0ODtU+L/YMjna6XB1tCMrv4jUnAI8Lq/WqwpGo8LBCxnEnLjIlhMpbItLJbvAgJujHa0D3WnXwIN2DT1o28CDUC+X6wZABUVGpv9xiG82nwKgc3A9Ph7aqc5tpCxqlwr/C//hhx948MEHcXV1pX379lXRp2ph4sSJ5u87depEdnY2M2fOLDOIeu211yzqaGVkZBAUFFSl/RRCVC9xyVVT3sCknou9GkRl51v9GpeyC/htbzxbjl9ka9xF0nKK515l5hcRG5dKbFyq+Zirox2tA9wJqu9MoKeeAA8nAjz1BF7+mpFbyJgFu9hzNg2AJ3s25sWoFtjrpN6zqNkqHEQ9//zzPPXUU/Tv35/hw4cTFRWFTlfx+h3e3t7odDoSExMtjicmJuLv71/ic/z9/ctsb/qamJhIQECARZvyjI6VJTw8nLfeeov8/HwcHR1LbOPo6FjqY0KIuqGqakSZ1Hd24GxqrtWTy9NyCug/ZxNnU3PNx1wcdIQ39qJbEy8imnjRzNeNE8lZ7Dufzv7z6ew7n86hCxlk5Rex7VQq206llnhujQYUBTyc7Jk1oAORsn2LqCUqHERduHCBVatWsXDhQgYOHIizszMDBgxg2LBhdOvWrdzncXBwICwsjHXr1plXvRmNRtatW8czzzxT4nMiIiJYt24d48aNMx9bs2YNERERAISGhuLv78+6devMQVNGRgaxsbHXXYl3Pbt376ZevXoSJAkhylTlQZR5/7x8q53TYFR4duEuzqbmEuihZ2h4IyKaeNO+oUex0aJWAe60CnBnYGd1lL3IYOREcjaHLmRwPi2XC+m5XEjLIz49jwvpuaTlFKIo0CHIk0+GdCKovqy2E7VHhYMoOzs7+vXrR79+/cjJyeHnn39mwYIF9O7dm4YNG3LixIlyn2v8+PGMHDmSzp0707VrV2bPnk12djaPPfYYACNGjKBBgwZMnz4dgLFjx9KrVy9mzZpF3759WbRoEdu3b+eLL74A1NpO48aNY9q0aTRr1ozQ0FAmTpxIYGCgRXmCM2fOkJqaypkzZzAYDOzevRuApk2b4urqym+//UZiYiK33norer2eNWvW8M477/Diiy9W9O0SQtQxJy8HUY2tuPHw1eqZgyjrjUTNWn2EjcdScLLX8b9Hu9AqwP36T7rMTqelhb8bLfzdSnw8p6CISzmFBHro0WgkcVzULjeU9ejs7ExUVBSXLl3i9OnTHDp0qELPHzRoEMnJyUyaNImEhAQ6duzIqlWrzInhZ86cQau98ldQt27dWLBgARMmTOD111+nWbNmLF++nLZt25rbvPzyy2RnZzN69GjS0tLo0aMHq1atQq/Xm9tMmjSJefPmme936tQJgPXr13P77bdjb2/PnDlzeP7551EUhaZNm/L+++/zxBNPVOp9EkLUDYqicOpyEBXiVTVBlNflIOqSlfbPW7X/Ap/+rf7x++7D7SsUQJWHs4Od1RPshaguNMr11u2XwDQCNX/+fNatW0dQUBBDhgxh2LBhtGzZsir6WSNlZGTg4eFBenq6RYV3IUTtlJCex63T16HTajj8Vp8qSZz+9O/jzFh1hIduacisgR1u6FzHEjOJnrOZ7AIDj/cIZUI/2e9UCCj/53eF/zwYPHgwK1aswNnZmYEDBzJx4kRzTpIQQtRlJy9XKm9U37nKVp5ZayQqI6+QJ7/fQXaBgYjGXrx6j/wBLERFVTiI0ul0LFmypMRVefv377eYWhNCiLqkqpPKAepd3kfu4g3sn2c0KoxfvIeTKdkEeuj5ZGgn7KTcgBAVVuEgav78+Rb3MzMzWbhwIV999RU7duzAYDBYrXNCCFGTVHWNKLiyOu/SDQRRn6w/ztpDiTjYaZn7SBherrLqWIjKqHS234YNG/jf//7HsmXLCAwM5MEHH2TOnDnW7JsQQtQoN2MkqjxBVF6hgeTMfAoMRgoNRgqLFPP3J5Kz+GDtUQCmRbelfUPPKuurELVdhYKohIQEvv32W/73v/+RkZHBwIEDyc/PZ/ny5bRuLQmJQoi6zRRENb4JQVRmfhH5RQYc7SzTKo4nZTH0y60kZZZdR2r4rY3MtZ6EEJVT7iDqvvvuY8OGDfTt25fZs2fTp08fdDqdedNhIYSoywoNRs6k5gAQWkU1ogDc9fbotBoMRoW0nEL83K8EUZl5hYz+fjtJmfk46LQ4Oeiw12lx0Gmwt9Nir1NvnYPrMVFW4glxw8odRP3xxx8899xzPP300zRr1qwq+ySEEDXOuUu5FBkVnOx1+Lnpr/+EStJqNdRzticlq4CLWQX4uavXMhoVXliyh5PJ2fi76/nt2R74uEmukxBVqdzLMTZt2kRmZiZhYWGEh4fzySefkJKSUpV9E0KIGiPucnmDYC9ntNqqrcxtWqF3dZmDz/45weqDiTjotHw2/BYJoIS4CcodRN166618+eWXXLhwgSeffJJFixYRGBiI0WhkzZo1ZGZmVmU/hRCiWjuZXLXbvVzNlBdlKnPwz9Fk3lt9BICp97ehU6N6Vd4HIUQFgigTFxcX/vOf/7Bp0yb27dvHCy+8wH//+198fX3p379/VfRRCCGqvZuxMs/k6hV6Z1NzeG7hLhQFhnQNYkjXRlV+fSGE6oaqq7Vo0YIZM2Zw7tw5Fi5caK0+CSFEjXPqoimIcq3ya5mCqPi0XEZ/v4P03EI6BHkypX+bKr+2EOIKq+wKqdPpiI6OJjo62hqnE0KIGudmFNo0MQVR32w+RYHBiLerA3OH31Ks3IEQompJnX8hhLhBuQUG4tPzgKqtEWViSiwvMBjRaTV8MvQWAjycqvy6QghLEkQJIcQNMk3leTrbU+/yKFFV8nK9co3X723FrY29qvyaQojirDKdJ4QQddnNTCoH6BpaHz93R6La+POf7iE35ZpCiOIkiBJCiBt0s4OoAA8ntr52JxpN1dajEkKUTabzhBDiBplqRIV63ZwgCpAASohqQIIoIYS4QaZq5VW5Z54QovqRIEoIIW5AUmYehxPUHRtu1nSeEKJ6kCBKCCEqSVEU3vh5PzkFBtoEutPK393WXRJC3EQSRAkhRCX9uieeNQcTsddpeG9AhyrfeFgIUb1IECWEEJWQlJnH5F8PAPDsHc1oFSCjUELUNRJECSFEBSmKwoSf95OWU0ibQHeevr2JrbskhLABCaKEEKKCft0Tz+qDidhp1Wk8e538VypEXST/8oUQogJkGk8IYSJBlBBClNPV03itA9z5v94yjSdEXSZBlBBClJNM4wkhrib/AwghqqWNx5L5auNJDEbF1l0BIDkz32Iar3WgTOMJUdfJBsRCiGonNbuAJ7/fQU6BgbxCA8/c0axKr2c0KpxJzeHQhQzScgvJLzSQX2Qkr9BIfpH6/fbTl2QaTwhhQYIoIUS189XGk+QUGAD4YO0xujf1plOjelY5d6HByInkLPafz+BAfDoH4jM4GJ9BVn7RdZ8r03hCiKtJECWEqFYuZRcwb8spAJr7uXI0MYuxi3bz+3M9cNPb39C5Nx9P4f/m7yQ9t7DYYw52Wlr6u+Hr5oijvQ5HOy36a752Dakv03hCCDMJooQQ1crXm+PILjDQKsCdRaNv5d4PN3ImNYfJvx7g/YEdK33eMxdzzAGUm6MdrQLdaRPoTptAD9o2cKeJj6uMMAkhKkSCKCFEtZGeU8i3m08BMPbOpng42fPh4I4M/DyGn3aep1dzH+7v2KDC583OL2L099tJzy2kY5Ani5+8FUc7nZV7L4Soa+TPLiFEtfG/zXFk5hfR0t+Nu1v7A9A5pL45sXzCz/s5m5pToXMqisJLP+7hcEImPm6OzB0eJgGUEMIqJIgSQlQL6bmFfLM5DlBLCGi1GvNjz93RlFsaeZKZX8Tzi3dTZDCW+7yf/XOClfsSsNdpmDv8Fvw99FbvuxCibpIgSghRLXy7+RSZeUU093Plnrb+Fo/Z6bR8OLgTro52bD99iU/WHy/XOdcfSWLmn0cAmNq/LWHB9a3ebyFE3SVBlBDC5jLyCvnfppNA8VEok6D6zkyLbgvAR+uOseN0apnnjEvJZuzCXSgKDOnaiKHhjazfcSFEnSZBlBDC5uZtPkVGXhFNfV25t11Aqe2iOzUgumMgRgWeW7ibpdvPcjwpE+M1Vc2z8osY/d12MvKKCAuux5T+rav6JQgh6iCbB1Fz5swhJCQEvV5PeHg427ZtK7P90qVLadmyJXq9nnbt2rFy5UqLxxVFYdKkSQQEBODk5ERkZCTHjh2zaPP222/TrVs3nJ2d8fT0LPE6Z86coW/fvjg7O+Pr68tLL71EUdH1i/EJISomM6+QrzaZcqGaoithFOpqb0a3pWE9J86n5fLSj3uJfH8DHaauZthXW5n552FWH0hg/OLdHEvKws/dkc+G3SKJ5EKIKmHTIGrx4sWMHz+eyZMns3PnTjp06EBUVBRJSUkltt+yZQtDhgxh1KhR7Nq1i+joaKKjo9m/f7+5zYwZM/joo4+YO3cusbGxuLi4EBUVRV5enrlNQUEBAwYM4Omnny7xOgaDgb59+1JQUMCWLVuYN28e3377LZMmTbLuGyCE4LuY06TnFtLYx4V+7QOv295db8+i0bfyeI9QuoTUQ2+vJTO/iM3HLzJn/QlGf7+D1QcTcdBp+Wx4GL7ukkguhKgaGkVRbLa7Z3h4OF26dOGTTz4BwGg0EhQUxLPPPsurr75arP2gQYPIzs5mxYoV5mO33norHTt2ZO7cuSiKQmBgIC+88AIvvvgiAOnp6fj5+fHtt98yePBgi/N9++23jBs3jrS0NIvjf/zxB/369SM+Ph4/Pz8A5s6dyyuvvEJycjIODg7len0ZGRl4eHiQnp6Ou7tUORbiWtn5RfR49y8u5RTywaAOPNCpYYXPUWgwcjQxkz1n09l99hJ7zqZz9lIO06Lb8uAtFT+fEEKU9/PbZsU2CwoK2LFjB6+99pr5mFarJTIykpiYmBKfExMTw/jx4y2ORUVFsXz5cgDi4uJISEggMjLS/LiHhwfh4eHExMQUC6JKExMTQ7t27cwBlOk6Tz/9NAcOHKBTp07lfZlC1HnbT6WSkJGHo526dYqjnda8rcrvey9wKaeQUG8X7ivHKFRJ7HVa2gR60CbQQ5LHhRA3lc2CqJSUFAwGg0WgAuDn58fhw4dLfE5CQkKJ7RMSEsyPm46V1qY8SrvO1dcoSX5+Pvn5+eb7GRkZ5b6mELXRyn0X+L/5O6/bbkzvptjJlitCiBpGtn2xounTpzN16lRbd0OIauFEchYvLd0DQEt/N/T2OvKLjOQXGcgvNKrfFxro2MiT6I6VG4USQghbslkQ5e3tjU6nIzEx0eJ4YmIi/v7+JT7H39+/zPamr4mJiQQEBFi06dixY7n75u/vX2yVoOm6pfUN4LXXXrOYbszIyCAoKKjc1xWitsgpKOLpH3aQXWAgPLQ+8x8Pl5EmIUStY7P/1RwcHAgLC2PdunXmY0ajkXXr1hEREVHicyIiIizaA6xZs8bcPjQ0FH9/f4s2GRkZxMbGlnrO0q6zb98+i1WCa9aswd3dndatS6834+joiLu7u8VNiLpGURTe+Hk/RxOz8HFz5OOhnSSAEkLUSjadzhs/fjwjR46kc+fOdO3aldmzZ5Odnc1jjz0GwIgRI2jQoAHTp08HYOzYsfTq1YtZs2bRt29fFi1axPbt2/niiy8A0Gg0jBs3jmnTptGsWTNCQ0OZOHEigYGBREdHm6975swZUlNTOXPmDAaDgd27dwPQtGlTXF1dufvuu2ndujWPPPIIM2bMICEhgQkTJjBmzBgcHR1v6nskRE3zQ+wZft51Hp1WwydDOuHrJiUGhBC1lGJjH3/8sdKoUSPFwcFB6dq1q7J161bzY7169VJGjhxp0X7JkiVK8+bNFQcHB6VNmzbK77//bvG40WhUJk6cqPj5+SmOjo7KnXfeqRw5csSizciRIxWg2G39+vXmNqdOnVLuuecexcnJSfH29lZeeOEFpbCwsEKvLT09XQGU9PT0Cj1PiJpq95lLSrPXVyrBr6xQPv/nuK27I4QQlVLez2+b1omq7aROlKhLLmUX0O/jTZxPyyWqjR9zh4eh0ZRdfVwIIaqj8n5+S6KCEOKGGY0K4xbv5nxaLiFezswc0EECKCFErSdBlBDihn3813H+OZqM3l7dasVdb2/rLgkhRJWTIEoIcUMW/3uG2euOAjAtuh2tAmTqWghRN0gQJWqVvefSiJi+jv9tirN1V2o9o1Fh+spDvLJsH4oCj9wazMNhsledEKLukCBK1BqKojD1t4NcSM9jxqrDJKTn2bpLtVZOQRFP/bCDzzecBGDsnc148/42Nu6VEELcXBJEiVrjr8NJ7Dh9CYD8IiMfrjtm4x7VTgnpeQz8PIbVBxNx0Gn5cHBHnr+ruSSSCyHqHAmiRK1gNCrM/PMIALc18wZgyfaznEjOsmW3ap3959OJnrOZ/eczqO/iwIInwrm/YwNbd0sIIWxCgihRK/y2N57DCZm46e34eEgn7mzpi8GoMGv1EVt3rcZIyshjw9Fktp68yJ6zaRxLzORsag4Xs/LJKShi9YEEBsyNISEjj6a+riz/v+50Dqlv624LIYTN2HTbFyGsodBg5P016uqwJ3s2xtPZgZf6tOCvI0ms3JfAnrNpdAjytG0nq6G8QgPb4lLZeCyZjcdSOJyQWa7n3dbMm0+G3oKHk5QxEELUbRJEiRpv8b9nOX0xB29XBx7rHgpAS393HujUgJ92nmfGn4eZ//itNu5l9RCflsuKvfFsPJZCbFwqBUVG82MaDTT2dgEgt8BAbqGBnAID+ZfbaDUwLDyYSfe1xl42FBZCCAmiRM2WW2Dgo8sJ5M/e0QwXxyu/0s9HNmfFngtsPn6RjceSua2Zj626aXN5hQY+/+ckn/593BwUAQR46LmtmTc9mvnQvYkXXq7FN9g2GhXyigwYFXB1lP8yhBDCRP5HFDXavJhTJGXm07CeE0O6NrJ4LKi+M8NubcQ3m08xY9URujfxRqutWyvIFEVhzcFE3lxxkHOXcgEIC65H33YB9GzuTRMf1+uuqtNqNTg7yH8VQghxLfmfUdRY6bmFfPb3CUAddXKwKz7F9Ezvpiz59yz7zqezcv8F+rUPvNndtJkTyVlM/e0gG44mA+qo0xt9W9G3XYCUIxBCCCuQIErUWF9sOEF6biHN/VyJ7lTyMnsvV0ee6NmY2WuP8d6fR4hq418r8nkURcFgVCgyKhiVy18v388vMvJdzCm+3hRHoUHBQafliZ6hjOndVEaUhBDCiuR/VFEjJWXm8fWmUwC8cHcLdGVM0z1+W2O+jznNqYs5LP73LMNvDb5Jvawa+86lM3bRLk6mZF+37R0tfZnUrzUhlxPGhRBCWE/N/5Nc1Elz/jpObqGBjkGe3N3ar8y2ro52PHtHUwA+XHeM3ALDzehilfhl93kenrulzABKp9XQzNeV/43szNePdpEASgghqoiMRIka52xqDgu2nQHg5agW5crvGRLeiK82xXHuUi5fb45jTO+mVd1NqzIYFd5bfcScA3ZHS1/eeaAdLo467LRatFrUrxok30kIIW4SGYkSNYqiKEz59QCFBoUeTb3p1tS7XM9ztNPxwt3NAfhy40lyCoqqsptWlZlXyOjvtpsDqKd6NeHLEZ3x99DjprfHyUGHo50OnVYjAZQQQtxEEkSJGmXRv2dZdzgJB52Wif1aV+i5/Ts0oFF9Z9JyCvlxx7kq6qF1nUrJ5oFPt7DucBKOdupmv6/e07LMHDAhhBA3hwRRosY4lZLNWysOAvBynxa08Her0PN1Wg2P36ZWNP9qYxwGo2L1PlrTpmMp3D9nM8eTsvBzd2TJkxGy2a8QQlQjEkSJGqHIYOT5JbvJKTAQ0diL/1ze3qWiHg5riKezPWdSc1hzMMHKvbSOY4mZPLtwF498HUt6biGdGnny2zM9ZP8/IYQwURSI3w17Ftu0G5JYLmqET/8+wa4zabg52vHewA6Vrjzu7GDH8PBgPll/nC82nKRP2wAr97TyjiZm8tG6Y/y+7wLK5UGyQZ2DmHp/G/T2Ott2TgghqoOkw7B/mXpLPQH2ztCqHzjYZhWyBFGi2ttzNo0PL++P92Z0Gxp4Ot3Q+UZ0C+aLDSfZeSaNHadTCQuub41uVtqRBDV4Wrn/SvDUp40/z97ZlDaBHjbtmxBC2NzFE3DgJ9j/MyQduHLczgmaR0FumgRRQpQkt8DA80t2YzAq9G0fQLQVcoJ83fQ80KkBi7ef5YsNJ/n8kaoLoooMRradSiU9p5DsAgO5BUXkFBgu34qIS8lh7aFEc/t72vrz3J3NaBXgXmV9EkKIas9ohCO/w6bZcH77leNae2h2F7R9CJr3AUdXm3URJIgS1dz0Pw5xMjkbXzdH3o5ua7Ul/I/fFsri7WdZfTCRuJRsQqugIGVWfhGjvv2X2LjU67a9t50aPLX0l+BJCFGHGY1w6Bf4Z+aVUSeNDhr3UgOnln3BqZ5t+3gVCaJEtfX3kSS+izkNwHsDOuDp7GC1czfzc+OOlr78dTiJ/206ybTodlY7N0BaTgEjv/mXPWfTcHHQ0TrQHScHO1wcdDg56HB20OHsYIebox13t/Gv8EpDIYSoVYwG2P8TbHwPkg+rxxzcIHw0hD8Frr627V8pJIgS1dKl7AJe+nEvAI92C6Fncx+rX+OJ2xrz1+Eklm4/x/i7WlDfxTpBWnJmPo/8L5bDCZnUc7bnu/+E066h5DYJIUQxhkLY96MaPF08rh5z9IBbn4bwJ8HZtjmr1yNBlKhWUrLyWfzvWeZvPU1yZj5NfFx4pU/LKrnWrY3r066BB/vOp/PD1tM8d2ezGz7nhfRchn0Zy8mUbHzcHJn/eDjN/WSUSQghLOSlw455EDsXMs6rx/SeEPGMOvqkrxl/eEoQJarUhfRcEjPyCfV2wcPJvsQ2iqKw88wlvos5zcp9Fyg0qEvUvF0d+XBwJ5wcqmZ5v0aj4YmejXlu4S7mbTnF6J6Nb6iUwOmL2Qz7KpZzl3Jp4OnE/MfDZfNfIUTNUlQAmRfUESAHV7D2VlJpZ9XAacc8KMhUj7n4qCNPXUeDY836o1OCKFFlTl/Mpt/Hm8jMU/ep83FzpImPC419XGni40oTHxcS0vP4LuY0By9kmJ/XMciTR24Npm/7gCqvj3RvW3/e9XTifFouP+86z5CujSp1nuNJmQz7KtYcMP7wePgNl2IQQoibKn43LBgEWZcLEescwNnr8q2++tWpPjh5qsndek/1e/3l+45uoNFeFXhpLn+vUUebtn4GB34GxaA+7N0Cuj0D7QaCvf4mv1jrkCBKVImCIiPPLdxFZl4RjnZa8ouMJGfmk5yZz9aTxVerOdpp6d8hkBERITc1f8hOp+Wx7iFM+/0QX248yaDOQeUu5JlTUMTJ5GwOJ2TyzspDpGYX0MLPje8f74qvW838D0EIUUedWA+Lh0NBlhoIKUYwXB6Vyrxg3WuF9oSIZ6FpJGhr9sYpEkSJKjFrzRH2nEvHw8meP8behpvejpPJ2ZxMyeJEUjYnkrM4mZwNwENhDRgQFkQ9KyV2V9Tgro34cN0xTiZn89fhJCJb+6EoCjkFBi7lFHApu5DUnALOX8rleFIWJ5KzOJ6Uxfm0XIvztGvgwXf/6Wqz1yGEEJWy70f4+SkwFqoBzqD5oLWDnItX3VKvfJ+Xpha4NH3NvaR+n5+JuWIwiuX3WntodZ868hTQwQYvsmpIECWsbsPRZD7/5yQAMx5uT+Dlaa0OQZ7Vcv83V0c7hoY34vN/TvLC0j042etIzSmgoMh43efWd3GgqY8rHYI8ePbOZrjrS877EkKIailmDvz5uvp9mwfggc/BzlG97+AMnkG261sNIEGUsKrkzHzGL9kDwCO3BhPVxt/GPSqfx7qF8t2W06TnFpKeW2g+7mCnpb6zA/VcHPB1c6Spr5rP1dRXvVmrLIIQQtxURiOsnQxbPlLvhz8FUdNr/PTazSZBlLAao1Fh/JLdpGTl09LfjTf6trJ1l8rN30PP78/14Oyl3MtBkz31XRxwstdZrUq6EEJUC4ZC+GUM7F2s3o+cAt3HWX8lXh0gQZSwmq82nWTjsRT09lo+HtKpylfWWVtjH1ca+9h2HyYhhKhSRgMsGgrHVqvbqdz/CXQcaute1VgSRAmr2HM2jRmrjgAw+b42NJMCk0IIUf0cXaUGUHZOMPA7aH63rXtUo8nkp7hhmXmFPLtwF0VGhb7tAhjcRRIRhRCiWtrxrfo1/EkJoKxARqJEheQXGUjNLuBiVgGp2erttz3xnEnNoYGnE+882E5yiIQQojpKOwvH1qjf3zLCtn2pJarFSNScOXMICQlBr9cTHh7Otm3bymy/dOlSWrZsiV6vp127dqxcudLicUVRmDRpEgEBATg5OREZGcmxY8cs2qSmpjJs2DDc3d3x9PRk1KhRZGVlmR8/deoUGo2m2G3r1q3We+E1xPojSdz74UbaTv6TFhNWETH9L/p9vIkRX29j3OLdrDuchE6r4aMhnUrd2kUIIYSN7foeUNRaUF5NbN2bWsHmQdTixYsZP348kydPZufOnXTo0IGoqCiSkpJKbL9lyxaGDBnCqFGj2LVrF9HR0URHR7N//35zmxkzZvDRRx8xd+5cYmNjcXFxISoqiry8PHObYcOGceDAAdasWcOKFSvYsGEDo0ePLna9tWvXcuHCBfMtLCzM+m9CNZWRV8jLP+7hsW/+5eCFDLLy1e1b7LQafN0caenvRvemXtzXIZCvRnQmLLiejXsshBCiRIYi2PWD+n3YozbtSm2iURRzSVGbCA8Pp0uXLnzyyScAGI1GgoKCePbZZ3n11VeLtR80aBDZ2dmsWLHCfOzWW2+lY8eOzJ07F0VRCAwM5IUXXuDFF18EID09HT8/P7799lsGDx7MoUOHaN26Nf/++y+dO3cGYNWqVdx7772cO3eOwMBATp06RWhoKLt27aJjx46Vem0ZGRl4eHiQnp6Ou7t7pc5hK/8cTebVZXu5kJ6HRqPWURp+ayO8XBxxd7KTKTshhKhJjqyChYPUve9eOHyloKYoUXk/v206ElVQUMCOHTuIjIw0H9NqtURGRhITE1Pic2JiYizaA0RFRZnbx8XFkZCQYNHGw8OD8PBwc5uYmBg8PT3NARRAZGQkWq2W2NhYi3P3798fX19fevTowa+//lrm68nPzycjI8PiVtNk5hXy6rK9jPx6GxfS8wjxcmbx6Agm3deaxj6ueDjbSwAlhBA1jSmhvONQCaCsyKaJ5SkpKRgMBvz8/CyO+/n5cfjw4RKfk5CQUGL7hIQE8+OmY2W18fX1tXjczs6O+vXrm9u4uroya9YsunfvjlarZdmyZURHR7N8+XL69+9fYt+mT5/O1KlTy/PSq6WNx5J55ce9xKer056PdQ/h5aiWODnUrHpPQgghrpJ+Ho79qX4vU3lWJavzSuHt7c348ePN97t06UJ8fDwzZ84sNYh67bXXLJ6TkZFBUFDNWO6/an8CT/2wA4BG9Z2Z8XB7bm3sZeNeCSGEuGG754NihOAe4N3M1r2pVWw6neft7Y1OpyMxMdHieGJiIv7+Je+55u/vX2Z709frtbk2cb2oqIjU1NRSrwtq/tbx48dLfdzR0RF3d3eLW03xXcwpAO7rEMiqcbdJACWEELWB0QA7v1O/Dxtp277UQjYNohwcHAgLC2PdunXmY0ajkXXr1hEREVHicyIiIizaA6xZs8bcPjQ0FH9/f4s2GRkZxMbGmttERESQlpbGjh07zG3++usvjEYj4eHhpfZ39+7dBAQEVPyFVnPJmflsPXkRgJejWuDsIAOUQghRK5z4C9LPgt4TWpU8iyIqz+afluPHj2fkyJF07tyZrl27Mnv2bLKzs3nssccAGDFiBA0aNGD69OkAjB07ll69ejFr1iz69u3LokWL2L59O1988QUAGo2GcePGMW3aNJo1a0ZoaCgTJ04kMDCQ6OhoAFq1akWfPn144oknmDt3LoWFhTzzzDMMHjyYwMBAAObNm4eDgwOdOnUC4KeffuLrr7/mq6++usnvUNX7Y/8FjAp0CPIkqL6zrbsjhBDCWq5OKLfX27QrtZHNg6hBgwaRnJzMpEmTSEhIoGPHjqxatcqcGH7mzBm02isDZt26dWPBggVMmDCB119/nWbNmrF8+XLatm1rbvPyyy+TnZ3N6NGjSUtLo0ePHqxatQq9/sov0Pz583nmmWe488470Wq1PPTQQ3z00UcWfXvrrbc4ffo0dnZ2tGzZksWLF/Pwww9X8Tty863YewGA+9rXvlE2IYSoszIT4Mgf6ve3yFReVbB5najarCbUiUrMyOPW6etQFNjy6h0EejrZuktCCFF3nNsBZ2Kg83/AwcozARveg7/egqBbYdSf1j13LVfez2+bj0QJ21q57wKKAmHB9SSAEkKIm+non7B4OBgKYN9SGLIQ3AOtc26jEXbOU7+XsgZVxubbvgjbMk3l9W0nU3lCCHHTHP4dFg1TAyiNFi7shi/vgPhd1jn/yfWQdgb0HtAm2jrnFMVIEFWHxaflsuP0JTQa6Cv5UEKIusBogJTjYMtMlgPLYckIMBZCmwdgzDbwaQmZF+Dre9THb5RpFKr9ILCXWYaqIkFUHbZynzoK1SWkPn7usmpDCFHN5GdBQbZ1zmU0wN6lMKcrfBIGSx+FwlzrnLsi9v0IP/4HjEXQbiA8+JVaAHPUamh6FxTlwtKR8M/MygV66edg+9fqSBfIVF4Vk5yoOuy3y1N5/WQUSghR3RxZBT+PBgW4513oMBgqs2+n0QgHf4a/34WUI1eOH1yu1k8avBDc/Ep9upmhUB0hyrmo7j1npwc7B/WrzlE95tEQ6oWU3s/dC+GX/1Orh3ccBv0/Bu3lbbX0HjB0MayeAFs/hfXT1P72/6Ts0gRFBWpi+vE1cGwtJB+68lhwd/Brc/3XJipNgqg66mxqDnvOpqHVQJ+2pVdpF0JUQwXZEPs5BHWFkB627o11GQ3w93TYMPPKseVPwaFfod/s8gU8oAZPh36Ff96FpIPqMb0ndHsWAjrAT0/A+R3w1Z1q8FJWsBG3AX5/0TIIK42rPzQKh0YR0OhW8GsHOju1avivzwGKWm6g32zQXjMZpNVBn+ng3RxWvqgmm6cchQadQTGoo1dG4+XvDZCfAae3QEHWlXNotNCwizqq1WVU+d4rUWlS4qAKVecSB3P/OcF//zhMRGMvFo6+1dbdEUKUV0EOLBykfrCjgTvegB4vFP9AromyL8JPj6tVtgG6PAHuAbB+upo/5FQP+s6Ctg+Vfo6sJDiyErZ9CYn71WOOHtDtGQh/CvSX/y++eAIWDISLx8HBDQZ8C80iLc+VcUEdGdr/o3rf2RtCb1NHfwz5UGS65am31Di1n1ezdwH/dnB265XXdM+M6/+84jbA4kcgL+167xq4+EDTSPXW5A5wrn/954gylffzW4KoKlSdg6h+H29k//kM3n6gLcPCg23dHSFEeRTmwcLB6sorrf2VD+yW/SD6sysBws10bjvEfAJHV6u5PY1vV2+NIipWIfv8DlgyUp1is3OC/h9B+4HqY4kH4OenIGGver91tBpMuXir9y+dgkMr4PAKOLMVdQ4QcHSHW/8Pbn0anDyLXzMnVU3wPrVRHcG5ZwZ0fUKduov9XB0RK8hSH+s8Sg1YneqV/hoKc9XVdWdi4EysGjjlpV95/Nb/g6h3yj8teek07FsChiJ1lEqjBa3d5e91oLOHhp3Bv0PtCKKrEQmiqoHqGkSdSsnm9vf+RqfVsO31O/FydbR1l4QQ11OUry6JP75GHd0Yvkyd6ln5orpM3qsZDJ4PPi0qf420M5CVDL4twcGl9HZGgzras+WTKyMs17LTq9NZpqCqfmM1qLk2gFAUdWuSP15WX0f9xjDoh+LTa4ZCtXjkxvfUaS0XH3Xl2cm/r4w4mQR2glb3Qdhj1x+VKSqAFc/D7h/U+x2GqoGQKbeoYRe49z0I7Fj2eUpiNELyYfU9sndW+1uZvC5x00kQVQ1U1yBqzvrjzPzzCLc18+b7UaVvuCyEqCaKCtQRk6N/qKM0w3+8kgt1bgcseQQyzoODKzwwVw0gyiMvA05tUqfPTq5Xp7ZAHfHwaakGI4GdIPAWNahRDLBrvpr4fClObau1V0eMbhmhjpycXK8GNpkXil9Po1NHcpzqqcGNUz11Guzk3+rjLfrCA5+pSdalid+tjkpdnUCt0UFwN/V1t+yrJnhXhKLApg9g3dQrx5y9IHKqmgAuozx1jgRR1UB1DaL6zN7A4YRM3n2oHYO6NLJ1d0RdZTTA7gXqX+Ydhlb9B5WiqMu+d/0ALl7QsKs6yuDT4soKKWvLTVOrUqccUROOPRqAewP1Q97Zq3yjEoZCdTn+4RXq6M7QxerIztWyktU2pzep9297AXq/oa4Cy89UE5DzMq58TdinBjtnt6mBkYlGpwY32cnF+6G1U69vSmJ2qqdOcXV9AtyuWZyiKOoo2cm/4cR6Nfk5P73YKa9cVwt3TITu48r3e1CUD1s+huQj0KQ3NO9jnTygg7/AmsnqOe+YKLlFdZgEUdVAdQyijidlEfn+P9hpNWyfEImns4OtuyTqopTj8MuYK1NBTSMhei64+lTN9U5tgrVT4Ny/xR9zcIMGt6gBVVBXNZfnRnKLslPUgOfQb3Dyn+KJxiY6R3WLD88g8G9/ZdSnfuMrwZWhCJaNUpfj6xzUbUGaRpZ8PkMhrJmkjhKB2t5QcP3+1m8MjXurgUPIbWruUMYFtYJ2/C71dn4n5KRcbt8EIv4POgwpe8rvWoW5alCZmwq5l9RbTqqaMxTSHRqElf9cQlQxCaKqgeoYRH249hgfrD3K7S18+PaxrrbujqhrjAaInQvr3lSncRxc1fyWojx1pObBL6BxL+td78Ie9VrH16r37Z3VkRONTg2ozu+EwmuKOdrpocW9av5K0zvV5N2yKIo6tXVsDRz8Fc5sUUeATHxaqrlB2SnqlFtGPGQlln4+vQcEdFQDqovH1YBMaw+DF0Dzu6//mvcuhd+eg8Kcq16TkxoYOrqDo5sauJkCp3oh1z+noqh9z0pS+ybTW6KWkyCqGqiOQdTdH/zD0cQs3hvQgYfDKpg3IGo3o0H9oHf1LX/yq6KoozwHfgZXPzUAahBWcuBx8YQ6+nQmRr3f+Ha1kGB+Jvz4mJqAiwZ6vgi9XlVr61TWxROw/p0rS9O1dmrl5p4vW9YZMhSpuTXn/lVXmZ3eciXXB9QptzYPqgFVw87q+1KYq+blnI1Vn3c2tvj0V0BHaN0fWt4HPs2L96+oADLjIf08pJ5Ug734Xeo0myHfsq3WTk20bnFP+V9/fqb6s9R7qEHT9QJBIYQFCaKqgeoWRB1NzOTuDzbgoNPy74RIPJzkP1aBuoLowE9q0JF6Ql3l1WGwGjh4BpX8nMI8tRBg7OeQuM/yMQdXtVJy49vVoMqnJWz7AtZOVbe0cHCFu6epQY0pWCvIgVWvqAUJQZ1Se+ir6ycIF+bBxWNqbkzKUcuvplyfdgOg9+vqtNX1KIo6jbV3ibo9R3bSlcfqhao5Mhf2Fp+i015eat7qPvXmWclcQ0MhJB1SA6oLuyHlGESMqVgAJYS4YRJEVQPVJYgyGBU2Hkvms79PEBuXSmQrX74a2cVm/RHVhKKoy9T/ehuSDpTcJuQ2NaBq1V+dDsq4AP9+BTu+Ube/AHWKrO1D6uhH3AY15+Vq9s5XppZCe8H9n5QeZOz7EX4bBwWZanXpOyaoSd+m/JnctMv5NKmQmQBppy2nzq7W9C64cxIEtK/gG3OZoQji/lYDqkO/WU6Pufqp+VMNu0JQuFoBuyI1kYQQ1ZoEUdWArYOoUynZ/LjjHD/uOEdCRh4AWg1881hXejWvogTemspQpG4RkZ+hjoJ4N6/6ei5FBXBum1oF2avJzZtyURR1ZdZf09QCh6DmynR7FjoNV5e771mkFiA0sXNSR1rOxKg5TAAeQWp+0S0jrhQgNBrVkamT/6grs87EqMGHgyvc9SZ0/s/139fUk+oGrfG7yvd69J7qCjvv5pe/tgDfVqWPolVGfpZan8lQBEFdwDNY6v0IUYtJEFUN2CKIyis08PveCyzZfpbYuCsjAp7O9kR3bMCgLkG0CrD91GK1oShqQvCaiZdzci5z9lbrzgR3V7/6tbHeMvicVHWX9W1fQlaCekznoAYBvq0u39qoBQ/tna9sLWEwbS9RoH71bGS5kut6Ci/X44n55EqAZO+sboXR7dniy7nTzqijMHsWqVNmJo26wa1PqTV9rpe3VJSvFkL0DL5SXbo8igrUooqnNqlBklM9ddWYqbaQU331fN7N1aKLEtAIIaxIgqhq4GYHUadSshk1719OJKurjTQa6NnMh4Gdg4hs7YujXRXVwqmpLuxV98WK+0e971RPDV7Ob1eDlKvpPcCnlTpapNFe2XZBq1MTfx1c1YrGDTqr00d2JVSBTzmmLj/fvVDNDQI1GCjKL75CrLzqhVzeM+sudU+va5ec56TCsdXqCq/jf125js5BrfFz23g1kbwsigLxO9XtNIK7V65ysxBC1CASRFUDNzOI2nIihad/2El6biE+bo6MjAjmwVsaEujpVKXXvS6jUQ1I7J2qz2hBRrw6lbV7AaCoAUX4U2qBQidPNaiJ3wWnN6urtc5stdwl/Xq09uqGow27qFNgeg/4939w7M8rbfzbQ8Qz0OYBNQhLP6vuNJ90UE0sTjqkJkcbC9V6QnZ6NTAz3bT26vL3qxOcdQ7qqFnTu9Tg7vDvav+vLqbo3kDNb+r2TMWrOgshRB0hQVQ1cLOCqPmxp5n8ywGKjAodgjz58pEwfN1tnOSalaROWf37P3WFk0arjtY4uILjVV/dAtTk5Sa9b+xDvahAHVE6uBxO/K0ec3S7XBvH7Up9HBS1jo5pJKjtQ2rycVm1cgxF6sanaWfUgMRoVPOCFINaFkC5XBrg/A51mbypKGExGnWV1a3/p27Zcb2g0mhU25TWLj9LnZY7tkbN10k7U3I7v7Zq3aOW96pL76tLMCuEENWUBFHVQFUHUUUGI9N+P8S3W04BcF+HQGY+3B69vQ2n7S7sVYsp7ltavmrJV/NqBk3uuFw5ucfloKcMhXlqEvTBX+DIH2VvK3GtoFsh6m11pMiaFEVdMXZuu3o7vx3Sz0HLfupO8l5NrHu9q6978bhaVPL4OnWEqlmUGjiVp5iiEEIIMwmiqoGqDKLScwt5duEuNhxVi/y9cFdznrmjKZobHWXIvaSOaFw6rQYDpu8zzqvTUp6N1CThesFXvnf1U/NuYudaruhqEKaOujSNVKf08rPUpev5Wer0WEG2OmV1cr06inP1UnWtnTol5uimTlNde8vPUAOoq6fZXP0ub0DaT+1rfoa67D4v48r+YQVZ6pL0FvfKiIwQQogSSRBVDVRVEHX21HFeW/ovCakZuNsZeenOECJC3C6v4CpQg5O8NLWmzrVf8zPU6SljoVrYz1ik3gyFaqBTkdyfkmh00Pp+NXgKqkAtqtw0tcbQyfXqhqVXV40uiynHp/X9at2eqtpIVgghRJ0hQVQ1UBVB1InkLILnBGFHKQUGrcHFRx1h8mx0ecQpWM1XykuHS6csR6jSz6pBmN4TOj8GXR63TsLypVPqFhhF+WqAZzB9LVCPAYT2hMBbZB8vIYQQVlXez+8b2JxK2EKIlwv5GicKFQOOeie0do5g53B5BZfp5qSuMtN7ql/N39dTE6x19upNa6/W+dHaXf7eAdwDKrYzu9GgbqbqVN+6FZvrhUgujxBCiGpNgqgaRqfVYHz1DHZaDVpbJpCbaHXgHmjrXgghhBA3nQRRNZCro/zYhBBCCFuTZBIhhBBCiEqQIEoIIYQQohIkiBJCCCGEqAQJooQQQgghKkGCKCGEEEKISpAgSgghhBCiEiSIEkIIIYSoBAmihBBCCCEqQYIoIYQQQohKkCBKCCGEEKISJIgSQgghhKgECaKEEEIIISpBgighhBBCiEqws3UHajNFUQDIyMiwcU+EEEIIUV6mz23T53hpJIiqQpmZmQAEBQXZuCdCCCGEqKjMzEw8PDxKfVyjXC/MEpVmNBqJj4/Hzc0NjUZToedmZGQQFBTE2bNncXd3r6Ie1kzy3pRN3p+yyftTOnlvyibvT+lq23ujKAqZmZkEBgai1Zae+SQjUVVIq9XSsGHDGzqHu7t7rfiFrAry3pRN3p+yyftTOnlvyibvT+lq03tT1giUiSSWCyGEEEJUggRRQgghhBCVIEFUNeXo6MjkyZNxdHS0dVeqHXlvyibvT9nk/SmdvDdlk/endHX1vZHEciGEEEKISpCRKCGEEEKISpAgSgghhBCiEiSIEkIIIYSoBAmihBBCCCEqQYKoamjOnDmEhISg1+sJDw9n27Zttu6STWzYsIH77ruPwMBANBoNy5cvt3hcURQmTZpEQEAATk5OREZGcuzYMdt09iabPn06Xbp0wc3NDV9fX6Kjozly5IhFm7y8PMaMGYOXlxeurq489NBDJCYm2qjHN9dnn33G/7d37zFtVn0cwL/dSjugCyCbbRlyG7dxZ9yDDjeQi7c5ieKCii6LbsIcE2TEQYYm24i3ZegyEKJdxAzEpZlguIVBVcbGfYyBG7BmTG1BokwoCATO+4cvz2s3tlerUsjz+yRP0p5zePj1m+bJr6ct+Pj4cH/4LywsDJWVldw8n7O5VW5uLgQCAVJTU7kxPueTk5MDgUCgd7i7u3PzfM5m3g8//IBnn30W1tbWMDU1hbe3N1pbW7l5Pl2bqYlaYkpLS/Haa6/h4MGDaG9vh6+vL2JiYjA8PGzs0hadTqeDr68vjh8/vuD822+/jby8POTn5+PChQswNzdHTEwMfvvtt0WudPGpVCokJyfj/PnzqK2txczMDKKjo6HT6bg1+/btQ3l5OcrKyqBSqfDjjz/iySefNGLVi8fW1ha5ubloa2tDa2srtmzZgq1bt+Ly5csA+J3NH7W0tKCgoAA+Pj5643zPx9PTExqNhju+/fZbbo7v2fzyyy8IDw+HiYkJKisr0dPTg/feew9WVlbcGl5dmxlZUoKDg1lycjJ3f3Z2ltnY2LAjR44YsSrjA8CUSiV3f25ujslkMvbOO+9wY6Ojo0wsFrNTp04ZoULjGh4eZgCYSqVijP2ehYmJCSsrK+PW9Pb2MgCsqanJWGUalZWVFSsqKqJs/mtsbIy5uLiw2tpaFhERwfbu3csYo+fOwYMHma+v74JzfM+GMcb279/P7r///jvO8+3aTDtRS8j09DTa2toQFRXFja1YsQJRUVFoamoyYmVLj1qthlar1cvKwsICISEhvMzq5s2bAIB77rkHANDW1oaZmRm9fNzd3WFnZ8e7fGZnZ1FSUgKdToewsDDK5r+Sk5PxyCOP6OUA0HMHAPr6+mBjYwMnJyckJiZicHAQAGUDAF9++SUCAwPx1FNP4d5774W/vz8KCwu5eb5dm6mJWkJGRkYwOzsLqVSqNy6VSqHVao1U1dI0nwdlBczNzSE1NRXh4eHw8vIC8Hs+IpEIlpaWemv5lM+lS5cgkUggFouxa9cuKJVKeHh4UDYASkpK0N7ejiNHjtw2x/d8QkJCoFAoUFVVhRMnTkCtVuOBBx7A2NgY77MBgGvXruHEiRNwcXFBdXU1du/ejVdffRUnT54EwL9rs9DYBRBC/p7k5GR0d3frfW6DAG5ubujs7MTNmzfxxRdfICkpCSqVythlGd2NGzewd+9e1NbWYtWqVcYuZ8mJi4vjbvv4+CAkJAT29vb4/PPPYWpqasTKloa5uTkEBgbi8OHDAAB/f390d3cjPz8fSUlJRq5u8dFO1BKyZs0arFy58rZvegwNDUEmkxmpqqVpPg++Z5WSkoKKigrU19fD1taWG5fJZJiensbo6Kjeej7lIxKJ4OzsjICAABw5cgS+vr44duwY77Npa2vD8PAwNm7cCKFQCKFQCJVKhby8PAiFQkilUl7ncytLS0u4urqiv7+f988dAJDL5fDw8NAb27BhA/eWJ9+uzdRELSEikQgBAQGoq6vjxubm5lBXV4ewsDAjVrb0ODo6QiaT6WX166+/4sKFC7zIijGGlJQUKJVKnD17Fo6OjnrzAQEBMDEx0cvnypUrGBwc5EU+C5mbm8PU1BTvs4mMjMSlS5fQ2dnJHYGBgUhMTORu8zmfW42Pj2NgYAByuZz3zx0ACA8Pv+3PqVy9ehX29vYAeHhtNvYn24m+kpISJhaLmUKhYD09Peyll15ilpaWTKvVGru0RTc2NsY6OjpYR0cHA8Def/991tHRwa5fv84YYyw3N5dZWlqyM2fOsK6uLrZ161bm6OjIJicnjVz5v2/37t3MwsKCNTQ0MI1Gwx0TExPcml27djE7Ozt29uxZ1traysLCwlhYWJgRq148mZmZTKVSMbVazbq6ulhmZiYTCASspqaGMcbvbBbyx2/nMcbvfNLS0lhDQwNTq9WssbGRRUVFsTVr1rDh4WHGGL+zYYyx5uZmJhQK2aFDh1hfXx/77LPPmJmZGSsuLubW8OnaTE3UEvTBBx8wOzs7JhKJWHBwMDt//ryxSzKK+vp6BuC2IykpiTH2+1dps7OzmVQqZWKxmEVGRrIrV64Yt+hFslAuANgnn3zCrZmcnGSvvPIKs7KyYmZmZmzbtm1Mo9EYr+hFtGPHDmZvb89EIhFbu3Yti4yM5BooxvidzUJubaL4nE9CQgKTy+VMJBKxdevWsYSEBNbf38/N8zmbeeXl5czLy4uJxWLm7u7OPvroI715Pl2bBYwxZpw9MEIIIYSQ5Ys+E0UIIYQQYgBqogghhBBCDEBNFCGEEEKIAaiJIoQQQggxADVRhBBCCCEGoCaKEEIIIcQA1EQRQgghhBiAmihCCPkTFAoFLC0t//Hz5uTkwM/P7x8/LyHk30dNFCFk2XjhhRcgEAi4w9raGrGxsejq6vpL51nMxkWpVCI0NBQWFhZYvXo1PD09kZqays2np6fr/Z8xQsjyQU0UIWRZiY2NhUajgUajQV1dHYRCIR599FFjl7Wguro6JCQkID4+Hs3NzWhra8OhQ4cwMzPDrZFIJLC2tjZilYQQQ1ETRQhZVsRiMWQyGWQyGfz8/JCZmYkbN27gp59+4tbs378frq6uMDMzg5OTE7Kzs7nGRaFQ4M0338TFixe5HS2FQgEAGB0dxcsvvwypVIpVq1bBy8sLFRUVer+/uroaGzZsgEQi4Rq6OykvL0d4eDhef/11uLm5wdXVFU888QSOHz/Orbl1V+yPO23zh4ODAzff3d2NuLg4SCQSSKVSPPfccxgZGfkbiRJCDEVNFCFk2RofH0dxcTGcnZ31dnNWr14NhUKBnp4eHDt2DIWFhTh69CgAICEhAWlpafD09OR2tBISEjA3N4e4uDg0NjaiuLgYPT09yM3NxcqVK7nzTkxM4N1338Wnn36Kr7/+GoODg0hPT79jfTKZDJcvX0Z3d/effkzzNWk0GvT398PZ2RmbNm0C8HuTt2XLFvj7+6O1tRVVVVUYGhrC008//VejI4T8A4TGLoAQQv6KiooKSCQSAIBOp4NcLkdFRQVWrPjfa8KsrCzutoODA9LT01FSUoKMjAyYmppCIpFAKBRCJpNx62pqatDc3Ize3l64uroCAJycnPR+98zMDPLz87F+/XoAQEpKCt5666071rpnzx5888038Pb2hr29PUJDQxEdHY3ExESIxeIFf2a+JsYY4uPjYWFhgYKCAgDAhx9+CH9/fxw+fJhb//HHH+O+++7D1atXuboJIYuDdqIIIcvK5s2b0dnZic7OTjQ3NyMmJgZxcXG4fv06t6a0tBTh4eGQyWSQSCTIysrC4ODgXc/b2dkJW1vbuzYiZmZmXAMFAHK5HMPDw3dcb25ujq+++gr9/f3IysqCRCJBWloagoODMTExcdd63njjDTQ1NeHMmTMwNTUFAFy8eBH19fWQSCTc4e7uDgAYGBi46/kIIf88aqIIIcuKubk5nJ2d4ezsjKCgIBQVFUGn06GwsBAA0NTUhMTERDz88MOoqKhAR0cHDhw4gOnp6bued75RuRsTExO9+wKBAIyx//tz69evx86dO1FUVIT29nb09PSgtLT0juuLi4tx9OhRKJVKrFu3jhsfHx/HY489xjWR80dfXx/3lh8hZPHQ23mEkGVNIBBgxYoVmJycBACcO3cO9vb2OHDgALfmj7tUACASiTA7O6s35uPjg++///5ff1vMwcEBZmZm0Ol0C843NTVh586dKCgoQGhoqN7cxo0bcfr0aTg4OEAopMs3IcZGO1GEkGVlamoKWq0WWq0Wvb292LNnD7dDAwAuLi4YHBxESUkJBgYGkJeXB6VSqXcOBwcHqNVqdHZ2YmRkBFNTU4iIiMCmTZsQHx+P2tpaqNVqVFZWoqqqyuBac3JykJGRgYaGBqjVanR0dGDHjh2YmZnBQw89dNt6rVaLbdu24ZlnnkFMTAz3OOe/eZicnIyff/4Z27dvR0tLCwYGBlBdXY0XX3zxtqaQEPLvoyaKELKsVFVVQS6XQy6XIyQkBC0tLSgrK8ODDz4IAHj88cexb98+pKSkwM/PD+fOnUN2drbeOeLj4xEbG4vNmzdj7dq1OHXqFADg9OnTCAoKwvbt2+Hh4YGMjIy/1ZxERETg2rVreP755+Hu7o64uDhotVrU1NTAzc3ttvXfffcdhoaGcPLkSe4xyuVyBAUFAQBsbGzQ2NiI2dlZREdHw9vbG6mpqbC0tNT7YD0hZHEI2J95Q58QQgghhOihly6EEEIIIQagJooQQgghxADURBFCCCGEGICaKEIIIYQQA1ATRQghhBBiAGqiCCGEEEIMQE0UIYQQQogBqIkihBBCCDEANVGEEEIIIQagJooQQgghxADURBFCCCGEGICaKEIIIYQQA/wHU12yYXa5AecAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantization\n",
        "\n",
        "The weights stored in model use 32-bit floating-point numbers.\n",
        "\n",
        "**Quantization** is a technique to reduce the precision of the numbers used in the model. For example, in 4-bit quantization, the weights and activations of the network are compressed from 32-bit floating-point numbers to 4-bit integers."
      ],
      "metadata": {
        "id": "c80BXEChZl2h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4-Bit NormalFloat Quantization\n",
        "\n",
        "A 4-bit integer can range from -8 to 7! How!?\n",
        "\n",
        "1. **Normalization:** The weights of the model are first normalized to have **zero mean** and **unit variance**. This ensures that the weights are **distributed around zero** and fall within a certain range.\n",
        "\n",
        "2. **Quantization:** The normalized weights are then **quantized to 4 bits**. This involves mapping the original high-precision weights to a smaller set of low-precision values. In the case of NF4, the **quantization levels are chosen to be evenly spaced** in the range of the normalized weights.\n",
        "\n",
        "3. **Dequantization:** During the forward pass and backpropagation, the quantized weights are **dequantized back to full precision**. This is done by mapping the 4-bit quantized values back to their original range. The dequantized weights are used in the computations, but they are stored in memory in their 4-bit quantized form.\n"
      ],
      "metadata": {
        "id": "jZARw3V4Z5v3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Note that while the weights are stored as 4-bit integers, they are typically converted back to 32- bit floating-point numbers for the actual computations.\n",
        "\n",
        "**Example**\n",
        "\n",
        "A weight in our NN that is a 32-bit floating-point number, and its value is 0.5678.\n",
        "\n",
        "Let's say our 4-bit integers represent 16 levels evenly spaced between -1 and 1. These levels would be: -1.0, -0.8667, -0.7333, -0.6, -0.4667, -0.3333, -0.2, -0.0667, 0.0667, 0.2, 0.3333, 0.4667, 0.6, 0.7333, 0.8667, 1.0\n",
        "\n",
        "Our original weight value of 0.5678 is closest to 0.6, so we would quantize this weight to 0.6.\n",
        "\n",
        "In our 4-bit representation, let's say 0.6 corresponds to the integer 13. We store the 4-bit integer 13 instead of the 32-bit floating-point number 0.5678.\n",
        "\n",
        "If we use this weight in a computation, we first dequantize it back (0.6) to the floating-point number. The dequantization error is 0.6 -0.5678 = 0.0322 (rem: 1 level spaced out is 0.1333-> 1/4 of a space)"
      ],
      "metadata": {
        "id": "xPrB6Cvibvih"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quantization and Low Rank Adaptors (QLoRA)\n",
        "\n",
        "4-bit Integer Quantization of original 32-bit weights and apply **Parameter Efficient Fine Tuning (PEFT)**, inject LoRA adapters into each layer, in 32-bit precision, and start to **fine-tune the complete Language model** on a specific task, for the quantized configuration to reduce quantization error of the system."
      ],
      "metadata": {
        "id": "gqa83-O9gTE_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Around 1% of all tensor weights are injected LoRa adapter weight tensors, in 32-bit precision\n",
        "\n",
        "If we have a 175B model, we have more than 1 billion injected adapter weights in 32-bit precision.\n",
        "\n",
        "The injected LoRA weight tensors are the only trainable parameters. The rest of the params (the other 99%) are frozen.\n",
        "\n",
        "\n",
        "$$\n",
        "\\begin{matrix}\n",
        "\\ddots & \\vdots & \\vdots & \\vdots & ⋰\\\\\n",
        "\\cdots & 4bit & 4bit & 4bit & \\cdots \\\\\n",
        "\\cdots & 4bit & 32bit & 4bit & \\cdots \\\\\n",
        "\\cdots & 4bit & 4bit & 4bit & \\cdots \\\\\n",
        "⋰ & \\vdots & \\vdots & \\vdots & \\ddots \\\\\n",
        "\\end{matrix} \\\\\n",
        "$$\n",
        "\n",
        "The $32bit$ weight is the LoRA adapter.\n",
        "\n",
        "During computation (forward pass or backward propogation), **dequantization** happens:\n",
        "\n",
        "$$\n",
        "\\begin{matrix}\n",
        "\\ddots & \\vdots & \\vdots & \\vdots & ⋰\\\\\n",
        "\\cdots & 32bit & 32bit & 32bit & \\cdots \\\\\n",
        "\\cdots & 32bit & 32bit & 32bit & \\cdots \\\\\n",
        "\\cdots & 32bit & 32bit & 32bit & \\cdots \\\\\n",
        "⋰ & \\vdots & \\vdots & \\vdots & \\ddots \\\\\n",
        "\\end{matrix} \\\\\n",
        "$$\n",
        "\n",
        "This process is not save in memory, dequantization only happens during computation.\n",
        "\n",
        "After backpropogation, only the LoRA weight is updated ($32bit \\rightarrow {32bit}^*$), and the rest of the weights are restored to the $4bit$ version.\n",
        "\n",
        "$$\n",
        "\\begin{matrix}\n",
        "\\ddots & \\vdots & \\vdots & \\vdots & ⋰\\\\\n",
        "\\cdots & 4bit & 4bit & 4bit & \\cdots \\\\\n",
        "\\cdots & 4bit & {32bit}^* & 4bit & \\cdots \\\\\n",
        "\\cdots & 4bit & 4bit & 4bit & \\cdots \\\\\n",
        "⋰ & \\vdots & \\vdots & \\vdots & \\ddots \\\\\n",
        "\\end{matrix} \\\\\n",
        "$$\n"
      ],
      "metadata": {
        "id": "4dVv5tLng-A7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each dequantized weight, would have a precision error when converted to full-bit size due to the rounding happening at the quantization time.\n",
        "\n",
        "The LoRA weight tensor is not affect by dequantization-error as it never gets quantized.\n",
        "\n",
        "\n",
        "With the QLORA fine-tuning the system (NN) learns the new specific task it is fine-tuned on, given its actual **dequantization error** of every single weight tensor (kept frozen, not updated) of **4-bit precision**."
      ],
      "metadata": {
        "id": "GxJOe1Xnw3L_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The additional low-rank adapters in the QLORA method are in a higher precision format, typically 32-bit floating-point (bflaot16), for a few reasons:\n",
        "\n",
        "- Higher precision allows the model to capture more subtle patterns in the data. This is particularly important for the low-rank adapters, as they are responsible for adapting the pre-trained model to the specific task it is being fine-tuned for.\n",
        "\n",
        "- Training neural networks involves a lot of incremental updates to the weights. Weights in a higher precision format ensures that updates are accurately captured.\n",
        "\n",
        "- While quantizing all weights can save memory, the computational efficiency might not always improve. GPUs are optimized for 32-bit (bfloat16) operations. Computations w/ 32-bit floating-point can be faster than with lower precision."
      ],
      "metadata": {
        "id": "Zp1lrLhSq8Qn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Implementation\n",
        "\n",
        "Run the cells below to setup and install the required libraries. For our experiment we will need `accelerate`, `peft`, `transformers`, `datasets` and TRL to leverage the recent [`SFTTrainer`](https://huggingface.co/docs/trl/main/en/sft_trainer). We will use `bitsandbytes` to [quantize the base model into 4bit](https://huggingface.co/blog/4bit-transformers-bitsandbytes). We will also install `einops` as it is a requirement to load Falcon models."
      ],
      "metadata": {
        "id": "xM44VjYlhpRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# From Artidoro Pagnoni @ https://colab.research.google.com/drive/1BiQiw31DT7-cDp1-0ySXvvhzqomTdI-o?usp=sharing\n",
        "!pip install -q -U trl transformers accelerate git+https://github.com/huggingface/peft.git\n",
        "!pip install -q datasets bitsandbytes einops wandb"
      ],
      "metadata": {
        "id": "f1Qj5VsBho57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset**\n",
        "\n",
        "For our experiment, we will use the Guanaco dataset, which is a clean subset of the OpenAssistant dataset adapted to train general purpose chatbots.\n",
        "\n",
        "The dataset can be found [here](https://huggingface.co/datasets/timdettmers/openassistant-guanaco)"
      ],
      "metadata": {
        "id": "Rnqmq7amRrU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset_name = \"timdettmers/openassistant-guanaco\"\n",
        "dataset = load_dataset(dataset_name, split=\"train\")"
      ],
      "metadata": {
        "id": "ga8ozl2chovb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the model**\n",
        "\n",
        "In this section we will load the [Falcon 7B model](https://huggingface.co/tiiuae/falcon-7b), quantize it in 4bit and attach LoRA adapters on it. Let's get started!"
      ],
      "metadata": {
        "id": "AjB0WAqFSzlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoTokenizer\n",
        "\n",
        "model_name = \"ybelkada/falcon-7b-sharded-bf16\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "model.config.use_cache = False"
      ],
      "metadata": {
        "id": "ZwXZbQ2dSwzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the tokenizer below\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "V2XvYIG1iUge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we will load the configuration file in order to create the LoRA model. According to QLoRA paper, it is important to consider all linear layers in the transformer block for maximum performance. Therefore we will add `dense`, `dense_h_to_4_h` and `dense_4h_to_h` layers in the target modules in addition to the mixed query key value layer."
      ],
      "metadata": {
        "id": "NuAx3zBeUL1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig\n",
        "\n",
        "lora_alpha = 16\n",
        "lora_dropout = 0.1\n",
        "lora_r = 64\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=lora_alpha,\n",
        "    lora_dropout=lora_dropout,\n",
        "    r=lora_r,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=[\n",
        "        \"query_key_value\",\n",
        "        \"dense\",\n",
        "        \"dense_h_to_4h\",\n",
        "        \"dense_4h_to_h\",\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "fKJVx_V8iUdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the trainer**\n",
        "\n",
        "Here we will use the [`SFTTrainer` from TRL library](https://huggingface.co/docs/trl/main/en/sft_trainer) that gives a wrapper around transformers `Trainer` to easily fine-tune models on instruction based datasets using PEFT adapters. Let's first load the training arguments below."
      ],
      "metadata": {
        "id": "aTBJVE4PaJwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "output_dir = \"./results\"\n",
        "per_device_train_batch_size = 4\n",
        "gradient_accumulation_steps = 4\n",
        "optim = \"paged_adamw_32bit\"\n",
        "save_steps = 10\n",
        "logging_steps = 10\n",
        "learning_rate = 2e-4\n",
        "max_grad_norm = 0.3\n",
        "max_steps = 500\n",
        "warmup_ratio = 0.03\n",
        "lr_scheduler_type = \"constant\"\n",
        "\n",
        "training_arguments = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    per_device_train_batch_size=per_device_train_batch_size,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "    optim=optim,\n",
        "    save_steps=save_steps,\n",
        "    logging_steps=logging_steps,\n",
        "    learning_rate=learning_rate,\n",
        "    fp16=True,\n",
        "    max_grad_norm=max_grad_norm,\n",
        "    max_steps=max_steps,\n",
        "    warmup_ratio=warmup_ratio,\n",
        "    group_by_length=True,\n",
        "    lr_scheduler_type=lr_scheduler_type,\n",
        "    gradient_checkpointing=True,\n",
        ")"
      ],
      "metadata": {
        "id": "OCFTvGW6aspE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then finally pass everthing to the trainer"
      ],
      "metadata": {
        "id": "I3t6b2TkcJwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer\n",
        "\n",
        "max_seq_length = 512\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset,\n",
        "    peft_config=peft_config,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        ")"
      ],
      "metadata": {
        "id": "TNeOBgZeTl2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will also pre-process the model by upcasting the layer norms in float 32 for more stable training"
      ],
      "metadata": {
        "id": "GWplqqDjb3sS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, module in trainer.model.named_modules():\n",
        "    if \"norm\" in name:\n",
        "        module = module.to(torch.float32)"
      ],
      "metadata": {
        "id": "7OyIvEx7b1GT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the model**\n",
        "\n",
        "Now let's train the model! Simply call `trainer.train()`"
      ],
      "metadata": {
        "id": "JjvisllacNZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "_kbS7nRxcMt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "During training, the model should converge nicely as follows:\n",
        "\n",
        "![image](https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/images/loss-falcon-7b.png)\n",
        "\n",
        "The `SFTTrainer` also takes care of properly saving only the adapters during training instead of saving the entire model."
      ],
      "metadata": {
        "id": "H5c0ppfasK29"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save and Loading fine-tuned model**"
      ],
      "metadata": {
        "id": "anK0_e51so_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir=\"fine-tuned-model\"\n",
        "\n",
        "model.save_pretrained(output_dir)"
      ],
      "metadata": {
        "id": "u_aHCBhAsuCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from peft import PeftModel, PeftConfig\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "config = PeftConfig.from_pretrained(output_dir)\n",
        "model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, return_dict=True, load_in_8bit=True, device_map='auto')\n",
        "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
        "\n",
        "# Load the Lora model\n",
        "model = PeftModel.from_pretrained(model, peft_model_id)"
      ],
      "metadata": {
        "id": "YlJRqH4QsrNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mixed Precision Training\n",
        "\n",
        "Perform additionally a **mixed precision training** to balance the trade-off between accuracy and speed/memory usage.\n",
        "\n",
        "With all optimization steps and additional training of the model, 4-bit QLoRA performs equivalent to a bfloat16 model."
      ],
      "metadata": {
        "id": "BE6k_bXIzJ6A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8-bit** binary number `11010110` represents the decimal number 214 (max 255)\n",
        "\n",
        "**16-bit integers** can represent values between 0 and 65,535 for unsign int.\n",
        "\n",
        "**float16**: 0 11101 1010000000 is the number 52736 (16-bit binary format, first digit is the sign, the next 5 are the exponents, and the rest are the mantissa bits.).\n",
        "\n",
        "**bfloat16**: one sign bit, eight exponent bits, and seven mantissa bits.\n",
        "\n",
        "> Hardware multiplier scales with the square of the mantissa width\n",
        "\n",
        "\n",
        "The *physical size* of **bfloat16 multiplier**s are **half the size in silicon of a FP16** multiplier, and are **eight times smaller than an float32** multiplier.\n",
        "\n",
        "> Neural networks are more sensitive to the size of the Exponent than the size of the mantissa.\n",
        "\n",
        "To ensure identical behavior **bfloat16** has **the same Exponent size as float32** (both have 8bit exponent size). Google optimized TPUs (also) for bfloat16.\n",
        "\n",
        "Mixed-precision training: **XLA compiler** automatically converts values between float32 and bfloat16. -> PyTorch 2.0, pure in JAX and in TensorFlow2"
      ],
      "metadata": {
        "id": "EAC8yh-TxoBW"
      }
    }
  ]
}