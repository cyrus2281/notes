{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyMoANELaERvTWVfPfiOBhvE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "31ab97db73884279b802cb28597f854c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_83ea4eee162148dea469ec22b6d1b275",
              "IPY_MODEL_71354a94885f4bc0816fba8c827373bd",
              "IPY_MODEL_90762208daa542f3935dbe2549e90f43"
            ],
            "layout": "IPY_MODEL_2cf0fe806ec74d4ca38f71e237d7af8c"
          }
        },
        "83ea4eee162148dea469ec22b6d1b275": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a724b525e98840cd929e54a2fc3110ba",
            "placeholder": "​",
            "style": "IPY_MODEL_5f360f5280bf43e68376ed445a07b067",
            "value": "config.json: 100%"
          }
        },
        "71354a94885f4bc0816fba8c827373bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f761f1c1c4bb451ba9d318261cc33972",
            "max": 662,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af2b9d318404498881e4bbfe0bc03255",
            "value": 662
          }
        },
        "90762208daa542f3935dbe2549e90f43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fc3724136a94b84a9c343160e965867",
            "placeholder": "​",
            "style": "IPY_MODEL_e4ce9cc0e8d046138ddbc983220e3caf",
            "value": " 662/662 [00:00&lt;00:00, 7.68kB/s]"
          }
        },
        "2cf0fe806ec74d4ca38f71e237d7af8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a724b525e98840cd929e54a2fc3110ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f360f5280bf43e68376ed445a07b067": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f761f1c1c4bb451ba9d318261cc33972": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af2b9d318404498881e4bbfe0bc03255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2fc3724136a94b84a9c343160e965867": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4ce9cc0e8d046138ddbc983220e3caf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6e090223748466d900c662e6d060c54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6da618803553499b966c312dc1491989",
              "IPY_MODEL_ea1d91b9a9584cdb922a5e0971cc08a0",
              "IPY_MODEL_334783b8076e49c0a81c415edbe778f1"
            ],
            "layout": "IPY_MODEL_37c511f431f74754bf6058a0dd3f2b2b"
          }
        },
        "6da618803553499b966c312dc1491989": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4aa6d6755b94621a1230d18daf22abb",
            "placeholder": "​",
            "style": "IPY_MODEL_c4503b22420e4317859594ac50db13c4",
            "value": "model.safetensors: 100%"
          }
        },
        "ea1d91b9a9584cdb922a5e0971cc08a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43fb970ef5624a6698203d167c7d6331",
            "max": 3132668804,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d899640d5f414e06b8eefd9802f90806",
            "value": 3132668804
          }
        },
        "334783b8076e49c0a81c415edbe778f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3beccb37c1ee4ade92557e5b794179fd",
            "placeholder": "​",
            "style": "IPY_MODEL_86bfebfe2d0d4476baa19ff64bcd017e",
            "value": " 3.13G/3.13G [00:34&lt;00:00, 121MB/s]"
          }
        },
        "37c511f431f74754bf6058a0dd3f2b2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4aa6d6755b94621a1230d18daf22abb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4503b22420e4317859594ac50db13c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43fb970ef5624a6698203d167c7d6331": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d899640d5f414e06b8eefd9802f90806": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3beccb37c1ee4ade92557e5b794179fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86bfebfe2d0d4476baa19ff64bcd017e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3af5eeaeab4a4d2fa721eb72774835e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b34eb9ade264304823a5abf4a57ce87",
              "IPY_MODEL_2628ef1c25864a3f9aac2411ecac840c",
              "IPY_MODEL_b73289dc59d4419984670acc900eac59"
            ],
            "layout": "IPY_MODEL_91df9796cd7a4a67829ec2fa3232ccec"
          }
        },
        "6b34eb9ade264304823a5abf4a57ce87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cde5b28a46d845a491de5a021f736265",
            "placeholder": "​",
            "style": "IPY_MODEL_61446619d4e14a5d888b14d741c21692",
            "value": "generation_config.json: 100%"
          }
        },
        "2628ef1c25864a3f9aac2411ecac840c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0523ac8d13cf4140a70ab3cb6bc458da",
            "max": 147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df1ef81a0eb84a76bd042f77a40977c0",
            "value": 147
          }
        },
        "b73289dc59d4419984670acc900eac59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ec03853ac8b42228896c35a775f3b6f",
            "placeholder": "​",
            "style": "IPY_MODEL_cc5d6dde52414ba18e89e8f2a519495b",
            "value": " 147/147 [00:00&lt;00:00, 2.87kB/s]"
          }
        },
        "91df9796cd7a4a67829ec2fa3232ccec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cde5b28a46d845a491de5a021f736265": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61446619d4e14a5d888b14d741c21692": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0523ac8d13cf4140a70ab3cb6bc458da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df1ef81a0eb84a76bd042f77a40977c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ec03853ac8b42228896c35a775f3b6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc5d6dde52414ba18e89e8f2a519495b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cyrus2281/notes/blob/main/MachineLearning/Generative_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Content"
      ],
      "metadata": {
        "id": "9CWyV4beAH0q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">[Content](#scrollTo=9CWyV4beAH0q&uniqifier=1)\n",
        "\n",
        ">[Generative AI](#scrollTo=d95n8HFhAJ3m&uniqifier=1)\n",
        "\n",
        ">>[OpenAI](#scrollTo=i4ToZgP9-rIo&uniqifier=1)\n",
        "\n",
        ">>>[Few shot Prompt](#scrollTo=wW5Py1HkneoI&uniqifier=1)\n",
        "\n",
        ">>>[Function Calling](#scrollTo=_sHjRxqRu1SE&uniqifier=1)\n",
        "\n",
        ">>[LangChain](#scrollTo=VaZgHOlOly0L&uniqifier=1)\n",
        "\n",
        ">>>[Prompt Templating](#scrollTo=Qrmc6aYCmyBE&uniqifier=1)\n",
        "\n",
        ">>>[Agents](#scrollTo=OSJlfKhYm05y&uniqifier=1)\n",
        "\n",
        ">>>[Chains](#scrollTo=wZB8-VEzm0qW&uniqifier=1)\n",
        "\n",
        ">>>[Document Loader](#scrollTo=094HkTgJ3LgE&uniqifier=1)\n",
        "\n",
        ">>>[Memory](#scrollTo=1yM7479RABo5&uniqifier=1)\n",
        "\n",
        ">>>>[Conversation Buffer Memory](#scrollTo=xUDLj9bZDX1H&uniqifier=1)\n",
        "\n",
        ">>>>[Conversation Chain](#scrollTo=34Wx_PAVHJZc&uniqifier=1)\n",
        "\n",
        ">>>>[Conversation Buffer Window Memory](#scrollTo=bE0qBhKn1sfW&uniqifier=1)\n",
        "\n",
        ">>[Hugging Face](#scrollTo=4J6b25uaB5TP&uniqifier=1)\n",
        "\n",
        ">>>[Using Models from HuggingFace](#scrollTo=Pq3G4sxRDmAH&uniqifier=1)\n",
        "\n",
        ">>>[Downloading Models Locally](#scrollTo=9VtpZ9UlMPlr&uniqifier=1)\n",
        "\n",
        ">>[Vector Databases](#scrollTo=3TY5pCv8w-5H&uniqifier=1)\n",
        "\n",
        ">>>[Pinecone VectorDB](#scrollTo=fX0221ouxAfx&uniqifier=1)\n",
        "\n",
        ">>>>[Creating Embeddings from text chunks](#scrollTo=ChlWuiNPB4er&uniqifier=1)\n",
        "\n",
        ">>>>[Querying VectorDB](#scrollTo=WtglMMDjKD-i&uniqifier=1)\n",
        "\n",
        ">>>[ChromaDB](#scrollTo=kD8z-5adnZ4T&uniqifier=1)\n",
        "\n",
        ">>>>[Creating ChromaDB](#scrollTo=glV_-rzq8mBE&uniqifier=1)\n",
        "\n",
        ">>>>[Retrieval](#scrollTo=EtSO9IhK-iZC&uniqifier=1)\n",
        "\n",
        ">>>>[Making a Chain](#scrollTo=Rz1W-meADHuS&uniqifier=1)\n",
        "\n",
        ">>>>[Removing ChromaDB](#scrollTo=nTnNTxUCHD2o&uniqifier=1)\n",
        "\n"
      ],
      "metadata": {
        "colab_type": "toc",
        "id": "Hse3FiY9AOWW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generative AI"
      ],
      "metadata": {
        "id": "d95n8HFhAJ3m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAI"
      ],
      "metadata": {
        "id": "i4ToZgP9-rIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "GGsVDqbG-20h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0738c5e0-8cdb-4fbe-8c8f-9aed14fa466f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.14.2-py3-none-any.whl (262 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/262.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/262.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m256.0/262.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.4/262.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.14.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFIeRudPAEFG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4afebc1-0605-4737-823b-1579201c926f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.14.1\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "print(openai.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key = \"\" # @param {type:\"string\"}"
      ],
      "metadata": {
        "id": "tzaXoSE1IRfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=openai_api_key)"
      ],
      "metadata": {
        "id": "IEgFPXKt-vpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
        "  ], # Roles: system, user, assistant, tool\n",
        "  max_tokens=128, # Maximum number of tokens you want result\n",
        "  temperature=1, # How creative the output should be\n",
        "  n=2 # Number of the outputs\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIo3YSteA1e5",
        "outputId": "b7b96b55-c363-40d6-b49f-71e58ec65000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content='In the realm of code, a concept lives and breathes,\\nWhere functions call themselves, like whispers in the trees.\\nRecursion is the art, a trance-like dance,\\nUnfolding mysteries with each recursive glance.\\n\\nLike a mirror reflecting its own reflection,\\nA function loops back, with no objection.\\nIt breaks down a problem, into smaller parts,\\nAnd solves them one by one, with gentle smarts.\\n\\nA journey through layers, like a dream unfurled,\\nEach invocation a thread in the code world.\\nIt reaches the base case, like a destination,\\nUnwinding the stack, with jubilation.\\n\\nSo embrace recursion, with courage and grace,\\nLet it guide your code through time and space.\\nFor in its elegant cycle, we find our place,\\nA recursive enchantment, woven with grace.', role='assistant', function_call=None, tool_calls=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This is an example of zero shot prompt**"
      ],
      "metadata": {
        "id": "aY6pLUaLpj55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Few shot Prompt\n"
      ],
      "metadata": {
        "id": "wW5Py1HkneoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "person_info=\"My name is Cyrus, I'm a software engineer at X, and I live in Canada.\""
      ],
      "metadata": {
        "id": "lnlScmEgnicb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f'''\n",
        "Extract the following information from the given text and return it as a JSON object:\n",
        "\n",
        "name\n",
        "job\n",
        "company\n",
        "country\n",
        "\n",
        "This is the body of text to extract the information from:\n",
        "{person_info}\n",
        "'''"
      ],
      "metadata": {
        "id": "WTl8OVAen3T1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiR1k8oJoQWx",
        "outputId": "23d7e648-a643-425f-dc32-d24951445fdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"name\": \"Cyrus\",\n",
            "  \"job\": \"software engineer\",\n",
            "  \"company\": \"X\",\n",
            "  \"country\": \"Canada\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This is an example of few shot prompt**"
      ],
      "metadata": {
        "id": "M86yU2LppbrR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function Calling"
      ],
      "metadata": {
        "id": "_sHjRxqRu1SE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Example dummy function hard coded to return the same weather\n",
        "# In production, this could be your backend API or an external API\n",
        "def get_current_weather(location, unit=\"fahrenheit\"):\n",
        "    \"\"\"Get the current weather in a given location\"\"\"\n",
        "    if \"tokyo\" in location.lower():\n",
        "        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": unit})\n",
        "    elif \"san francisco\" in location.lower():\n",
        "        return json.dumps({\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": unit})\n",
        "    elif \"paris\" in location.lower():\n",
        "        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": unit})\n",
        "    else:\n",
        "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})\n"
      ],
      "metadata": {
        "id": "nOKVKSi1u--n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: send the conversation and available functions to the model\n",
        "messages = [{\"role\": \"user\", \"content\": \"What's the weather like in San Francisco, Tokyo, and Paris?\"}]\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_current_weather\",\n",
        "            \"description\": \"Get the current weather in a given location\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"location\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
        "                    },\n",
        "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
        "                },\n",
        "                \"required\": [\"location\"],\n",
        "            },\n",
        "        },\n",
        "    }\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo-0125\",\n",
        "    messages=messages,\n",
        "    tools=tools,\n",
        "    tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
        ")\n",
        "response_message = response.choices[0].message\n",
        "tool_calls = response_message.tool_calls"
      ],
      "metadata": {
        "id": "ABv2CX9svGQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: check if the model wanted to call a function\n",
        "if tool_calls:\n",
        "    # Step 3: call the function\n",
        "    # Note: the JSON response may not always be valid; be sure to handle errors\n",
        "    available_functions = {\n",
        "        \"get_current_weather\": get_current_weather,\n",
        "    }  # only one function in this example, but you can have multiple\n",
        "    messages.append(response_message)  # extend conversation with assistant's reply\n",
        "    # Step 4: send the info for each function call and function response to the model\n",
        "    for tool_call in tool_calls:\n",
        "        print(tool_call)\n",
        "        function_name = tool_call.function.name\n",
        "        function_to_call = available_functions[function_name]\n",
        "        function_args = json.loads(tool_call.function.arguments)\n",
        "        function_response = function_to_call(\n",
        "            location=function_args.get(\"location\"),\n",
        "            unit=function_args.get(\"unit\"),\n",
        "        )\n",
        "        messages.append(\n",
        "            {\n",
        "                \"tool_call_id\": tool_call.id,\n",
        "                \"role\": \"tool\",\n",
        "                \"name\": function_name,\n",
        "                \"content\": function_response,\n",
        "            }\n",
        "        )  # extend conversation with function response\n",
        "    second_response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo-0125\",\n",
        "        messages=messages,\n",
        "    )  # get a new response from the model where it can see the function response\n",
        "    print(second_response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOO64huru4Eo",
        "outputId": "d3b38c5f-05db-43d7-d320-a7351a0aa7b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessageToolCall(id='call_Q6tNs8Yd24ROxqmgrMYYYAC1', function=Function(arguments='{\"location\": \"San Francisco\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function')\n",
            "ChatCompletionMessageToolCall(id='call_efCZ1xEyMhMqKCVvFNsU3gax', function=Function(arguments='{\"location\": \"Tokyo\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function')\n",
            "ChatCompletionMessageToolCall(id='call_UgPOHn0Gls5GEtPiNdYlseoB', function=Function(arguments='{\"location\": \"Paris\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function')\n",
            "Currently in San Francisco, the weather is 72°C. In Tokyo, it is 10°C, and in Paris, it is 22°C.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LangChain"
      ],
      "metadata": {
        "id": "VaZgHOlOly0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "id": "xZHmSegSlwDb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "307d0416-5b12-4f3d-b203-42c81599f2c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.13-py3-none-any.whl (810 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/810.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/810.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m604.2/810.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.29 (from langchain)\n",
            "  Downloading langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.33 (from langchain)\n",
            "  Downloading langchain_core-0.1.33-py3-none-any.whl (269 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.1/269.1 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.31-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain) (3.7.1)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.33->langchain)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.13 langchain-community-0.0.29 langchain-core-0.1.33 langchain-text-splitters-0.0.1 langsmith-0.1.31 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.9.15 packaging-23.2 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "print(langchain.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RcCAU_3lxwo",
        "outputId": "2d2901b6-c9a5-4eb4-abe6-8ca09319bcb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "client=OpenAI(openai_api_key=openai_api_key)"
      ],
      "metadata": {
        "id": "gzwDMWWJkRwR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5639bda1-4c1c-43d0-e613-948632a6e5a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Zero shot prompting\n",
        "prompt=\"Can you tell me total number of counntries in north america\"\n",
        "print(client.invoke(prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TISsuVVflAZ3",
        "outputId": "9007d70a-d576-43de-b6b8-69b5761c3dda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "There are 23 countries in North America. They are:\n",
            "\n",
            "1. Antigua and Barbuda\n",
            "2. Bahamas\n",
            "3. Barbados\n",
            "4. Belize\n",
            "5. Canada\n",
            "6. Costa Rica\n",
            "7. Cuba\n",
            "8. Dominica\n",
            "9. Dominican Republic\n",
            "10. El Salvador\n",
            "11. Grenada\n",
            "12. Guatemala\n",
            "13. Haiti\n",
            "14. Honduras\n",
            "15. Jamaica\n",
            "16. Mexico\n",
            "17. Nicaragua\n",
            "18. Panama\n",
            "19. Saint Kitts and Nevis\n",
            "20. Saint Lucia\n",
            "21. Saint Vincent and the Grenadines\n",
            "22. Trinidad and Tobago\n",
            "23. United States of America\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompt Templating"
      ],
      "metadata": {
        "id": "Qrmc6aYCmyBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"country\"],\n",
        "    template=\"Can you tell me the capital {country}\"\n",
        ")\n",
        "prompt_template"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYe_bl8wlJ_D",
        "outputId": "c1c90e1f-2e33-4a51-8174-9f1e0ccd8ba9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['country'], template='Can you tell me the capital {country}')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = prompt_template.format(country=\"Canada\")"
      ],
      "metadata": {
        "id": "7jmpqHl4xHDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(client.invoke(prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h72pXwUtxi2k",
        "outputId": "e87371cc-de2e-4bb4-cfe7-73ff888cc94f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "The capital of Canada is Ottawa.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = PromptTemplate.from_template(\"What is the language of {country}\")"
      ],
      "metadata": {
        "id": "WTt4288nx5N6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template.format(country=\"Canada\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5F2a9CoxyEAx",
        "outputId": "129f1bc5-953e-4d40-c5eb-49fd91b836ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What is the language of Canada'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agents\n",
        "\n",
        "Used to call third-party tools"
      ],
      "metadata": {
        "id": "OSJlfKhYm05y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = PromptTemplate.from_template(\"What is the weather in {city} now?\")\n",
        "prompt=prompt_template.format(city=\"Ottawa\")"
      ],
      "metadata": {
        "id": "NItv_FVdxqCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(client.invoke(prompt)) # Not a good answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7uqD_n80LbW",
        "outputId": "0503c606-ee15-406b-eb84-a176286cf4f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "I am an AI and do not have access to real-time weather data. Please check a weather website or app for the current weather in Ottawa.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-search-results"
      ],
      "metadata": {
        "id": "HaXUoHBs0Vo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "serp_api_key = \"\" # @param {type:\"string\"}\n"
      ],
      "metadata": {
        "id": "djK_ONZ_2Exi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentType, load_tools, initialize_agent"
      ],
      "metadata": {
        "id": "hDttvoWH0tzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tool = load_tools([\"serpapi\"], serpapi_api_key=serp_api_key, llm=client)\n",
        "tool"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwXgMdFr2q0w",
        "outputId": "1ce274b2-4178-44a2-c72f-79ac7ac1be7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Tool(name='Search', description='A search engine. Useful for when you need to answer questions about current events. Input should be a search query.', func=<bound method SerpAPIWrapper.run of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='46f2201c74213cb9e5f88667f9bc98ea9b2ce2343d5cc3a206bc5c67c9c85b33', aiosession=None)>, coroutine=<bound method SerpAPIWrapper.arun of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='46f2201c74213cb9e5f88667f9bc98ea9b2ce2343d5cc3a206bc5c67c9c85b33', aiosession=None)>)]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent=initialize_agent(\n",
        "    tool,\n",
        "    client,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "9mkEsC7X2_0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "m_WVIwuU4GI1",
        "outputId": "0b2c8b2a-fdff-428c-e202-1af26bfad568"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should use the search engine to find the current weather in Ottawa\n",
            "Action: Search\n",
            "Action Input: \"weather in Ottawa\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m{'type': 'weather_result', 'temperature': '33', 'unit': 'Fahrenheit', 'precipitation': '19%', 'humidity': '91%', 'wind': '8 mph', 'location': 'Ottawa, ON, Canada', 'date': 'Tuesday 11:00 PM', 'weather': 'Cloudy'}\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m The current weather in Ottawa is cloudy with a temperature of 33 degrees Fahrenheit.\n",
            "Final Answer: The current weather in Ottawa is cloudy with a temperature of 33 degrees Fahrenheit.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The current weather in Ottawa is cloudy with a temperature of 33 degrees Fahrenheit.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chains\n",
        "\n",
        "Chains refer to sequences of calls - whether to an LLM, a tool, or a data preprocessing step."
      ],
      "metadata": {
        "id": "wZB8-VEzm0qW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "prompt_template1 = PromptTemplate.from_template(\"What is a good name for a {obj} bussiness? (Only one example)\")\n",
        "prompt_template2 = PromptTemplate.from_template(\"Creating a startup with the name {name} , give me ideas?\")"
      ],
      "metadata": {
        "id": "aE8Odg_R9-3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "name_chain = LLMChain(llm=client, prompt=prompt_template1, output_key=\"name\")"
      ],
      "metadata": {
        "id": "3-edf8MhAb8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(name_chain.run(\"flower\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43nqtzUCA99x",
        "outputId": "e217b417-8779-4173-c020-d7acd8f7dd63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"Blooming Blossoms\" \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idea_chain = LLMChain(llm=client, prompt=prompt_template2, output_key=\"ideas\")"
      ],
      "metadata": {
        "id": "s2v2vqiXDiJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SimpleSequentialChain\n",
        "chain=SimpleSequentialChain(chains=[name_chain, idea_chain])"
      ],
      "metadata": {
        "id": "pvHtM5lKDvnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.run(\"flower\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9Q6DXhtD3Cc",
        "outputId": "bfcc7899-3a86-4a45-9feb-1641a89096b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. A unique and personalized floral subscription service, where customers can receive a fresh bouquet of flowers every week or month.\n",
            "\n",
            "2. Offering floral arrangements for special events such as weddings, birthdays, and corporate events.\n",
            "\n",
            "3. Partnering with local businesses to provide floral arrangements for their offices or storefronts.\n",
            "\n",
            "4. Hosting workshops and classes on floral arrangement and design for individuals or groups.\n",
            "\n",
            "5. Developing a line of eco-friendly and sustainable floral products, such as biodegradable flower pots and packaging.\n",
            "\n",
            "6. Providing flower delivery services for last-minute gifts or special occasions.\n",
            "\n",
            "7. Collaborating with local artists to create unique and one-of-a-kind floral art installations for public spaces.\n",
            "\n",
            "8. Offering a selection of dried and preserved flowers for long-lasting home decor.\n",
            "\n",
            "9. Creating a social media presence to showcase the beauty of flowers and engage with customers.\n",
            "\n",
            "10. Partnering with local flower farms to source fresh, locally grown blooms for a farm-to-table approach.\n",
            "\n",
            "11. Developing a line of handmade botanical skincare and wellness products using natural flower essences.\n",
            "\n",
            "12. Expanding into event planning services, offering a full package of floral design, venue decoration, and coordination.\n",
            "\n",
            "13. Creating a loyalty program to reward frequent customers with discounts and special perks.\n",
            "\n",
            "14. Offering a \"flower bar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Alternative syntax**"
      ],
      "metadata": {
        "id": "nNP2DkUzBtKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt_template1 | client\n",
        "\n",
        "print(chain.invoke({\"obj\": \"flower bussiness\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2NBE0aDBD4M",
        "outputId": "8cac257e-fcb8-4b88-c7f7-d95673ec34c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"Petals & Blooms Co.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def str_parser(input):\n",
        "  print(input)\n",
        "  return {\"name\": input}\n",
        "\n",
        "chain = prompt_template1 | client | str_parser | prompt_template2 | client\n",
        "print(chain.invoke({\"obj\": \"flower bussiness\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTHj9tEeEByy",
        "outputId": "e7ea6077-f407-45e9-92c8-b893227d3ee9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"Blooming Oasis Florals\"\n",
            "\n",
            "\n",
            "1. Unique floral arrangements: Offer a variety of unique and creative floral arrangements, such as succulent bouquets, preserved flower displays, and personalized floral designs.\n",
            "\n",
            "2. Subscription services: Provide a subscription service for weekly or monthly flower deliveries to homes and businesses, offering a convenient and cost-effective option for customers.\n",
            "\n",
            "3. Event and wedding services: Partner with event planners and wedding venues to offer floral design services for special occasions, including customized centerpieces, bouquets, and installations.\n",
            "\n",
            "4. Online presence: Create a strong online presence through a website and social media platforms to showcase your work, promote your services, and interact with customers.\n",
            "\n",
            "5. Green and sustainable practices: Promote eco-friendly and sustainable practices, such as using locally sourced flowers and recyclable packaging, to appeal to environmentally conscious customers.\n",
            "\n",
            "6. Collaborations: Collaborate with local businesses, such as cafes and boutiques, to offer floral arrangements for their spaces, creating a mutually beneficial partnership.\n",
            "\n",
            "7. Workshops and classes: Host workshops and classes to teach customers how to create their own floral arrangements and offer team-building events for corporate clients.\n",
            "\n",
            "8. Mobile flower truck: Take your business on the road by converting a truck into a mobile flower shop, allowing you to reach new customers and attend events and markets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sequential Chains"
      ],
      "metadata": {
        "id": "XCI8L81d0L8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SequentialChain\n",
        "\n",
        "chain=SequentialChain(\n",
        "    chains=[name_chain, idea_chain],\n",
        "    input_variables=[\"obj\"],\n",
        "    output_variables=[\"name\", \"ideas\"]\n",
        "    )"
      ],
      "metadata": {
        "id": "3zTJJY1k0K1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain({\"obj\": \"flower\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UM34GHEx04uM",
        "outputId": "11acb812-69ad-4187-f8d4-647a1421575c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'obj': 'flower',\n",
              " 'name': '\\n\\n\"Petals & Blooms Floral Co.\" ',\n",
              " 'ideas': ' \\n\\n1. Online Flower Delivery Service: Offer a convenient and easy way for customers to order and send flowers to their loved ones with same-day delivery options.\\n\\n2. Custom Floral Arrangements: Create unique and personalized floral arrangements for special occasions such as weddings, birthdays, and anniversaries.\\n\\n3. Subscription Services: Offer a subscription service where customers can receive a fresh bouquet of flowers every week or month.\\n\\n4. Event Planning and Decor: Partner with event planners and offer floral decor for weddings, corporate events, and other special occasions.\\n\\n5. Floral Workshops: Host workshops for customers to learn how to create their own floral arrangements and bouquets.\\n\\n6. Greenhouse and Nursery: Have a greenhouse and nursery on-site where customers can purchase plants and flowers for their home or garden.\\n\\n7. Corporate Gifting: Partner with businesses to provide custom floral arrangements for employee recognition, client gifts, and office decor.\\n\\n8. Online Floral Design Courses: Offer online courses for customers to learn the art of floral design and create their own arrangements at home.\\n\\n9. Eco-Friendly Options: Use sustainable and eco-friendly materials for packaging and offer options for customers to recycle or compost their flowers after use.\\n\\n10. Collaborations with Local Artists: Partner with local artists to create unique and one'}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Document Loader"
      ],
      "metadata": {
        "id": "094HkTgJ3LgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf langchain_openai  faiss-cpu"
      ],
      "metadata": {
        "id": "6S31iTBN3Pn0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b4ba249-dd80-4c2c-f16b-a30e9a1e8773"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-4.1.0-py3-none-any.whl (286 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/286.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m204.8/286.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.1/286.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain_openai\n",
            "  Downloading langchain_openai-0.1.0-py3-none-any.whl (32 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain-core<0.2.0,>=0.1.33 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.1.33)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.14.2)\n",
            "Collecting tiktoken<1,>=0.5.2 (from langchain_openai)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.25.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain_openai) (6.0.1)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain_openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain_openai) (0.1.31)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain_openai) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain_openai) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain_openai) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain_openai) (8.2.3)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.10.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2023.12.25)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain_openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain_openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (1.0.4)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.33->langchain_openai) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.33->langchain_openai) (3.9.15)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.33->langchain_openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.33->langchain_openai) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.33->langchain_openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.33->langchain_openai) (2.0.7)\n",
            "Installing collected packages: pypdf, faiss-cpu, tiktoken, langchain_openai\n",
            "Successfully installed faiss-cpu-1.8.0 langchain_openai-0.1.0 pypdf-4.1.0 tiktoken-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://papers.neurips.cc/paper/7181-attention-is-all-you-need.pdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lkci7D_D4pM7",
        "outputId": "7f18316a-8cce-4547-8259-63fa08a79c33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-21 02:42:10--  https://papers.neurips.cc/paper/7181-attention-is-all-you-need.pdf\n",
            "Resolving papers.neurips.cc (papers.neurips.cc)... 198.202.70.94\n",
            "Connecting to papers.neurips.cc (papers.neurips.cc)|198.202.70.94|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf [following]\n",
            "--2024-03-21 02:42:10--  https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf\n",
            "Resolving proceedings.neurips.cc (proceedings.neurips.cc)... 198.202.70.94\n",
            "Connecting to proceedings.neurips.cc (proceedings.neurips.cc)|198.202.70.94|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 569417 (556K) [application/pdf]\n",
            "Saving to: ‘7181-attention-is-all-you-need.pdf’\n",
            "\n",
            "7181-attention-is-a 100%[===================>] 556.07K  1.69MB/s    in 0.3s    \n",
            "\n",
            "2024-03-21 02:42:11 (1.69 MB/s) - ‘7181-attention-is-all-you-need.pdf’ saved [569417/569417]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"/content/7181-attention-is-all-you-need.pdf\")\n",
        "pages = loader.load_and_split()"
      ],
      "metadata": {
        "id": "jjaTv_s14fNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(pages), pages[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8r8zdgk43CE",
        "outputId": "3843d22c-adce-432a-d08b-c967884d8176"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12,\n",
              " Document(page_content='Attention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.comNoam Shazeer∗\\nGoogle Brain\\nnoam@google.comNiki Parmar∗\\nGoogle Research\\nnikip@google.comJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.comAidan N. Gomez∗†\\nUniversity of Toronto\\naidan@cs.toronto.eduŁukasz Kaiser∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring signiﬁcantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41.0 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature.\\n1 Introduction\\nRecurrent neural networks, long short-term memory [ 12] and gated recurrent [ 7] neural networks\\nin particular, have been ﬁrmly established as state of the art approaches in sequence modeling and\\ntransduction problems such as language modeling and machine translation [ 29,2,5]. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\\narchitectures [31, 21, 13].\\n∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the ﬁrst Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\\nefﬁcient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research.\\n†Work performed while at Google Brain.\\n‡Work performed while at Google Research.\\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.', metadata={'source': '/content/7181-attention-is-all-you-need.pdf', 'page': 0}))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "faiss_index = FAISS.from_documents(pages[0:3], OpenAIEmbeddings(api_key=openai_api_key))"
      ],
      "metadata": {
        "id": "5RZa2_hZ4315"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = faiss_index.similarity_search(\"What is attention?\", k=2)\n",
        "for doc in docs:\n",
        "    print(str(doc.metadata[\"page\"]) + \":\", doc.page_content[:300])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaqX1z0R5PzU",
        "outputId": "9c9ddc95-9782-4456-dff1-18896a3057c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: Attention Is All You Need\n",
            "Ashish Vaswani∗\n",
            "Google Brain\n",
            "avaswani@google.comNoam Shazeer∗\n",
            "Google Brain\n",
            "noam@google.comNiki Parmar∗\n",
            "Google Research\n",
            "nikip@google.comJakob Uszkoreit∗\n",
            "Google Research\n",
            "usz@google.com\n",
            "Llion Jones∗\n",
            "Google Research\n",
            "llion@google.comAidan N. Gomez∗†\n",
            "University of Toronto\n",
            "aidan@c\n",
            "1: Recurrent models typically factor computation along the symbol positions of the input and output\n",
            "sequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\n",
            "statesht, as a function of the previous hidden state ht−1and the input for position t. This inherently\n",
            "s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Memory"
      ],
      "metadata": {
        "id": "1yM7479RABo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "prompt_template = PromptTemplate.from_template(\"What is a good name for a {obj} bussiness? (Only one example)\")"
      ],
      "metadata": {
        "id": "7dk_BQgHBtlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "chain = LLMChain(llm=client, prompt=prompt_template)"
      ],
      "metadata": {
        "id": "IlDyTgOQCLpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(\"AI\").strip()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9XIGaBLnCTar",
        "outputId": "19596f39-ba7a-4cf5-a301-0fc15c0cb061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"Synapse Solutions\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.memory"
      ],
      "metadata": {
        "id": "VMb4uJSiCXJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(chain.memory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0M-9C2MgCtXB",
        "outputId": "0e2f4b92-fa3f-4239-c0cd-e6f1b9bd45a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NoneType"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Conversation Buffer Memory"
      ],
      "metadata": {
        "id": "xUDLj9bZDX1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory()"
      ],
      "metadata": {
        "id": "H9G9Cny2DZ09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manually adding to memory\n",
        "\n",
        "```python\n",
        "memory.chat_memory.add_user_message(\"hi!\")\n",
        "memory.chat_memory.add_ai_message(\"what's up?\")\n",
        "```"
      ],
      "metadata": {
        "id": "uOLXXSULGbUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(llm=client, prompt=prompt_template, memory=memory)"
      ],
      "metadata": {
        "id": "TMJ0urxAGQNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(\"AI\").strip()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0AERpcGdGl41",
        "outputId": "51b12bd9-ccaf-4282-97a2-625d2b75e2bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"NeuroNexus Solutions\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.memory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceEhfhEsGpwr",
        "outputId": "e49229f8-d933-4084-e9e2-59da1e5bec8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConversationBufferMemory(chat_memory=ChatMessageHistory(messages=[HumanMessage(content='AI'), AIMessage(content='\\n\\n\"NeuroNexus Solutions\"')]))"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0bvf3qjG20T",
        "outputId": "1ef5974c-1a55-4602-d46e-c9579ec129f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: AI\n",
            "AI: \n",
            "\n",
            "\"NeuroNexus Solutions\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Conversation Chain\n",
        "\n",
        "Conversation buffer memory goes growing endlessly.\n",
        "\n",
        "Restrict to last 5 conversation chain"
      ],
      "metadata": {
        "id": "34Wx_PAVHJZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationChain\n",
        "from langchain_openai import OpenAI"
      ],
      "metadata": {
        "id": "xkrkvedyG4a4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convo = ConversationChain(llm=OpenAI(openai_api_key=openai_api_key, temperature=0.7))"
      ],
      "metadata": {
        "id": "4mRaPep2yN_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(convo.prompt.template)"
      ],
      "metadata": {
        "id": "17fDiJ21x9Kp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5f41531-495b-4b7d-f6ab-78334a8d17ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "{history}\n",
            "Human: {input}\n",
            "AI:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"Who invented the light bulb?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "euQlvcdkzbk7",
        "outputId": "22b0e0ab-a756-4abe-d3d8-ab057064da92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The light bulb was invented by Thomas Edison in 1879. However, he was not the only person working on this technology at the time. Other inventors like Joseph Swan and Hiram Maxim were also working on improving the design and functionality of the light bulb.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"When did he born?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "SmqvsT9zzpvQ",
        "outputId": "33db61b3-b94a-47d1-9c43-8dde604bbc3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Thomas Edison was born on February 11, 1847 in Milan, Ohio. He was the youngest of seven children and showed an interest in science and technology from a young age.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Conversation Buffer Window Memory\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bE0qBhKn1sfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferWindowMemory"
      ],
      "metadata": {
        "id": "SV3LxDRlz7Gg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory=ConversationBufferWindowMemory(k=1)"
      ],
      "metadata": {
        "id": "CvRBbBWy2SD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convo = ConversationChain(llm=OpenAI(openai_api_key=openai_api_key, temperature=0.7), memory=memory)"
      ],
      "metadata": {
        "id": "I4Zog2WE2ami"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"Who invented the light bulb?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "PKfoI9342fV5",
        "outputId": "89cf197f-8a7c-45da-f9c5-1cebdc15b5bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The light bulb was invented by Thomas Edison in 1879. He experimented with over 6,000 different materials before discovering that carbonized bamboo worked best as a filament.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"What year is today?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bjmITB8m2mjR",
        "outputId": "da79f502-9001-40ca-93f5-9f011db59002"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Today is Monday, December 13, 2021.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"When did he born?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UPcOg3a-2iBM",
        "outputId": "ee95307e-8da0-4674-aabc-6c2d714651d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' I do not have enough information to accurately answer your question. Who are you referring to?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hugging Face"
      ],
      "metadata": {
        "id": "4J6b25uaB5TP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub transformers accelerate bitsandbytes langchain"
      ],
      "metadata": {
        "id": "g3Y6kbhhB6_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gttbGrgCTTE",
        "outputId": "003de5bd-4f32-4867-97d7-0509e8950cff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.13 langchain-community-0.0.29 langchain-core-0.1.33 langchain-text-splitters-0.0.1 langsmith-0.1.31 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.9.15 packaging-23.2 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate, HuggingFaceHub, LLMChain\n",
        "import os"
      ],
      "metadata": {
        "id": "J8jGZNxJCiwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HUGGINGFACEHUB_API_TOKEN = \"\" # @param {type:\"string\"}\n"
      ],
      "metadata": {
        "id": "ABDFJje9Cu50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['HUGGINGFACEHUB_API_TOKEN']=HUGGINGFACEHUB_API_TOKEN"
      ],
      "metadata": {
        "id": "yLX-4sMIDJzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Models from HuggingFace"
      ],
      "metadata": {
        "id": "Pq3G4sxRDmAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"product\"],\n",
        "    template=\"What is a good name for a company that make {product}\"\n",
        ")"
      ],
      "metadata": {
        "id": "DNEAaltpDpSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(\n",
        "    llm=HuggingFaceHub(repo_id=\"google/flan-t5-large\", model_kwargs={'temperature': 0}),\n",
        "    prompt=prompt\n",
        "  )"
      ],
      "metadata": {
        "id": "pPmBiUntEKf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(\"flower\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vjwES_yREe_M",
        "outputId": "8643c442-3982-40ad-8e72-7c3fcdb6073c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'lilies'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading Models Locally"
      ],
      "metadata": {
        "id": "9VtpZ9UlMPlr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFacePipeline\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModelForSeq2SeqLM"
      ],
      "metadata": {
        "id": "w3vYjqsqMUlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id=\"google/flan-t5-large\""
      ],
      "metadata": {
        "id": "2DybuFhXH0Uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ],
      "metadata": {
        "id": "k6NeqlrYMohf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_id, device_map=\"auto\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "31ab97db73884279b802cb28597f854c",
            "83ea4eee162148dea469ec22b6d1b275",
            "71354a94885f4bc0816fba8c827373bd",
            "90762208daa542f3935dbe2549e90f43",
            "2cf0fe806ec74d4ca38f71e237d7af8c",
            "a724b525e98840cd929e54a2fc3110ba",
            "5f360f5280bf43e68376ed445a07b067",
            "f761f1c1c4bb451ba9d318261cc33972",
            "af2b9d318404498881e4bbfe0bc03255",
            "2fc3724136a94b84a9c343160e965867",
            "e4ce9cc0e8d046138ddbc983220e3caf",
            "e6e090223748466d900c662e6d060c54",
            "6da618803553499b966c312dc1491989",
            "ea1d91b9a9584cdb922a5e0971cc08a0",
            "334783b8076e49c0a81c415edbe778f1",
            "37c511f431f74754bf6058a0dd3f2b2b",
            "c4aa6d6755b94621a1230d18daf22abb",
            "c4503b22420e4317859594ac50db13c4",
            "43fb970ef5624a6698203d167c7d6331",
            "d899640d5f414e06b8eefd9802f90806",
            "3beccb37c1ee4ade92557e5b794179fd",
            "86bfebfe2d0d4476baa19ff64bcd017e",
            "3af5eeaeab4a4d2fa721eb72774835e7",
            "6b34eb9ade264304823a5abf4a57ce87",
            "2628ef1c25864a3f9aac2411ecac840c",
            "b73289dc59d4419984670acc900eac59",
            "91df9796cd7a4a67829ec2fa3232ccec",
            "cde5b28a46d845a491de5a021f736265",
            "61446619d4e14a5d888b14d741c21692",
            "0523ac8d13cf4140a70ab3cb6bc458da",
            "df1ef81a0eb84a76bd042f77a40977c0",
            "6ec03853ac8b42228896c35a775f3b6f",
            "cc5d6dde52414ba18e89e8f2a519495b"
          ]
        },
        "id": "-AachrPDMtYP",
        "outputId": "0f273dbb-aa12-4e14-ddff-c545d92da6d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31ab97db73884279b802cb28597f854c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.13G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6e090223748466d900c662e6d060c54"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3af5eeaeab4a4d2fa721eb72774835e7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pline = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, max_length=128)"
      ],
      "metadata": {
        "id": "gFUDZxcEMznE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "local_llm = HuggingFacePipeline(pipeline=pline)"
      ],
      "metadata": {
        "id": "LbxVjo8ONB-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"item\"],\n",
        "    template=\"Tell me about {item}\"\n",
        ")"
      ],
      "metadata": {
        "id": "8nO8RwC_FIgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(llm=local_llm, prompt=prompt)"
      ],
      "metadata": {
        "id": "fkn-Y40PNSng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain(\"Sun\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwgUyZlVNoJs",
        "outputId": "c1fdda49-7d3a-4205-e716-5141e08ef5a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'item': 'Sun',\n",
              " 'text': 'Sun is a constellation in the constellation of Aries.'}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector Databases"
      ],
      "metadata": {
        "id": "3TY5pCv8w-5H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pinecone VectorDB"
      ],
      "metadata": {
        "id": "fX0221ouxAfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain pinecone-client pypdf openai tiktoken langchain_pinecone langchain-openai"
      ],
      "metadata": {
        "id": "pcgnKk1SNq5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFDirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_openai import OpenAI\n",
        "import os"
      ],
      "metadata": {
        "id": "QULNAZX-xwSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir pdfs"
      ],
      "metadata": {
        "id": "cs8UOQR31HCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://papers.neurips.cc/paper/7181-attention-is-all-you-need.pdf\n",
        "!mv /content/7181-attention-is-all-you-need.pdf /content/pdfs/attention-is-all-you-need.pdf"
      ],
      "metadata": {
        "id": "gEjw4N0H4-Pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFDirectoryLoader('pdfs')"
      ],
      "metadata": {
        "id": "qypQypsW4smX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = loader.load()\n",
        "len(data), data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRwx8q085x8L",
        "outputId": "16b9251f-9047-4b5b-c085-7bcf5e4eb3ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11,\n",
              " Document(page_content='Attention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.comNoam Shazeer∗\\nGoogle Brain\\nnoam@google.comNiki Parmar∗\\nGoogle Research\\nnikip@google.comJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.comAidan N. Gomez∗†\\nUniversity of Toronto\\naidan@cs.toronto.eduŁukasz Kaiser∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring signiﬁcantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41.0 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature.\\n1 Introduction\\nRecurrent neural networks, long short-term memory [ 12] and gated recurrent [ 7] neural networks\\nin particular, have been ﬁrmly established as state of the art approaches in sequence modeling and\\ntransduction problems such as language modeling and machine translation [ 29,2,5]. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\\narchitectures [31, 21, 13].\\n∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the ﬁrst Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\\nefﬁcient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research.\\n†Work performed while at Google Brain.\\n‡Work performed while at Google Research.\\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.', metadata={'source': 'pdfs/attention-is-all-you-need.pdf', 'page': 0}))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)"
      ],
      "metadata": {
        "id": "lzsGNVdY5yu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks = text_splitter.split_documents(data)"
      ],
      "metadata": {
        "id": "2T7qWMvc5_E4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text_chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEH3J1O46isS",
        "outputId": "87879de8-62e8-4b05-fd3d-7255c8be81bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "76"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_chunks[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mMjatJ46nsU",
        "outputId": "8a85739d-4a5b-4320-f823-7757351dc852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention Is All You Need\n",
            "Ashish Vaswani∗\n",
            "Google Brain\n",
            "avaswani@google.comNoam Shazeer∗\n",
            "Google Brain\n",
            "noam@google.comNiki Parmar∗\n",
            "Google Research\n",
            "nikip@google.comJakob Uszkoreit∗\n",
            "Google Research\n",
            "usz@google.com\n",
            "Llion Jones∗\n",
            "Google Research\n",
            "llion@google.comAidan N. Gomez∗†\n",
            "University of Toronto\n",
            "aidan@cs.toronto.eduŁukasz Kaiser∗\n",
            "Google Brain\n",
            "lukaszkaiser@google.com\n",
            "Illia Polosukhin∗‡\n",
            "illia.polosukhin@gmail.com\n",
            "Abstract\n",
            "The dominant sequence transduction models are based on complex recurrent or\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_chunks[1].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C80gdjJt6y-e",
        "outputId": "19c3cd13-6ec6-4d26-d8a4-baf869e324dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "convolutional neural networks that include an encoder and a decoder. The best\n",
            "performing models also connect the encoder and decoder through an attention\n",
            "mechanism. We propose a new simple network architecture, the Transformer,\n",
            "based solely on attention mechanisms, dispensing with recurrence and convolutions\n",
            "entirely. Experiments on two machine translation tasks show these models to\n",
            "be superior in quality while being more parallelizable and requiring signiﬁcantly\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key = \"\" # @param {type:\"string\"}"
      ],
      "metadata": {
        "id": "sP8UUFY07rrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = OpenAIEmbeddings(api_key=openai_api_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kqgo5x9Z8TtR",
        "outputId": "2c9f2ea0-b77f-45aa-924c-e06c34c947af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_example = embedding.embed_query(\"Hello World\")\n",
        "len(embedding_example), embedding_example[:15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3Z5US0a8YhY",
        "outputId": "988bccd4-3483-4e9f-fd98-7de4b19621cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1536,\n",
              " [-0.007116983617481661,\n",
              "  0.0034469901452434362,\n",
              "  -0.007148840903008569,\n",
              "  -0.029156057052714266,\n",
              "  -0.013061608137966748,\n",
              "  0.010946264448676999,\n",
              "  -0.020274164077690417,\n",
              "  0.0052533149518593026,\n",
              "  -0.008563317325787047,\n",
              "  -0.03017549950280105,\n",
              "  0.024390162806934363,\n",
              "  0.009863106496213825,\n",
              "  -0.027524949877633466,\n",
              "  -0.006632748500256566,\n",
              "  0.009111268411049814])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pinecone_api_key = \"\" # @param {type:\"string\"}\n",
        "pinecone_api_env = \"\" # @param {type:\"string\"}"
      ],
      "metadata": {
        "id": "wD170J5l1DGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import Pinecone\n",
        "pc = Pinecone(\n",
        "    api_key=pinecone_api_key,\n",
        "    environment=pinecone_api_env\n",
        ")"
      ],
      "metadata": {
        "id": "q6dORQG88Yc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pc.list_indexes()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFRs2YjU8Yab",
        "outputId": "bd6becf5-80ad-40b3-c554-4b52d43bcb4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'indexes': [{'dimension': 1536,\n",
              "              'host': 'genai-course-iqutuem.svc.gcp-starter.pinecone.io',\n",
              "              'metric': 'cosine',\n",
              "              'name': 'genai-course',\n",
              "              'spec': {'pod': {'environment': 'gcp-starter',\n",
              "                               'pod_type': 'starter',\n",
              "                               'pods': 1,\n",
              "                               'replicas': 1,\n",
              "                               'shards': 1}},\n",
              "              'status': {'ready': True, 'state': 'Ready'}}]}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating Embeddings from text chunks"
      ],
      "metadata": {
        "id": "ChlWuiNPB4er"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "0SGExxwzDIvs",
        "outputId": "9a525bf5-8d9f-419e-ab92-6c5cdd19bef0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Attention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.comNoam Shazeer∗\\nGoogle Brain\\nnoam@google.comNiki Parmar∗\\nGoogle Research\\nnikip@google.comJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.comAidan N. Gomez∗†\\nUniversity of Toronto\\naidan@cs.toronto.eduŁukasz Kaiser∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_name = \"genai-course\"\n",
        "os.environ[\"PINECONE_API_KEY\"] = pinecone_api_key\n",
        "os.environ[\"PINECONE_INDEX_NAME\"] = index_name"
      ],
      "metadata": {
        "id": "DEhb3ahQEHBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_name = \"genai-course\"\n",
        "\n",
        "docsearch = PineconeVectorStore.from_documents(\n",
        "    text_chunks,\n",
        "    embedding,\n",
        "    index_name=index_name,\n",
        ")"
      ],
      "metadata": {
        "id": "b22MmbDTDVAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Querying VectorDB"
      ],
      "metadata": {
        "id": "WtglMMDjKD-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What are decoder components\""
      ],
      "metadata": {
        "id": "6X-uu_jaFCqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = docsearch.similarity_search(query)"
      ],
      "metadata": {
        "id": "suwasDV8B0dP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs), docs[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XL32AD9WFSo4",
        "outputId": "c4abb9bd-9f66-4a87-f908-a01758119a07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4,\n",
              " 'Decoder: The decoder is also composed of a stack of N= 6identical layers. In addition to the two\\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\\nattention over the output of the encoder stack. Similar to the encoder, we employ residual connections\\naround each of the sub-layers, followed by layer normalization. We also modify the self-attention\\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions. This')"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manually decoding embeded vectors"
      ],
      "metadata": {
        "id": "cafiTMvpFzY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(api_key=openai_api_key)"
      ],
      "metadata": {
        "id": "Zw7aRTtt7sN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=docsearch.as_retriever()\n",
        ")"
      ],
      "metadata": {
        "id": "zXXhDIf7GLas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "XH83DC_qGg6g",
        "outputId": "757145c3-e7a6-4ea7-c164-ee81356af10a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The decoder components include a stack of N= 6 identical layers, with a third sub-layer for multi-head attention over the output of the encoder stack. The decoder also uses residual connections and layer normalization, and modifies the self-attention sub-layer to prevent positions from attending to subsequent positions. Additionally, the decoder follows the same overall architecture as the encoder, using stacked self-attention and point-wise, fully connected layers. '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docsearch.as_retriever()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcsS5xBTJaCq",
        "outputId": "c72495ab-7b0f-4ffd-e638-2d79c5b02ac4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VectorStoreRetriever(tags=['PineconeVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_pinecone.vectorstores.PineconeVectorStore object at 0x7bf5a8303a90>)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Pinecone directly"
      ],
      "metadata": {
        "id": "WZsEJp1WKM3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = pc.Index(index_name)"
      ],
      "metadata": {
        "id": "-rbJrKv2J3nD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pc.list_indexes()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpirQnB4KSKT",
        "outputId": "a5fc6a1f-9844-4dc3-e003-05103979a34b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'indexes': [{'dimension': 1536,\n",
              "              'host': 'genai-course-iqutuem.svc.gcp-starter.pinecone.io',\n",
              "              'metric': 'cosine',\n",
              "              'name': 'genai-course',\n",
              "              'spec': {'pod': {'environment': 'gcp-starter',\n",
              "                               'pod_type': 'starter',\n",
              "                               'pods': 1,\n",
              "                               'replicas': 1,\n",
              "                               'shards': 1}},\n",
              "              'status': {'ready': True, 'state': 'Ready'}}]}"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeded_query = embedding.embed_query(query)\n",
        "len(embeded_query), embeded_query[:15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKeG5UZeKgYS",
        "outputId": "0415829e-87d0-495a-dc9d-5d2eee214bca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1536,\n",
              " [-0.027967285621545507,\n",
              "  0.007272935520456191,\n",
              "  0.00372656855753541,\n",
              "  -0.036588130280438405,\n",
              "  -0.030850511135379583,\n",
              "  0.01670829110761046,\n",
              "  -0.006833243722728746,\n",
              "  -0.011114833238243343,\n",
              "  -0.0013605219229251401,\n",
              "  -0.02120612253666261,\n",
              "  0.03330125095949351,\n",
              "  0.025934610889234464,\n",
              "  -0.02910615895445195,\n",
              "  -0.0020831302940467426,\n",
              "  -0.019865422300200757])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = index.query(\n",
        "    # namespace=\"ns1\",\n",
        "    vector=embeded_query,\n",
        "    top_k=3,\n",
        "    include_values=True\n",
        ")"
      ],
      "metadata": {
        "id": "Ovf4ZeYLJ-5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(result.matches), \\\n",
        "result.matches[0].id, \\\n",
        "result.matches[0].score, \\\n",
        "result.matches[0].values[:15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Xv23QcBKqaQ",
        "outputId": "0afe8c8f-ca26-4967-ff83-5e656cc822a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3,\n",
              " '6127f943-c2e2-4a09-9d60-357eec482557',\n",
              " 0.796478271,\n",
              " [-0.0240785182,\n",
              "  0.0146332774,\n",
              "  0.012422544,\n",
              "  -0.0345504135,\n",
              "  0.0149207413,\n",
              "  0.00992434658,\n",
              "  -0.0147154108,\n",
              "  0.00101125659,\n",
              "  0.00319119077,\n",
              "  -0.00310905813,\n",
              "  0.0283357203,\n",
              "  0.0291296691,\n",
              "  0.00343587715,\n",
              "  0.00145614112,\n",
              "  -0.00544127962])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index.fetch([result.matches[0].id]) \\\n",
        "  .vectors[result.matches[0].id]['metadata'][\"text\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "Ud5w8dgkMKvW",
        "outputId": "8ffea901-1b5f-4c31-b6e5-eeb5f6a113c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Decoder: The decoder is also composed of a stack of N= 6identical layers. In addition to the two\\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\\nattention over the output of the encoder stack. Similar to the encoder, we employ residual connections\\naround each of the sub-layers, followed by layer normalization. We also modify the self-attention\\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions. This'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ChromaDB"
      ],
      "metadata": {
        "id": "kD8z-5adnZ4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q chromadb openai langchain tiktoken langchain-openai"
      ],
      "metadata": {
        "id": "MZG9y6-P7-tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://www.dropbox.com/s/vs6ocyvpzzncvwh/new_articles.zip\n",
        "!unzip -q new_articles.zip -d new_articles\n",
        "!rm -f new_articles/05-03** new_articles/05-04** new_articles/05-05**"
      ],
      "metadata": {
        "id": "4hzdK-o_8D3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "openai_api_key = \"\" # @param {type:\"string\"}\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
      ],
      "metadata": {
        "id": "zep2gqAm93yK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain_openai import OpenAI\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.document_loaders import TextLoader"
      ],
      "metadata": {
        "id": "XjPlqPvD_Lu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = DirectoryLoader(\"./new_articles\", glob=\"./*.txt\", loader_cls=TextLoader)"
      ],
      "metadata": {
        "id": "M9ASBhRdAGWm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document = loader.load()\n",
        "\n",
        "len(document), document[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcY-rZuJAJVU",
        "outputId": "8cc722de-70ed-4282-8160-a1340b1330ef"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6,\n",
              " Document(page_content='Welcome back to This Week in Apps, the weekly TechCrunch series that recaps the latest in mobile OS news, mobile applications and the overall app economy.\\n\\nThe app economy in 2023 hit a few snags, as consumer spending last year dropped for the first time by 2% to $167 billion, according to data.ai’s “State of Mobile” report. However, downloads are continuing to grow, up 11% year-over-year in 2022 to reach 255 billion. Consumers are also spending more time in mobile apps than ever before. On Android devices alone, hours spent in 2022 grew 9%, reaching 4.1 trillion.\\n\\nThis Week in Apps offers a way to keep up with this fast-moving industry in one place with the latest from the world of apps, including news, updates, startup fundings, mergers and acquisitions, and much more.\\n\\nDo you want This Week in Apps in your inbox every Saturday? Sign up here: techcrunch.com/newsletters\\n\\nTop Stories\\n\\nDorsey criticizes Twitter, Musk on the alternative social networks he’s backing\\n\\nAs demand for Bluesky, the Jack Dorsey-backed decentralized Twitter rival grows, the former Twitter CEO took to the app to share his thoughts on Twitter’s future, Elon Musk and the decision to take the company private. As TechCrunch’s Darrell Etherington reported, Dorsey responded to questions posed to him from other users and reporters on Bluesky, including one where he was asked if Musk has proven to be the best possible steward for the social network.\\n\\nDorsey said he had not:\\n\\nNo. Nor do I think he acted right after realizing his timing was bad. Nor do I think the board should have forced the sale. It all went south. But it happened and all we can do now is build something to avoid that ever happening again. So I’m happy Jay and team and nostr devs exist and building it.\\n\\nHowever, the Twitter co-founder stressed that Twitter would have never survived as a public company and defended himself from an accusation that he was deflecting blame for Twitter’s current situation.\\n\\nThough Bluesky is having a moment, particularly as a haven for marginalized groups, sex workers and trans users, it’s not the only Twitter alternative Dorsey is now backing. In fact, he’s been more active in recent days on the social network nostr (which he also financially backed), where he’s also been critical of some of Musk’s recent decisions. For example, as The NYT reported, Dorsey posted last month “This is weak,” in response to Musk’s move to stop Twitter users from linking to Substack after it launched a Twitter-like service for its own community of writers and readers.\\n\\nDorsey also touted his belief in these platforms during Block’s recent earnings call, suggesting on his nostr profile this may be the first time the network’s name had been mentioned during a public earnings event.\\n\\n“Open protocols represent another fork in the road moment for people and companies,” Dorsey told investors. “Bitcoin, nostr, Bluesky, web5 and others are all working to level the playing field for competition and give individuals and organizations entirely new capabilities,” he added.\\n\\nOver the past few weeks, Bluesky has been gaining traction, but the network has been difficult to access due to its invite-only nature. That’s turned Bluesky invites into hot commodities, where they’re even selling for hundreds of dollars on eBay, as most users have to wait to receive only one invite every two weeks.\\n\\nBluesky leadership will also sometimes gift a user with a larger number of invites in order to have them invite members of a specific community. Developers who can demonstrate they’re building a Bluesky app may also request additional invites, we understand.\\n\\nThe network has received outsized press coverage relative to its size — just 50,000+ users — possibly because of the heavy infusion of tech journalists on there and Dorsey’s name attached. But the reality is that Bluesky’s future remains uncertain. The company, for now, is able to build and grow thanks to the $13 million in initial funds it received from Twitter, where it was incubated under Dorsey’s leadership. It has since spun out into its own, independent company (a public benefit LLC). It’s unclear how Bluesky intends to maintain its operations in the long term, not to mention its freewheeling culture and accepting community. Networks can often be pleasant and welcoming when small, like Bluesky — or early Twitter, for that matter — but face challenges once they scale to millions of users.\\n\\nNewFronts round-up\\n\\nThis week was IAB’s NewFronts, where digital media companies and social networks pitched their platforms to advertisers looking to reach online audiences. The event saw major brands introducing a range of new offerings, including both ad products and formats, as well as touting their latest features, in some cases, as Snap did with its My AI integration.\\n\\nHere’s what you may have missed from the app makers’ NewFronts this week:\\n\\nSnap said it’s beginning to test a feature that lets partners leverage its new My AI chatbot to place sponsored links in front of users. Snap also announced new ad slots, including the option to reserve the first video ad seen in Snapchat’s Friend Stories and the ability to advertise within its TikTok-like Spotlight feature.\\n\\nSnap also announced including the option to reserve the and the ability to YouTube introduced new ad opportunities for Shorts, including the expansion of Shorts into Video reach campaigns that leverage Google AI to serve the best combination of ads and improve reach on YouTube. Plus, YouTube Select is now coming to Shorts, allowing advertisers to place their ads alongside the most popular YouTube Shorts’ content, similar to TikTok Pulse. Another option, First Position on Shorts, will let advertisers be the first ad Shorts users see in their viewing session.\\n\\nincluding the that leverage Google AI to serve the best combination of ads and improve reach on YouTube. Plus, allowing advertisers to place their ads alongside the most popular YouTube Shorts’ content, similar to TikTok Pulse. Another option, will let advertisers be the first ad Shorts users see in their viewing session. TikTok announced partnerships with big-name publishers, including NBCU, Condé Nast, DotDash Meredith, BuzzFeed and others, in an effort to pull in more premium ad dollars. The new premium ad product, Pulse Premiere, would allow marketers, for the first time, to position their brand ads directly after TikTok’s publisher and media partners’ content in over a dozen categories, including lifestyle, sports, entertainment, education and more. Publisher partners would receive a rev share as a result.\\n\\nThe would allow marketers, for the first time, to position their brand ads directly after TikTok’s publisher and media partners’ content in over a dozen categories, including lifestyle, sports, entertainment, education and more. Publisher partners would receive a rev share as a result. Meta announced AR would become available to Reels Ads and Facebook Stories. They had previously been available only to the Facebook Feed, Instagram Feed and Instagram Stories. It also announced features to make Reels Ads more interactive, including a t est of a larger “call to action” button with additional advertiser information on Facebook and Instagram Reels ads. Other updates included multi-destination product ads, the ability to pause a video ad to preview a link’s destination and support for Reels Ads campaigns with select third-party measurement firms .\\n\\nThey had previously been available only to the Facebook Feed, Instagram Feed and Instagram Stories. It also announced features to make Reels Ads more interactive, including a t with additional advertiser information on Facebook and Instagram Reels ads. Other updates included the ability to and support for . NBCU will let Peacock users shop products that appear in its content through “Must ShopTV,” which puts a QR code on the screen when a shoppable product appears.\\n\\nApple & Google team up on Bluetooth tracker safety\\n\\nAfter numerous cases of Bluetooth trackers like Apple’s AirTag being used for stalking or other criminal apps, Apple and Google this week released a joint announcement saying they will work together to lead an industry-wide initiative to draft a specification that would alert users in the case of unwanted tracking from Bluetooth devices. The companies said they’re seeking input from other industry participants and advocacy groups in the matter, and noted that other tracker makers like Samsung, Tile, Chipolo, eufy Security and Pebblebee have also expressed interest in the draft.\\n\\nThe companies submitted a proposed specification as an Internet-Draft via a standards development organization, the Internet Engineering Task Force (IETF). Other interested parties are now being invited to review and comment over the next three months. After this time, Apple and Google will offer feedback and will release a production implementation of the specification by year’s end that will be supported in future versions of iOS and Android, they said.\\n\\nThe spec would build on the AirTag protections Apple had already released but also, critically, would ensure that users would be able to combat unwanted tracking by offering tools across both iOS and Android platforms.\\n\\nGoogle’s participation could signal more than a desire to protect its users — it’s been rumored the company may also be developing an AirTag rival.\\n\\nPlatforms\\n\\nApple\\n\\nGoogle — I/O Preview\\n\\nGoogle I/O kicks off next week and we already know at least one of the announcements — because Google leaked it. The company plans to introduce its first foldable smartphone with the Pixel Fold. The device shares Pixel’s familiar camera bar and features an interface that showcases Material UI design. We expect to learn more at the event.\\n\\nIn addition, Google I/O 2023 should bring a Pixel 7a , a budget device that could also help address Pixel demand in emerging markets, plus possibly a Pixel tablet, an AirTag rival, a Wear OS update, and a lot of new developer tools and features. We also expect to hear quite a bit about Google’s AI plans, with generative AI (like Bard) appearing across Google’s line of products.\\n\\n, a budget device that could also help address Pixel demand in emerging markets, plus possibly a Pixel tablet, an AirTag rival, a Wear OS update, and a lot of new developer tools and features. We also expect to hear quite a bit about Google’s AI plans, with generative AI (like Bard) appearing across Google’s line of products. To get ready for I/O, even if you’re attending virtually, Google offered a new planning guide and a playlist of developer content to help attendees prepare.\\n\\nto help attendees prepare. Checks, Google’s AI-powered data protection project, exited to Google from its in-house incubator Area 120. The tool uses AI to check mobile apps for compliance with various privacy rules and regulations.\\n\\nApp Updates\\n\\nSocial\\n\\nSocial networking app IRL’s CEO Abraham Shafi stepped down following allegations he used bots to inflate the number of users IRL reported publicly and to its investors , The Information reported. A former employee had alleged he was fired after expressing concern over the use of bots. The SEC is now investigating if the company violated securities laws. IRL raised around $200 million from SoftBank Vision Fund, Founders Fund and others.\\n\\n, The Information reported. A former employee had alleged he was fired after expressing concern over the use of bots. The SEC is now investigating if the company violated securities laws. IRL raised around $200 million from SoftBank Vision Fund, Founders Fund and others. After laying off 50% of staff, declining audio social network Clubhouse says it’s building “Clubhouse 2.0,” but hasn’t shared exactly what that plan may involve. Last year, the company began shifting its focus away from public audio to private rooms but it’s not clear there’s much demand for audio social networking in the post-pandemic market.\\n\\nbut hasn’t shared exactly what that plan may involve. Last year, the company began shifting its focus away from public audio to private rooms but it’s not clear there’s much demand for audio social networking in the post-pandemic market. Once-hot viral app Poparazzi shuts down and returns remaining funds to investors. The app had let friends tag others to build out their social profiles of real moments, not polished images, but had been on the decline, with only a few thousand MAUs down from a height of 4 million MAUs previously.\\n\\nA Twitter bug saw users able to regain their blue Verification checks just by editing their bio. Shortly afterward, the Twitter desktop website began randomly logging out users. Later in the week, the mobile website was also down.\\n\\nShortly afterward, the Twitter desktop website began randomly logging out users. Later in the week, the mobile website was also down. As Bluesky gains attention, rival decentralized social platform Mastodon announced a new, simpler onboarding experience that provides new users with an account on mastodon.social by default , instead of requiring them to pick a server. This doesn’t eliminate server choice, it simply means that joining another server requires a few extra clicks.\\n\\n, instead of requiring them to pick a server. This doesn’t eliminate server choice, it simply means that joining another server requires a few extra clicks. Neighborhood social network Nextdoor added new features powered by generative AI, including an Assistant feature aimed at helping users write posts that are more likely to drive positive community engagement. The Assistant will offer writing suggestions that users can review and optionally adopt. The company says it will also use AI to better match content to users when providing recommendations.\\n\\nincluding an Assistant feature aimed at helping users write posts that are more likely to drive positive community engagement. The Assistant will offer writing suggestions that users can review and optionally adopt. The company says it will also use AI to better match content to users when providing recommendations. BeReal is testing another new feature in the U.K., “RealPeople,” that shows users a timeline of the “world’s most interesting people” — that is, athletes, artists, activists and other public figures. The company also recently began testing the option to post more often as usage has declined.\\n\\nand other public figures. The company also recently began testing the option to post more often as usage has declined. Meta introduced new discovery and personalization options for Facebook Reels. Users can now choose “Show More” or “Show Less” options to control what sort of Reels they want to see. Facebook will also explain why it’s showing you a Reel, like if a friend viewed it, and is adding Reels to the main navigation at the top of Facebook Watch.\\n\\nWordPress drops Twitter integration, says sharing to Instagram and Mastodon is coming instead. The Automattic-owned publishing platform said the Twitter connection on Jetpack and WordPress.com will cease to work, meaning users’ blog posts will no longer be auto-shared to Twitter as before. The company said Elon Musk’s decision to “dramatically change the terms and pricing” for Twitter’s API was to blame for this decision. The API now starts at $42,000/month for 50 million tweets. The move will likely hurt Twitter more than WordPress, as the latter powers over 40% of the global internet, including WordPress.com blogs.\\n\\nThe Automattic-owned publishing platform said the Twitter connection on Jetpack and WordPress.com will cease to work, meaning users’ blog posts will no longer be auto-shared to Twitter as before. The company said Elon Musk’s decision to “dramatically change the terms and pricing” for Twitter’s API was to blame for this decision. The API now starts at $42,000/month for 50 million tweets. The move will likely hurt Twitter more than WordPress, as the latter powers over 40% of the global internet, including WordPress.com blogs. Mozilla announced it’s opening up its own Mastodon server — or “instance,” in Mastodon lingo — into private beta testing. The company had said last year it planned to create and begin testing a publicly accessible instance at mozilla.social. It explains its approach to Mastodon will involve high levels of moderation.\\n\\nThe company had said last year it planned to create and begin testing a publicly accessible instance at mozilla.social. It explains its approach to Mastodon will involve high levels of moderation. Twitter announced it would make its API free for public service announcements after New York’s Metro Transit Service (MTS) abandoned the service and the National Weather Services (NWS) said it would no longer auto-post warnings.\\n\\nafter New York’s Metro Transit Service (MTS) abandoned the service and the National Weather Services (NWS) said it would no longer auto-post warnings. TikTok’s U.S. head of trust and safety Eric Han is leaving the company on May 12 as lawmakers weigh a TikTok ban. Han had played a key role in TikTok’s strategy to avoid a U.S. ban.\\n\\nas lawmakers weigh a TikTok ban. Han had played a key role in TikTok’s strategy to avoid a U.S. ban. Discord is making all users change their usernames, the company announced this week. Originally, Discord users had been identified by a name and random number separated by a hash sign, but now it wants to adopt a simpler format so people can more easily share their usernames with others. The new plan will include a unique alphanumeric username with the @ symbol in front of it, plus a freely assignable display name that can be changed at any time.\\n\\nAI\\n\\nSlack introduced SlackGPT, its own generative AI built on Slack’s platform which developers can use to create AI-driven experiences.\\n\\nwhich developers can use to create AI-driven experiences. Microsoft launched its Bing chatbot to all users globally, meaning there’s no more waitlist to get started. It’s also adding more image- and graphic-centric answers in Bing Chat, including by creating graphs and charts and generating images from text prompts. It will also allow users to export their Bing Chat histories. And it will embrace multimodality, meaning it can understand queries with images and text combined. Bing now sees more than 100 million daily active users and says visitors have engaged in over half a billion chats.\\n\\nIt’s also adding more image- and graphic-centric answers in Bing Chat, including by creating graphs and charts and generating images from text prompts. It will also allow users to export their Bing Chat histories. And it will embrace multimodality, meaning it can understand queries with images and text combined. Bing now sees more than 100 million daily active users and says visitors have engaged in over half a billion chats. Plexamp, the music player originally incubated by the Labs division of media company Plex, is tapping into ChatGPT with its latest update. The new feature called “Sonic Sage,” powered by OpenAI’s ChatGPT, will build unique music playlists by scanning users’ libraries and leveraging their TIDAL subscription.\\n\\nMedia & Entertainment\\n\\nFintech\\n\\nYC-backed Kenyan fintech Fingo launched its neobanking app, developed in collaboration with Pan-African financial institution Ecobank Kenya. The company raised $4 million in seed funding after its YC S21 participation. Fingo offers users a bank account, paired with free peer-to-peer transactions and access to savings, financial education and smart spending analytics.\\n\\nThe company raised $4 million in seed funding after its YC S21 participation. Fingo offers users a bank account, paired with free peer-to-peer transactions and access to savings, financial education and smart spending analytics. The FDIC is looking into Tellus, an Andreessen Horowitz-backed fintech company that claims it can offer people higher yields on their savings balances by using that money to fund certain U.S. single-family-home loans. U.S. Senator Sherrod Brown, chairman of the Senate Banking, Housing, and Urban Affairs Committee, wrote a letter to FDIC Chairman Martin Gruenberg expressing concerns about Tellus, and asking the FDIC to review Tellus’s business practices which may put customers at risk.\\n\\nMessaging\\n\\nWhatsApp now lets users create single-vote polls and forward media with captions, Meta announced this week. Single-vote polls let users run a poll where people are only allowed to vote once, including multiple choice, as has been the default.\\n\\nMeta announced this week. Single-vote polls let users run a poll where people are only allowed to vote once, including multiple choice, as has been the default. Reddit’s latest update provides link previews for messaging apps. Now, when you share a Reddit link via a messaging app, it will include a visual preview of the content, the subreddit name, the total upvotes tally and the number of comments. The update also includes the ability to share directly to IG Stories and other tools for publishers.\\n\\nTravel & Transportation\\n\\nFollowing its acquisition by Via, Citymapper said it’s lowering the paywall for its premium features while also introducing a new subscription plan ($1.49/mo) purely for removing ads.\\n\\nwhile also introducing a new subscription plan ($1.49/mo) purely for removing ads. Uber reported a Q1 earnings beat with its revenue up 29% YoY to $8.82 billion, gross bookings up 19% YoY to $31.4 billion and adjusted EBITDA up 353% YoY to $761 million. It also reported a $157 million net loss.\\n\\ngross bookings up 19% YoY to $31.4 billion and adjusted EBITDA up 353% YoY to $761 million. It also reported a $157 million net loss. Uber Eats is also planning to offer support for Live Activities and Dynamic Island on iPhone and integrated with Alexa for order updates.\\n\\nfor order updates. Lyft shared worrisome Q2 guidance sending its stock down after Q1 earnings where it had reported a 14% YoY increase in revenue to $1 billion and a net loss drop of 5% to $187.6 million. Ridership was up 9.8% YoY to 19.5 million.\\n\\nGaming\\n\\nSnowman, the mobile game studio behind Alto’s Adventure and Alto’s Odyssey, launched its newest title, Laya’s Horizon, exclusively with Netflix. The wingsuit game sees players mastering the art of flying, diving off mountains, weaving across forests and gliding over rivers to unlock new abilities as they explore a vast and peaceful world.\\n\\nCross-platform game engine Unity announced layoffs of 8% of its workforce, or around 600 jobs, after laying off 500+ in January and last June.\\n\\nafter laying off 500+ in January and last June. Amazon announced that customers in the United States, Canada, Germany and the United Kingdom can now play Fortnite on their Fire TVs via its Amazon Luna cloud gaming service.\\n\\nCommerce & Food Delivery\\n\\nAmazon Inspire, the e-commerce giant’s in-app TikTok-like shopping feed has rolled out to all customers in the United States. The company had been experimenting since last year with the new feed, which features content creators by influencers.\\n\\nThe company had been experimenting since last year with the new feed, which features content creators by influencers. DoorDash revenue was up 40% YoY in Q1, reaching $2.04 billion, beating estimates of $1.93 billion. Its net loss also declined 3% to $162 million and orders were up 27% to 512 million.\\n\\nEtc.\\n\\nAmazon rolled out a Matter update for Alexa that includes support for Thread, setup on iOS, and a new version of its Works with Alexa program.\\n\\nand a new version of its Works with Alexa program. Match Group posted a Q1 earnings miss with revenue down by 1% YoY to $787 million and paying users down 3% to 15.9 million. The company, however, said it’s “very possible” the recent Apple-Epic court decision could result in App Store fee relief.\\n\\nMedtech startup Healthy.io, which provides urine analysis through a mobile app, is laying off a third of its staff, or around 70 people. The company had just raised $50 million in Series D funding.\\n\\nThe company had just raised $50 million in Series D funding. Airbnb announced Rooms, a feature that focuses on the ability to book single rooms averaging $67 per night as users complain about excessive fees, onerous checkout procedures and rising Airbnb prices.\\n\\naveraging $67 per night as users complain about excessive fees, onerous checkout procedures and rising Airbnb prices. Google’s smart home app, Google Home, added support for smart garage door openers.\\n\\nSecurity\\n\\nGoogle announced that passkeys are now rolling out to Google Account users globally. Passkey let users sign in to websites and apps using the same biometrics or screen-lock PIN they use to unlock their devices.\\n\\nPasskey let users sign in to websites and apps using the same biometrics or screen-lock PIN they use to unlock their devices. Google announced that in 2022, it prevented 1.43 million policy-violating apps from being published on Google Play “in part due to new and improved security features and policy enhancements.”\\n\\nGovernment, Policy and Lawsuits\\n\\nThe EU’s Digital Markets Act (DMA) became applicable on May 2, but enforcement is not expected until spring 2024. The act focused on gatekeepers like Apple, Google, Meta and Microsoft. It limits how they can use third-party data, bans self-preferencing, introduces interoperability requirements, bans tracking users for targeted ads without consent and more. It also says app stores can’t require the use of their own payment services and permits app sideloading.\\n\\nBipartisan U.S. lawmakers reintroduced the Kids Online Safety Act with updates aimed at fixing earlier issues. The bill says platforms have to take reasonable steps to stop the spread of posts that promote eating disorders, suicide, substance abuse and more and undergo independent analysis about their safety for minors. It now also includes protections for support services, like the National Suicide Hotline, substance abuse groups and LGBTQ+ youth centers. However, critics, including the ACLU, say the changes are not enough and they remain opposed to the increased surveillance of kids this bill would require and other matters.\\n\\nThe bill says platforms have to take reasonable steps to stop the spread of posts that promote eating disorders, suicide, substance abuse and more and undergo independent analysis about their safety for minors. It now also includes protections for support services, like the National Suicide Hotline, substance abuse groups and LGBTQ+ youth centers. However, critics, including the ACLU, say the changes are not enough and they remain opposed to the increased surveillance of kids this bill would require and other matters. France’s competition watchdog announced interim measures against Meta, saying it suspects Meta of abusing its dominant position in the French market for ads on social media and across the broader (non-search-related) online ads market.\\n\\nsaying it suspects Meta of abusing its dominant position in the French market for ads on social media and across the broader (non-search-related) online ads market. The U.S. Federal Trade Commission (FTC) says Meta has “repeatedly violated” privacy rules and proposed to tighten its 2020 privacy order against the company, which would completely bar it from monetizing data from anyone under 18 in any way, among other new restrictions. The FTC also accused Meta of COPPA, a children’s privacy law, by misrepresenting its Messenger Kids parental controls, which allowed group chats and group calls with unapproved contacts.\\n\\nFunding and M&A\\n\\nAmazon acquired a small audio-focused artificial intelligence firm called Snackable.AI in 2022, The Post reported. Deal terms weren’t disclosed but Mari Joller, the founder and CEO of Snackable, is now the artificial intelligence and machine learning product leader at Amazon.\\n\\nDownloads\\n\\nRTRO\\n\\nNew social networking startup RTRO launched its app this week with the goal of connecting brands, creators and their fans and followers in a more positive environment focused on human connections and communities, not algorithm-driven content. To accomplish this, RTRO divides its social experience into two parts — on one side, you can keep up with friends or family in RTRO’s “circles.” On the other side, users can switch over to see content from creators and brands in their own space, dubbed RTRO TV.\\n\\nDistroKid\\n\\nMusic distribution service DistroKid this week launched its first mobile app, initially only for iPhone. The new app lets artists upload new releases, receive instant payment alerts, access stats from Apple and Spotify, edit metadata and more from their phones. The company said the mobile app had been the number one request from DistroKid members.', metadata={'source': 'new_articles/05-06-this-week-in-apps-apple-and-google-team-up-on-trackers-google-i-o-preview-apps-hit-newfronts.txt'}))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "text = text_splitter.split_documents(document)"
      ],
      "metadata": {
        "id": "bsw-Ma2p7OWJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text), text[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSF5nCpp8WUU",
        "outputId": "57a1cbe4-bead-46b5-d385-9c4f354a113b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80,\n",
              " Document(page_content='Welcome back to This Week in Apps, the weekly TechCrunch series that recaps the latest in mobile OS news, mobile applications and the overall app economy.\\n\\nThe app economy in 2023 hit a few snags, as consumer spending last year dropped for the first time by 2% to $167 billion, according to data.ai’s “State of Mobile” report. However, downloads are continuing to grow, up 11% year-over-year in 2022 to reach 255 billion. Consumers are also spending more time in mobile apps than ever before. On Android devices alone, hours spent in 2022 grew 9%, reaching 4.1 trillion.\\n\\nThis Week in Apps offers a way to keep up with this fast-moving industry in one place with the latest from the world of apps, including news, updates, startup fundings, mergers and acquisitions, and much more.\\n\\nDo you want This Week in Apps in your inbox every Saturday? Sign up here: techcrunch.com/newsletters\\n\\nTop Stories\\n\\nDorsey criticizes Twitter, Musk on the alternative social networks he’s backing', metadata={'source': 'new_articles/05-06-this-week-in-apps-apple-and-google-team-up-on-trackers-google-i-o-preview-apps-hit-newfronts.txt'}))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating ChromaDB"
      ],
      "metadata": {
        "id": "glV_-rzq8mBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import embeddings\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "persist_directory = 'db'\n",
        "\n",
        "embedding = OpenAIEmbeddings()\n",
        "\n",
        "vectordb = Chroma.from_documents(\n",
        "    documents=text,\n",
        "    embedding=embedding,\n",
        "    persist_directory=persist_directory\n",
        ")"
      ],
      "metadata": {
        "id": "sO_G_7v18lkt"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To persiste the data to disk\n",
        "vectordb.persist()"
      ],
      "metadata": {
        "id": "B3N67ATj9MHH"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb = None\n",
        "# Loading the persisted database from disk\n",
        "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)"
      ],
      "metadata": {
        "id": "4m-7AjWt9-tD"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HREi_Mfb-LnF",
        "outputId": "342b82cf-67f1-4ff0-d9e5-86bb3cf72f78"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_community.vectorstores.chroma.Chroma at 0x78d85f4af910>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Retrieval"
      ],
      "metadata": {
        "id": "EtSO9IhK-iZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectordb.as_retriever()"
      ],
      "metadata": {
        "id": "rfwX56TA-lL6"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = retriever.get_relevant_documents(\n",
        "    \"When did Google rolled out passkeys to Google Account users globally\"\n",
        ")\n",
        "\n",
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAEiAiUC-sHT",
        "outputId": "0cbea1a1-d434-4f0a-d75b-695f4eefe357"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='Google ditches passwords for passkeys: This week Google rolled out passkeys to Google Account users globally, roughly a year after the company — alongside Apple, Microsoft and the FIDO Alliance — announced a partnership to broadly advance passkey adoption. With passkeys, users’ authentication synchronizes across devices through the cloud using cryptographic key pairs, allowing them to sign in to websites and apps using the same biometrics or screen-lock PIN they use to unlock their devices.\\n\\nMicrosoft debuts Pegasus: Microsoft this week announced that it’ll extend the Startup Founders Hub, its self-service platform that provides founders with free resources, including Azure credits, with a new incubator program called the Pegasus Program. Pegasus will select startups with products that “fill a market need” and give them up to $350,000 in Azure, GitHub and LinkedIn credits plus backing from advisors, as well as “access to the best Microsoft tech,” Microsoft says.', metadata={'source': 'new_articles/05-06-amazon-launches-free-channels-check-marks-come-to-gmail-and-openai-raises-more-moolah.txt'}),\n",
              " Document(page_content='Google ditches passwords for passkeys: This week Google rolled out passkeys to Google Account users globally, roughly a year after the company — alongside Apple, Microsoft and the FIDO Alliance — announced a partnership to broadly advance passkey adoption. With passkeys, users’ authentication synchronizes across devices through the cloud using cryptographic key pairs, allowing them to sign in to websites and apps using the same biometrics or screen-lock PIN they use to unlock their devices.\\n\\nMicrosoft debuts Pegasus: Microsoft this week announced that it’ll extend the Startup Founders Hub, its self-service platform that provides founders with free resources, including Azure credits, with a new incubator program called the Pegasus Program. Pegasus will select startups with products that “fill a market need” and give them up to $350,000 in Azure, GitHub and LinkedIn credits plus backing from advisors, as well as “access to the best Microsoft tech,” Microsoft says.', metadata={'source': 'new_articles/05-06-amazon-launches-free-channels-check-marks-come-to-gmail-and-openai-raises-more-moolah.txt'}),\n",
              " Document(page_content='averaging $67 per night as users complain about excessive fees, onerous checkout procedures and rising Airbnb prices. Google’s smart home app, Google Home, added support for smart garage door openers.\\n\\nSecurity\\n\\nGoogle announced that passkeys are now rolling out to Google Account users globally. Passkey let users sign in to websites and apps using the same biometrics or screen-lock PIN they use to unlock their devices.\\n\\nPasskey let users sign in to websites and apps using the same biometrics or screen-lock PIN they use to unlock their devices. Google announced that in 2022, it prevented 1.43 million policy-violating apps from being published on Google Play “in part due to new and improved security features and policy enhancements.”\\n\\nGovernment, Policy and Lawsuits', metadata={'source': 'new_articles/05-06-this-week-in-apps-apple-and-google-team-up-on-trackers-google-i-o-preview-apps-hit-newfronts.txt'}),\n",
              " Document(page_content='averaging $67 per night as users complain about excessive fees, onerous checkout procedures and rising Airbnb prices. Google’s smart home app, Google Home, added support for smart garage door openers.\\n\\nSecurity\\n\\nGoogle announced that passkeys are now rolling out to Google Account users globally. Passkey let users sign in to websites and apps using the same biometrics or screen-lock PIN they use to unlock their devices.\\n\\nPasskey let users sign in to websites and apps using the same biometrics or screen-lock PIN they use to unlock their devices. Google announced that in 2022, it prevented 1.43 million policy-violating apps from being published on Google Play “in part due to new and improved security features and policy enhancements.”\\n\\nGovernment, Policy and Lawsuits', metadata={'source': 'new_articles/05-06-this-week-in-apps-apple-and-google-team-up-on-trackers-google-i-o-preview-apps-hit-newfronts.txt'})]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectordb.as_retriever(search_kwargs={\"k\":2})\n",
        "docs = retriever.get_relevant_documents(\n",
        "    \"What did Amazon CEO Andy Jassy during the company’s first-quarter earnings call\"\n",
        ")\n",
        "\n",
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bmZk2yX_CYD",
        "outputId": "afa4dbcb-cc80-470d-a047-474798407b06"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='A new LLM for Alexa: Amazon is building a more “generalized and capable” large language model to power Alexa, said Amazon CEO Andy Jassy during the company’s first-quarter earnings call this week. He added that although Amazon has had an LLM powering Alexa, Amazon is working on one that’s more capable than the current one.\\n\\naudio', metadata={'source': 'new_articles/05-06-amazon-launches-free-channels-check-marks-come-to-gmail-and-openai-raises-more-moolah.txt'}),\n",
              " Document(page_content='A new LLM for Alexa: Amazon is building a more “generalized and capable” large language model to power Alexa, said Amazon CEO Andy Jassy during the company’s first-quarter earnings call this week. He added that although Amazon has had an LLM powering Alexa, Amazon is working on one that’s more capable than the current one.\\n\\naudio', metadata={'source': 'new_articles/05-06-amazon-launches-free-channels-check-marks-come-to-gmail-and-openai-raises-more-moolah.txt'})]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Making a Chain"
      ],
      "metadata": {
        "id": "Rz1W-meADHuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI()\n",
        "llm"
      ],
      "metadata": {
        "id": "1B_98nswALHf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5deff13a-116f-4985-9e93-c0eaae90ae3d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OpenAI(client=<openai.resources.completions.Completions object at 0x78d8651c86a0>, async_client=<openai.resources.completions.AsyncCompletions object at 0x78d8651cb610>, openai_api_key=SecretStr('**********'), openai_proxy='')"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True\n",
        ")"
      ],
      "metadata": {
        "id": "jh-X0KV5DtiW"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_llm_response(llm_response):\n",
        "  print(llm_response['result'])\n",
        "  print('\\nSources:')\n",
        "  for source in llm_response['source_documents']:\n",
        "    print(source.metadata[\"source\"])"
      ],
      "metadata": {
        "id": "UAR6vFu8ELuC"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usage Example\n",
        "query = \"What was the Apple and Google joint announcement?\"\n",
        "process_llm_response(qa_chain(query))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEb5RSFMEZoB",
        "outputId": "8ac8beb7-7f1f-44a3-ee63-33a7d3266f1e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " They announced that they will be working together to draft a specification that would alert users in the case of unwanted tracking from Bluetooth devices.\n",
            "\n",
            "Sources:\n",
            "new_articles/05-06-this-week-in-apps-apple-and-google-team-up-on-trackers-google-i-o-preview-apps-hit-newfronts.txt\n",
            "new_articles/05-06-this-week-in-apps-apple-and-google-team-up-on-trackers-google-i-o-preview-apps-hit-newfronts.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Removing ChromaDB"
      ],
      "metadata": {
        "id": "nTnNTxUCHD2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Zipping to save the DB\n",
        "!zip -r db.zip ./db"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NN24SA89HIGe",
        "outputId": "3d97d71c-f94f-4750-f029-a56f2bad0086"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: db/ (stored 0%)\n",
            "  adding: db/chroma.sqlite3 (deflated 45%)\n",
            "  adding: db/3b591d91-cf4f-4043-9482-ec2227d3efd2/ (stored 0%)\n",
            "  adding: db/3b591d91-cf4f-4043-9482-ec2227d3efd2/header.bin (deflated 61%)\n",
            "  adding: db/3b591d91-cf4f-4043-9482-ec2227d3efd2/link_lists.bin (stored 0%)\n",
            "  adding: db/3b591d91-cf4f-4043-9482-ec2227d3efd2/length.bin (deflated 84%)\n",
            "  adding: db/3b591d91-cf4f-4043-9482-ec2227d3efd2/data_level0.bin (deflated 100%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb.delete_collection()\n",
        "vectordb.persist()"
      ],
      "metadata": {
        "id": "_UDIlgLoHL6L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}