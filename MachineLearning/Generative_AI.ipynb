{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "collapsed_sections": [
        "Qrmc6aYCmyBE"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "31ab97db73884279b802cb28597f854c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_83ea4eee162148dea469ec22b6d1b275",
              "IPY_MODEL_71354a94885f4bc0816fba8c827373bd",
              "IPY_MODEL_90762208daa542f3935dbe2549e90f43"
            ],
            "layout": "IPY_MODEL_2cf0fe806ec74d4ca38f71e237d7af8c"
          }
        },
        "83ea4eee162148dea469ec22b6d1b275": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a724b525e98840cd929e54a2fc3110ba",
            "placeholder": "​",
            "style": "IPY_MODEL_5f360f5280bf43e68376ed445a07b067",
            "value": "config.json: 100%"
          }
        },
        "71354a94885f4bc0816fba8c827373bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f761f1c1c4bb451ba9d318261cc33972",
            "max": 662,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af2b9d318404498881e4bbfe0bc03255",
            "value": 662
          }
        },
        "90762208daa542f3935dbe2549e90f43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fc3724136a94b84a9c343160e965867",
            "placeholder": "​",
            "style": "IPY_MODEL_e4ce9cc0e8d046138ddbc983220e3caf",
            "value": " 662/662 [00:00&lt;00:00, 7.68kB/s]"
          }
        },
        "2cf0fe806ec74d4ca38f71e237d7af8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a724b525e98840cd929e54a2fc3110ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f360f5280bf43e68376ed445a07b067": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f761f1c1c4bb451ba9d318261cc33972": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af2b9d318404498881e4bbfe0bc03255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2fc3724136a94b84a9c343160e965867": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4ce9cc0e8d046138ddbc983220e3caf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6e090223748466d900c662e6d060c54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6da618803553499b966c312dc1491989",
              "IPY_MODEL_ea1d91b9a9584cdb922a5e0971cc08a0",
              "IPY_MODEL_334783b8076e49c0a81c415edbe778f1"
            ],
            "layout": "IPY_MODEL_37c511f431f74754bf6058a0dd3f2b2b"
          }
        },
        "6da618803553499b966c312dc1491989": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4aa6d6755b94621a1230d18daf22abb",
            "placeholder": "​",
            "style": "IPY_MODEL_c4503b22420e4317859594ac50db13c4",
            "value": "model.safetensors: 100%"
          }
        },
        "ea1d91b9a9584cdb922a5e0971cc08a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43fb970ef5624a6698203d167c7d6331",
            "max": 3132668804,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d899640d5f414e06b8eefd9802f90806",
            "value": 3132668804
          }
        },
        "334783b8076e49c0a81c415edbe778f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3beccb37c1ee4ade92557e5b794179fd",
            "placeholder": "​",
            "style": "IPY_MODEL_86bfebfe2d0d4476baa19ff64bcd017e",
            "value": " 3.13G/3.13G [00:34&lt;00:00, 121MB/s]"
          }
        },
        "37c511f431f74754bf6058a0dd3f2b2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4aa6d6755b94621a1230d18daf22abb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4503b22420e4317859594ac50db13c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43fb970ef5624a6698203d167c7d6331": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d899640d5f414e06b8eefd9802f90806": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3beccb37c1ee4ade92557e5b794179fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86bfebfe2d0d4476baa19ff64bcd017e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3af5eeaeab4a4d2fa721eb72774835e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b34eb9ade264304823a5abf4a57ce87",
              "IPY_MODEL_2628ef1c25864a3f9aac2411ecac840c",
              "IPY_MODEL_b73289dc59d4419984670acc900eac59"
            ],
            "layout": "IPY_MODEL_91df9796cd7a4a67829ec2fa3232ccec"
          }
        },
        "6b34eb9ade264304823a5abf4a57ce87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cde5b28a46d845a491de5a021f736265",
            "placeholder": "​",
            "style": "IPY_MODEL_61446619d4e14a5d888b14d741c21692",
            "value": "generation_config.json: 100%"
          }
        },
        "2628ef1c25864a3f9aac2411ecac840c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0523ac8d13cf4140a70ab3cb6bc458da",
            "max": 147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df1ef81a0eb84a76bd042f77a40977c0",
            "value": 147
          }
        },
        "b73289dc59d4419984670acc900eac59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ec03853ac8b42228896c35a775f3b6f",
            "placeholder": "​",
            "style": "IPY_MODEL_cc5d6dde52414ba18e89e8f2a519495b",
            "value": " 147/147 [00:00&lt;00:00, 2.87kB/s]"
          }
        },
        "91df9796cd7a4a67829ec2fa3232ccec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cde5b28a46d845a491de5a021f736265": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61446619d4e14a5d888b14d741c21692": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0523ac8d13cf4140a70ab3cb6bc458da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df1ef81a0eb84a76bd042f77a40977c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ec03853ac8b42228896c35a775f3b6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc5d6dde52414ba18e89e8f2a519495b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9475298cfa58414d9e8b61133ff6a7ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a39a243aa03429bbbddb3d33554fb14",
              "IPY_MODEL_47ef6b493cf6414396992e6489b57dfe",
              "IPY_MODEL_5c3e900e036147819899cfb31a4b3b8b"
            ],
            "layout": "IPY_MODEL_88c5af1d05bb4befb65ce9941a060f5c"
          }
        },
        "0a39a243aa03429bbbddb3d33554fb14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4aba50bc42fe4b3b88f2ca9c1b95f012",
            "placeholder": "​",
            "style": "IPY_MODEL_de673b9799c94d588436403033cf0a06",
            "value": "llama-2-13b-chat.Q5_K_M.gguf: 100%"
          }
        },
        "47ef6b493cf6414396992e6489b57dfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22a369b084f146618a174c5e54bd2061",
            "max": 9229924224,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f2c6df2a5a84cd9b982987a3700d29d",
            "value": 9229924224
          }
        },
        "5c3e900e036147819899cfb31a4b3b8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2ea3f101e4b4d519761357c3c43255c",
            "placeholder": "​",
            "style": "IPY_MODEL_a55734deae1b43f7887d9ef536a169f3",
            "value": " 9.23G/9.23G [00:59&lt;00:00, 95.0MB/s]"
          }
        },
        "88c5af1d05bb4befb65ce9941a060f5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4aba50bc42fe4b3b88f2ca9c1b95f012": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de673b9799c94d588436403033cf0a06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22a369b084f146618a174c5e54bd2061": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f2c6df2a5a84cd9b982987a3700d29d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c2ea3f101e4b4d519761357c3c43255c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a55734deae1b43f7887d9ef536a169f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ad01cefe6094addb48c31ec17b3ff9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c89fc33db374be9b2d2ae5c28aa27ab",
              "IPY_MODEL_19554aacc62c432b84fc8826bf03187b",
              "IPY_MODEL_fd5d4e2d81c1498193022318ce5eb2ad"
            ],
            "layout": "IPY_MODEL_c98ee2458ff84e2db4c7952f6be68455"
          }
        },
        "0c89fc33db374be9b2d2ae5c28aa27ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd0d1aab4bb54cb9b69db39dfd6471df",
            "placeholder": "​",
            "style": "IPY_MODEL_a95ebb492d5442df811c5090ae3f9ad5",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "19554aacc62c432b84fc8826bf03187b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03da0c1ec63d40edbe18b1f6a8e6268e",
            "max": 776,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_904de62e67e74a6285cde9dd843ee13f",
            "value": 776
          }
        },
        "fd5d4e2d81c1498193022318ce5eb2ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_717ef9f7b6884bc0932b369425851426",
            "placeholder": "​",
            "style": "IPY_MODEL_af841b98084c45539b404f6beae732fe",
            "value": " 776/776 [00:00&lt;00:00, 28.3kB/s]"
          }
        },
        "c98ee2458ff84e2db4c7952f6be68455": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd0d1aab4bb54cb9b69db39dfd6471df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a95ebb492d5442df811c5090ae3f9ad5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03da0c1ec63d40edbe18b1f6a8e6268e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "904de62e67e74a6285cde9dd843ee13f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "717ef9f7b6884bc0932b369425851426": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af841b98084c45539b404f6beae732fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3377bc33e1a74fd8a75fe212e5fa16ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_22a7e96256a1485ca9bca831a6c72c37",
              "IPY_MODEL_57e4ece7aa8942a98433c148cd94d579",
              "IPY_MODEL_5d52463878e34fd99cc17a1ba384477d"
            ],
            "layout": "IPY_MODEL_88fcb3d99fc141d3a7a92eee63af5835"
          }
        },
        "22a7e96256a1485ca9bca831a6c72c37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe9331421ec643348497a5ef32928d89",
            "placeholder": "​",
            "style": "IPY_MODEL_72be241a59eb47cfa3101474f95d0c80",
            "value": "tokenizer.model: 100%"
          }
        },
        "57e4ece7aa8942a98433c148cd94d579": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61f2312c79034af0bf2a08e4ac454bb3",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_624127ce96b247f7b04521ec451f3539",
            "value": 499723
          }
        },
        "5d52463878e34fd99cc17a1ba384477d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b17b42fd7c7a42deb3903bdea7cb391c",
            "placeholder": "​",
            "style": "IPY_MODEL_468adb776f2d4709b368dbde66936386",
            "value": " 500k/500k [00:00&lt;00:00, 6.46MB/s]"
          }
        },
        "88fcb3d99fc141d3a7a92eee63af5835": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe9331421ec643348497a5ef32928d89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72be241a59eb47cfa3101474f95d0c80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61f2312c79034af0bf2a08e4ac454bb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "624127ce96b247f7b04521ec451f3539": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b17b42fd7c7a42deb3903bdea7cb391c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "468adb776f2d4709b368dbde66936386": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be14f06bde77434b92f72225d60fc137": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bdbf831e1f2e40478d753537305b370c",
              "IPY_MODEL_72c4c6ac886a48f2bbadbaf627048752",
              "IPY_MODEL_9c02f8870d6242ec8bdada2eb8e2cf37"
            ],
            "layout": "IPY_MODEL_9ec1bc80cebd4f7db342b4a9c215a24e"
          }
        },
        "bdbf831e1f2e40478d753537305b370c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f9b65405fa945328fe59f50f7f77c20",
            "placeholder": "​",
            "style": "IPY_MODEL_a59aa85c87aa4fa49b4258fb69769f3b",
            "value": "tokenizer.json: 100%"
          }
        },
        "72c4c6ac886a48f2bbadbaf627048752": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_830a032c4dfd49b8b9088b882638a662",
            "max": 1842767,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8bfa5b3c42fb484b8d7d4f439732ad65",
            "value": 1842767
          }
        },
        "9c02f8870d6242ec8bdada2eb8e2cf37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc5eeb809f3041708ef25f722e74c00d",
            "placeholder": "​",
            "style": "IPY_MODEL_fd17baf92ed1493fa8a3f83e5ba95544",
            "value": " 1.84M/1.84M [00:00&lt;00:00, 7.15MB/s]"
          }
        },
        "9ec1bc80cebd4f7db342b4a9c215a24e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f9b65405fa945328fe59f50f7f77c20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a59aa85c87aa4fa49b4258fb69769f3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "830a032c4dfd49b8b9088b882638a662": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bfa5b3c42fb484b8d7d4f439732ad65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dc5eeb809f3041708ef25f722e74c00d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd17baf92ed1493fa8a3f83e5ba95544": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b17e94c3af2346d88e2dbbc97e3a1eaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e3bd9b7f37fe42699e738ec8063d1fc3",
              "IPY_MODEL_a605f69557d446009475194b62ae2060",
              "IPY_MODEL_e51e5c46d14a4ffe872b9f28dc3d80d9"
            ],
            "layout": "IPY_MODEL_7374f710a79b4f6ca1bff5340d8bc238"
          }
        },
        "e3bd9b7f37fe42699e738ec8063d1fc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d750cacc912b4f368ac87b81ccda4be1",
            "placeholder": "​",
            "style": "IPY_MODEL_7287e6edce384b97974cab51adbe6a04",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "a605f69557d446009475194b62ae2060": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c067d3cc8d941d4bb74f957504fbd1d",
            "max": 414,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_31f37a37192944cfa9fb88015f04c09f",
            "value": 414
          }
        },
        "e51e5c46d14a4ffe872b9f28dc3d80d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fd681a9e62944488fbaf368045a24a7",
            "placeholder": "​",
            "style": "IPY_MODEL_c5324dc3d6ea4b08bacc65930062bcd8",
            "value": " 414/414 [00:00&lt;00:00, 10.7kB/s]"
          }
        },
        "7374f710a79b4f6ca1bff5340d8bc238": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d750cacc912b4f368ac87b81ccda4be1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7287e6edce384b97974cab51adbe6a04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c067d3cc8d941d4bb74f957504fbd1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31f37a37192944cfa9fb88015f04c09f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9fd681a9e62944488fbaf368045a24a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5324dc3d6ea4b08bacc65930062bcd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7f74c8ab34648418fef2eba5d0de7ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bdbe190d3d4f41fba500c1ef4bd4d0dc",
              "IPY_MODEL_7ab6020d76374911a6f9c70bd1447d8b",
              "IPY_MODEL_210bbffb8c474b039492d7d6205ffe40"
            ],
            "layout": "IPY_MODEL_0120a802a7a84634854f3054d33c9c42"
          }
        },
        "bdbe190d3d4f41fba500c1ef4bd4d0dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68cab4488533469b9706921df559f640",
            "placeholder": "​",
            "style": "IPY_MODEL_c2a222f270494b5daaacc3d2045a79bb",
            "value": "config.json: 100%"
          }
        },
        "7ab6020d76374911a6f9c70bd1447d8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d47eec8533634439928e4a61de211144",
            "max": 609,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a55db660d9fd4e6c89f23c9fab5dbba6",
            "value": 609
          }
        },
        "210bbffb8c474b039492d7d6205ffe40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_535cdc3ba82b460f9708ba6327b1d9ae",
            "placeholder": "​",
            "style": "IPY_MODEL_5678dc6dc8bd4dde88e0b32d97cec6f1",
            "value": " 609/609 [00:00&lt;00:00, 32.5kB/s]"
          }
        },
        "0120a802a7a84634854f3054d33c9c42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68cab4488533469b9706921df559f640": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2a222f270494b5daaacc3d2045a79bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d47eec8533634439928e4a61de211144": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a55db660d9fd4e6c89f23c9fab5dbba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "535cdc3ba82b460f9708ba6327b1d9ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5678dc6dc8bd4dde88e0b32d97cec6f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14f1deeee7a843278c9e872b78d738e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d7f129de6cd4e7d8fa67ffbdea352f2",
              "IPY_MODEL_c438d273aa564adead144a56111fc9a3",
              "IPY_MODEL_5c45b5a9c6c942ee971211083f5d6511"
            ],
            "layout": "IPY_MODEL_51ca40a393544a77a2674ac5fd351a38"
          }
        },
        "1d7f129de6cd4e7d8fa67ffbdea352f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7280e66f62e49f580d9fcbafbe4b964",
            "placeholder": "​",
            "style": "IPY_MODEL_e9b0f02f314747b68472090393b1507d",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "c438d273aa564adead144a56111fc9a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb605b7078ab479992160717cf9e9323",
            "max": 26788,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e152a129d4b40d59a5d4ba30a37e2f2",
            "value": 26788
          }
        },
        "5c45b5a9c6c942ee971211083f5d6511": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50b5c0a165934831918592a84e154dd5",
            "placeholder": "​",
            "style": "IPY_MODEL_64c1218247464d98a4cd08fdfac5bae9",
            "value": " 26.8k/26.8k [00:00&lt;00:00, 1.39MB/s]"
          }
        },
        "51ca40a393544a77a2674ac5fd351a38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7280e66f62e49f580d9fcbafbe4b964": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9b0f02f314747b68472090393b1507d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb605b7078ab479992160717cf9e9323": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e152a129d4b40d59a5d4ba30a37e2f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "50b5c0a165934831918592a84e154dd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64c1218247464d98a4cd08fdfac5bae9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "096d9321a7a340cd8c38e93be3c9cc0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb5fda1fb0654542ba9fa8fe4517c97b",
              "IPY_MODEL_c61f881a333144f7accf2bbaf4ffee51",
              "IPY_MODEL_cc3ee1371d36482d9775448ce9cd184f"
            ],
            "layout": "IPY_MODEL_e41918b59b8c4e56bc38ef10af37125c"
          }
        },
        "eb5fda1fb0654542ba9fa8fe4517c97b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1557836a3ead474897b155897b268192",
            "placeholder": "​",
            "style": "IPY_MODEL_4464b318cc1243d69b9b9628b5064064",
            "value": "Downloading shards: 100%"
          }
        },
        "c61f881a333144f7accf2bbaf4ffee51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31d5af25471e49dbad950123ac4c6df8",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a9f8531e55d844fb810e19b030083733",
            "value": 2
          }
        },
        "cc3ee1371d36482d9775448ce9cd184f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e3d161f1de144a7a27344bdf9ca5f76",
            "placeholder": "​",
            "style": "IPY_MODEL_827502d848fa458784b831e9d6e8793f",
            "value": " 2/2 [01:54&lt;00:00, 53.49s/it]"
          }
        },
        "e41918b59b8c4e56bc38ef10af37125c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1557836a3ead474897b155897b268192": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4464b318cc1243d69b9b9628b5064064": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31d5af25471e49dbad950123ac4c6df8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9f8531e55d844fb810e19b030083733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7e3d161f1de144a7a27344bdf9ca5f76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "827502d848fa458784b831e9d6e8793f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0af7243c07340269e0b71ca3583047e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be528ffd28614b248d72cf26f52bb71e",
              "IPY_MODEL_a953545824f448af8432897cec3968fa",
              "IPY_MODEL_cbef3319bfaa4a73a747d56b3ad0fd49"
            ],
            "layout": "IPY_MODEL_571bc7dfb9c14d538063524e8fcf6b7e"
          }
        },
        "be528ffd28614b248d72cf26f52bb71e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_228549e6c8664f62b007035729b4fa64",
            "placeholder": "​",
            "style": "IPY_MODEL_2686798d57e74c67a565255fed662ecd",
            "value": "model-00001-of-00002.safetensors: 100%"
          }
        },
        "a953545824f448af8432897cec3968fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d37b750dd714711b806e67a1268474a",
            "max": 9976578928,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b1e6bc0b85746bb8a192e628ddf717e",
            "value": 9976578928
          }
        },
        "cbef3319bfaa4a73a747d56b3ad0fd49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_279c2f82c21742c4aea1b8a6aa87bd58",
            "placeholder": "​",
            "style": "IPY_MODEL_e6ebdc428ab8467eb8e8859f03ef5257",
            "value": " 9.98G/9.98G [01:19&lt;00:00, 92.7MB/s]"
          }
        },
        "571bc7dfb9c14d538063524e8fcf6b7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "228549e6c8664f62b007035729b4fa64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2686798d57e74c67a565255fed662ecd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d37b750dd714711b806e67a1268474a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b1e6bc0b85746bb8a192e628ddf717e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "279c2f82c21742c4aea1b8a6aa87bd58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6ebdc428ab8467eb8e8859f03ef5257": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fd63e3624544ec68f6b7cfe4c15ec24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c4b4078471f42fab8dbd10bf750bcac",
              "IPY_MODEL_bd0518b12a62452f9a8c610583f72fc1",
              "IPY_MODEL_fac2bb8899b046f2a34c8623cdf75ead"
            ],
            "layout": "IPY_MODEL_7322d152aa3043d4bc9891643dc9ac02"
          }
        },
        "6c4b4078471f42fab8dbd10bf750bcac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1a8ed9d8c5b433bb7981d9042482f60",
            "placeholder": "​",
            "style": "IPY_MODEL_8ee27a186c894b78bd2c3d5c321500be",
            "value": "model-00002-of-00002.safetensors: 100%"
          }
        },
        "bd0518b12a62452f9a8c610583f72fc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3253761249b34778aca53557e4dcd4f1",
            "max": 3500297344,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a92844dbd3843eb824de0635fa8bc45",
            "value": 3500297344
          }
        },
        "fac2bb8899b046f2a34c8623cdf75ead": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f70e78a6f2364a2ca6e9f2b432b37872",
            "placeholder": "​",
            "style": "IPY_MODEL_cfe22643342147eda07789413d78de99",
            "value": " 3.50G/3.50G [00:35&lt;00:00, 144MB/s]"
          }
        },
        "7322d152aa3043d4bc9891643dc9ac02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1a8ed9d8c5b433bb7981d9042482f60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ee27a186c894b78bd2c3d5c321500be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3253761249b34778aca53557e4dcd4f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a92844dbd3843eb824de0635fa8bc45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f70e78a6f2364a2ca6e9f2b432b37872": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfe22643342147eda07789413d78de99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55c257592607455ebfd649c4e03421fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_95e4836fa4d74b51ba4c0ab8fb48f434",
              "IPY_MODEL_1ea2cb9c6dc641f2b8a34810325520da",
              "IPY_MODEL_36cff9ecbffb4fc481f959eaf842e49f"
            ],
            "layout": "IPY_MODEL_60315265a33845289585f51d3c1bf774"
          }
        },
        "95e4836fa4d74b51ba4c0ab8fb48f434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fa6b1f83bc84697aac4a2f121769762",
            "placeholder": "​",
            "style": "IPY_MODEL_d7b9e092a2024bfbac870383b392ea62",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "1ea2cb9c6dc641f2b8a34810325520da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_254eb8994b51406cb5a3d848841be189",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc1254165fa74e178c1dc13e6dac6199",
            "value": 2
          }
        },
        "36cff9ecbffb4fc481f959eaf842e49f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36a64993d2464c15bfc9876ef42ed0ef",
            "placeholder": "​",
            "style": "IPY_MODEL_02a372d8f39e4f35a309b3d053b90d00",
            "value": " 2/2 [01:00&lt;00:00, 27.84s/it]"
          }
        },
        "60315265a33845289585f51d3c1bf774": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fa6b1f83bc84697aac4a2f121769762": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7b9e092a2024bfbac870383b392ea62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "254eb8994b51406cb5a3d848841be189": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc1254165fa74e178c1dc13e6dac6199": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "36a64993d2464c15bfc9876ef42ed0ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02a372d8f39e4f35a309b3d053b90d00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66c650b6e1cb4111aca156f1b5d0954d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b53d4fb423fa4c2da894cd0763a5a3a4",
              "IPY_MODEL_a901b0a8d50d459699b8a88909654c2d",
              "IPY_MODEL_e5b01842a3a54a1e8407d0ad33340d59"
            ],
            "layout": "IPY_MODEL_2c9307e3231e49818c6ce27b07f0a3bb"
          }
        },
        "b53d4fb423fa4c2da894cd0763a5a3a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dc8784fc30a47bcbb7ba7d099c20ec8",
            "placeholder": "​",
            "style": "IPY_MODEL_08e7f300f4fe4dcba6e18f155055523b",
            "value": "generation_config.json: 100%"
          }
        },
        "a901b0a8d50d459699b8a88909654c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb82bbe8020045948e0f15c2c70c1662",
            "max": 188,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5825facf48cf407faa6d68a1bc3fb41f",
            "value": 188
          }
        },
        "e5b01842a3a54a1e8407d0ad33340d59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f805abc759a4a388a2ec7a847223aa5",
            "placeholder": "​",
            "style": "IPY_MODEL_aba8bc42b5034beda172178bbf863f24",
            "value": " 188/188 [00:00&lt;00:00, 10.3kB/s]"
          }
        },
        "2c9307e3231e49818c6ce27b07f0a3bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dc8784fc30a47bcbb7ba7d099c20ec8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08e7f300f4fe4dcba6e18f155055523b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb82bbe8020045948e0f15c2c70c1662": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5825facf48cf407faa6d68a1bc3fb41f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f805abc759a4a388a2ec7a847223aa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aba8bc42b5034beda172178bbf863f24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Content"
      ],
      "metadata": {
        "id": "9CWyV4beAH0q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">[Content](#scrollTo=9CWyV4beAH0q&uniqifier=2)\n",
        "\n",
        ">[Generative AI](#scrollTo=d95n8HFhAJ3m&uniqifier=2)\n",
        "\n",
        ">>[OpenAI](#scrollTo=i4ToZgP9-rIo&uniqifier=2)\n",
        "\n",
        ">>>[Few shot Prompt](#scrollTo=wW5Py1HkneoI&uniqifier=2)\n",
        "\n",
        ">>>[Function Calling](#scrollTo=_sHjRxqRu1SE&uniqifier=2)\n",
        "\n",
        ">>[LangChain](#scrollTo=VaZgHOlOly0L&uniqifier=2)\n",
        "\n",
        ">>>[Prompt Templating](#scrollTo=Qrmc6aYCmyBE&uniqifier=2)\n",
        "\n",
        ">>>[Agents](#scrollTo=OSJlfKhYm05y&uniqifier=2)\n",
        "\n",
        ">>>[Chains](#scrollTo=wZB8-VEzm0qW&uniqifier=2)\n",
        "\n",
        ">>>[Document Loader](#scrollTo=094HkTgJ3LgE&uniqifier=2)\n",
        "\n",
        ">>>[Memory](#scrollTo=1yM7479RABo5&uniqifier=2)\n",
        "\n",
        ">>>>[Conversation Buffer Memory](#scrollTo=xUDLj9bZDX1H&uniqifier=2)\n",
        "\n",
        ">>>>[Conversation Chain](#scrollTo=34Wx_PAVHJZc&uniqifier=2)\n",
        "\n",
        ">>>>[Conversation Buffer Window Memory](#scrollTo=bE0qBhKn1sfW&uniqifier=2)\n",
        "\n",
        ">>[Hugging Face](#scrollTo=4J6b25uaB5TP&uniqifier=2)\n",
        "\n",
        ">>>[Using Models from HuggingFace](#scrollTo=Pq3G4sxRDmAH&uniqifier=2)\n",
        "\n",
        ">>>[Downloading Models Locally](#scrollTo=9VtpZ9UlMPlr&uniqifier=2)\n",
        "\n",
        ">>[Llama](#scrollTo=cIbus3vrIFjB&uniqifier=2)\n",
        "\n",
        ">>>[Llama CPP Python](#scrollTo=KwSz42p_TGN4&uniqifier=2)\n",
        "\n",
        ">>>[Llama with Langchain](#scrollTo=U_LQmLSHMnoO&uniqifier=2)\n",
        "\n",
        ">>[LangGraph](#scrollTo=e7WbSwZe0sd1&uniqifier=2)\n",
        "\n",
        ">>>[Agent Executor](#scrollTo=NcVLSks00vwG&uniqifier=2)\n",
        "\n",
        ">>>[Chat Agent Executor](#scrollTo=ZVSc3odHCyAG&uniqifier=2)\n",
        "\n",
        ">>>[Multi-Agent Workflows](#scrollTo=SxZnY3SCO-jU&uniqifier=2)\n",
        "\n",
        ">>>>[Agent Supervisor](#scrollTo=9iMJUxC7A8-C&uniqifier=2)\n",
        "\n",
        ">>[CrewAI](#scrollTo=kyZD8W_RdoXA&uniqifier=2)\n",
        "\n",
        ">>>[Agentic Design Pattern](#scrollTo=MPxfeexmdq3h&uniqifier=2)\n",
        "\n",
        ">>>[Multi-Agent Systems](#scrollTo=4HrBs6wseFgJ&uniqifier=2)\n",
        "\n",
        ">>>>[Article Writer Example](#scrollTo=tGUx0w7JmHsO&uniqifier=2)\n",
        "\n",
        ">>>>[Customer Support Automation Example](#scrollTo=F5HL_6fumNPC&uniqifier=2)\n",
        "\n",
        ">>>[CrewAI Tools](#scrollTo=NVQh0lz0tHFK&uniqifier=2)\n",
        "\n",
        ">[Vector Databases](#scrollTo=3TY5pCv8w-5H&uniqifier=2)\n",
        "\n",
        ">>[Pinecone VectorDB](#scrollTo=fX0221ouxAfx&uniqifier=2)\n",
        "\n",
        ">>>[Creating Embeddings from text chunks](#scrollTo=ChlWuiNPB4er&uniqifier=2)\n",
        "\n",
        ">>>[Querying VectorDB](#scrollTo=WtglMMDjKD-i&uniqifier=2)\n",
        "\n",
        ">>[ChromaDB](#scrollTo=kD8z-5adnZ4T&uniqifier=2)\n",
        "\n",
        ">>>[Creating ChromaDB](#scrollTo=glV_-rzq8mBE&uniqifier=2)\n",
        "\n",
        ">>>[Retrieval](#scrollTo=EtSO9IhK-iZC&uniqifier=2)\n",
        "\n",
        ">>>[Making a Chain](#scrollTo=Rz1W-meADHuS&uniqifier=2)\n",
        "\n",
        ">>>[Removing ChromaDB](#scrollTo=nTnNTxUCHD2o&uniqifier=2)\n",
        "\n",
        ">[Serving LLMs](#scrollTo=revomOFbe7lN&uniqifier=2)\n",
        "\n",
        ">>[Text Generation](#scrollTo=TnghqQQsfv96&uniqifier=2)\n",
        "\n",
        ">>>[Optimizing text generation with KV-caching](#scrollTo=1lj8HSS1gwsP&uniqifier=2)\n",
        "\n",
        ">>[Batching](#scrollTo=XxoSxWcQi-wj&uniqifier=2)\n",
        "\n",
        ">>>[Throughput vs Latency](#scrollTo=l5kHfIoDoMwa&uniqifier=2)\n",
        "\n",
        ">>>[Continuous Batching](#scrollTo=M6VLBm8Wtom0&uniqifier=2)\n",
        "\n",
        ">>[Quantization](#scrollTo=MPwF3Y_PV3T0&uniqifier=2)\n",
        "\n",
        ">[Fine-Tuning](#scrollTo=s8tRQu9eS9Yv&uniqifier=2)\n",
        "\n",
        ">>[Parameter-Efficient Fine-Tuning (PEFT)](#scrollTo=-WFpUVghVoad&uniqifier=2)\n",
        "\n",
        ">>[Adapter Tuning](#scrollTo=8T4beGTiWInB&uniqifier=2)\n",
        "\n",
        ">>>[AdapterFusion](#scrollTo=p0rZtDfybRt8&uniqifier=2)\n",
        "\n",
        ">>[Low-Rank Adaptation (LoRA)](#scrollTo=ssTHZig_CFSb&uniqifier=2)\n",
        "\n",
        ">>>[Implementing LoRA](#scrollTo=nUppikWVgfwZ&uniqifier=2)\n",
        "\n",
        ">>>[Implementing Multi-LoRA](#scrollTo=lnFGYyZskYxD&uniqifier=2)\n",
        "\n",
        ">>[Quantization](#scrollTo=c80BXEChZl2h&uniqifier=2)\n",
        "\n",
        ">>>[4-Bit NormalFloat Quantization](#scrollTo=jZARw3V4Z5v3&uniqifier=2)\n",
        "\n",
        ">>>[Quantization and Low Rank Adaptors (QLoRA)](#scrollTo=gqa83-O9gTE_&uniqifier=2)\n",
        "\n",
        ">>>>[Implementation](#scrollTo=xM44VjYlhpRV&uniqifier=2)\n",
        "\n",
        ">>>[Mixed Precision Training](#scrollTo=BE6k_bXIzJ6A&uniqifier=2)\n",
        "\n"
      ],
      "metadata": {
        "colab_type": "toc",
        "id": "Hse3FiY9AOWW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generative AI"
      ],
      "metadata": {
        "id": "d95n8HFhAJ3m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAI"
      ],
      "metadata": {
        "id": "i4ToZgP9-rIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "GGsVDqbG-20h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFIeRudPAEFG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4afebc1-0605-4737-823b-1579201c926f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.14.1\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "print(openai.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key = \"\" # @param {type:\"string\"}"
      ],
      "metadata": {
        "id": "tzaXoSE1IRfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=openai_api_key)"
      ],
      "metadata": {
        "id": "IEgFPXKt-vpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
        "  ], # Roles: system, user, assistant, tool\n",
        "  max_tokens=128, # Maximum number of tokens you want result\n",
        "  temperature=1, # How creative the output should be\n",
        "  n=2 # Number of the outputs\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIo3YSteA1e5",
        "outputId": "b7b96b55-c363-40d6-b49f-71e58ec65000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content='In the realm of code, a concept lives and breathes,\\nWhere functions call themselves, like whispers in the trees.\\nRecursion is the art, a trance-like dance,\\nUnfolding mysteries with each recursive glance.\\n\\nLike a mirror reflecting its own reflection,\\nA function loops back, with no objection.\\nIt breaks down a problem, into smaller parts,\\nAnd solves them one by one, with gentle smarts.\\n\\nA journey through layers, like a dream unfurled,\\nEach invocation a thread in the code world.\\nIt reaches the base case, like a destination,\\nUnwinding the stack, with jubilation.\\n\\nSo embrace recursion, with courage and grace,\\nLet it guide your code through time and space.\\nFor in its elegant cycle, we find our place,\\nA recursive enchantment, woven with grace.', role='assistant', function_call=None, tool_calls=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This is an example of zero shot prompt**"
      ],
      "metadata": {
        "id": "aY6pLUaLpj55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Few shot Prompt\n"
      ],
      "metadata": {
        "id": "wW5Py1HkneoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "person_info=\"My name is Cyrus, I'm a software engineer at X, and I live in Canada.\""
      ],
      "metadata": {
        "id": "lnlScmEgnicb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f'''\n",
        "Extract the following information from the given text and return it as a JSON object:\n",
        "\n",
        "name\n",
        "job\n",
        "company\n",
        "country\n",
        "\n",
        "This is the body of text to extract the information from:\n",
        "{person_info}\n",
        "'''"
      ],
      "metadata": {
        "id": "WTl8OVAen3T1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiR1k8oJoQWx",
        "outputId": "23d7e648-a643-425f-dc32-d24951445fdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"name\": \"Cyrus\",\n",
            "  \"job\": \"software engineer\",\n",
            "  \"company\": \"X\",\n",
            "  \"country\": \"Canada\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This is an example of few shot prompt**"
      ],
      "metadata": {
        "id": "M86yU2LppbrR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function Calling"
      ],
      "metadata": {
        "id": "_sHjRxqRu1SE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Example dummy function hard coded to return the same weather\n",
        "# In production, this could be your backend API or an external API\n",
        "def get_current_weather(location, unit=\"fahrenheit\"):\n",
        "    \"\"\"Get the current weather in a given location\"\"\"\n",
        "    if \"tokyo\" in location.lower():\n",
        "        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": unit})\n",
        "    elif \"san francisco\" in location.lower():\n",
        "        return json.dumps({\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": unit})\n",
        "    elif \"paris\" in location.lower():\n",
        "        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": unit})\n",
        "    else:\n",
        "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})\n"
      ],
      "metadata": {
        "id": "nOKVKSi1u--n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: send the conversation and available functions to the model\n",
        "messages = [{\"role\": \"user\", \"content\": \"What's the weather like in San Francisco, Tokyo, and Paris?\"}]\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_current_weather\",\n",
        "            \"description\": \"Get the current weather in a given location\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"location\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
        "                    },\n",
        "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
        "                },\n",
        "                \"required\": [\"location\"],\n",
        "            },\n",
        "        },\n",
        "    }\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo-0125\",\n",
        "    messages=messages,\n",
        "    tools=tools,\n",
        "    tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
        ")\n",
        "response_message = response.choices[0].message\n",
        "tool_calls = response_message.tool_calls"
      ],
      "metadata": {
        "id": "ABv2CX9svGQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: check if the model wanted to call a function\n",
        "if tool_calls:\n",
        "    # Step 3: call the function\n",
        "    # Note: the JSON response may not always be valid; be sure to handle errors\n",
        "    available_functions = {\n",
        "        \"get_current_weather\": get_current_weather,\n",
        "    }  # only one function in this example, but you can have multiple\n",
        "    messages.append(response_message)  # extend conversation with assistant's reply\n",
        "    # Step 4: send the info for each function call and function response to the model\n",
        "    for tool_call in tool_calls:\n",
        "        print(tool_call)\n",
        "        function_name = tool_call.function.name\n",
        "        function_to_call = available_functions[function_name]\n",
        "        function_args = json.loads(tool_call.function.arguments)\n",
        "        function_response = function_to_call(\n",
        "            location=function_args.get(\"location\"),\n",
        "            unit=function_args.get(\"unit\"),\n",
        "        )\n",
        "        messages.append(\n",
        "            {\n",
        "                \"tool_call_id\": tool_call.id,\n",
        "                \"role\": \"tool\",\n",
        "                \"name\": function_name,\n",
        "                \"content\": function_response,\n",
        "            }\n",
        "        )  # extend conversation with function response\n",
        "    second_response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo-0125\",\n",
        "        messages=messages,\n",
        "    )  # get a new response from the model where it can see the function response\n",
        "    print(second_response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOO64huru4Eo",
        "outputId": "d3b38c5f-05db-43d7-d320-a7351a0aa7b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessageToolCall(id='call_Q6tNs8Yd24ROxqmgrMYYYAC1', function=Function(arguments='{\"location\": \"San Francisco\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function')\n",
            "ChatCompletionMessageToolCall(id='call_efCZ1xEyMhMqKCVvFNsU3gax', function=Function(arguments='{\"location\": \"Tokyo\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function')\n",
            "ChatCompletionMessageToolCall(id='call_UgPOHn0Gls5GEtPiNdYlseoB', function=Function(arguments='{\"location\": \"Paris\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function')\n",
            "Currently in San Francisco, the weather is 72°C. In Tokyo, it is 10°C, and in Paris, it is 22°C.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LangChain"
      ],
      "metadata": {
        "id": "VaZgHOlOly0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "id": "xZHmSegSlwDb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3e86d40-634f-437d-8948-baa58d89c15f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.20)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.6)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.38 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.38)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.52 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.52)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.59)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain) (2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "print(langchain.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RcCAU_3lxwo",
        "outputId": "2d2901b6-c9a5-4eb4-abe6-8ca09319bcb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "client=OpenAI(openai_api_key=openai_api_key)"
      ],
      "metadata": {
        "id": "gzwDMWWJkRwR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5639bda1-4c1c-43d0-e613-948632a6e5a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Zero shot prompting\n",
        "prompt=\"Can you tell me total number of counntries in north america\"\n",
        "print(client.invoke(prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TISsuVVflAZ3",
        "outputId": "9007d70a-d576-43de-b6b8-69b5761c3dda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "There are 23 countries in North America. They are:\n",
            "\n",
            "1. Antigua and Barbuda\n",
            "2. Bahamas\n",
            "3. Barbados\n",
            "4. Belize\n",
            "5. Canada\n",
            "6. Costa Rica\n",
            "7. Cuba\n",
            "8. Dominica\n",
            "9. Dominican Republic\n",
            "10. El Salvador\n",
            "11. Grenada\n",
            "12. Guatemala\n",
            "13. Haiti\n",
            "14. Honduras\n",
            "15. Jamaica\n",
            "16. Mexico\n",
            "17. Nicaragua\n",
            "18. Panama\n",
            "19. Saint Kitts and Nevis\n",
            "20. Saint Lucia\n",
            "21. Saint Vincent and the Grenadines\n",
            "22. Trinidad and Tobago\n",
            "23. United States of America\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompt Templating"
      ],
      "metadata": {
        "id": "Qrmc6aYCmyBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"country\"],\n",
        "    template=\"Can you tell me the capital {country}\"\n",
        ")\n",
        "prompt_template"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYe_bl8wlJ_D",
        "outputId": "c1c90e1f-2e33-4a51-8174-9f1e0ccd8ba9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['country'], template='Can you tell me the capital {country}')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = prompt_template.format(country=\"Canada\")"
      ],
      "metadata": {
        "id": "7jmpqHl4xHDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(client.invoke(prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h72pXwUtxi2k",
        "outputId": "e87371cc-de2e-4bb4-cfe7-73ff888cc94f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "The capital of Canada is Ottawa.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = PromptTemplate.from_template(\"What is the language of {country}\")"
      ],
      "metadata": {
        "id": "WTt4288nx5N6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template.format(country=\"Canada\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5F2a9CoxyEAx",
        "outputId": "129f1bc5-953e-4d40-c5eb-49fd91b836ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What is the language of Canada'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agents\n",
        "\n",
        "Used to call third-party tools"
      ],
      "metadata": {
        "id": "OSJlfKhYm05y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = PromptTemplate.from_template(\"What is the weather in {city} now?\")\n",
        "prompt=prompt_template.format(city=\"Ottawa\")"
      ],
      "metadata": {
        "id": "NItv_FVdxqCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(client.invoke(prompt)) # Not a good answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7uqD_n80LbW",
        "outputId": "0503c606-ee15-406b-eb84-a176286cf4f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "I am an AI and do not have access to real-time weather data. Please check a weather website or app for the current weather in Ottawa.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-search-results"
      ],
      "metadata": {
        "id": "HaXUoHBs0Vo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "serp_api_key = \"\" # @param {type:\"string\"}"
      ],
      "metadata": {
        "id": "djK_ONZ_2Exi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentType, load_tools, initialize_agent"
      ],
      "metadata": {
        "id": "hDttvoWH0tzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tool = load_tools([\"serpapi\"], serpapi_api_key=serp_api_key, llm=client)\n",
        "tool"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwXgMdFr2q0w",
        "outputId": "1ce274b2-4178-44a2-c72f-79ac7ac1be7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Tool(name='Search', description='A search engine. Useful for when you need to answer questions about current events. Input should be a search query.', func=<bound method SerpAPIWrapper.run of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='46f2201c74213cb9e5f88667f9bc98ea9b2ce2343d5cc3a206bc5c67c9c85b33', aiosession=None)>, coroutine=<bound method SerpAPIWrapper.arun of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='46f2201c74213cb9e5f88667f9bc98ea9b2ce2343d5cc3a206bc5c67c9c85b33', aiosession=None)>)]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent=initialize_agent(\n",
        "    tool,\n",
        "    client,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "9mkEsC7X2_0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "m_WVIwuU4GI1",
        "outputId": "0b2c8b2a-fdff-428c-e202-1af26bfad568"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should use the search engine to find the current weather in Ottawa\n",
            "Action: Search\n",
            "Action Input: \"weather in Ottawa\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m{'type': 'weather_result', 'temperature': '33', 'unit': 'Fahrenheit', 'precipitation': '19%', 'humidity': '91%', 'wind': '8 mph', 'location': 'Ottawa, ON, Canada', 'date': 'Tuesday 11:00 PM', 'weather': 'Cloudy'}\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m The current weather in Ottawa is cloudy with a temperature of 33 degrees Fahrenheit.\n",
            "Final Answer: The current weather in Ottawa is cloudy with a temperature of 33 degrees Fahrenheit.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The current weather in Ottawa is cloudy with a temperature of 33 degrees Fahrenheit.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chains\n",
        "\n",
        "Chains refer to sequences of calls - whether to an LLM, a tool, or a data preprocessing step."
      ],
      "metadata": {
        "id": "wZB8-VEzm0qW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "prompt_template1 = PromptTemplate.from_template(\"What is a good name for a {obj} bussiness? (Only one example)\")\n",
        "prompt_template2 = PromptTemplate.from_template(\"Creating a startup with the name {name} , give me ideas?\")"
      ],
      "metadata": {
        "id": "aE8Odg_R9-3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "name_chain = LLMChain(llm=client, prompt=prompt_template1, output_key=\"name\")"
      ],
      "metadata": {
        "id": "3-edf8MhAb8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(name_chain.run(\"flower\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43nqtzUCA99x",
        "outputId": "e217b417-8779-4173-c020-d7acd8f7dd63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"Blooming Blossoms\" \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idea_chain = LLMChain(llm=client, prompt=prompt_template2, output_key=\"ideas\")"
      ],
      "metadata": {
        "id": "s2v2vqiXDiJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SimpleSequentialChain\n",
        "chain=SimpleSequentialChain(chains=[name_chain, idea_chain])"
      ],
      "metadata": {
        "id": "pvHtM5lKDvnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.run(\"flower\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9Q6DXhtD3Cc",
        "outputId": "bfcc7899-3a86-4a45-9feb-1641a89096b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. A unique and personalized floral subscription service, where customers can receive a fresh bouquet of flowers every week or month.\n",
            "\n",
            "2. Offering floral arrangements for special events such as weddings, birthdays, and corporate events.\n",
            "\n",
            "3. Partnering with local businesses to provide floral arrangements for their offices or storefronts.\n",
            "\n",
            "4. Hosting workshops and classes on floral arrangement and design for individuals or groups.\n",
            "\n",
            "5. Developing a line of eco-friendly and sustainable floral products, such as biodegradable flower pots and packaging.\n",
            "\n",
            "6. Providing flower delivery services for last-minute gifts or special occasions.\n",
            "\n",
            "7. Collaborating with local artists to create unique and one-of-a-kind floral art installations for public spaces.\n",
            "\n",
            "8. Offering a selection of dried and preserved flowers for long-lasting home decor.\n",
            "\n",
            "9. Creating a social media presence to showcase the beauty of flowers and engage with customers.\n",
            "\n",
            "10. Partnering with local flower farms to source fresh, locally grown blooms for a farm-to-table approach.\n",
            "\n",
            "11. Developing a line of handmade botanical skincare and wellness products using natural flower essences.\n",
            "\n",
            "12. Expanding into event planning services, offering a full package of floral design, venue decoration, and coordination.\n",
            "\n",
            "13. Creating a loyalty program to reward frequent customers with discounts and special perks.\n",
            "\n",
            "14. Offering a \"flower bar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Alternative syntax**"
      ],
      "metadata": {
        "id": "nNP2DkUzBtKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt_template1 | client\n",
        "\n",
        "print(chain.invoke({\"obj\": \"flower bussiness\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2NBE0aDBD4M",
        "outputId": "8cac257e-fcb8-4b88-c7f7-d95673ec34c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"Petals & Blooms Co.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def str_parser(input):\n",
        "  print(input)\n",
        "  return {\"name\": input}\n",
        "\n",
        "chain = prompt_template1 | client | str_parser | prompt_template2 | client\n",
        "print(chain.invoke({\"obj\": \"flower bussiness\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTHj9tEeEByy",
        "outputId": "e7ea6077-f407-45e9-92c8-b893227d3ee9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"Blooming Oasis Florals\"\n",
            "\n",
            "\n",
            "1. Unique floral arrangements: Offer a variety of unique and creative floral arrangements, such as succulent bouquets, preserved flower displays, and personalized floral designs.\n",
            "\n",
            "2. Subscription services: Provide a subscription service for weekly or monthly flower deliveries to homes and businesses, offering a convenient and cost-effective option for customers.\n",
            "\n",
            "3. Event and wedding services: Partner with event planners and wedding venues to offer floral design services for special occasions, including customized centerpieces, bouquets, and installations.\n",
            "\n",
            "4. Online presence: Create a strong online presence through a website and social media platforms to showcase your work, promote your services, and interact with customers.\n",
            "\n",
            "5. Green and sustainable practices: Promote eco-friendly and sustainable practices, such as using locally sourced flowers and recyclable packaging, to appeal to environmentally conscious customers.\n",
            "\n",
            "6. Collaborations: Collaborate with local businesses, such as cafes and boutiques, to offer floral arrangements for their spaces, creating a mutually beneficial partnership.\n",
            "\n",
            "7. Workshops and classes: Host workshops and classes to teach customers how to create their own floral arrangements and offer team-building events for corporate clients.\n",
            "\n",
            "8. Mobile flower truck: Take your business on the road by converting a truck into a mobile flower shop, allowing you to reach new customers and attend events and markets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sequential Chains"
      ],
      "metadata": {
        "id": "XCI8L81d0L8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SequentialChain\n",
        "\n",
        "chain=SequentialChain(\n",
        "    chains=[name_chain, idea_chain],\n",
        "    input_variables=[\"obj\"],\n",
        "    output_variables=[\"name\", \"ideas\"]\n",
        "    )"
      ],
      "metadata": {
        "id": "3zTJJY1k0K1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain({\"obj\": \"flower\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UM34GHEx04uM",
        "outputId": "11acb812-69ad-4187-f8d4-647a1421575c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'obj': 'flower',\n",
              " 'name': '\\n\\n\"Petals & Blooms Floral Co.\" ',\n",
              " 'ideas': ' \\n\\n1. Online Flower Delivery Service: Offer a convenient and easy way for customers to order and send flowers to their loved ones with same-day delivery options.\\n\\n2. Custom Floral Arrangements: Create unique and personalized floral arrangements for special occasions such as weddings, birthdays, and anniversaries.\\n\\n3. Subscription Services: Offer a subscription service where customers can receive a fresh bouquet of flowers every week or month.\\n\\n4. Event Planning and Decor: Partner with event planners and offer floral decor for weddings, corporate events, and other special occasions.\\n\\n5. Floral Workshops: Host workshops for customers to learn how to create their own floral arrangements and bouquets.\\n\\n6. Greenhouse and Nursery: Have a greenhouse and nursery on-site where customers can purchase plants and flowers for their home or garden.\\n\\n7. Corporate Gifting: Partner with businesses to provide custom floral arrangements for employee recognition, client gifts, and office decor.\\n\\n8. Online Floral Design Courses: Offer online courses for customers to learn the art of floral design and create their own arrangements at home.\\n\\n9. Eco-Friendly Options: Use sustainable and eco-friendly materials for packaging and offer options for customers to recycle or compost their flowers after use.\\n\\n10. Collaborations with Local Artists: Partner with local artists to create unique and one'}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Document Loader"
      ],
      "metadata": {
        "id": "094HkTgJ3LgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf langchain_openai  faiss-cpu"
      ],
      "metadata": {
        "id": "6S31iTBN3Pn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://papers.neurips.cc/paper/7181-attention-is-all-you-need.pdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lkci7D_D4pM7",
        "outputId": "7f18316a-8cce-4547-8259-63fa08a79c33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-21 02:42:10--  https://papers.neurips.cc/paper/7181-attention-is-all-you-need.pdf\n",
            "Resolving papers.neurips.cc (papers.neurips.cc)... 198.202.70.94\n",
            "Connecting to papers.neurips.cc (papers.neurips.cc)|198.202.70.94|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf [following]\n",
            "--2024-03-21 02:42:10--  https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf\n",
            "Resolving proceedings.neurips.cc (proceedings.neurips.cc)... 198.202.70.94\n",
            "Connecting to proceedings.neurips.cc (proceedings.neurips.cc)|198.202.70.94|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 569417 (556K) [application/pdf]\n",
            "Saving to: ‘7181-attention-is-all-you-need.pdf’\n",
            "\n",
            "7181-attention-is-a 100%[===================>] 556.07K  1.69MB/s    in 0.3s    \n",
            "\n",
            "2024-03-21 02:42:11 (1.69 MB/s) - ‘7181-attention-is-all-you-need.pdf’ saved [569417/569417]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"/content/7181-attention-is-all-you-need.pdf\")\n",
        "pages = loader.load_and_split()"
      ],
      "metadata": {
        "id": "jjaTv_s14fNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(pages), pages[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8r8zdgk43CE",
        "outputId": "3843d22c-adce-432a-d08b-c967884d8176"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12,\n",
              " Document(page_content='Attention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.comNoam Shazeer∗\\nGoogle Brain\\nnoam@google.comNiki Parmar∗\\nGoogle Research\\nnikip@google.comJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.comAidan N. Gomez∗†\\nUniversity of Toronto\\naidan@cs.toronto.eduŁukasz Kaiser∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring signiﬁcantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41.0 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature.\\n1 Introduction\\nRecurrent neural networks, long short-term memory [ 12] and gated recurrent [ 7] neural networks\\nin particular, have been ﬁrmly established as state of the art approaches in sequence modeling and\\ntransduction problems such as language modeling and machine translation [ 29,2,5]. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\\narchitectures [31, 21, 13].\\n∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the ﬁrst Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\\nefﬁcient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research.\\n†Work performed while at Google Brain.\\n‡Work performed while at Google Research.\\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.', metadata={'source': '/content/7181-attention-is-all-you-need.pdf', 'page': 0}))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "faiss_index = FAISS.from_documents(pages[0:3], OpenAIEmbeddings(api_key=openai_api_key))"
      ],
      "metadata": {
        "id": "5RZa2_hZ4315"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = faiss_index.similarity_search(\"What is attention?\", k=2)\n",
        "for doc in docs:\n",
        "    print(str(doc.metadata[\"page\"]) + \":\", doc.page_content[:300])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaqX1z0R5PzU",
        "outputId": "9c9ddc95-9782-4456-dff1-18896a3057c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: Attention Is All You Need\n",
            "Ashish Vaswani∗\n",
            "Google Brain\n",
            "avaswani@google.comNoam Shazeer∗\n",
            "Google Brain\n",
            "noam@google.comNiki Parmar∗\n",
            "Google Research\n",
            "nikip@google.comJakob Uszkoreit∗\n",
            "Google Research\n",
            "usz@google.com\n",
            "Llion Jones∗\n",
            "Google Research\n",
            "llion@google.comAidan N. Gomez∗†\n",
            "University of Toronto\n",
            "aidan@c\n",
            "1: Recurrent models typically factor computation along the symbol positions of the input and output\n",
            "sequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\n",
            "statesht, as a function of the previous hidden state ht−1and the input for position t. This inherently\n",
            "s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Memory"
      ],
      "metadata": {
        "id": "1yM7479RABo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "prompt_template = PromptTemplate.from_template(\"What is a good name for a {obj} bussiness? (Only one example)\")"
      ],
      "metadata": {
        "id": "7dk_BQgHBtlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "chain = LLMChain(llm=client, prompt=prompt_template)"
      ],
      "metadata": {
        "id": "IlDyTgOQCLpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(\"AI\").strip()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9XIGaBLnCTar",
        "outputId": "19596f39-ba7a-4cf5-a301-0fc15c0cb061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"Synapse Solutions\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.memory"
      ],
      "metadata": {
        "id": "VMb4uJSiCXJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(chain.memory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0M-9C2MgCtXB",
        "outputId": "0e2f4b92-fa3f-4239-c0cd-e6f1b9bd45a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NoneType"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Conversation Buffer Memory"
      ],
      "metadata": {
        "id": "xUDLj9bZDX1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory()"
      ],
      "metadata": {
        "id": "H9G9Cny2DZ09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manually adding to memory\n",
        "\n",
        "```python\n",
        "memory.chat_memory.add_user_message(\"hi!\")\n",
        "memory.chat_memory.add_ai_message(\"what's up?\")\n",
        "```"
      ],
      "metadata": {
        "id": "uOLXXSULGbUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(llm=client, prompt=prompt_template, memory=memory)"
      ],
      "metadata": {
        "id": "TMJ0urxAGQNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(\"AI\").strip()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0AERpcGdGl41",
        "outputId": "51b12bd9-ccaf-4282-97a2-625d2b75e2bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"NeuroNexus Solutions\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.memory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceEhfhEsGpwr",
        "outputId": "e49229f8-d933-4084-e9e2-59da1e5bec8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConversationBufferMemory(chat_memory=ChatMessageHistory(messages=[HumanMessage(content='AI'), AIMessage(content='\\n\\n\"NeuroNexus Solutions\"')]))"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0bvf3qjG20T",
        "outputId": "1ef5974c-1a55-4602-d46e-c9579ec129f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: AI\n",
            "AI: \n",
            "\n",
            "\"NeuroNexus Solutions\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Conversation Chain\n",
        "\n",
        "Conversation buffer memory goes growing endlessly.\n",
        "\n",
        "Restrict to last 5 conversation chain"
      ],
      "metadata": {
        "id": "34Wx_PAVHJZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationChain\n",
        "from langchain_openai import OpenAI"
      ],
      "metadata": {
        "id": "xkrkvedyG4a4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convo = ConversationChain(llm=OpenAI(openai_api_key=openai_api_key, temperature=0.7))"
      ],
      "metadata": {
        "id": "4mRaPep2yN_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(convo.prompt.template)"
      ],
      "metadata": {
        "id": "17fDiJ21x9Kp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5f41531-495b-4b7d-f6ab-78334a8d17ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "{history}\n",
            "Human: {input}\n",
            "AI:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"Who invented the light bulb?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "euQlvcdkzbk7",
        "outputId": "22b0e0ab-a756-4abe-d3d8-ab057064da92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The light bulb was invented by Thomas Edison in 1879. However, he was not the only person working on this technology at the time. Other inventors like Joseph Swan and Hiram Maxim were also working on improving the design and functionality of the light bulb.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"When did he born?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "SmqvsT9zzpvQ",
        "outputId": "33db61b3-b94a-47d1-9c43-8dde604bbc3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Thomas Edison was born on February 11, 1847 in Milan, Ohio. He was the youngest of seven children and showed an interest in science and technology from a young age.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Conversation Buffer Window Memory\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bE0qBhKn1sfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferWindowMemory"
      ],
      "metadata": {
        "id": "SV3LxDRlz7Gg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory=ConversationBufferWindowMemory(k=1)"
      ],
      "metadata": {
        "id": "CvRBbBWy2SD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convo = ConversationChain(llm=OpenAI(openai_api_key=openai_api_key, temperature=0.7), memory=memory)"
      ],
      "metadata": {
        "id": "I4Zog2WE2ami"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"Who invented the light bulb?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "PKfoI9342fV5",
        "outputId": "89cf197f-8a7c-45da-f9c5-1cebdc15b5bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The light bulb was invented by Thomas Edison in 1879. He experimented with over 6,000 different materials before discovering that carbonized bamboo worked best as a filament.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"What year is today?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bjmITB8m2mjR",
        "outputId": "da79f502-9001-40ca-93f5-9f011db59002"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Today is Monday, December 13, 2021.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"When did he born?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UPcOg3a-2iBM",
        "outputId": "ee95307e-8da0-4674-aabc-6c2d714651d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' I do not have enough information to accurately answer your question. Who are you referring to?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hugging Face"
      ],
      "metadata": {
        "id": "4J6b25uaB5TP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub transformers accelerate bitsandbytes langchain"
      ],
      "metadata": {
        "id": "g3Y6kbhhB6_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gttbGrgCTTE",
        "outputId": "003de5bd-4f32-4867-97d7-0509e8950cff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.13 langchain-community-0.0.29 langchain-core-0.1.33 langchain-text-splitters-0.0.1 langsmith-0.1.31 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.9.15 packaging-23.2 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate, HuggingFaceHub, LLMChain\n",
        "import os"
      ],
      "metadata": {
        "id": "J8jGZNxJCiwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HUGGINGFACEHUB_API_TOKEN = \"\" # @param {type:\"string\"}\n"
      ],
      "metadata": {
        "id": "ABDFJje9Cu50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['HUGGINGFACEHUB_API_TOKEN']=HUGGINGFACEHUB_API_TOKEN"
      ],
      "metadata": {
        "id": "yLX-4sMIDJzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Models from HuggingFace"
      ],
      "metadata": {
        "id": "Pq3G4sxRDmAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"product\"],\n",
        "    template=\"What is a good name for a company that make {product}\"\n",
        ")"
      ],
      "metadata": {
        "id": "DNEAaltpDpSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(\n",
        "    llm=HuggingFaceHub(repo_id=\"google/flan-t5-large\", model_kwargs={'temperature': 0}),\n",
        "    prompt=prompt\n",
        "  )"
      ],
      "metadata": {
        "id": "pPmBiUntEKf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(\"flower\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vjwES_yREe_M",
        "outputId": "8643c442-3982-40ad-8e72-7c3fcdb6073c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'lilies'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading Models Locally"
      ],
      "metadata": {
        "id": "9VtpZ9UlMPlr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFacePipeline\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModelForSeq2SeqLM"
      ],
      "metadata": {
        "id": "w3vYjqsqMUlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id=\"google/flan-t5-large\""
      ],
      "metadata": {
        "id": "2DybuFhXH0Uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ],
      "metadata": {
        "id": "k6NeqlrYMohf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_id, device_map=\"auto\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "31ab97db73884279b802cb28597f854c",
            "83ea4eee162148dea469ec22b6d1b275",
            "71354a94885f4bc0816fba8c827373bd",
            "90762208daa542f3935dbe2549e90f43",
            "2cf0fe806ec74d4ca38f71e237d7af8c",
            "a724b525e98840cd929e54a2fc3110ba",
            "5f360f5280bf43e68376ed445a07b067",
            "f761f1c1c4bb451ba9d318261cc33972",
            "af2b9d318404498881e4bbfe0bc03255",
            "2fc3724136a94b84a9c343160e965867",
            "e4ce9cc0e8d046138ddbc983220e3caf",
            "e6e090223748466d900c662e6d060c54",
            "6da618803553499b966c312dc1491989",
            "ea1d91b9a9584cdb922a5e0971cc08a0",
            "334783b8076e49c0a81c415edbe778f1",
            "37c511f431f74754bf6058a0dd3f2b2b",
            "c4aa6d6755b94621a1230d18daf22abb",
            "c4503b22420e4317859594ac50db13c4",
            "43fb970ef5624a6698203d167c7d6331",
            "d899640d5f414e06b8eefd9802f90806",
            "3beccb37c1ee4ade92557e5b794179fd",
            "86bfebfe2d0d4476baa19ff64bcd017e",
            "3af5eeaeab4a4d2fa721eb72774835e7",
            "6b34eb9ade264304823a5abf4a57ce87",
            "2628ef1c25864a3f9aac2411ecac840c",
            "b73289dc59d4419984670acc900eac59",
            "91df9796cd7a4a67829ec2fa3232ccec",
            "cde5b28a46d845a491de5a021f736265",
            "61446619d4e14a5d888b14d741c21692",
            "0523ac8d13cf4140a70ab3cb6bc458da",
            "df1ef81a0eb84a76bd042f77a40977c0",
            "6ec03853ac8b42228896c35a775f3b6f",
            "cc5d6dde52414ba18e89e8f2a519495b"
          ]
        },
        "id": "-AachrPDMtYP",
        "outputId": "0f273dbb-aa12-4e14-ddff-c545d92da6d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31ab97db73884279b802cb28597f854c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.13G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6e090223748466d900c662e6d060c54"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3af5eeaeab4a4d2fa721eb72774835e7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pline = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, max_length=128)"
      ],
      "metadata": {
        "id": "gFUDZxcEMznE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "local_llm = HuggingFacePipeline(pipeline=pline)"
      ],
      "metadata": {
        "id": "LbxVjo8ONB-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"item\"],\n",
        "    template=\"Tell me about {item}\"\n",
        ")"
      ],
      "metadata": {
        "id": "8nO8RwC_FIgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(llm=local_llm, prompt=prompt)"
      ],
      "metadata": {
        "id": "fkn-Y40PNSng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain(\"Sun\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwgUyZlVNoJs",
        "outputId": "c1fdda49-7d3a-4205-e716-5141e08ef5a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'item': 'Sun',\n",
              " 'text': 'Sun is a constellation in the constellation of Aries.'}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Llama"
      ],
      "metadata": {
        "id": "cIbus3vrIFjB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Llama CPP Python"
      ],
      "metadata": {
        "id": "KwSz42p_TGN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!CMAKE_ARGS=\"-DLLAMA_CUDA=on\" pip install llama-cpp-python"
      ],
      "metadata": {
        "id": "hsojIcPp-94X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'TheBloke/Llama-2-13B-chat-GGUF'\n",
        "model_basename= 'llama-2-13b-chat.Q5_K_M.gguf'"
      ],
      "metadata": {
        "id": "nBgnCtnUA6Mu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "from llama_cpp import Llama"
      ],
      "metadata": {
        "id": "lRY2ijJsB0p9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = hf_hub_download(\n",
        "    repo_id=model_name,\n",
        "    filename=model_basename\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "9475298cfa58414d9e8b61133ff6a7ef",
            "0a39a243aa03429bbbddb3d33554fb14",
            "47ef6b493cf6414396992e6489b57dfe",
            "5c3e900e036147819899cfb31a4b3b8b",
            "88c5af1d05bb4befb65ce9941a060f5c",
            "4aba50bc42fe4b3b88f2ca9c1b95f012",
            "de673b9799c94d588436403033cf0a06",
            "22a369b084f146618a174c5e54bd2061",
            "8f2c6df2a5a84cd9b982987a3700d29d",
            "c2ea3f101e4b4d519761357c3c43255c",
            "a55734deae1b43f7887d9ef536a169f3"
          ]
        },
        "id": "iB3eSu-WB6D3",
        "outputId": "a4ce49a8-689a-4207-f145-77b897020508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "llama-2-13b-chat.Q5_K_M.gguf:   0%|          | 0.00/9.23G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9475298cfa58414d9e8b61133ff6a7ef"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "HMiYUvU2CEnx",
        "outputId": "8dbc2252-44b2-49ee-8619-5ad65f11e9a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGUF/snapshots/4458acc949de0a9914c3eab623904d4fe999050a/llama-2-13b-chat.Q5_K_M.gguf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLuKNbgoC8Bz",
        "outputId": "3c6fa03f-2a8c-4337-8ea8-70a28602433b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Apr  5 03:00:23 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU\n",
        "lcpp_llm = Llama(\n",
        "    model_path=model_path,\n",
        "    n_threads=2, # CPU Cores\n",
        "    n_batch=1024, # Should be between 1 and n_ctx, consider the amount of VRAM in GPU\n",
        "    n_gpu_layers=-1 # Change this value based on your model and your GPU VRAM pool\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iF-MaNMTCgbf",
        "outputId": "a8689234-3db1-4c8f-83b3-97a22f72af31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 19 key-value pairs and 363 tensors from /root/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGUF/snapshots/4458acc949de0a9914c3eab623904d4fe999050a/llama-2-13b-chat.Q5_K_M.gguf (version GGUF V2)\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 5120\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 40\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 13824\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 40\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 40\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 17\n",
            "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   81 tensors\n",
            "llama_model_loader: - type q5_K:  241 tensors\n",
            "llama_model_loader: - type q6_K:   41 tensors\n",
            "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
            "llm_load_print_meta: format           = GGUF V2\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 4096\n",
            "llm_load_print_meta: n_embd           = 5120\n",
            "llm_load_print_meta: n_head           = 40\n",
            "llm_load_print_meta: n_head_kv        = 40\n",
            "llm_load_print_meta: n_layer          = 40\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: n_embd_k_gqa     = 5120\n",
            "llm_load_print_meta: n_embd_v_gqa     = 5120\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 13824\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 13B\n",
            "llm_load_print_meta: model ftype      = Q5_K - Medium\n",
            "llm_load_print_meta: model params     = 13.02 B\n",
            "llm_load_print_meta: model size       = 8.60 GiB (5.67 BPW) \n",
            "llm_load_print_meta: general.name     = LLaMA v2\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.28 MiB\n",
            "llm_load_tensors: offloading 40 repeating layers to GPU\n",
            "llm_load_tensors: offloading non-repeating layers to GPU\n",
            "llm_load_tensors: offloaded 41/41 layers to GPU\n",
            "llm_load_tensors:        CPU buffer size =   107.42 MiB\n",
            "llm_load_tensors:      CUDA0 buffer size =  8694.21 MiB\n",
            "....................................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 512\n",
            "llama_new_context_with_model: n_batch    = 512\n",
            "llama_new_context_with_model: n_ubatch   = 512\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:      CUDA0 KV buffer size =   400.00 MiB\n",
            "llama_new_context_with_model: KV self size  =  400.00 MiB, K (f16):  200.00 MiB, V (f16):  200.00 MiB\n",
            "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.12 MiB\n",
            "llama_new_context_with_model:      CUDA0 compute buffer size =    85.00 MiB\n",
            "llama_new_context_with_model:  CUDA_Host compute buffer size =    11.01 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1286\n",
            "llama_new_context_with_model: graph splits = 2\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n",
            "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '5120', 'llama.feed_forward_length': '13824', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '40', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '40', 'llama.attention.head_count_kv': '40', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '17'}\n",
            "Using fallback chat format: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"Write a linear regression code\"\n",
        "prompt_template=f'''SYSTEM: You are a helpful assistant.\n",
        "\n",
        "USER: {prompt}\n",
        "\n",
        "ASSISTANT:\n",
        "'''\n",
        "\n",
        "print(prompt_template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IMZwZY_Duzu",
        "outputId": "64cc22dd-22bc-4b51-bd85-7bf1412f717d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SYSTEM: You are a helpful assistant.\n",
            "\n",
            "USER: Write a linear regression code\n",
            "\n",
            "ASSISTANT:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = lcpp_llm(\n",
        "    prompt=prompt_template,\n",
        "    max_tokens=256,\n",
        "    temperature=0.5,\n",
        "    top_p=0.95,\n",
        "    repeat_penalty=1.2,\n",
        "    top_k=150,\n",
        "    echo=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rZkQQw5GsbV",
        "outputId": "5207fcb6-2401-418a-c406-d705d2e076fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     892.48 ms\n",
            "llama_print_timings:      sample time =     156.96 ms /   256 runs   (    0.61 ms per token,  1631.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =     892.37 ms /    27 tokens (   33.05 ms per token,    30.26 tokens per second)\n",
            "llama_print_timings:        eval time =   12067.04 ms /   255 runs   (   47.32 ms per token,    21.13 tokens per second)\n",
            "llama_print_timings:       total time =   13926.02 ms /   282 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9YkQavvG5aO",
        "outputId": "20b84e61-55f6-42ab-c1cb-19a56d0c8a58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 'cmpl-2d9e8f48-31fa-40b8-8071-68055287c39b',\n",
              " 'object': 'text_completion',\n",
              " 'created': 1712286064,\n",
              " 'model': '/root/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGUF/snapshots/4458acc949de0a9914c3eab623904d4fe999050a/llama-2-13b-chat.Q5_K_M.gguf',\n",
              " 'choices': [{'text': 'SYSTEM: You are a helpful assistant.\\n\\nUSER: Write a linear regression code\\n\\nASSISTANT:\\n\\nHere is an example of how you could write a linear regression code in Python using scikit-learn library:\\n```\\nimport pandas as pd\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn.model_selection import train_test_split\\n\\n# Load the data\\ndf = pd.read_csv(\\'data.csv\\')\\n\\n# Split the data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(df.drop(\\'target\\', axis=1), df[\\'target\\'], test_size=0.2)\\n\\n# Create a linear regression object and fit it to the training data\\nreg = LinearRegression()\\nreg.fit(X_train, y_train)\\n\\n# Make predictions on the testing data\\ny_pred = reg.predict(X_test)\\n\\n# Evaluate the model using mean squared error\\nmse = ((y_test - y_pred) ** 2).mean()\\nprint(\\'Mean squared error:\\', mse)\\n```\\nThis code assumes that you have a CSV file called \"data.csv\" containing the data, with',\n",
              "   'index': 0,\n",
              "   'logprobs': None,\n",
              "   'finish_reason': 'length'}],\n",
              " 'usage': {'prompt_tokens': 27, 'completion_tokens': 256, 'total_tokens': 283}}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response['choices'][0]['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDDoW_myJkIq",
        "outputId": "83fe3e0a-dc83-40c1-9495-4a982eda880b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SYSTEM: You are a helpful assistant.\n",
            "\n",
            "USER: Write a linear regression code\n",
            "\n",
            "ASSISTANT:\n",
            "\n",
            "Here is an example of how you could write a linear regression code in Python using scikit-learn library:\n",
            "```\n",
            "import pandas as pd\n",
            "from sklearn.linear_model import LinearRegression\n",
            "from sklearn.model_selection import train_test_split\n",
            "\n",
            "# Load the data\n",
            "df = pd.read_csv('data.csv')\n",
            "\n",
            "# Split the data into training and testing sets\n",
            "X_train, X_test, y_train, y_test = train_test_split(df.drop('target', axis=1), df['target'], test_size=0.2)\n",
            "\n",
            "# Create a linear regression object and fit it to the training data\n",
            "reg = LinearRegression()\n",
            "reg.fit(X_train, y_train)\n",
            "\n",
            "# Make predictions on the testing data\n",
            "y_pred = reg.predict(X_test)\n",
            "\n",
            "# Evaluate the model using mean squared error\n",
            "mse = ((y_test - y_pred) ** 2).mean()\n",
            "print('Mean squared error:', mse)\n",
            "```\n",
            "This code assumes that you have a CSV file called \"data.csv\" containing the data, with\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Llama with Langchain"
      ],
      "metadata": {
        "id": "U_LQmLSHMnoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers einops accelerate langchain bitsandbytes"
      ],
      "metadata": {
        "id": "XUD4jbMrMqHs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41ca29d7-c448-4e7f-b818-6330c4d79a9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.2/121.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkJEulaVNSRZ",
        "outputId": "ccdd89ce-605e-4ba2-d5ff-4b443b25146e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFacePipeline\n",
        "from transformers import AutoTokenizer\n",
        "import transformers\n",
        "import torch"
      ],
      "metadata": {
        "id": "fR9cmUEwNUiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=\"meta-llama/Llama-2-7b-hf\""
      ],
      "metadata": {
        "id": "UqGr6-rhN8FN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=AutoTokenizer.from_pretrained(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269,
          "referenced_widgets": [
            "7ad01cefe6094addb48c31ec17b3ff9b",
            "0c89fc33db374be9b2d2ae5c28aa27ab",
            "19554aacc62c432b84fc8826bf03187b",
            "fd5d4e2d81c1498193022318ce5eb2ad",
            "c98ee2458ff84e2db4c7952f6be68455",
            "bd0d1aab4bb54cb9b69db39dfd6471df",
            "a95ebb492d5442df811c5090ae3f9ad5",
            "03da0c1ec63d40edbe18b1f6a8e6268e",
            "904de62e67e74a6285cde9dd843ee13f",
            "717ef9f7b6884bc0932b369425851426",
            "af841b98084c45539b404f6beae732fe",
            "3377bc33e1a74fd8a75fe212e5fa16ac",
            "22a7e96256a1485ca9bca831a6c72c37",
            "57e4ece7aa8942a98433c148cd94d579",
            "5d52463878e34fd99cc17a1ba384477d",
            "88fcb3d99fc141d3a7a92eee63af5835",
            "fe9331421ec643348497a5ef32928d89",
            "72be241a59eb47cfa3101474f95d0c80",
            "61f2312c79034af0bf2a08e4ac454bb3",
            "624127ce96b247f7b04521ec451f3539",
            "b17b42fd7c7a42deb3903bdea7cb391c",
            "468adb776f2d4709b368dbde66936386",
            "be14f06bde77434b92f72225d60fc137",
            "bdbf831e1f2e40478d753537305b370c",
            "72c4c6ac886a48f2bbadbaf627048752",
            "9c02f8870d6242ec8bdada2eb8e2cf37",
            "9ec1bc80cebd4f7db342b4a9c215a24e",
            "3f9b65405fa945328fe59f50f7f77c20",
            "a59aa85c87aa4fa49b4258fb69769f3b",
            "830a032c4dfd49b8b9088b882638a662",
            "8bfa5b3c42fb484b8d7d4f439732ad65",
            "dc5eeb809f3041708ef25f722e74c00d",
            "fd17baf92ed1493fa8a3f83e5ba95544",
            "b17e94c3af2346d88e2dbbc97e3a1eaa",
            "e3bd9b7f37fe42699e738ec8063d1fc3",
            "a605f69557d446009475194b62ae2060",
            "e51e5c46d14a4ffe872b9f28dc3d80d9",
            "7374f710a79b4f6ca1bff5340d8bc238",
            "d750cacc912b4f368ac87b81ccda4be1",
            "7287e6edce384b97974cab51adbe6a04",
            "1c067d3cc8d941d4bb74f957504fbd1d",
            "31f37a37192944cfa9fb88015f04c09f",
            "9fd681a9e62944488fbaf368045a24a7",
            "c5324dc3d6ea4b08bacc65930062bcd8"
          ]
        },
        "id": "InK-cdDjOH1P",
        "outputId": "f36ada80-65e5-44d2-ffd2-4afb7bc8a556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ad01cefe6094addb48c31ec17b3ff9b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3377bc33e1a74fd8a75fe212e5fa16ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be14f06bde77434b92f72225d60fc137"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b17e94c3af2346d88e2dbbc97e3a1eaa"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline=transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    trust_remote_code=True,\n",
        "    device_map=\"auto\",\n",
        "    max_length=1000,\n",
        "    do_sample=True,\n",
        "    top_k=10,\n",
        "    num_return_sequences=1,\n",
        "    eos_token_id=tokenizer.eos_token_id\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "d7f74c8ab34648418fef2eba5d0de7ff",
            "bdbe190d3d4f41fba500c1ef4bd4d0dc",
            "7ab6020d76374911a6f9c70bd1447d8b",
            "210bbffb8c474b039492d7d6205ffe40",
            "0120a802a7a84634854f3054d33c9c42",
            "68cab4488533469b9706921df559f640",
            "c2a222f270494b5daaacc3d2045a79bb",
            "d47eec8533634439928e4a61de211144",
            "a55db660d9fd4e6c89f23c9fab5dbba6",
            "535cdc3ba82b460f9708ba6327b1d9ae",
            "5678dc6dc8bd4dde88e0b32d97cec6f1",
            "14f1deeee7a843278c9e872b78d738e7",
            "1d7f129de6cd4e7d8fa67ffbdea352f2",
            "c438d273aa564adead144a56111fc9a3",
            "5c45b5a9c6c942ee971211083f5d6511",
            "51ca40a393544a77a2674ac5fd351a38",
            "c7280e66f62e49f580d9fcbafbe4b964",
            "e9b0f02f314747b68472090393b1507d",
            "bb605b7078ab479992160717cf9e9323",
            "5e152a129d4b40d59a5d4ba30a37e2f2",
            "50b5c0a165934831918592a84e154dd5",
            "64c1218247464d98a4cd08fdfac5bae9",
            "096d9321a7a340cd8c38e93be3c9cc0e",
            "eb5fda1fb0654542ba9fa8fe4517c97b",
            "c61f881a333144f7accf2bbaf4ffee51",
            "cc3ee1371d36482d9775448ce9cd184f",
            "e41918b59b8c4e56bc38ef10af37125c",
            "1557836a3ead474897b155897b268192",
            "4464b318cc1243d69b9b9628b5064064",
            "31d5af25471e49dbad950123ac4c6df8",
            "a9f8531e55d844fb810e19b030083733",
            "7e3d161f1de144a7a27344bdf9ca5f76",
            "827502d848fa458784b831e9d6e8793f",
            "a0af7243c07340269e0b71ca3583047e",
            "be528ffd28614b248d72cf26f52bb71e",
            "a953545824f448af8432897cec3968fa",
            "cbef3319bfaa4a73a747d56b3ad0fd49",
            "571bc7dfb9c14d538063524e8fcf6b7e",
            "228549e6c8664f62b007035729b4fa64",
            "2686798d57e74c67a565255fed662ecd",
            "8d37b750dd714711b806e67a1268474a",
            "4b1e6bc0b85746bb8a192e628ddf717e",
            "279c2f82c21742c4aea1b8a6aa87bd58",
            "e6ebdc428ab8467eb8e8859f03ef5257",
            "8fd63e3624544ec68f6b7cfe4c15ec24",
            "6c4b4078471f42fab8dbd10bf750bcac",
            "bd0518b12a62452f9a8c610583f72fc1",
            "fac2bb8899b046f2a34c8623cdf75ead",
            "7322d152aa3043d4bc9891643dc9ac02",
            "b1a8ed9d8c5b433bb7981d9042482f60",
            "8ee27a186c894b78bd2c3d5c321500be",
            "3253761249b34778aca53557e4dcd4f1",
            "0a92844dbd3843eb824de0635fa8bc45",
            "f70e78a6f2364a2ca6e9f2b432b37872",
            "cfe22643342147eda07789413d78de99",
            "55c257592607455ebfd649c4e03421fa",
            "95e4836fa4d74b51ba4c0ab8fb48f434",
            "1ea2cb9c6dc641f2b8a34810325520da",
            "36cff9ecbffb4fc481f959eaf842e49f",
            "60315265a33845289585f51d3c1bf774",
            "3fa6b1f83bc84697aac4a2f121769762",
            "d7b9e092a2024bfbac870383b392ea62",
            "254eb8994b51406cb5a3d848841be189",
            "bc1254165fa74e178c1dc13e6dac6199",
            "36a64993d2464c15bfc9876ef42ed0ef",
            "02a372d8f39e4f35a309b3d053b90d00",
            "66c650b6e1cb4111aca156f1b5d0954d",
            "b53d4fb423fa4c2da894cd0763a5a3a4",
            "a901b0a8d50d459699b8a88909654c2d",
            "e5b01842a3a54a1e8407d0ad33340d59",
            "2c9307e3231e49818c6ce27b07f0a3bb",
            "7dc8784fc30a47bcbb7ba7d099c20ec8",
            "08e7f300f4fe4dcba6e18f155055523b",
            "cb82bbe8020045948e0f15c2c70c1662",
            "5825facf48cf407faa6d68a1bc3fb41f",
            "6f805abc759a4a388a2ec7a847223aa5",
            "aba8bc42b5034beda172178bbf863f24"
          ]
        },
        "id": "EC-JRg2oPfI3",
        "outputId": "b3004abf-2d6c-4556-c829-ff7eeca6bbe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/609 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7f74c8ab34648418fef2eba5d0de7ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "14f1deeee7a843278c9e872b78d738e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "096d9321a7a340cd8c38e93be3c9cc0e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a0af7243c07340269e0b71ca3583047e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8fd63e3624544ec68f6b7cfe4c15ec24"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "55c257592607455ebfd649c4e03421fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66c650b6e1cb4111aca156f1b5d0954d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This LLM can be used with all other langchain functions\n",
        "llm=HuggingFacePipeline(pipeline=pipeline, model_kwargs={'temperature':0})"
      ],
      "metadata": {
        "id": "iGc9dOTURF48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"What is a good name for a tech company\""
      ],
      "metadata": {
        "id": "eHUZr0NERPPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm.invoke(prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZOJYmQyRTr4",
        "outputId": "f7849692-8660-4022-bd50-e538914dc09e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is a good name for a tech company?\n",
            "What is a good name for a tech company?\n",
            "What is the most successful tech company?\n",
            "What is the most successful tech company in the world?\n",
            "What are the top 10 tech companies?\n",
            "What is the best tech company to work for?\n",
            "What is the best tech company to work for?\n",
            "What is the best tech company in the world?\n",
            "What is the most successful company in the world?\n",
            "What is the most successful company in the world?\n",
            "What is the best company in the world?\n",
            "What is the best tech company to work for?\n",
            "What is the best tech company to work for?\n",
            "What is the best tech company to work for?\n",
            "What is the best tech company to work for?\n",
            "What is the best tech company to work for?\n",
            "What is the best tech company to work for?What is the best tech company to work for?\n",
            "What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work for?What is the best tech company to work\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LangGraph\n",
        "\n",
        "Official examples: https://github.com/langchain-ai/langgraph/tree/main/examples"
      ],
      "metadata": {
        "id": "e7WbSwZe0sd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U langchain langchainhub langchain_openai openai tavily-python langgraph  langsmith langchain_experimental"
      ],
      "metadata": {
        "id": "nuTPbCTP3Pev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agent Executor"
      ],
      "metadata": {
        "id": "NcVLSks00vwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n",
        "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Tavily API Key:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfbSqFTw3IfO",
        "outputId": "c4744123-c246-4187-9129-5eb8e2489086"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key:··········\n",
            "Tavily API Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create the LangChain agent**"
      ],
      "metadata": {
        "id": "nvSnxiFc4ZDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "from langchain.agents import create_openai_functions_agent\n",
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "tools = [TavilySearchResults(max_results=1)]\n",
        "\n",
        "# Get the prompt to use\n",
        "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
        "\n",
        "# Choose the LLM that will drive the agent\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", streaming=True)\n",
        "\n",
        "# Construct the OpenAI Functions agent\n",
        "agent_runnable = create_openai_functions_agent(llm, tools, prompt)"
      ],
      "metadata": {
        "id": "JerFKlwo4JfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the graph sta**te\n",
        "\n",
        "We now define the graph state. The state for the traditional LangChain agent has a few attributes:\n",
        "\n",
        "1. **input**: This is the input string representing the main ask from the user, passed in as input.\n",
        "2. **chat_history**: This is any previous conversation messages, also passed in as input.\n",
        "3. **intermediate_steps**: This is list of actions and corresponding observations that the agent takes over time. This is updated each iteration of the agent.\n",
        "4. **agent_outcome**: This is the response from the agent, either an AgentAction or AgentFinish. The AgentExecutor should finish when this is an AgentFinish, otherwise it should call the requested tools."
      ],
      "metadata": {
        "id": "0Lg-rkVE5U86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, Annotated, List, Union\n",
        "from langchain_core.agents import AgentAction, AgentFinish\n",
        "from langchain_core.messages import BaseMessage\n",
        "import operator\n",
        "\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    # The input string\n",
        "    input: str\n",
        "    # The list of previous messages in the conversation\n",
        "    chat_history: list[BaseMessage]\n",
        "    # The outcome of a given call to the agent\n",
        "    # Needs `None` as a valid type, since this is what this will start as\n",
        "    agent_outcome: Union[AgentAction, AgentFinish, None]\n",
        "    # List of actions and corresponding observations\n",
        "    # Here we annotate this with `operator.add` to indicate that operations to\n",
        "    # this state should be ADDED to the existing values (not overwrite it)\n",
        "    intermediate_steps: Annotated[list[tuple[AgentAction, str]], operator.add]"
      ],
      "metadata": {
        "id": "iq6xYbJk55aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the nodes**\n",
        "\n",
        "We now need to define a few different nodes in our graph. In langgraph, a node can be either a function or a runnable. There are two main nodes we need for this:\n",
        "\n",
        "1. The agent: responsible for deciding what (if any) actions to take.\n",
        "2. A function to invoke tools: if the agent decides to take an action, this node will then execute that action.\n",
        "\n",
        "\n",
        "We will also need to define some edges. Some of these edges may be conditional. The reason they are conditional is that based on the output of a node, one of several paths may be taken. The path that is taken is not known until that node is run (the LLM decides).\n",
        "\n",
        "1. Conditional Edge: after the agent is called, we should either: a. If the agent said to take an action, then the function to invoke tools should be called b. If the agent said that it was finished, then it should finish\n",
        "2. Normal Edge: after the tools are invoked, it should always go back to the agent to decide what to do next\n",
        "\n",
        "\n",
        "Let's define the nodes, as well as a function to decide how what conditional edge to take."
      ],
      "metadata": {
        "id": "Cuyl0cg256K9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.agents import AgentFinish\n",
        "from langgraph.prebuilt.tool_executor import ToolExecutor\n",
        "\n",
        "# This a helper class we have that is useful for running tools\n",
        "# It takes in an agent action and calls that tool and returns the result\n",
        "tool_executor = ToolExecutor(tools)\n",
        "\n",
        "\n",
        "# Define the agent\n",
        "def run_agent(data):\n",
        "    agent_outcome = agent_runnable.invoke(data)\n",
        "    return {\"agent_outcome\": agent_outcome}\n",
        "\n",
        "\n",
        "# Define the function to execute tools\n",
        "def execute_tools(data):\n",
        "    # Get the most recent agent_outcome - this is the key added in the `agent` above\n",
        "    agent_action = data[\"agent_outcome\"]\n",
        "    output = tool_executor.invoke(agent_action)\n",
        "    return {\"intermediate_steps\": [(agent_action, str(output))]}\n",
        "\n",
        "\n",
        "# Define logic that will be used to determine which conditional edge to go down\n",
        "def should_continue(data):\n",
        "    # If the agent outcome is an AgentFinish, then we return `exit` string\n",
        "    # This will be used when setting up the graph to define the flow\n",
        "    if isinstance(data[\"agent_outcome\"], AgentFinish):\n",
        "        return \"end\"\n",
        "    # Otherwise, an AgentAction is returned\n",
        "    # Here we return `continue` string\n",
        "    # This will be used when setting up the graph to define the flow\n",
        "    else:\n",
        "        return \"continue\""
      ],
      "metadata": {
        "id": "e6lap60D6NM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the graph**\n",
        "\n",
        "We can now put it all together and define the graph!"
      ],
      "metadata": {
        "id": "haDkVAkp6P8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import END, StateGraph\n",
        "\n",
        "# Define a new graph\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# Define the two nodes we will cycle between\n",
        "workflow.add_node(\"agent\", run_agent)\n",
        "workflow.add_node(\"action\", execute_tools)\n",
        "\n",
        "# Set the entrypoint as `agent`\n",
        "# This means that this node is the first one called\n",
        "workflow.set_entry_point(\"agent\")\n",
        "\n",
        "# We now add a conditional edge\n",
        "workflow.add_conditional_edges(\n",
        "    # First, we define the start node. We use `agent`.\n",
        "    # This means these are the edges taken after the `agent` node is called.\n",
        "    \"agent\",\n",
        "    # Next, we pass in the function that will determine which node is called next.\n",
        "    should_continue,\n",
        "    # Finally we pass in a mapping.\n",
        "    # The keys are strings, and the values are other nodes.\n",
        "    # END is a special node marking that the graph should finish.\n",
        "    # What will happen is we will call `should_continue`, and then the output of that\n",
        "    # will be matched against the keys in this mapping.\n",
        "    # Based on which one it matches, that node will then be called.\n",
        "    {\n",
        "        # If `tools`, then we call the tool node.\n",
        "        \"continue\": \"action\",\n",
        "        # Otherwise we finish.\n",
        "        \"end\": END,\n",
        "    },\n",
        ")\n",
        "\n",
        "# We now add a normal edge from `tools` to `agent`.\n",
        "# This means that after `tools` is called, `agent` node is called next.\n",
        "workflow.add_edge(\"action\", \"agent\")\n",
        "\n",
        "# Finally, we compile it!\n",
        "# This compiles it into a LangChain Runnable,\n",
        "# meaning you can use it as you would any other runnable\n",
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "YzPwe3av6Pww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\"input\": \"what is the weather in sf\", \"chat_history\": []}\n",
        "for s in app.stream(inputs):\n",
        "    print(list(s.values())[0])\n",
        "    print(\"----\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8iC-63R6VbW",
        "outputId": "d4b719ae-1b4b-4122-e31f-635c183c70c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'agent_outcome': AgentActionMessageLog(tool='tavily_search_results_json', tool_input={'query': 'weather in San Francisco'}, log=\"\\nInvoking: `tavily_search_results_json` with `{'query': 'weather in San Francisco'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"weather in San Francisco\"}', 'name': 'tavily_search_results_json'}}, response_metadata={'finish_reason': 'function_call'}, id='run-9517941b-08d3-47c1-894d-8945838ac958-0')])}\n",
            "----\n",
            "{'intermediate_steps': [(AgentActionMessageLog(tool='tavily_search_results_json', tool_input={'query': 'weather in San Francisco'}, log=\"\\nInvoking: `tavily_search_results_json` with `{'query': 'weather in San Francisco'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"weather in San Francisco\"}', 'name': 'tavily_search_results_json'}}, response_metadata={'finish_reason': 'function_call'}, id='run-9517941b-08d3-47c1-894d-8945838ac958-0')]), '[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.78, \\'lon\\': -122.42, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1714682434, \\'localtime\\': \\'2024-05-02 13:40\\'}, \\'current\\': {\\'last_updated_epoch\\': 1714681800, \\'last_updated\\': \\'2024-05-02 13:30\\', \\'temp_c\\': 18.3, \\'temp_f\\': 64.9, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Partly cloudy\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/116.png\\', \\'code\\': 1003}, \\'wind_mph\\': 20.6, \\'wind_kph\\': 33.1, \\'wind_degree\\': 270, \\'wind_dir\\': \\'W\\', \\'pressure_mb\\': 1017.0, \\'pressure_in\\': 30.02, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 61, \\'cloud\\': 25, \\'feelslike_c\\': 18.3, \\'feelslike_f\\': 64.9, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 5.0, \\'gust_mph\\': 25.1, \\'gust_kph\\': 40.3}}\"}]')]}\n",
            "----\n",
            "{'agent_outcome': AgentFinish(return_values={'output': 'The current weather in San Francisco is 64.9°F (18.3°C) with partly cloudy conditions. The wind speed is 33.1 kph coming from the west, and the humidity is at 61%.'}, log='The current weather in San Francisco is 64.9°F (18.3°C) with partly cloudy conditions. The wind speed is 33.1 kph coming from the west, and the humidity is at 61%.')}\n",
            "----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chat Agent Executor"
      ],
      "metadata": {
        "id": "ZVSc3odHCyAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangSmith API Key:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEaz3FuMC8Oc",
        "outputId": "ac391a28-59ff-4cd0-eefb-c0d3957faaed"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LangSmith API Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "tools = [TavilySearchResults(max_results=1)]"
      ],
      "metadata": {
        "id": "kMtaqT9AD0i4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import ToolExecutor\n",
        "\n",
        "tool_executor = ToolExecutor(tools)"
      ],
      "metadata": {
        "id": "iD_wgTXsD25i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Set up the model**\n",
        "\n",
        "Now we need to load the chat model we want to use. Importantly, this should satisfy two criteria:\n",
        "\n",
        "1. It should work with messages. We will represent all agent state in the form of messages, so it needs to be able to work well with them.\n",
        "2. It should work with OpenAI function calling. This means it should either be an OpenAI model or a model that exposes a similar interface.\n",
        "\n",
        "Note: these model requirements are not requirements for using LangGraph - they are just requirements for this one example."
      ],
      "metadata": {
        "id": "Zpn0UwVFD53h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# We will set streaming=True so that we can stream tokens\n",
        "# See the streaming section for more information on this.\n",
        "model = ChatOpenAI(temperature=0, streaming=True)"
      ],
      "metadata": {
        "id": "QFpHy3Q2D6H5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.utils.function_calling import convert_to_openai_function\n",
        "\n",
        "functions = [convert_to_openai_function(t) for t in tools]\n",
        "model = model.bind_functions(functions)"
      ],
      "metadata": {
        "id": "HpwN-8aiEHg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the agent state**\n",
        "\n",
        "The main type of graph in langgraph is the StatefulGraph. This graph is parameterized by a state object that it passes around to each node. Each node then returns operations to update that state. These operations can either SET specific attributes on the state (e.g. overwrite the existing values) or ADD to the existing attribute. Whether to set or add is denoted by annotating the state object you construct the graph with.\n",
        "\n",
        "For this example, the state we will track will just be a list of messages. We want each node to just add messages to that list. Therefore, we will use a TypedDict with one key (messages) and annotate it so that the messages attribute is always added to."
      ],
      "metadata": {
        "id": "qCgwewJwFEPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, Annotated, Sequence\n",
        "import operator\n",
        "from langchain_core.messages import BaseMessage\n",
        "\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[Sequence[BaseMessage], operator.add]"
      ],
      "metadata": {
        "id": "2w9C60ikEa8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the nodes**\n",
        "\n",
        "We now need to define a few different nodes in our graph. In langgraph, a node can be either a function or a runnable. There are two main nodes we need for this:\n",
        "\n",
        "1. The agent: responsible for deciding what (if any) actions to take.\n",
        "2. A function to invoke tools: if the agent decides to take an action, this node will then execute that action.\n",
        "\n",
        "\n",
        "We will also need to define some edges. Some of these edges may be conditional. The reason they are conditional is that based on the output of a node, one of several paths may be taken. The path that is taken is not known until that node is run (the LLM decides).\n",
        "\n",
        "1. Conditional Edge: after the agent is called, we should either: a. If the agent said to take an action, then the function to invoke tools should be called b. If the agent said that it was finished, then it should finish\n",
        "2. Normal Edge: after the tools are invoked, it should always go back to the agent to decide what to do next\n",
        "\n",
        "Let's define the nodes, as well as a function to decide how what conditional edge to take."
      ],
      "metadata": {
        "id": "S9ZmW8UgFGn6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import ToolInvocation\n",
        "import json\n",
        "from langchain_core.messages import FunctionMessage\n",
        "\n",
        "\n",
        "# Define the function that determines whether to continue or not\n",
        "def should_continue(state):\n",
        "    messages = state[\"messages\"]\n",
        "    last_message = messages[-1]\n",
        "    # If there is no function call, then we finish\n",
        "    if \"function_call\" not in last_message.additional_kwargs:\n",
        "        return \"end\"\n",
        "    # Otherwise if there is, we continue\n",
        "    else:\n",
        "        return \"continue\"\n",
        "\n",
        "\n",
        "# Define the function that calls the model\n",
        "def call_model(state):\n",
        "    messages = state[\"messages\"]\n",
        "    response = model.invoke(messages)\n",
        "    # We return a list, because this will get added to the existing list\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "\n",
        "# Define the function to execute tools\n",
        "def call_tool(state):\n",
        "    messages = state[\"messages\"]\n",
        "    # Based on the continue condition\n",
        "    # we know the last message involves a function call\n",
        "    last_message = messages[-1]\n",
        "    # We construct an ToolInvocation from the function_call\n",
        "    action = ToolInvocation(\n",
        "        tool=last_message.additional_kwargs[\"function_call\"][\"name\"],\n",
        "        tool_input=json.loads(\n",
        "            last_message.additional_kwargs[\"function_call\"][\"arguments\"]\n",
        "        ),\n",
        "    )\n",
        "    # We call the tool_executor and get back a response\n",
        "    response = tool_executor.invoke(action)\n",
        "    # We use the response to create a FunctionMessage\n",
        "    function_message = FunctionMessage(content=str(response), name=action.tool)\n",
        "    # We return a list, because this will get added to the existing list\n",
        "    return {\"messages\": [function_message]}"
      ],
      "metadata": {
        "id": "mjICdqofFGSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the graph**\n",
        "We can now put it all together and define the graph!"
      ],
      "metadata": {
        "id": "f6hg057dFG8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# Define a new graph\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# Define the two nodes we will cycle between\n",
        "workflow.add_node(\"agent\", call_model)\n",
        "workflow.add_node(\"action\", call_tool)\n",
        "\n",
        "# Set the entrypoint as `agent`\n",
        "# This means that this node is the first one called\n",
        "workflow.set_entry_point(\"agent\")\n",
        "\n",
        "# We now add a conditional edge\n",
        "workflow.add_conditional_edges(\n",
        "    # First, we define the start node. We use `agent`.\n",
        "    # This means these are the edges taken after the `agent` node is called.\n",
        "    \"agent\",\n",
        "    # Next, we pass in the function that will determine which node is called next.\n",
        "    should_continue,\n",
        "    # Finally we pass in a mapping.\n",
        "    # The keys are strings, and the values are other nodes.\n",
        "    # END is a special node marking that the graph should finish.\n",
        "    # What will happen is we will call `should_continue`, and then the output of that\n",
        "    # will be matched against the keys in this mapping.\n",
        "    # Based on which one it matches, that node will then be called.\n",
        "    {\n",
        "        # If `tools`, then we call the tool node.\n",
        "        \"continue\": \"action\",\n",
        "        # Otherwise we finish.\n",
        "        \"end\": END,\n",
        "    },\n",
        ")\n",
        "\n",
        "# We now add a normal edge from `tools` to `agent`.\n",
        "# This means that after `tools` is called, `agent` node is called next.\n",
        "workflow.add_edge(\"action\", \"agent\")\n",
        "\n",
        "# Finally, we compile it!\n",
        "# This compiles it into a LangChain Runnable,\n",
        "# meaning you can use it as you would any other runnable\n",
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "5zro-d1jFHN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use it!\n",
        "We can now use it! This now exposes the same interface as all other LangChain runnables."
      ],
      "metadata": {
        "id": "LkUGP2McFHbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "inputs = {\"messages\": [HumanMessage(content=\"what is the weather in sf\")]}\n",
        "app.invoke(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-B6h6OZFH5I",
        "outputId": "9f04d308-d794-4622-e5b0-1cda2fd66820"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='what is the weather in sf'),\n",
              "  AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"weather in San Francisco\"}', 'name': 'tavily_search_results_json'}}, response_metadata={'finish_reason': 'function_call'}, id='run-2d0d7907-d9cc-4136-b447-2803ec05a60a-0'),\n",
              "  FunctionMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.78, \\'lon\\': -122.42, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1714683271, \\'localtime\\': \\'2024-05-02 13:54\\'}, \\'current\\': {\\'last_updated_epoch\\': 1714682700, \\'last_updated\\': \\'2024-05-02 13:45\\', \\'temp_c\\': 18.3, \\'temp_f\\': 64.9, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Partly cloudy\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/116.png\\', \\'code\\': 1003}, \\'wind_mph\\': 20.6, \\'wind_kph\\': 33.1, \\'wind_degree\\': 270, \\'wind_dir\\': \\'W\\', \\'pressure_mb\\': 1017.0, \\'pressure_in\\': 30.02, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 61, \\'cloud\\': 25, \\'feelslike_c\\': 18.3, \\'feelslike_f\\': 64.9, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 5.0, \\'gust_mph\\': 25.1, \\'gust_kph\\': 40.3}}\"}]', name='tavily_search_results_json'),\n",
              "  AIMessage(content='The current weather in San Francisco is partly cloudy with a temperature of 64.9°F (18.3°C). The wind speed is 33.1 kph coming from the west. The humidity is at 61% and the visibility is 16.0 km.', response_metadata={'finish_reason': 'stop'}, id='run-2785fde4-c1c6-4641-93f1-7546a55d75a8-0')]}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Streaming**\n",
        "LangGraph has support for several different types of streaming."
      ],
      "metadata": {
        "id": "kowmp9tqFYEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\"messages\": [HumanMessage(content=\"what is the weather in sf\")]}\n",
        "for output in app.stream(inputs):\n",
        "    # stream() yields dictionaries with output keyed by node name\n",
        "    for key, value in output.items():\n",
        "        print(f\"Output from node '{key}':\")\n",
        "        print(\"---\")\n",
        "        print(value)\n",
        "    print(\"\\n---\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFNBcddKFXpD",
        "outputId": "0b672b64-c030-43ea-b9b6-fd6caa3d60db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output from node 'agent':\n",
            "---\n",
            "{'messages': [AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"weather in San Francisco\"}', 'name': 'tavily_search_results_json'}}, response_metadata={'finish_reason': 'function_call'}, id='run-d221e860-f027-4832-a86f-493517294c50-0')]}\n",
            "\n",
            "---\n",
            "\n",
            "Output from node 'action':\n",
            "---\n",
            "{'messages': [FunctionMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.78, \\'lon\\': -122.42, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1714683271, \\'localtime\\': \\'2024-05-02 13:54\\'}, \\'current\\': {\\'last_updated_epoch\\': 1714682700, \\'last_updated\\': \\'2024-05-02 13:45\\', \\'temp_c\\': 18.3, \\'temp_f\\': 64.9, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Partly cloudy\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/116.png\\', \\'code\\': 1003}, \\'wind_mph\\': 20.6, \\'wind_kph\\': 33.1, \\'wind_degree\\': 270, \\'wind_dir\\': \\'W\\', \\'pressure_mb\\': 1017.0, \\'pressure_in\\': 30.02, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 61, \\'cloud\\': 25, \\'feelslike_c\\': 18.3, \\'feelslike_f\\': 64.9, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 5.0, \\'gust_mph\\': 25.1, \\'gust_kph\\': 40.3}}\"}]', name='tavily_search_results_json')]}\n",
            "\n",
            "---\n",
            "\n",
            "Output from node 'agent':\n",
            "---\n",
            "{'messages': [AIMessage(content='The current weather in San Francisco is partly cloudy with a temperature of 64.9°F (18.3°C). The wind speed is 20.6 mph (33.1 kph) coming from the west. The humidity is at 61% and the visibility is 9.0 miles.', response_metadata={'finish_reason': 'stop'}, id='run-a189b2e8-ba09-44fe-bc08-4442b47a0e97-0')]}\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-Agent Workflows\n"
      ],
      "metadata": {
        "id": "SxZnY3SCO-jU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Basic Multi-agent Collaboration**\n",
        "\n",
        "A single agent can usually operate effectively using a handful of tools within a single domain, but even using powerful models like gpt-4, it can be less effective at using many tools.\n",
        "\n",
        "One way to approach complicated tasks is through a \"divide-and-conquer\" approach: create an specialized agent for each task or domain and route tasks to the correct \"expert\".\n",
        "\n",
        "This notebook (inspired by the paper AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation, by Wu, et. al.) shows one way to do this using LangGraph.\n",
        "\n",
        "The resulting graph will look something like the following diagram:\n",
        "\n",
        "![graph](https://raw.githubusercontent.com/langchain-ai/langgraph/8a38226078383d49f57cd30c0df4203b0ea7cb2d/examples/multi_agent/img/simple_multi_agent_diagram.png)\n",
        "\n"
      ],
      "metadata": {
        "id": "g8aoh_ds8J7g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create Agents**\n",
        "The following helper functions will help create agents. These agents will then be nodes in the graph.\n",
        "\n",
        "You can skip ahead if you just want to see what the graph looks like."
      ],
      "metadata": {
        "id": "bch54l2h8Z8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "from langchain_core.messages import (\n",
        "    AIMessage,\n",
        "    BaseMessage,\n",
        "    ChatMessage,\n",
        "    FunctionMessage,\n",
        "    HumanMessage,\n",
        ")\n",
        "from langchain.tools.render import format_tool_to_openai_function\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langgraph.graph import END, StateGraph\n",
        "from langgraph.prebuilt.tool_executor import ToolExecutor, ToolInvocation\n",
        "\n",
        "\n",
        "def create_agent(llm, tools, system_message: str):\n",
        "    \"\"\"Create an agent.\"\"\"\n",
        "    functions = [format_tool_to_openai_function(t) for t in tools]\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\n",
        "                \"system\",\n",
        "                \"You are a helpful AI assistant, collaborating with other assistants.\"\n",
        "                \" Use the provided tools to progress towards answering the question.\"\n",
        "                \" If you are unable to fully answer, that's OK, another assistant with different tools \"\n",
        "                \" will help where you left off. Execute what you can to make progress.\"\n",
        "                \" If you or any of the other assistants have the final answer or deliverable,\"\n",
        "                \" prefix your response with FINAL ANSWER so the team knows to stop.\"\n",
        "                \" You have access to the following tools: {tool_names}.\\n{system_message}\",\n",
        "            ),\n",
        "            MessagesPlaceholder(variable_name=\"messages\"),\n",
        "        ]\n",
        "    )\n",
        "    prompt = prompt.partial(system_message=system_message)\n",
        "    prompt = prompt.partial(tool_names=\", \".join([tool.name for tool in tools]))\n",
        "    return prompt | llm.bind_functions(functions)"
      ],
      "metadata": {
        "id": "qWK7gnKD8ZKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define tools**\n",
        "We will also define some tools that our agents will use in the future"
      ],
      "metadata": {
        "id": "zUAKhVQD8eiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import tool\n",
        "from typing import Annotated\n",
        "from langchain_experimental.utilities import PythonREPL\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "tavily_tool = TavilySearchResults(max_results=5)\n",
        "\n",
        "# Warning: This executes code locally, which can be unsafe when not sandboxed\n",
        "\n",
        "repl = PythonREPL()\n",
        "\n",
        "\n",
        "@tool\n",
        "def python_repl(\n",
        "    code: Annotated[str, \"The python code to execute to generate your chart.\"]\n",
        "):\n",
        "    \"\"\"Use this to execute python code. If you want to see the output of a value,\n",
        "    you should print it out with `print(...)`. This is visible to the user.\"\"\"\n",
        "    try:\n",
        "        result = repl.run(code)\n",
        "    except BaseException as e:\n",
        "        return f\"Failed to execute. Error: {repr(e)}\"\n",
        "    return f\"Succesfully executed:\\n```python\\n{code}\\n```\\nStdout: {result}\""
      ],
      "metadata": {
        "id": "4A58Hy7M8ZHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create graph**\n",
        "Now that we've defined our tools and made some helper functions, will create the individual agents below and tell them how to talk to each other using LangGraph.\n",
        "\n",
        "**Define State**\n",
        "We first define the state of the graph. This will just a list of messages, along with a key to track the most recent sender"
      ],
      "metadata": {
        "id": "qPV3rBKo8hHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import operator\n",
        "from typing import Annotated, List, Sequence, Tuple, TypedDict, Union\n",
        "\n",
        "from langchain.agents import create_openai_functions_agent\n",
        "from langchain.tools.render import format_tool_to_openai_function\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "\n",
        "# This defines the object that is passed between each node\n",
        "# in the graph. We will create different nodes for each agent and tool\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
        "    sender: str"
      ],
      "metadata": {
        "id": "I604q12K8ZEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Agent Nodes**\n",
        "We now need to define the nodes. First, let's define the nodes for the agents."
      ],
      "metadata": {
        "id": "lHbF6Yqs8kCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import functools\n",
        "\n",
        "\n",
        "# Helper function to create a node for a given agent\n",
        "def agent_node(state, agent, name):\n",
        "    result = agent.invoke(state)\n",
        "    # We convert the agent output into a format that is suitable to append to the global state\n",
        "    if isinstance(result, FunctionMessage):\n",
        "        pass\n",
        "    else:\n",
        "        result = HumanMessage(**result.dict(exclude={\"type\", \"name\"}), name=name)\n",
        "    return {\n",
        "        \"messages\": [result],\n",
        "        # Since we have a strict workflow, we can\n",
        "        # track the sender so we know who to pass to next.\n",
        "        \"sender\": name,\n",
        "    }\n",
        "\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4-1106-preview\")\n",
        "\n",
        "# Research agent and node\n",
        "research_agent = create_agent(\n",
        "    llm,\n",
        "    [tavily_tool],\n",
        "    system_message=\"You should provide accurate data for the chart generator to use.\",\n",
        ")\n",
        "research_node = functools.partial(agent_node, agent=research_agent, name=\"Researcher\")\n",
        "\n",
        "# Chart Generator\n",
        "chart_agent = create_agent(\n",
        "    llm,\n",
        "    [python_repl],\n",
        "    system_message=\"Any charts you display will be visible by the user.\",\n",
        ")\n",
        "chart_node = functools.partial(agent_node, agent=chart_agent, name=\"Chart Generator\")"
      ],
      "metadata": {
        "id": "bliShcj78Y_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Tool Node**\n",
        "We now define a node to run the tools"
      ],
      "metadata": {
        "id": "JhBfizEl8mPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [tavily_tool, python_repl]\n",
        "tool_executor = ToolExecutor(tools)\n",
        "\n",
        "\n",
        "def tool_node(state):\n",
        "    \"\"\"This runs tools in the graph\n",
        "\n",
        "    It takes in an agent action and calls that tool and returns the result.\"\"\"\n",
        "    messages = state[\"messages\"]\n",
        "    # Based on the continue condition\n",
        "    # we know the last message involves a function call\n",
        "    last_message = messages[-1]\n",
        "    # We construct an ToolInvocation from the function_call\n",
        "    tool_input = json.loads(\n",
        "        last_message.additional_kwargs[\"function_call\"][\"arguments\"]\n",
        "    )\n",
        "    # We can pass single-arg inputs by value\n",
        "    if len(tool_input) == 1 and \"__arg1\" in tool_input:\n",
        "        tool_input = next(iter(tool_input.values()))\n",
        "    tool_name = last_message.additional_kwargs[\"function_call\"][\"name\"]\n",
        "    action = ToolInvocation(\n",
        "        tool=tool_name,\n",
        "        tool_input=tool_input,\n",
        "    )\n",
        "    # We call the tool_executor and get back a response\n",
        "    response = tool_executor.invoke(action)\n",
        "    # We use the response to create a FunctionMessage\n",
        "    function_message = FunctionMessage(\n",
        "        content=f\"{tool_name} response: {str(response)}\", name=action.tool\n",
        "    )\n",
        "    # We return a list, because this will get added to the existing list\n",
        "    return {\"messages\": [function_message]}"
      ],
      "metadata": {
        "id": "f53amOuP8mdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Edge Logic**\n",
        "We can define some of the edge logic that is needed to decide what to do based on results of the agents"
      ],
      "metadata": {
        "id": "5DU5CowM8p3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Either agent can decide to end\n",
        "def router(state):\n",
        "    # This is the router\n",
        "    messages = state[\"messages\"]\n",
        "    last_message = messages[-1]\n",
        "    if \"function_call\" in last_message.additional_kwargs:\n",
        "        # The previus agent is invoking a tool\n",
        "        return \"call_tool\"\n",
        "    if \"FINAL ANSWER\" in last_message.content:\n",
        "        # Any agent decided the work is done\n",
        "        return \"end\"\n",
        "    return \"continue\""
      ],
      "metadata": {
        "id": "t-XY11oq8qk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the Graph**\n",
        "We can now put it all together and define the graph!"
      ],
      "metadata": {
        "id": "YVj9t0_j8sr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "workflow.add_node(\"Researcher\", research_node)\n",
        "workflow.add_node(\"Chart Generator\", chart_node)\n",
        "workflow.add_node(\"call_tool\", tool_node)\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"Researcher\",\n",
        "    router,\n",
        "    {\"continue\": \"Chart Generator\", \"call_tool\": \"call_tool\", \"end\": END},\n",
        ")\n",
        "workflow.add_conditional_edges(\n",
        "    \"Chart Generator\",\n",
        "    router,\n",
        "    {\"continue\": \"Researcher\", \"call_tool\": \"call_tool\", \"end\": END},\n",
        ")\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"call_tool\",\n",
        "    # Each agent node updates the 'sender' field\n",
        "    # the tool calling node does not, meaning\n",
        "    # this edge will route back to the original agent\n",
        "    # who invoked the tool\n",
        "    lambda x: x[\"sender\"],\n",
        "    {\n",
        "        \"Researcher\": \"Researcher\",\n",
        "        \"Chart Generator\": \"Chart Generator\",\n",
        "    },\n",
        ")\n",
        "workflow.set_entry_point(\"Researcher\")\n",
        "graph = workflow.compile()"
      ],
      "metadata": {
        "id": "zE5hV_pK8tnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Invoke**\n",
        "With the graph created, you can invoke it! Let's have it chart some stats for us."
      ],
      "metadata": {
        "id": "K-3MGKxY8vfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for s in graph.stream(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            HumanMessage(\n",
        "                content=\"Fetch the UK's GDP over the past 5 years,\"\n",
        "                \" then draw a line graph of it.\"\n",
        "                \" Once you code it up, finish.\"\n",
        "            )\n",
        "        ],\n",
        "    },\n",
        "    # Maximum number of steps to take in the graph\n",
        "    {\"recursion_limit\": 150},\n",
        "):\n",
        "    print(s)\n",
        "    print(\"----\")"
      ],
      "metadata": {
        "id": "lEXbn4RS8wPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Agent Supervisor"
      ],
      "metadata": {
        "id": "9iMJUxC7A8-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also choose to use an LLM to orchestrate the different agents.\n",
        "\n",
        "Below, we will create an agent group, with an agent supervisor to help delegate tasks.\n",
        "\n",
        "![Agent Supervisor](https://raw.githubusercontent.com/langchain-ai/langgraph/8a38226078383d49f57cd30c0df4203b0ea7cb2d/examples/multi_agent/img/supervisor-diagram.png)\n",
        "\n",
        "To simplify the code in each agent node, we will use the AgentExecutor class from LangChain. This and other \"advanced agent\" notebooks are designed to show how you can implement certain design patterns in LangGraph. If the pattern suits your needs, we recommend combining it with some of the other fundamental patterns described elsewhere in the docs for best performance."
      ],
      "metadata": {
        "id": "so2ElI1XBAo5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create tools**\n",
        "\n",
        "For this example, you will make an agent to do web research with a search engine, and one agent to create plots. Define the tools they'll use below:"
      ],
      "metadata": {
        "id": "JfOXWBBkBMzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated, List, Tuple, Union\n",
        "\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_core.tools import tool\n",
        "from langchain_experimental.tools import PythonREPLTool\n",
        "\n",
        "tavily_tool = TavilySearchResults(max_results=5)\n",
        "\n",
        "# This executes code locally, which can be unsafe\n",
        "python_repl_tool = PythonREPLTool()"
      ],
      "metadata": {
        "id": "BE_5SZpeA_Vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Helper Utilites**\n",
        "\n",
        "Define a helper function below, which make it easier to add new agent worker nodes."
      ],
      "metadata": {
        "id": "Of38MF9wBPgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
        "from langchain_core.messages import BaseMessage, HumanMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "\n",
        "def create_agent(llm: ChatOpenAI, tools: list, system_prompt: str):\n",
        "    # Each worker node will be given a name and some tools.\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\n",
        "                \"system\",\n",
        "                system_prompt,\n",
        "            ),\n",
        "            MessagesPlaceholder(variable_name=\"messages\"),\n",
        "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "        ]\n",
        "    )\n",
        "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
        "    executor = AgentExecutor(agent=agent, tools=tools)\n",
        "    return executor"
      ],
      "metadata": {
        "id": "0SPJF9YxBPzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also define a function that we will use to be the nodes in the graph - it takes care of converting the agent response to a human message. This is important because that is how we will add it the global state of the graph"
      ],
      "metadata": {
        "id": "rL4kQFuoBTtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def agent_node(state, agent, name):\n",
        "    result = agent.invoke(state)\n",
        "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}"
      ],
      "metadata": {
        "id": "-iysFO_LBQTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create Agent Supervisor**\n",
        "\n",
        "It will use function calling to choose the next worker node OR finish processing."
      ],
      "metadata": {
        "id": "F-r5ifHpBVgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "members = [\"Researcher\", \"Coder\"]\n",
        "system_prompt = (\n",
        "    \"You are a supervisor tasked with managing a conversation between the\"\n",
        "    \" following workers:  {members}. Given the following user request,\"\n",
        "    \" respond with the worker to act next. Each worker will perform a\"\n",
        "    \" task and respond with their results and status. When finished,\"\n",
        "    \" respond with FINISH.\"\n",
        ")\n",
        "# Our team supervisor is an LLM node. It just picks the next agent to process\n",
        "# and decides when the work is completed\n",
        "options = [\"FINISH\"] + members\n",
        "# Using openai function calling can make output parsing easier for us\n",
        "function_def = {\n",
        "    \"name\": \"route\",\n",
        "    \"description\": \"Select the next role.\",\n",
        "    \"parameters\": {\n",
        "        \"title\": \"routeSchema\",\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"next\": {\n",
        "                \"title\": \"Next\",\n",
        "                \"anyOf\": [\n",
        "                    {\"enum\": options},\n",
        "                ],\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"next\"],\n",
        "    },\n",
        "}\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "        (\n",
        "            \"system\",\n",
        "            \"Given the conversation above, who should act next?\"\n",
        "            \" Or should we FINISH? Select one of: {options}\",\n",
        "        ),\n",
        "    ]\n",
        ").partial(options=str(options), members=\", \".join(members))\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4-1106-preview\")\n",
        "\n",
        "supervisor_chain = (\n",
        "    prompt\n",
        "    | llm.bind_functions(functions=[function_def], function_call=\"route\")\n",
        "    | JsonOutputFunctionsParser()\n",
        ")"
      ],
      "metadata": {
        "id": "idXl8lORBQQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Construct Graph**\n",
        "\n",
        "We're ready to start building the graph. Below, define the state and worker nodes using the function we just defined."
      ],
      "metadata": {
        "id": "iQYKckixBYOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import operator\n",
        "from typing import Annotated, Any, Dict, List, Optional, Sequence, TypedDict\n",
        "import functools\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "\n",
        "# The agent state is the input to each node in the graph\n",
        "class AgentState(TypedDict):\n",
        "    # The annotation tells the graph that new messages will always\n",
        "    # be added to the current states\n",
        "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
        "    # The 'next' field indicates where to route to next\n",
        "    next: str\n",
        "\n",
        "\n",
        "research_agent = create_agent(llm, [tavily_tool], \"You are a web researcher.\")\n",
        "research_node = functools.partial(agent_node, agent=research_agent, name=\"Researcher\")\n",
        "\n",
        "# NOTE: THIS PERFORMS ARBITRARY CODE EXECUTION. PROCEED WITH CAUTION\n",
        "code_agent = create_agent(\n",
        "    llm,\n",
        "    [python_repl_tool],\n",
        "    \"You may generate safe python code to analyze data and generate charts using matplotlib.\",\n",
        ")\n",
        "code_node = functools.partial(agent_node, agent=code_agent, name=\"Coder\")\n",
        "\n",
        "workflow = StateGraph(AgentState)\n",
        "workflow.add_node(\"Researcher\", research_node)\n",
        "workflow.add_node(\"Coder\", code_node)\n",
        "workflow.add_node(\"supervisor\", supervisor_chain)"
      ],
      "metadata": {
        "id": "gK6PAZ0wBQNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now connect all the edges in the graph."
      ],
      "metadata": {
        "id": "rmfyUhqyBbj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for member in members:\n",
        "    # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
        "    workflow.add_edge(member, \"supervisor\")\n",
        "# The supervisor populates the \"next\" field in the graph state\n",
        "# which routes to a node or finishes\n",
        "conditional_map = {k: k for k in members}\n",
        "conditional_map[\"FINISH\"] = END\n",
        "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
        "# Finally, add entrypoint\n",
        "workflow.set_entry_point(\"supervisor\")\n",
        "\n",
        "graph = workflow.compile()"
      ],
      "metadata": {
        "id": "bkoY_Ry5BQHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Invoke the team\n",
        "With the graph created, we can now invoke it and see how it performs!"
      ],
      "metadata": {
        "id": "GWOPaa-BBd4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for s in graph.stream(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            HumanMessage(content=\"Code hello world and print it to the terminal\")\n",
        "        ]\n",
        "    }\n",
        "):\n",
        "    if \"__end__\" not in s:\n",
        "        print(s)\n",
        "        print(\"----\")"
      ],
      "metadata": {
        "id": "uBoMUODlBcBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for s in graph.stream(\n",
        "    {\"messages\": [HumanMessage(content=\"Write a brief research report on pikas.\")]},\n",
        "    {\"recursion_limit\": 100},\n",
        "):\n",
        "    if \"__end__\" not in s:\n",
        "        print(s)\n",
        "        print(\"----\")"
      ],
      "metadata": {
        "id": "SUfHoVPGBb0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CrewAI\n",
        "\n",
        "João Moura: Founder and CEO of CrewAI"
      ],
      "metadata": {
        "id": "kyZD8W_RdoXA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agentic Design Pattern\n",
        "\n",
        "In the past you would go from point a to point b, and you can write code to automate that.\n",
        "and then what happens is that as edge cases appear you start to kind of make that a little more complex by adding a lot of if's and conditions there.\n",
        "\n",
        "The beauty of agentic automation is that you don't need to draw a map, you just show all the options and let the agent choose.\n",
        "\n",
        "\n",
        "Traditional: strongly typed inputs, predefined transformation steps, and a strongly typed output.\n",
        "\n",
        "Agentic: Fuzzy inputs, fuzzy tranformations, fuzzy outputs\n",
        "\n",
        "\\\n",
        "\n",
        "**What are Agents:**\n",
        "\n",
        "An agent is born when you get LLMs to engage in their thinking process throughout it ask questions and answer the questions itself to the point that it can move on and ge better by itself.\n",
        "\n",
        "Once at this stage, it allows you to pass a task to this agent, and throughout process this agent can then come up with a better answer, it's not the first answer that it would have given you but it can think through and optimize the answer upto the point that satisfies itself and then spits it out.\n",
        "\n",
        "The ability to use tools (capabilities) make them super powerful.\n",
        "\n"
      ],
      "metadata": {
        "id": "MPxfeexmdq3h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-Agent Systems\n",
        "\n",
        "It grows on top of this topic, where instead of having just one agent, you can now have multiple agents.\n",
        "so each time you task an agent, it can task another agent, and at the end you would get one single final answer.\n",
        "\n",
        "What are the benefits of this?\n",
        "- You can have each agent be customized to don one single thing, and do it well\n",
        "- They could be running on different LLMs\n",
        "\n",
        "\\\n",
        "\n",
        "**What makes an agent great?**\n",
        "\n",
        "- Role playing\n",
        "- Focus\n",
        "- Tools\n",
        "- Cooperation\n",
        "- Guardrails\n",
        "- Memory"
      ],
      "metadata": {
        "id": "4HrBs6wseFgJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Article Writer Example"
      ],
      "metadata": {
        "id": "tGUx0w7JmHsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install crewai==0.28.8 crewai_tools==0.1.6 langchain_community==0.0.29"
      ],
      "metadata": {
        "id": "t2zHXTLzeOfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Task, Crew\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "YTYL_ZlXeSMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "os.environ[\"OPENAI_MODEL_NAME\"] = 'gpt-3.5-turbo'\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYunsmwfegP4",
        "outputId": "589fa08e-64ce-44c3-c9d7-16c075d0f4da"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Agents**\n",
        "\n",
        "- Define your Agents, and provide them a `role`, `goal` and `backstory`.\n",
        "- It has been seen that LLMs perform better when they are role playing."
      ],
      "metadata": {
        "id": "4_bOellbe__4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Agent: Planner**\n"
      ],
      "metadata": {
        "id": "rVtMj0H_fEtN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "planner = Agent(\n",
        "    role=\"Content Planner\",\n",
        "    goal=\"Plan engaging and factually accurate content on {topic}\",\n",
        "    backstory=\"You're working on planning a blog article \"\n",
        "              \"about the topic: {topic}.\"\n",
        "              \"You collect information that helps the \"\n",
        "              \"audience learn something \"\n",
        "              \"and make informed decisions. \"\n",
        "              \"Your work is the basis for \"\n",
        "              \"the Content Writer to write an article on this topic.\",\n",
        "    allow_delegation=False,\n",
        "\tverbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "p1G2WGrJfMaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Agent: Writer**"
      ],
      "metadata": {
        "id": "u6QcsFJ9fekH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "writer = Agent(\n",
        "    role=\"Content Writer\",\n",
        "    goal=\"Write insightful and factually accurate \"\n",
        "         \"opinion piece about the topic: {topic}\",\n",
        "    backstory=\"You're working on a writing \"\n",
        "              \"a new opinion piece about the topic: {topic}. \"\n",
        "              \"You base your writing on the work of \"\n",
        "              \"the Content Planner, who provides an outline \"\n",
        "              \"and relevant context about the topic. \"\n",
        "              \"You follow the main objectives and \"\n",
        "              \"direction of the outline, \"\n",
        "              \"as provide by the Content Planner. \"\n",
        "              \"You also provide objective and impartial insights \"\n",
        "              \"and back them up with information \"\n",
        "              \"provide by the Content Planner. \"\n",
        "              \"You acknowledge in your opinion piece \"\n",
        "              \"when your statements are opinions \"\n",
        "              \"as opposed to objective statements.\",\n",
        "    allow_delegation=False,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "WHHFsv2WffXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Agent: Editor**"
      ],
      "metadata": {
        "id": "2KY_SH--fY67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "editor = Agent(\n",
        "    role=\"Editor\",\n",
        "    goal=\"Edit a given blog post to align with \"\n",
        "         \"the writing style of the organization. \",\n",
        "    backstory=\"You are an editor who receives a blog post \"\n",
        "              \"from the Content Writer. \"\n",
        "              \"Your goal is to review the blog post \"\n",
        "              \"to ensure that it follows journalistic best practices,\"\n",
        "              \"provides balanced viewpoints \"\n",
        "              \"when providing opinions or assertions, \"\n",
        "              \"and also avoids major controversial topics \"\n",
        "              \"or opinions when possible.\",\n",
        "    allow_delegation=False,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "n3O9ILxvfWLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Tasks**\n",
        "\n",
        "- Define your Tasks, and provide them a `description`, `expected_output` and `agent`."
      ],
      "metadata": {
        "id": "JJ9eRSiWfjfv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task: Plan**"
      ],
      "metadata": {
        "id": "U2JCQvLafq7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plan = Task(\n",
        "    description=(\n",
        "        \"1. Prioritize the latest trends, key players, \"\n",
        "            \"and noteworthy news on {topic}.\\n\"\n",
        "        \"2. Identify the target audience, considering \"\n",
        "            \"their interests and pain points.\\n\"\n",
        "        \"3. Develop a detailed content outline including \"\n",
        "            \"an introduction, key points, and a call to action.\\n\"\n",
        "        \"4. Include SEO keywords and relevant data or sources.\"\n",
        "    ),\n",
        "    expected_output=\"A comprehensive content plan document \"\n",
        "        \"with an outline, audience analysis, \"\n",
        "        \"SEO keywords, and resources.\",\n",
        "    agent=planner,\n",
        ")"
      ],
      "metadata": {
        "id": "xgjX2grvfwl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task: Write**"
      ],
      "metadata": {
        "id": "u0McDFCmfq1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "write = Task(\n",
        "    description=(\n",
        "        \"1. Use the content plan to craft a compelling \"\n",
        "            \"blog post on {topic}.\\n\"\n",
        "        \"2. Incorporate SEO keywords naturally.\\n\"\n",
        "\t\t\"3. Sections/Subtitles are properly named \"\n",
        "            \"in an engaging manner.\\n\"\n",
        "        \"4. Ensure the post is structured with an \"\n",
        "            \"engaging introduction, insightful body, \"\n",
        "            \"and a summarizing conclusion.\\n\"\n",
        "        \"5. Proofread for grammatical errors and \"\n",
        "            \"alignment with the brand's voice.\\n\"\n",
        "    ),\n",
        "    expected_output=\"A well-written blog post \"\n",
        "        \"in markdown format, ready for publication, \"\n",
        "        \"each section should have 2 or 3 paragraphs.\",\n",
        "    agent=writer,\n",
        ")"
      ],
      "metadata": {
        "id": "f251KqyKfyB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task: Edit**"
      ],
      "metadata": {
        "id": "cOliQOx9fqoo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "edit = Task(\n",
        "    description=(\"Proofread the given blog post for \"\n",
        "                 \"grammatical errors and \"\n",
        "                 \"alignment with the brand's voice.\"),\n",
        "    expected_output=\"A well-written blog post in markdown format, \"\n",
        "                    \"ready for publication, \"\n",
        "                    \"each section should have 2 or 3 paragraphs.\",\n",
        "    agent=editor\n",
        ")"
      ],
      "metadata": {
        "id": "2RWHtFP1fjya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating the Crew**\n",
        "\n",
        "- Create your crew of Agents\n",
        "- Pass the tasks to be performed by those agents.\n",
        "    - **Note**: *For this simple example*, the tasks will be performed sequentially (i.e they are dependent on each other), so the _order_ of the task in the list _matters_.\n",
        "- `verbose=2` allows you to see all the logs of the execution."
      ],
      "metadata": {
        "id": "vigOexxvf7Hb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "crew = Crew(\n",
        "    agents=[planner, writer, editor],\n",
        "    tasks=[plan, write, edit],\n",
        "    verbose=2\n",
        ")"
      ],
      "metadata": {
        "id": "GekwdeEXf_Wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Running the Crew**"
      ],
      "metadata": {
        "id": "8qWgCSaRgBq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = crew.kickoff(inputs={\"topic\": \"Artificial Intelligence\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BEOslnmgCOo",
        "outputId": "e1439eb4-e3d0-4e74-dcff-19d2e7d19344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Content Planner\u001b[00m\n",
            "\u001b[1m\u001b[95m [INFO]: == Starting Task: 1. Prioritize the latest trends, key players, and noteworthy news on Artificial Intelligence.\n",
            "2. Identify the target audience, considering their interests and pain points.\n",
            "3. Develop a detailed content outline including an introduction, key points, and a call to action.\n",
            "4. Include SEO keywords and relevant data or sources.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI now can give a great answer\n",
            "\n",
            "Final Answer: \n",
            "\n",
            "Title: The Future of Artificial Intelligence: Latest Trends, Key Players, and Noteworthy News\n",
            "\n",
            "Outline:\n",
            "\n",
            "I. Introduction\n",
            "- Definition of Artificial Intelligence (AI)\n",
            "- Brief history of AI development\n",
            "- Importance of AI in various industries\n",
            "\n",
            "II. Latest Trends in Artificial Intelligence\n",
            "- Machine learning advancements\n",
            "- Natural language processing innovations\n",
            "- AI ethics and regulations\n",
            "- AI in healthcare, finance, and other sectors\n",
            "\n",
            "III. Key Players in the AI Industry\n",
            "- Google\n",
            "- Amazon\n",
            "- Microsoft\n",
            "- IBM\n",
            "- Tesla\n",
            "\n",
            "IV. Noteworthy News in Artificial Intelligence\n",
            "- Recent breakthroughs in AI research\n",
            "- AI applications in everyday life\n",
            "- Impact of AI on job markets and society\n",
            "\n",
            "V. Target Audience Analysis\n",
            "- Tech-savvy individuals interested in AI innovations\n",
            "- Business professionals seeking to implement AI solutions\n",
            "- Students and researchers studying AI trends\n",
            "- General audience curious about the future of technology\n",
            "\n",
            "VI. SEO Keywords\n",
            "- Artificial Intelligence trends\n",
            "- Key players in AI industry\n",
            "- Latest news on AI developments\n",
            "- AI applications in various sectors\n",
            "\n",
            "VII. Resources\n",
            "- Forbes article on top AI trends for 2021\n",
            "- Gartner report on key players in the AI industry\n",
            "- MIT Technology Review for latest news in AI\n",
            "- AI Ethics guidelines from IEEE\n",
            "\n",
            "Call to Action: Stay informed about the latest advancements in Artificial Intelligence by following reputable sources and engaging in discussions with industry experts. Embrace the possibilities of AI while also considering the ethical implications and societal impact of its widespread adoption. Remember, the future of AI is in our hands.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[1m\u001b[92m [DEBUG]: == [Content Planner] Task output: Title: The Future of Artificial Intelligence: Latest Trends, Key Players, and Noteworthy News\n",
            "\n",
            "Outline:\n",
            "\n",
            "I. Introduction\n",
            "- Definition of Artificial Intelligence (AI)\n",
            "- Brief history of AI development\n",
            "- Importance of AI in various industries\n",
            "\n",
            "II. Latest Trends in Artificial Intelligence\n",
            "- Machine learning advancements\n",
            "- Natural language processing innovations\n",
            "- AI ethics and regulations\n",
            "- AI in healthcare, finance, and other sectors\n",
            "\n",
            "III. Key Players in the AI Industry\n",
            "- Google\n",
            "- Amazon\n",
            "- Microsoft\n",
            "- IBM\n",
            "- Tesla\n",
            "\n",
            "IV. Noteworthy News in Artificial Intelligence\n",
            "- Recent breakthroughs in AI research\n",
            "- AI applications in everyday life\n",
            "- Impact of AI on job markets and society\n",
            "\n",
            "V. Target Audience Analysis\n",
            "- Tech-savvy individuals interested in AI innovations\n",
            "- Business professionals seeking to implement AI solutions\n",
            "- Students and researchers studying AI trends\n",
            "- General audience curious about the future of technology\n",
            "\n",
            "VI. SEO Keywords\n",
            "- Artificial Intelligence trends\n",
            "- Key players in AI industry\n",
            "- Latest news on AI developments\n",
            "- AI applications in various sectors\n",
            "\n",
            "VII. Resources\n",
            "- Forbes article on top AI trends for 2021\n",
            "- Gartner report on key players in the AI industry\n",
            "- MIT Technology Review for latest news in AI\n",
            "- AI Ethics guidelines from IEEE\n",
            "\n",
            "Call to Action: Stay informed about the latest advancements in Artificial Intelligence by following reputable sources and engaging in discussions with industry experts. Embrace the possibilities of AI while also considering the ethical implications and societal impact of its widespread adoption. Remember, the future of AI is in our hands.\n",
            "\n",
            "\u001b[00m\n",
            "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Content Writer\u001b[00m\n",
            "\u001b[1m\u001b[95m [INFO]: == Starting Task: 1. Use the content plan to craft a compelling blog post on Artificial Intelligence.\n",
            "2. Incorporate SEO keywords naturally.\n",
            "3. Sections/Subtitles are properly named in an engaging manner.\n",
            "4. Ensure the post is structured with an engaging introduction, insightful body, and a summarizing conclusion.\n",
            "5. Proofread for grammatical errors and alignment with the brand's voice.\n",
            "\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI now can give a great answer\n",
            "\n",
            "Final Answer:\n",
            "\n",
            "# The Future of Artificial Intelligence: Latest Trends, Key Players, and Noteworthy News\n",
            "\n",
            "## Introduction\n",
            "Artificial Intelligence (AI) is the simulation of human intelligence processes by machines, typically computer systems. The concept of AI dates back to the 1950s, with significant advancements seen in recent years due to the availability of large datasets and powerful computing resources. AI plays a crucial role in transforming various industries by automating tasks, analyzing data at scale, and enabling predictive capabilities.\n",
            "\n",
            "## Latest Trends in Artificial Intelligence\n",
            "Machine learning, a subset of AI, has seen remarkable advancements with the development of deep learning algorithms that can learn from data and improve over time. Natural language processing (NLP) is another area of AI that has made significant strides, allowing machines to understand and generate human language. Ethical considerations and regulations surrounding AI use have also become increasingly important, with organizations focusing on responsible AI deployment. In sectors like healthcare and finance, AI is revolutionizing processes by enabling personalized treatments and more efficient financial operations.\n",
            "\n",
            "## Key Players in the AI Industry\n",
            "Several tech giants lead the way in AI development, including Google, Amazon, Microsoft, IBM, and Tesla. These companies invest heavily in AI research and development, creating innovative solutions that impact various aspects of our lives. Google, for instance, is known for its advancements in AI-powered search algorithms and voice assistants, while Tesla leads the way in autonomous driving technology.\n",
            "\n",
            "## Noteworthy News in Artificial Intelligence\n",
            "Recent breakthroughs in AI research include the development of AI models that can generate human-like text and images, as well as advancements in AI-driven healthcare diagnostics. AI applications in everyday life range from virtual assistants like Siri to recommendation systems on streaming platforms. However, the widespread adoption of AI raises concerns about its impact on job markets and society, leading to discussions on upskilling the workforce and ensuring equitable access to AI technologies.\n",
            "\n",
            "## Target Audience Analysis\n",
            "Tech-savvy individuals interested in AI innovations can stay informed through reputable sources like Forbes and MIT Technology Review. Business professionals seeking to implement AI solutions can benefit from Gartner's insights on key players in the industry. Students and researchers studying AI trends should explore AI Ethics guidelines from IEEE to understand the ethical implications of AI technologies. For the general audience curious about the future of technology, engaging in discussions with industry experts can provide valuable insights into the potential of AI.\n",
            "\n",
            "## SEO Keywords\n",
            "Artificial Intelligence trends, key players in the AI industry, latest news on AI developments, AI applications in various sectors\n",
            "\n",
            "## Resources\n",
            "- Forbes article on top AI trends for 2021\n",
            "- Gartner report on key players in the AI industry\n",
            "- MIT Technology Review for latest news in AI\n",
            "- AI Ethics guidelines from IEEE\n",
            "\n",
            "## Call to Action\n",
            "Stay informed about the latest advancements in Artificial Intelligence by following reputable sources and engaging in discussions with industry experts. Embrace the possibilities of AI while also considering the ethical implications and societal impact of its widespread adoption. Remember, the future of AI is in our hands.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[1m\u001b[92m [DEBUG]: == [Content Writer] Task output: # The Future of Artificial Intelligence: Latest Trends, Key Players, and Noteworthy News\n",
            "\n",
            "## Introduction\n",
            "Artificial Intelligence (AI) is the simulation of human intelligence processes by machines, typically computer systems. The concept of AI dates back to the 1950s, with significant advancements seen in recent years due to the availability of large datasets and powerful computing resources. AI plays a crucial role in transforming various industries by automating tasks, analyzing data at scale, and enabling predictive capabilities.\n",
            "\n",
            "## Latest Trends in Artificial Intelligence\n",
            "Machine learning, a subset of AI, has seen remarkable advancements with the development of deep learning algorithms that can learn from data and improve over time. Natural language processing (NLP) is another area of AI that has made significant strides, allowing machines to understand and generate human language. Ethical considerations and regulations surrounding AI use have also become increasingly important, with organizations focusing on responsible AI deployment. In sectors like healthcare and finance, AI is revolutionizing processes by enabling personalized treatments and more efficient financial operations.\n",
            "\n",
            "## Key Players in the AI Industry\n",
            "Several tech giants lead the way in AI development, including Google, Amazon, Microsoft, IBM, and Tesla. These companies invest heavily in AI research and development, creating innovative solutions that impact various aspects of our lives. Google, for instance, is known for its advancements in AI-powered search algorithms and voice assistants, while Tesla leads the way in autonomous driving technology.\n",
            "\n",
            "## Noteworthy News in Artificial Intelligence\n",
            "Recent breakthroughs in AI research include the development of AI models that can generate human-like text and images, as well as advancements in AI-driven healthcare diagnostics. AI applications in everyday life range from virtual assistants like Siri to recommendation systems on streaming platforms. However, the widespread adoption of AI raises concerns about its impact on job markets and society, leading to discussions on upskilling the workforce and ensuring equitable access to AI technologies.\n",
            "\n",
            "## Target Audience Analysis\n",
            "Tech-savvy individuals interested in AI innovations can stay informed through reputable sources like Forbes and MIT Technology Review. Business professionals seeking to implement AI solutions can benefit from Gartner's insights on key players in the industry. Students and researchers studying AI trends should explore AI Ethics guidelines from IEEE to understand the ethical implications of AI technologies. For the general audience curious about the future of technology, engaging in discussions with industry experts can provide valuable insights into the potential of AI.\n",
            "\n",
            "## SEO Keywords\n",
            "Artificial Intelligence trends, key players in the AI industry, latest news on AI developments, AI applications in various sectors\n",
            "\n",
            "## Resources\n",
            "- Forbes article on top AI trends for 2021\n",
            "- Gartner report on key players in the AI industry\n",
            "- MIT Technology Review for latest news in AI\n",
            "- AI Ethics guidelines from IEEE\n",
            "\n",
            "## Call to Action\n",
            "Stay informed about the latest advancements in Artificial Intelligence by following reputable sources and engaging in discussions with industry experts. Embrace the possibilities of AI while also considering the ethical implications and societal impact of its widespread adoption. Remember, the future of AI is in our hands.\n",
            "\n",
            "\u001b[00m\n",
            "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Editor\u001b[00m\n",
            "\u001b[1m\u001b[95m [INFO]: == Starting Task: Proofread the given blog post for grammatical errors and alignment with the brand's voice.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI now can give a great answer\n",
            "\n",
            "Final Answer: \n",
            "\n",
            "# The Future of Artificial Intelligence: Latest Trends, Key Players, and Noteworthy News\n",
            "\n",
            "## Introduction\n",
            "Artificial Intelligence (AI) has come a long way since its inception in the 1950s, with recent years witnessing significant advancements fueled by the availability of vast datasets and powerful computing resources. AI, at its core, involves the simulation of human intelligence processes by machines, particularly computer systems. Its impact on various industries is undeniable, as it automates tasks, analyzes data at scale, and enables predictive capabilities, thus transforming the way we work and live.\n",
            "\n",
            "## Latest Trends in Artificial Intelligence\n",
            "Machine learning, a subset of AI, has witnessed remarkable progress with the development of deep learning algorithms that can continuously learn and improve from data. Natural language processing (NLP) is another key area in AI that has made significant strides, enabling machines to understand and generate human language effectively. As AI continues to evolve, ethical considerations and regulations surrounding its use have become increasingly crucial, with organizations emphasizing responsible AI deployment. Industries like healthcare and finance are experiencing a revolution through AI, with personalized treatments and more efficient financial operations becoming the new norm.\n",
            "\n",
            "## Key Players in the AI Industry\n",
            "Leading the charge in AI development are tech giants such as Google, Amazon, Microsoft, IBM, and Tesla, who heavily invest in AI research and development. These companies are at the forefront of creating innovative solutions that have a profound impact on our daily lives. Google, for example, is renowned for its AI-powered search algorithms and voice assistants, while Tesla is a trailblazer in autonomous driving technology, showcasing the diverse applications of AI across industries.\n",
            "\n",
            "## Noteworthy News in Artificial Intelligence\n",
            "Recent breakthroughs in AI research have led to the development of models capable of generating human-like text and images, along with advancements in AI-driven healthcare diagnostics. Everyday AI applications, ranging from virtual assistants like Siri to recommendation systems on streaming platforms, are becoming more prevalent. However, the widespread adoption of AI has raised concerns regarding its impact on job markets and society, sparking discussions on upskilling the workforce and ensuring equitable access to AI technologies.\n",
            "\n",
            "## Target Audience Analysis\n",
            "For tech-savvy individuals keen on staying updated on AI innovations, reputable sources like Forbes and MIT Technology Review offer valuable insights. Business professionals looking to implement AI solutions can benefit from Gartner's analysis of key players in the industry. Students and researchers delving into AI trends should explore AI Ethics guidelines from IEEE to grasp the ethical considerations surrounding AI technologies. Finally, the general audience intrigued by the future of technology can gain valuable insights by engaging in discussions with industry experts to understand the potential of AI.\n",
            "\n",
            "## SEO Keywords\n",
            "Artificial Intelligence trends, key players in the AI industry, latest news on AI developments, AI applications in various sectors\n",
            "\n",
            "## Resources\n",
            "- Forbes article on top AI trends for 2021\n",
            "- Gartner report on key players in the AI industry\n",
            "- MIT Technology Review for the latest news in AI\n",
            "- AI Ethics guidelines from IEEE\n",
            "\n",
            "## Call to Action\n",
            "To stay abreast of the latest advancements in Artificial Intelligence, follow reputable sources and engage in discussions with industry experts. Embrace the possibilities AI offers while also considering its ethical implications and societal impact. Remember, the future of AI is shaped by our choices and actions.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[1m\u001b[92m [DEBUG]: == [Editor] Task output: # The Future of Artificial Intelligence: Latest Trends, Key Players, and Noteworthy News\n",
            "\n",
            "## Introduction\n",
            "Artificial Intelligence (AI) has come a long way since its inception in the 1950s, with recent years witnessing significant advancements fueled by the availability of vast datasets and powerful computing resources. AI, at its core, involves the simulation of human intelligence processes by machines, particularly computer systems. Its impact on various industries is undeniable, as it automates tasks, analyzes data at scale, and enables predictive capabilities, thus transforming the way we work and live.\n",
            "\n",
            "## Latest Trends in Artificial Intelligence\n",
            "Machine learning, a subset of AI, has witnessed remarkable progress with the development of deep learning algorithms that can continuously learn and improve from data. Natural language processing (NLP) is another key area in AI that has made significant strides, enabling machines to understand and generate human language effectively. As AI continues to evolve, ethical considerations and regulations surrounding its use have become increasingly crucial, with organizations emphasizing responsible AI deployment. Industries like healthcare and finance are experiencing a revolution through AI, with personalized treatments and more efficient financial operations becoming the new norm.\n",
            "\n",
            "## Key Players in the AI Industry\n",
            "Leading the charge in AI development are tech giants such as Google, Amazon, Microsoft, IBM, and Tesla, who heavily invest in AI research and development. These companies are at the forefront of creating innovative solutions that have a profound impact on our daily lives. Google, for example, is renowned for its AI-powered search algorithms and voice assistants, while Tesla is a trailblazer in autonomous driving technology, showcasing the diverse applications of AI across industries.\n",
            "\n",
            "## Noteworthy News in Artificial Intelligence\n",
            "Recent breakthroughs in AI research have led to the development of models capable of generating human-like text and images, along with advancements in AI-driven healthcare diagnostics. Everyday AI applications, ranging from virtual assistants like Siri to recommendation systems on streaming platforms, are becoming more prevalent. However, the widespread adoption of AI has raised concerns regarding its impact on job markets and society, sparking discussions on upskilling the workforce and ensuring equitable access to AI technologies.\n",
            "\n",
            "## Target Audience Analysis\n",
            "For tech-savvy individuals keen on staying updated on AI innovations, reputable sources like Forbes and MIT Technology Review offer valuable insights. Business professionals looking to implement AI solutions can benefit from Gartner's analysis of key players in the industry. Students and researchers delving into AI trends should explore AI Ethics guidelines from IEEE to grasp the ethical considerations surrounding AI technologies. Finally, the general audience intrigued by the future of technology can gain valuable insights by engaging in discussions with industry experts to understand the potential of AI.\n",
            "\n",
            "## SEO Keywords\n",
            "Artificial Intelligence trends, key players in the AI industry, latest news on AI developments, AI applications in various sectors\n",
            "\n",
            "## Resources\n",
            "- Forbes article on top AI trends for 2021\n",
            "- Gartner report on key players in the AI industry\n",
            "- MIT Technology Review for the latest news in AI\n",
            "- AI Ethics guidelines from IEEE\n",
            "\n",
            "## Call to Action\n",
            "To stay abreast of the latest advancements in Artificial Intelligence, follow reputable sources and engage in discussions with industry experts. Embrace the possibilities AI offers while also considering its ethical implications and societal impact. Remember, the future of AI is shaped by our choices and actions.\n",
            "\n",
            "\u001b[00m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "Markdown(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 993
        },
        "id": "9qL7dOTQgFfh",
        "outputId": "43a81c08-764e-4e88-ba05-38300fa8b32f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# The Future of Artificial Intelligence: Latest Trends, Key Players, and Noteworthy News\n\n## Introduction\nArtificial Intelligence (AI) has come a long way since its inception in the 1950s, with recent years witnessing significant advancements fueled by the availability of vast datasets and powerful computing resources. AI, at its core, involves the simulation of human intelligence processes by machines, particularly computer systems. Its impact on various industries is undeniable, as it automates tasks, analyzes data at scale, and enables predictive capabilities, thus transforming the way we work and live.\n\n## Latest Trends in Artificial Intelligence\nMachine learning, a subset of AI, has witnessed remarkable progress with the development of deep learning algorithms that can continuously learn and improve from data. Natural language processing (NLP) is another key area in AI that has made significant strides, enabling machines to understand and generate human language effectively. As AI continues to evolve, ethical considerations and regulations surrounding its use have become increasingly crucial, with organizations emphasizing responsible AI deployment. Industries like healthcare and finance are experiencing a revolution through AI, with personalized treatments and more efficient financial operations becoming the new norm.\n\n## Key Players in the AI Industry\nLeading the charge in AI development are tech giants such as Google, Amazon, Microsoft, IBM, and Tesla, who heavily invest in AI research and development. These companies are at the forefront of creating innovative solutions that have a profound impact on our daily lives. Google, for example, is renowned for its AI-powered search algorithms and voice assistants, while Tesla is a trailblazer in autonomous driving technology, showcasing the diverse applications of AI across industries.\n\n## Noteworthy News in Artificial Intelligence\nRecent breakthroughs in AI research have led to the development of models capable of generating human-like text and images, along with advancements in AI-driven healthcare diagnostics. Everyday AI applications, ranging from virtual assistants like Siri to recommendation systems on streaming platforms, are becoming more prevalent. However, the widespread adoption of AI has raised concerns regarding its impact on job markets and society, sparking discussions on upskilling the workforce and ensuring equitable access to AI technologies.\n\n## Target Audience Analysis\nFor tech-savvy individuals keen on staying updated on AI innovations, reputable sources like Forbes and MIT Technology Review offer valuable insights. Business professionals looking to implement AI solutions can benefit from Gartner's analysis of key players in the industry. Students and researchers delving into AI trends should explore AI Ethics guidelines from IEEE to grasp the ethical considerations surrounding AI technologies. Finally, the general audience intrigued by the future of technology can gain valuable insights by engaging in discussions with industry experts to understand the potential of AI.\n\n## SEO Keywords\nArtificial Intelligence trends, key players in the AI industry, latest news on AI developments, AI applications in various sectors\n\n## Resources\n- Forbes article on top AI trends for 2021\n- Gartner report on key players in the AI industry\n- MIT Technology Review for the latest news in AI\n- AI Ethics guidelines from IEEE\n\n## Call to Action\nTo stay abreast of the latest advancements in Artificial Intelligence, follow reputable sources and engage in discussions with industry experts. Embrace the possibilities AI offers while also considering its ethical implications and societal impact. Remember, the future of AI is shaped by our choices and actions."
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Customer Support Automation Example"
      ],
      "metadata": {
        "id": "F5HL_6fumNPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install crewai==0.28.8 crewai_tools==0.1.6 langchain_community==0.0.29"
      ],
      "metadata": {
        "id": "TB1XjrrImNPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Task, Crew\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "6VKzWlkKmNPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "os.environ[\"OPENAI_MODEL_NAME\"] = 'gpt-3.5-turbo'\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "589fa08e-64ce-44c3-c9d7-16c075d0f4da",
        "id": "VP-2N77MmNPI"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Role Playing, Focus and Cooperation**"
      ],
      "metadata": {
        "id": "6ZRfSJXBmT0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "support_agent = Agent(\n",
        "    role=\"Senior Support Representative\",\n",
        "\tgoal=\"Be the most friendly and helpful \"\n",
        "        \"support representative in your team\",\n",
        "\tbackstory=(\n",
        "\t\t\"You work at crewAI (https://crewai.com) and \"\n",
        "        \" are now working on providing \"\n",
        "\t\t\"support to {customer}, a super important customer \"\n",
        "        \" for your company.\"\n",
        "\t\t\"You need to make sure that you provide the best support!\"\n",
        "\t\t\"Make sure to provide full complete answers, \"\n",
        "        \" and make no assumptions.\"\n",
        "\t),\n",
        "\tallow_delegation=False,\n",
        "\tverbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "j2aWR7n-mVnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- By not setting `allow_delegation=False`, `allow_delegation` takes its default value of being `True`.\n",
        "- This means the agent _can_ delegate its work to another agent which is better suited to do a particular task."
      ],
      "metadata": {
        "id": "AySwKLEwmWri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "support_quality_assurance_agent = Agent(\n",
        "\trole=\"Support Quality Assurance Specialist\",\n",
        "\tgoal=\"Get recognition for providing the \"\n",
        "    \"best support quality assurance in your team\",\n",
        "\tbackstory=(\n",
        "\t\t\"You work at crewAI (https://crewai.com) and \"\n",
        "        \"are now working with your team \"\n",
        "\t\t\"on a request from {customer} ensuring that \"\n",
        "        \"the support representative is \"\n",
        "\t\t\"providing the best support possible.\\n\"\n",
        "\t\t\"You need to make sure that the support representative \"\n",
        "        \"is providing full\"\n",
        "\t\t\"complete answers, and make no assumptions.\"\n",
        "\t),\n",
        "\tverbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "uTArSEpwmYIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Role Playing**: Both agents have been given a role, goal and backstory.\n",
        "* **Focus**: Both agents have been prompted to get into the character of the roles they are playing.\n",
        "* **Cooperation**: Support Quality Assurance Agent can delegate work back to the Support Agent, allowing for these agents to work together."
      ],
      "metadata": {
        "id": "zOzzTyx-mcZg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tools, Guardrails and Memory**"
      ],
      "metadata": {
        "id": "Rj4znC8Wml6a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import CrewAI tools"
      ],
      "metadata": {
        "id": "jyj7nznamyT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai_tools import SerperDevTool, \\\n",
        "                         ScrapeWebsiteTool, \\\n",
        "                         WebsiteSearchTool"
      ],
      "metadata": {
        "id": "yiC5vgaOm1tO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Possible Custom Tools**\n",
        "- Load customer data\n",
        "- Tap into previous conversations\n",
        "- Load data from a CRM\n",
        "- Checking existing bug reports\n",
        "- Checking existing feature requests\n",
        "- Checking ongoing tickets\n",
        "- ... and more"
      ],
      "metadata": {
        "id": "SuVC6GQDm9wZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Different Ways to Give Agents Tools**\n",
        "\n",
        "- Agent Level: The Agent can use the Tool(s) on any Task it performs.\n",
        "- Task Level: The Agent will only use the Tool(s) when performing that specific Task.\n",
        "\n",
        "**Note**: Task Tools override the Agent Tools."
      ],
      "metadata": {
        "id": "WSCQO8j4nMt5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Tasks**\n",
        "- You are passing the Tool on the Task Level."
      ],
      "metadata": {
        "id": "_UzdtnunnQ9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs_scrape_tool = ScrapeWebsiteTool(\n",
        "    website_url=\"https://docs.crewai.com/how-to/Creating-a-Crew-and-kick-it-off/\"\n",
        ")"
      ],
      "metadata": {
        "id": "U-paU-lBnZ0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_tool = SerperDevTool()\n",
        "scrape_tool = ScrapeWebsiteTool()"
      ],
      "metadata": {
        "id": "NVc-Wg3Oniaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inquiry_resolution = Task(\n",
        "    description=(\n",
        "        \"{customer} just reached out with a super important ask:\\n\"\n",
        "\t    \"{inquiry}\\n\\n\"\n",
        "        \"{person} from {customer} is the one that reached out. \"\n",
        "\t\t\"Make sure to use everything you know \"\n",
        "        \"to provide the best support possible.\"\n",
        "\t\t\"You must strive to provide a complete \"\n",
        "        \"and accurate response to the customer's inquiry.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "\t    \"A detailed, informative response to the \"\n",
        "        \"customer's inquiry that addresses \"\n",
        "        \"all aspects of their question.\\n\"\n",
        "        \"The response should include references \"\n",
        "        \"to everything you used to find the answer, \"\n",
        "        \"including external data or solutions. \"\n",
        "        \"Ensure the answer is complete, \"\n",
        "\t\t\"leaving no questions unanswered, and maintain a helpful and friendly \"\n",
        "\t\t\"tone throughout.\"\n",
        "    ),\n",
        "\ttools=[docs_scrape_tool],\n",
        "  agent=support_agent,\n",
        ")"
      ],
      "metadata": {
        "id": "uClzrjBGnRtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `quality_assurance_review` is not using any Tool(s)\n",
        "- Here the QA Agent will only review the work of the Support Agent"
      ],
      "metadata": {
        "id": "sIlO6qYLn5V0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quality_assurance_review = Task(\n",
        "    description=(\n",
        "        \"Review the response drafted by the Senior Support Representative for {customer}'s inquiry. \"\n",
        "        \"Ensure that the answer is comprehensive, accurate, and adheres to the \"\n",
        "\t\t\"high-quality standards expected for customer support.\\n\"\n",
        "        \"Verify that all parts of the customer's inquiry \"\n",
        "        \"have been addressed \"\n",
        "\t\t\"thoroughly, with a helpful and friendly tone.\\n\"\n",
        "        \"Check for references and sources used to \"\n",
        "        \" find the information, \"\n",
        "\t\t\"ensuring the response is well-supported and \"\n",
        "        \"leaves no questions unanswered.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A final, detailed, and informative response \"\n",
        "        \"ready to be sent to the customer.\\n\"\n",
        "        \"This response should fully address the \"\n",
        "        \"customer's inquiry, incorporating all \"\n",
        "\t\t\"relevant feedback and improvements.\\n\"\n",
        "\t\t\"Don't be too formal, we are a chill and cool company \"\n",
        "\t    \"but maintain a professional and friendly tone throughout.\"\n",
        "    ),\n",
        "    agent=support_quality_assurance_agent,\n",
        ")"
      ],
      "metadata": {
        "id": "D_UUy4ATn5xO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating the Crew**\n",
        "\n",
        "**Memory**\n",
        "- Setting `memory=True` when putting the crew together enables Memory."
      ],
      "metadata": {
        "id": "HNuhXF47n_0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "crew = Crew(\n",
        "  agents=[support_agent, support_quality_assurance_agent],\n",
        "  tasks=[inquiry_resolution, quality_assurance_review],\n",
        "  verbose=2,\n",
        "  memory=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aA7AReyeoDIf",
        "outputId": "d17d2d9f-1f0d-4ae1-c5eb-76fff8174355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Running the Crew**"
      ],
      "metadata": {
        "id": "_6haFlE-oFZj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Guardrails**\n",
        "- By running the execution below, you can see that the agents and the responses are within the scope of what we expect from them."
      ],
      "metadata": {
        "id": "XaIb2JwVoIXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\n",
        "    \"customer\": \"DeepLearningAI\",\n",
        "    \"person\": \"Andrew Ng\",\n",
        "    \"inquiry\": \"I need help with setting up a Crew \"\n",
        "               \"and kicking it off, specifically \"\n",
        "               \"how can I add memory to my crew? \"\n",
        "               \"Can you provide guidance?\"\n",
        "}\n",
        "result = crew.kickoff(inputs=inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbSNDXGyoJUq",
        "outputId": "1bdca03d-2e94-4422-ffc0-10e903814744"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Senior Support Representative\u001b[00m\n",
            "\u001b[1m\u001b[95m [INFO]: == Starting Task: DeepLearningAI just reached out with a super important ask:\n",
            "I need help with setting up a Crew and kicking it off, specifically how can I add memory to my crew? Can you provide guidance?\n",
            "\n",
            "Andrew Ng from DeepLearningAI is the one that reached out. Make sure to use everything you know to provide the best support possible.You must strive to provide a complete and accurate response to the customer's inquiry.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to provide the best support possible to DeepLearningAI by using the tools available to me and ensuring that I address all aspects of their inquiry.\n",
            "\n",
            "Action: Read website content\n",
            "Action Input: {\"url\": \"https://docs.crewai.com/how-to/Creating-a-Crew-and-kick-it-off/\"}\u001b[0m\u001b[95m \n",
            "\n",
            "Assembling and Activating Your CrewAI Team - crewAI\n",
            " Skip to content\n",
            " crewAI\n",
            " Assembling and Activating Your CrewAI Team\n",
            " crewAI\n",
            " crewAI\n",
            " crewAI\n",
            " Home\n",
            " Core Concepts\n",
            " Core Concepts\n",
            " Agents\n",
            " Tasks\n",
            " Tools\n",
            " Processes\n",
            " Crews\n",
            " Collaboration\n",
            " Memory\n",
            " How to Guides\n",
            " How to Guides\n",
            " Installing CrewAI\n",
            " Getting Started\n",
            " Getting Started\n",
            " Table of contents\n",
            " Introduction\n",
            " Step 0: Installation\n",
            " Step 1: Assemble Your Agents\n",
            " Step 2: Define the Tasks\n",
            " Step 3: Form the Crew\n",
            " Step 4: Kick It Off\n",
            " Conclusion\n",
            " Create Custom Tools\n",
            " Using Sequential Process\n",
            " Using Hierarchical Process\n",
            " Connecting to any LLM\n",
            " Customizing Agents\n",
            " Human Input on Execution\n",
            " Agent Monitoring with AgentOps\n",
            " Tools Docs\n",
            " Tools Docs\n",
            " Google Serper Search\n",
            " Browserbase Web Loader\n",
            " Scrape Website\n",
            " Directory Read\n",
            " File Read\n",
            " Selenium Scraper\n",
            " Directory RAG Search\n",
            " PDF RAG Search\n",
            " TXT RAG Search\n",
            " CSV RAG Search\n",
            " XML RAG Search\n",
            " JSON RAG Search\n",
            " Docx Rag Search\n",
            " MDX RAG Search\n",
            " PG RAG Search\n",
            " Website RAG Search\n",
            " Github RAG Search\n",
            " Code Docs RAG Search\n",
            " Youtube Video RAG Search\n",
            " Youtube Channel RAG Search\n",
            " Examples\n",
            " Examples\n",
            " Trip Planner Crew\n",
            " Create Instagram Post\n",
            " Stock Analysis\n",
            " Game Generator\n",
            " Drafting emails with LangGraph\n",
            " Landing Page Generator\n",
            " Prepare for meetings\n",
            " Telemetry\n",
            "Getting Started\n",
            "Introduction¶\n",
            "Embark on your CrewAI journey by setting up your environment and initiating your AI crew with the latest features. This guide ensures a smooth start, incorporating all recent updates for an enhanced experience.\n",
            "Step 0: Installation¶\n",
            "Install CrewAI and any necessary packages for your project. CrewAI is compatible with Python >=3.10,<=3.13.\n",
            "pip install crewai\n",
            "pip install 'crewai[tools]'\n",
            "Step 1: Assemble Your Agents¶\n",
            "Define your agents with distinct roles, backstories, and enhanced capabilities like verbose mode and memory usage. These elements add depth and guide their task execution and interaction within the crew.\n",
            "import os\n",
            "os.environ[\"SERPER_API_KEY\"] = \"Your Key\" # serper.dev API key\n",
            "os.environ[\"OPENAI_API_KEY\"] = \"Your Key\"\n",
            "from crewai import Agent\n",
            "from crewai_tools import SerperDevTool\n",
            "search_tool = SerperDevTool()\n",
            "# Creating a senior researcher agent with memory and verbose mode\n",
            "researcher = Agent(\n",
            " role='Senior Researcher',\n",
            " goal='Uncover groundbreaking technologies in {topic}',\n",
            " verbose=True,\n",
            " memory=True,\n",
            " backstory=(\n",
            " \"Driven by curiosity, you're at the forefront of\"\n",
            " \"innovation, eager to explore and share knowledge that could change\"\n",
            " \"the world.\"\n",
            " ),\n",
            " tools=[search_tool],\n",
            " allow_delegation=True\n",
            ")\n",
            "# Creating a writer agent with custom tools and delegation capability\n",
            "writer = Agent(\n",
            " role='Writer',\n",
            " goal='Narrate compelling tech stories about {topic}',\n",
            " verbose=True,\n",
            " memory=True,\n",
            " backstory=(\n",
            " \"With a flair for simplifying complex topics, you craft\"\n",
            " \"engaging narratives that captivate and educate, bringing new\"\n",
            " \"discoveries to light in an accessible manner.\"\n",
            " ),\n",
            " tools=[search_tool],\n",
            " allow_delegation=False\n",
            ")\n",
            "Step 2: Define the Tasks¶\n",
            "Detail the specific objectives for your agents, including new features for asynchronous execution and output customization. These tasks ensure a targeted approach to their roles.\n",
            "from crewai import Task\n",
            "# Research task\n",
            "research_task = Task(\n",
            " description=(\n",
            " \"Identify the next big trend in {topic}.\"\n",
            " \"Focus on identifying pros and cons and the overall narrative.\"\n",
            " \"Your final report should clearly articulate the key points,\"\n",
            " \"its market opportunities, and potential risks.\"\n",
            " ),\n",
            " expected_output='A comprehensive 3 paragraphs long report on the latest AI trends.',\n",
            " tools=[search_tool],\n",
            " agent=researcher,\n",
            ")\n",
            "# Writing task with language model configuration\n",
            "write_task = Task(\n",
            " description=(\n",
            " \"Compose an insightful article on {topic}.\"\n",
            " \"Focus on the latest trends and how it's impacting the industry.\"\n",
            " \"This article should be easy to understand, engaging, and positive.\"\n",
            " ),\n",
            " expected_output='A 4 paragraph article on {topic} advancements formatted as markdown.',\n",
            " tools=[search_tool],\n",
            " agent=writer,\n",
            " async_execution=False,\n",
            " output_file='new-blog-post.md' # Example of output customization\n",
            ")\n",
            "Step 3: Form the Crew¶\n",
            "Combine your agents into a crew, setting the workflow process they'll follow to accomplish the tasks. Now with options to configure language models for enhanced interaction and additional configurations for optimizing performance.\n",
            "from crewai import Crew, Process\n",
            "# Forming the tech-focused crew with some enhanced configurations\n",
            "crew = Crew(\n",
            " agents=[researcher, writer],\n",
            " tasks=[research_task, write_task],\n",
            " process=Process.sequential, # Optional: Sequential task execution is default\n",
            " memory=True,\n",
            " cache=True,\n",
            " max_rpm=100,\n",
            " share_crew=True\n",
            ")\n",
            "Step 4: Kick It Off¶\n",
            "Initiate the process with your enhanced crew ready. Observe as your agents collaborate, leveraging their new capabilities for a successful project outcome. Input variables will be interpolated into the agents and tasks for a personalized approach.\n",
            "# Starting the task execution process with enhanced feedback\n",
            "result = crew.kickoff(inputs={'topic': 'AI in healthcare'})\n",
            "print(result)\n",
            "Conclusion¶\n",
            "Building and activating a crew in CrewAI has evolved with new functionalities. By incorporating verbose mode, memory capabilities, asynchronous task execution, output customization, language model configuration, and enhanced crew configurations, your AI team is more equipped than ever to tackle challenges efficiently. The depth of agent backstories and the precision of their objectives enrich collaboration, leading to successful project outcomes. This guide aims to provide you with a clear and detailed understanding of setting up and utilizing the CrewAI framework to its full potential.\n",
            " Back to top\n",
            " Previous\n",
            " Installing CrewAI\n",
            " Next\n",
            " Create Custom Tools\n",
            " Copyright © 2024 crewAI, Inc\n",
            " Made with\n",
            " Material for MkDocs\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3mFinal Answer: \n",
            "\n",
            "Hello Andrew Ng from DeepLearningAI,\n",
            "\n",
            "Thank you for reaching out for assistance with setting up a Crew and kicking it off, specifically on how to add memory to your crew. I have gathered information from the crewAI documentation on how you can achieve this.\n",
            "\n",
            "To add memory to your crew in crewAI, you need to follow these steps:\n",
            "\n",
            "1. Assemble Your Agents:\n",
            "Define your agents with distinct roles, backstories, and enhanced capabilities like memory usage. You can create agents with memory capabilities by setting the memory parameter to True when creating the agent.\n",
            "\n",
            "Example:\n",
            "```python\n",
            "researcher = Agent(\n",
            " role='Senior Researcher',\n",
            " goal='Uncover groundbreaking technologies in {topic}',\n",
            " verbose=True,\n",
            " memory=True,\n",
            " backstory=(\n",
            " \"Driven by curiosity, you're at the forefront of\"\n",
            " \"innovation, eager to explore and share knowledge that could change\"\n",
            " \"the world.\"\n",
            " ),\n",
            " tools=[search_tool],\n",
            " allow_delegation=True\n",
            ")\n",
            "```\n",
            "\n",
            "2. Form the Crew:\n",
            "Combine your agents into a crew and set the workflow process they'll follow to accomplish the tasks. When forming the crew, make sure to set the memory parameter to True to enable memory capabilities for the crew.\n",
            "\n",
            "Example:\n",
            "```python\n",
            "crew = Crew(\n",
            " agents=[researcher, writer],\n",
            " tasks=[research_task, write_task],\n",
            " process=Process.sequential,\n",
            " memory=True,\n",
            " cache=True,\n",
            " max_rpm=100,\n",
            " share_crew=True\n",
            ")\n",
            "```\n",
            "\n",
            "3. Kick It Off:\n",
            "Initiate the process with your crew ready. Your agents will collaborate, leveraging their memory capabilities for a successful project outcome.\n",
            "\n",
            "Example:\n",
            "```python\n",
            "result = crew.kickoff(inputs={'topic': 'AI in healthcare'})\n",
            "print(result)\n",
            "```\n",
            "\n",
            "By following these steps, you can successfully add memory to your crew in crewAI. If you have any further questions or need additional assistance, please feel free to reach out.\n",
            "\n",
            "Best regards,\n",
            "[Your Name]\n",
            "Senior Support Representative\n",
            "crewAI\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[1m\u001b[92m [DEBUG]: == [Senior Support Representative] Task output: Hello Andrew Ng from DeepLearningAI,\n",
            "\n",
            "Thank you for reaching out for assistance with setting up a Crew and kicking it off, specifically on how to add memory to your crew. I have gathered information from the crewAI documentation on how you can achieve this.\n",
            "\n",
            "To add memory to your crew in crewAI, you need to follow these steps:\n",
            "\n",
            "1. Assemble Your Agents:\n",
            "Define your agents with distinct roles, backstories, and enhanced capabilities like memory usage. You can create agents with memory capabilities by setting the memory parameter to True when creating the agent.\n",
            "\n",
            "Example:\n",
            "```python\n",
            "researcher = Agent(\n",
            " role='Senior Researcher',\n",
            " goal='Uncover groundbreaking technologies in {topic}',\n",
            " verbose=True,\n",
            " memory=True,\n",
            " backstory=(\n",
            " \"Driven by curiosity, you're at the forefront of\"\n",
            " \"innovation, eager to explore and share knowledge that could change\"\n",
            " \"the world.\"\n",
            " ),\n",
            " tools=[search_tool],\n",
            " allow_delegation=True\n",
            ")\n",
            "```\n",
            "\n",
            "2. Form the Crew:\n",
            "Combine your agents into a crew and set the workflow process they'll follow to accomplish the tasks. When forming the crew, make sure to set the memory parameter to True to enable memory capabilities for the crew.\n",
            "\n",
            "Example:\n",
            "```python\n",
            "crew = Crew(\n",
            " agents=[researcher, writer],\n",
            " tasks=[research_task, write_task],\n",
            " process=Process.sequential,\n",
            " memory=True,\n",
            " cache=True,\n",
            " max_rpm=100,\n",
            " share_crew=True\n",
            ")\n",
            "```\n",
            "\n",
            "3. Kick It Off:\n",
            "Initiate the process with your crew ready. Your agents will collaborate, leveraging their memory capabilities for a successful project outcome.\n",
            "\n",
            "Example:\n",
            "```python\n",
            "result = crew.kickoff(inputs={'topic': 'AI in healthcare'})\n",
            "print(result)\n",
            "```\n",
            "\n",
            "By following these steps, you can successfully add memory to your crew in crewAI. If you have any further questions or need additional assistance, please feel free to reach out.\n",
            "\n",
            "Best regards,\n",
            "[Your Name]\n",
            "Senior Support Representative\n",
            "crewAI\n",
            "\n",
            "\u001b[00m\n",
            "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Support Quality Assurance Specialist\u001b[00m\n",
            "\u001b[1m\u001b[95m [INFO]: == Starting Task: Review the response drafted by the Senior Support Representative for DeepLearningAI's inquiry. Ensure that the answer is comprehensive, accurate, and adheres to the high-quality standards expected for customer support.\n",
            "Verify that all parts of the customer's inquiry have been addressed thoroughly, with a helpful and friendly tone.\n",
            "Check for references and sources used to  find the information, ensuring the response is well-supported and leaves no questions unanswered.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to ensure that the response from the Senior Support Representative is comprehensive, accurate, and meets the high-quality standards expected for customer support. I must verify that all parts of the customer's inquiry have been thoroughly addressed and that the response is well-supported with no unanswered questions.\n",
            "\n",
            "Action: Ask question to co-worker\n",
            "Action Input:\n",
            "{\n",
            "    \"coworker\": \"Senior Support Representative\",\n",
            "    \"question\": \"Can you confirm if all steps for adding memory to the crew in crewAI have been clearly explained and if any additional information or clarification is needed?\",\n",
            "    \"context\": \"Reviewing the response drafted for DeepLearningAI's inquiry on how to add memory to their crew.\"\n",
            "}\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI now can give a great answer\n",
            "\n",
            "Final Answer: \n",
            "\n",
            "After reviewing the response drafted for DeepLearningAI's inquiry on how to add memory to their crew, I can confirm that all steps for adding memory to the crew in crewAI have been clearly explained. The process involves accessing the Crew Settings, navigating to the Memory section, and then selecting the option to add memory. Additional information or clarification may be needed on specific details such as the maximum memory limit allowed per crew member or any potential restrictions on memory allocation. It is crucial to ensure that DeepLearningAI receives comprehensive guidance to successfully add memory to their crew. If any further assistance is required, please do not hesitate to reach out for more detailed instructions or troubleshooting tips.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[95m \n",
            "\n",
            "After reviewing the response drafted for DeepLearningAI's inquiry on how to add memory to their crew, I can confirm that all steps for adding memory to the crew in crewAI have been clearly explained. The process involves accessing the Crew Settings, navigating to the Memory section, and then selecting the option to add memory. Additional information or clarification may be needed on specific details such as the maximum memory limit allowed per crew member or any potential restrictions on memory allocation. It is crucial to ensure that DeepLearningAI receives comprehensive guidance to successfully add memory to their crew. If any further assistance is required, please do not hesitate to reach out for more detailed instructions or troubleshooting tips.\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mThought: I now can give a great answer\n",
            "\n",
            "Final Answer:\n",
            "Hello Andrew Ng from DeepLearningAI,\n",
            "\n",
            "Thank you for reaching out for assistance with setting up a Crew and adding memory to your crew in crewAI. I appreciate your interest in enhancing your crew's capabilities. Below are the detailed steps you need to follow to successfully add memory to your crew:\n",
            "\n",
            "1. Assemble Your Agents:\n",
            "To add memory to your crew, you first need to define your agents with distinct roles, backstories, and capabilities. When creating an agent, ensure to set the memory parameter to True. This will enable the agent to utilize memory capabilities during crew tasks.\n",
            "\n",
            "Example:\n",
            "```python\n",
            "researcher = Agent(\n",
            " role='Senior Researcher',\n",
            " goal='Uncover groundbreaking technologies in {topic}',\n",
            " verbose=True,\n",
            " memory=True,\n",
            " backstory=(\n",
            " \"Driven by curiosity, you're at the forefront of\"\n",
            " \"innovation, eager to explore and share knowledge that could change\"\n",
            " \"the world.\"\n",
            " ),\n",
            " tools=[search_tool],\n",
            " allow_delegation=True\n",
            ")\n",
            "```\n",
            "\n",
            "2. Form the Crew:\n",
            "Once you have defined your agents with memory capabilities, you can combine them into a crew. When forming the crew, ensure to set the memory parameter to True to activate memory capabilities for the entire crew.\n",
            "\n",
            "Example:\n",
            "```python\n",
            "crew = Crew(\n",
            " agents=[researcher, writer],\n",
            " tasks=[research_task, write_task],\n",
            " process=Process.sequential,\n",
            " memory=True,\n",
            " cache=True,\n",
            " max_rpm=100,\n",
            " share_crew=True\n",
            ")\n",
            "```\n",
            "\n",
            "3. Kick It Off:\n",
            "Initiate the process with your crew ready. Your agents will collaborate, leveraging their memory capabilities for a successful project outcome.\n",
            "\n",
            "Example:\n",
            "```python\n",
            "result = crew.kickoff(inputs={'topic': 'AI in healthcare'})\n",
            "print(result)\n",
            "```\n",
            "\n",
            "By following these steps, you can effectively add memory to your crew in crewAI. If you encounter any challenges or require further assistance, feel free to reach out for additional guidance. We are here to support you in optimizing your crew's performance.\n",
            "\n",
            "Best regards,\n",
            "[Your Name]\n",
            "Senior Support Representative\n",
            "crewAI\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[1m\u001b[92m [DEBUG]: == [Support Quality Assurance Specialist] Task output: Hello Andrew Ng from DeepLearningAI,\n",
            "\n",
            "Thank you for reaching out for assistance with setting up a Crew and adding memory to your crew in crewAI. I appreciate your interest in enhancing your crew's capabilities. Below are the detailed steps you need to follow to successfully add memory to your crew:\n",
            "\n",
            "1. Assemble Your Agents:\n",
            "To add memory to your crew, you first need to define your agents with distinct roles, backstories, and capabilities. When creating an agent, ensure to set the memory parameter to True. This will enable the agent to utilize memory capabilities during crew tasks.\n",
            "\n",
            "Example:\n",
            "```python\n",
            "researcher = Agent(\n",
            " role='Senior Researcher',\n",
            " goal='Uncover groundbreaking technologies in {topic}',\n",
            " verbose=True,\n",
            " memory=True,\n",
            " backstory=(\n",
            " \"Driven by curiosity, you're at the forefront of\"\n",
            " \"innovation, eager to explore and share knowledge that could change\"\n",
            " \"the world.\"\n",
            " ),\n",
            " tools=[search_tool],\n",
            " allow_delegation=True\n",
            ")\n",
            "```\n",
            "\n",
            "2. Form the Crew:\n",
            "Once you have defined your agents with memory capabilities, you can combine them into a crew. When forming the crew, ensure to set the memory parameter to True to activate memory capabilities for the entire crew.\n",
            "\n",
            "Example:\n",
            "```python\n",
            "crew = Crew(\n",
            " agents=[researcher, writer],\n",
            " tasks=[research_task, write_task],\n",
            " process=Process.sequential,\n",
            " memory=True,\n",
            " cache=True,\n",
            " max_rpm=100,\n",
            " share_crew=True\n",
            ")\n",
            "```\n",
            "\n",
            "3. Kick It Off:\n",
            "Initiate the process with your crew ready. Your agents will collaborate, leveraging their memory capabilities for a successful project outcome.\n",
            "\n",
            "Example:\n",
            "```python\n",
            "result = crew.kickoff(inputs={'topic': 'AI in healthcare'})\n",
            "print(result)\n",
            "```\n",
            "\n",
            "By following these steps, you can effectively add memory to your crew in crewAI. If you encounter any challenges or require further assistance, feel free to reach out for additional guidance. We are here to support you in optimizing your crew's performance.\n",
            "\n",
            "Best regards,\n",
            "[Your Name]\n",
            "Senior Support Representative\n",
            "crewAI\n",
            "\n",
            "\u001b[00m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "Markdown(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 808
        },
        "id": "X7jGbI-UoLrz",
        "outputId": "80813090-db94-4065-f70f-d00b3444eae8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Hello Andrew Ng from DeepLearningAI,\n\nThank you for reaching out for assistance with setting up a Crew and adding memory to your crew in crewAI. I appreciate your interest in enhancing your crew's capabilities. Below are the detailed steps you need to follow to successfully add memory to your crew:\n\n1. Assemble Your Agents:\nTo add memory to your crew, you first need to define your agents with distinct roles, backstories, and capabilities. When creating an agent, ensure to set the memory parameter to True. This will enable the agent to utilize memory capabilities during crew tasks.\n\nExample:\n```python\nresearcher = Agent(\n role='Senior Researcher',\n goal='Uncover groundbreaking technologies in {topic}',\n verbose=True,\n memory=True,\n backstory=(\n \"Driven by curiosity, you're at the forefront of\"\n \"innovation, eager to explore and share knowledge that could change\"\n \"the world.\"\n ),\n tools=[search_tool],\n allow_delegation=True\n)\n```\n\n2. Form the Crew:\nOnce you have defined your agents with memory capabilities, you can combine them into a crew. When forming the crew, ensure to set the memory parameter to True to activate memory capabilities for the entire crew.\n\nExample:\n```python\ncrew = Crew(\n agents=[researcher, writer],\n tasks=[research_task, write_task],\n process=Process.sequential,\n memory=True,\n cache=True,\n max_rpm=100,\n share_crew=True\n)\n```\n\n3. Kick It Off:\nInitiate the process with your crew ready. Your agents will collaborate, leveraging their memory capabilities for a successful project outcome.\n\nExample:\n```python\nresult = crew.kickoff(inputs={'topic': 'AI in healthcare'})\nprint(result)\n```\n\nBy following these steps, you can effectively add memory to your crew in crewAI. If you encounter any challenges or require further assistance, feel free to reach out for additional guidance. We are here to support you in optimizing your crew's performance.\n\nBest regards,\n[Your Name]\nSenior Support Representative\ncrewAI"
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CrewAI Tools\n",
        "\n",
        "- Versatility\n",
        "- Fault Tolerance\n",
        "- Caching"
      ],
      "metadata": {
        "id": "NVQh0lz0tHFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install crewai==0.28.8 crewai_tools==0.1.6 langchain_community==0.0.29"
      ],
      "metadata": {
        "id": "oT5FSO5mtJ61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Task, Crew\n",
        "# Warning control\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "RuZ2ZhtqtMph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "os.environ[\"OPENAI_MODEL_NAME\"] = 'gpt-3.5-turbo'\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
      ],
      "metadata": {
        "id": "jOXrY5iUtSmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Agents**"
      ],
      "metadata": {
        "id": "T0QOYxLAtY9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sales_rep_agent = Agent(\n",
        "    role=\"Sales Representative\",\n",
        "    goal=\"Identify high-value leads that match \"\n",
        "         \"our ideal customer profile\",\n",
        "    backstory=(\n",
        "        \"As a part of the dynamic sales team at CrewAI, \"\n",
        "        \"your mission is to scour \"\n",
        "        \"the digital landscape for potential leads. \"\n",
        "        \"Armed with cutting-edge tools \"\n",
        "        \"and a strategic mindset, you analyze data, \"\n",
        "        \"trends, and interactions to \"\n",
        "        \"unearth opportunities that others might overlook. \"\n",
        "        \"Your work is crucial in paving the way \"\n",
        "        \"for meaningful engagements and driving the company's growth.\"\n",
        "    ),\n",
        "    allow_delegation=False,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "-PrOMwbptTH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lead_sales_rep_agent = Agent(\n",
        "    role=\"Lead Sales Representative\",\n",
        "    goal=\"Nurture leads with personalized, compelling communications\",\n",
        "    backstory=(\n",
        "        \"Within the vibrant ecosystem of CrewAI's sales department, \"\n",
        "        \"you stand out as the bridge between potential clients \"\n",
        "        \"and the solutions they need.\"\n",
        "        \"By creating engaging, personalized messages, \"\n",
        "        \"you not only inform leads about our offerings \"\n",
        "        \"but also make them feel seen and heard.\"\n",
        "        \"Your role is pivotal in converting interest \"\n",
        "        \"into action, guiding leads through the journey \"\n",
        "        \"from curiosity to commitment.\"\n",
        "    ),\n",
        "    allow_delegation=False,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "r-DS0Og0taef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Tools**"
      ],
      "metadata": {
        "id": "EzdRs6qrtdHL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**crewAI Tools**"
      ],
      "metadata": {
        "id": "SaR0MqvHtdvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai_tools import DirectoryReadTool, \\\n",
        "                         FileReadTool, \\\n",
        "                         SerperDevTool"
      ],
      "metadata": {
        "id": "Dwj_H1BktfKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory_read_tool = DirectoryReadTool(directory='./instructions')\n",
        "file_read_tool = FileReadTool()\n",
        "search_tool = SerperDevTool()"
      ],
      "metadata": {
        "id": "HkVU96ZPtg4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Custom Tool**\n",
        "\n",
        "- Create a custom tool using crewAi's [BaseTool](https://docs.crewai.com/core-concepts/Tools/#subclassing-basetool) class"
      ],
      "metadata": {
        "id": "jmFD_drhtixw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai_tools import BaseTool"
      ],
      "metadata": {
        "id": "0Gx_rzhetlAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Every Tool needs to have a `name` and a `description`.\n",
        "- For simplicity and classroom purposes, `SentimentAnalysisTool` will return `positive` for every text.\n",
        "- When running locally, you can customize the code with your logic in the `_run` function."
      ],
      "metadata": {
        "id": "czTvpBPDtncN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentAnalysisTool(BaseTool):\n",
        "    name: str =\"Sentiment Analysis Tool\"\n",
        "    description: str = (\"Analyzes the sentiment of text \"\n",
        "         \"to ensure positive and engaging communication.\")\n",
        "\n",
        "    def _run(self, text: str) -> str:\n",
        "        # Your custom code tool goes here\n",
        "        return \"positive\""
      ],
      "metadata": {
        "id": "u6f6g-ewtmWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_analysis_tool = SentimentAnalysisTool()"
      ],
      "metadata": {
        "id": "YMssBZN9tqwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Tasks**\n",
        "\n",
        "- The Lead Profiling Task is using crewAI Tools."
      ],
      "metadata": {
        "id": "yPFw4RaatsnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lead_profiling_task = Task(\n",
        "    description=(\n",
        "        \"Conduct an in-depth analysis of {lead_name}, \"\n",
        "        \"a company in the {industry} sector \"\n",
        "        \"that recently showed interest in our solutions. \"\n",
        "        \"Utilize all available data sources \"\n",
        "        \"to compile a detailed profile, \"\n",
        "        \"focusing on key decision-makers, recent business \"\n",
        "        \"developments, and potential needs \"\n",
        "        \"that align with our offerings. \"\n",
        "        \"This task is crucial for tailoring \"\n",
        "        \"our engagement strategy effectively.\\n\"\n",
        "        \"Don't make assumptions and \"\n",
        "        \"only use information you absolutely sure about.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A comprehensive report on {lead_name}, \"\n",
        "        \"including company background, \"\n",
        "        \"key personnel, recent milestones, and identified needs. \"\n",
        "        \"Highlight potential areas where \"\n",
        "        \"our solutions can provide value, \"\n",
        "        \"and suggest personalized engagement strategies.\"\n",
        "    ),\n",
        "    tools=[directory_read_tool, file_read_tool, search_tool],\n",
        "    agent=sales_rep_agent,\n",
        ")"
      ],
      "metadata": {
        "id": "PdgsKuk_ttf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The Personalized Outreach Task is using your custom Tool `SentimentAnalysisTool`, as well as crewAI's `SerperDevTool` (search_tool)."
      ],
      "metadata": {
        "id": "IbpqWGUptxMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "personalized_outreach_task = Task(\n",
        "    description=(\n",
        "        \"Using the insights gathered from \"\n",
        "        \"the lead profiling report on {lead_name}, \"\n",
        "        \"craft a personalized outreach campaign \"\n",
        "        \"aimed at {key_decision_maker}, \"\n",
        "        \"the {position} of {lead_name}. \"\n",
        "        \"The campaign should address their recent {milestone} \"\n",
        "        \"and how our solutions can support their goals. \"\n",
        "        \"Your communication must resonate \"\n",
        "        \"with {lead_name}'s company culture and values, \"\n",
        "        \"demonstrating a deep understanding of \"\n",
        "        \"their business and needs.\\n\"\n",
        "        \"Don't make assumptions and only \"\n",
        "        \"use information you absolutely sure about.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A series of personalized email drafts \"\n",
        "        \"tailored to {lead_name}, \"\n",
        "        \"specifically targeting {key_decision_maker}.\"\n",
        "        \"Each draft should include \"\n",
        "        \"a compelling narrative that connects our solutions \"\n",
        "        \"with their recent achievements and future goals. \"\n",
        "        \"Ensure the tone is engaging, professional, \"\n",
        "        \"and aligned with {lead_name}'s corporate identity.\"\n",
        "    ),\n",
        "    tools=[sentiment_analysis_tool, search_tool],\n",
        "    agent=lead_sales_rep_agent,\n",
        ")"
      ],
      "metadata": {
        "id": "sAJmw1AAtxg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating the Crew**"
      ],
      "metadata": {
        "id": "fIjXCH9Ctyw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "crew = Crew(\n",
        "    agents=[sales_rep_agent,\n",
        "            lead_sales_rep_agent],\n",
        "\n",
        "    tasks=[lead_profiling_task,\n",
        "           personalized_outreach_task],\n",
        "\n",
        "    verbose=2,\n",
        "\tmemory=True\n",
        ")"
      ],
      "metadata": {
        "id": "gjAgy1rjt0Yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Running the Crew**"
      ],
      "metadata": {
        "id": "FPe42ypkt00W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\n",
        "    \"lead_name\": \"DeepLearningAI\",\n",
        "    \"industry\": \"Online Learning Platform\",\n",
        "    \"key_decision_maker\": \"Andrew Ng\",\n",
        "    \"position\": \"CEO\",\n",
        "    \"milestone\": \"product launch\"\n",
        "}\n",
        "\n",
        "result = crew.kickoff(inputs=inputs)"
      ],
      "metadata": {
        "id": "9DRAJAo7t3AD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vector Databases"
      ],
      "metadata": {
        "id": "3TY5pCv8w-5H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pinecone VectorDB"
      ],
      "metadata": {
        "id": "fX0221ouxAfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain pinecone-client pypdf openai tiktoken langchain_pinecone langchain-openai"
      ],
      "metadata": {
        "id": "pcgnKk1SNq5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFDirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_openai import OpenAI\n",
        "import os"
      ],
      "metadata": {
        "id": "QULNAZX-xwSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir pdfs"
      ],
      "metadata": {
        "id": "cs8UOQR31HCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://papers.neurips.cc/paper/7181-attention-is-all-you-need.pdf\n",
        "!mv /content/7181-attention-is-all-you-need.pdf /content/pdfs/attention-is-all-you-need.pdf"
      ],
      "metadata": {
        "id": "gEjw4N0H4-Pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFDirectoryLoader('pdfs')"
      ],
      "metadata": {
        "id": "qypQypsW4smX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = loader.load()\n",
        "len(data), data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRwx8q085x8L",
        "outputId": "16b9251f-9047-4b5b-c085-7bcf5e4eb3ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11,\n",
              " Document(page_content='Attention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.comNoam Shazeer∗\\nGoogle Brain\\nnoam@google.comNiki Parmar∗\\nGoogle Research\\nnikip@google.comJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.comAidan N. Gomez∗†\\nUniversity of Toronto\\naidan@cs.toronto.eduŁukasz Kaiser∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring signiﬁcantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41.0 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature.\\n1 Introduction\\nRecurrent neural networks, long short-term memory [ 12] and gated recurrent [ 7] neural networks\\nin particular, have been ﬁrmly established as state of the art approaches in sequence modeling and\\ntransduction problems such as language modeling and machine translation [ 29,2,5]. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\\narchitectures [31, 21, 13].\\n∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the ﬁrst Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\\nefﬁcient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research.\\n†Work performed while at Google Brain.\\n‡Work performed while at Google Research.\\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.', metadata={'source': 'pdfs/attention-is-all-you-need.pdf', 'page': 0}))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)"
      ],
      "metadata": {
        "id": "lzsGNVdY5yu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks = text_splitter.split_documents(data)"
      ],
      "metadata": {
        "id": "2T7qWMvc5_E4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text_chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEH3J1O46isS",
        "outputId": "87879de8-62e8-4b05-fd3d-7255c8be81bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "76"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_chunks[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mMjatJ46nsU",
        "outputId": "8a85739d-4a5b-4320-f823-7757351dc852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention Is All You Need\n",
            "Ashish Vaswani∗\n",
            "Google Brain\n",
            "avaswani@google.comNoam Shazeer∗\n",
            "Google Brain\n",
            "noam@google.comNiki Parmar∗\n",
            "Google Research\n",
            "nikip@google.comJakob Uszkoreit∗\n",
            "Google Research\n",
            "usz@google.com\n",
            "Llion Jones∗\n",
            "Google Research\n",
            "llion@google.comAidan N. Gomez∗†\n",
            "University of Toronto\n",
            "aidan@cs.toronto.eduŁukasz Kaiser∗\n",
            "Google Brain\n",
            "lukaszkaiser@google.com\n",
            "Illia Polosukhin∗‡\n",
            "illia.polosukhin@gmail.com\n",
            "Abstract\n",
            "The dominant sequence transduction models are based on complex recurrent or\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_chunks[1].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C80gdjJt6y-e",
        "outputId": "19c3cd13-6ec6-4d26-d8a4-baf869e324dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "convolutional neural networks that include an encoder and a decoder. The best\n",
            "performing models also connect the encoder and decoder through an attention\n",
            "mechanism. We propose a new simple network architecture, the Transformer,\n",
            "based solely on attention mechanisms, dispensing with recurrence and convolutions\n",
            "entirely. Experiments on two machine translation tasks show these models to\n",
            "be superior in quality while being more parallelizable and requiring signiﬁcantly\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key = \"\" # @param {type:\"string\"}"
      ],
      "metadata": {
        "id": "sP8UUFY07rrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = OpenAIEmbeddings(api_key=openai_api_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kqgo5x9Z8TtR",
        "outputId": "2c9f2ea0-b77f-45aa-924c-e06c34c947af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_example = embedding.embed_query(\"Hello World\")\n",
        "len(embedding_example), embedding_example[:15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3Z5US0a8YhY",
        "outputId": "988bccd4-3483-4e9f-fd98-7de4b19621cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1536,\n",
              " [-0.007116983617481661,\n",
              "  0.0034469901452434362,\n",
              "  -0.007148840903008569,\n",
              "  -0.029156057052714266,\n",
              "  -0.013061608137966748,\n",
              "  0.010946264448676999,\n",
              "  -0.020274164077690417,\n",
              "  0.0052533149518593026,\n",
              "  -0.008563317325787047,\n",
              "  -0.03017549950280105,\n",
              "  0.024390162806934363,\n",
              "  0.009863106496213825,\n",
              "  -0.027524949877633466,\n",
              "  -0.006632748500256566,\n",
              "  0.009111268411049814])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pinecone_api_key = \"\" # @param {type:\"string\"}\n",
        "pinecone_api_env = \"\" # @param {type:\"string\"}"
      ],
      "metadata": {
        "id": "wD170J5l1DGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import Pinecone\n",
        "pc = Pinecone(\n",
        "    api_key=pinecone_api_key,\n",
        "    environment=pinecone_api_env\n",
        ")"
      ],
      "metadata": {
        "id": "q6dORQG88Yc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pc.list_indexes()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFRs2YjU8Yab",
        "outputId": "bd6becf5-80ad-40b3-c554-4b52d43bcb4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'indexes': [{'dimension': 1536,\n",
              "              'host': 'genai-course-iqutuem.svc.gcp-starter.pinecone.io',\n",
              "              'metric': 'cosine',\n",
              "              'name': 'genai-course',\n",
              "              'spec': {'pod': {'environment': 'gcp-starter',\n",
              "                               'pod_type': 'starter',\n",
              "                               'pods': 1,\n",
              "                               'replicas': 1,\n",
              "                               'shards': 1}},\n",
              "              'status': {'ready': True, 'state': 'Ready'}}]}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Embeddings from text chunks"
      ],
      "metadata": {
        "id": "ChlWuiNPB4er"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "0SGExxwzDIvs",
        "outputId": "9a525bf5-8d9f-419e-ab92-6c5cdd19bef0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Attention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.comNoam Shazeer∗\\nGoogle Brain\\nnoam@google.comNiki Parmar∗\\nGoogle Research\\nnikip@google.comJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.comAidan N. Gomez∗†\\nUniversity of Toronto\\naidan@cs.toronto.eduŁukasz Kaiser∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_name = \"genai-course\"\n",
        "os.environ[\"PINECONE_API_KEY\"] = pinecone_api_key\n",
        "os.environ[\"PINECONE_INDEX_NAME\"] = index_name"
      ],
      "metadata": {
        "id": "DEhb3ahQEHBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_name = \"genai-course\"\n",
        "\n",
        "docsearch = PineconeVectorStore.from_documents(\n",
        "    text_chunks,\n",
        "    embedding,\n",
        "    index_name=index_name,\n",
        ")"
      ],
      "metadata": {
        "id": "b22MmbDTDVAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Querying VectorDB"
      ],
      "metadata": {
        "id": "WtglMMDjKD-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What are decoder components\""
      ],
      "metadata": {
        "id": "6X-uu_jaFCqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = docsearch.similarity_search(query)"
      ],
      "metadata": {
        "id": "suwasDV8B0dP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs), docs[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XL32AD9WFSo4",
        "outputId": "c4abb9bd-9f66-4a87-f908-a01758119a07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4,\n",
              " 'Decoder: The decoder is also composed of a stack of N= 6identical layers. In addition to the two\\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\\nattention over the output of the encoder stack. Similar to the encoder, we employ residual connections\\naround each of the sub-layers, followed by layer normalization. We also modify the self-attention\\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions. This')"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manually decoding embeded vectors"
      ],
      "metadata": {
        "id": "cafiTMvpFzY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(api_key=openai_api_key)"
      ],
      "metadata": {
        "id": "Zw7aRTtt7sN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=docsearch.as_retriever()\n",
        ")"
      ],
      "metadata": {
        "id": "zXXhDIf7GLas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "XH83DC_qGg6g",
        "outputId": "757145c3-e7a6-4ea7-c164-ee81356af10a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The decoder components include a stack of N= 6 identical layers, with a third sub-layer for multi-head attention over the output of the encoder stack. The decoder also uses residual connections and layer normalization, and modifies the self-attention sub-layer to prevent positions from attending to subsequent positions. Additionally, the decoder follows the same overall architecture as the encoder, using stacked self-attention and point-wise, fully connected layers. '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docsearch.as_retriever()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcsS5xBTJaCq",
        "outputId": "c72495ab-7b0f-4ffd-e638-2d79c5b02ac4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VectorStoreRetriever(tags=['PineconeVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_pinecone.vectorstores.PineconeVectorStore object at 0x7bf5a8303a90>)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Pinecone directly"
      ],
      "metadata": {
        "id": "WZsEJp1WKM3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = pc.Index(index_name)"
      ],
      "metadata": {
        "id": "-rbJrKv2J3nD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pc.list_indexes()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpirQnB4KSKT",
        "outputId": "a5fc6a1f-9844-4dc3-e003-05103979a34b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'indexes': [{'dimension': 1536,\n",
              "              'host': 'genai-course-iqutuem.svc.gcp-starter.pinecone.io',\n",
              "              'metric': 'cosine',\n",
              "              'name': 'genai-course',\n",
              "              'spec': {'pod': {'environment': 'gcp-starter',\n",
              "                               'pod_type': 'starter',\n",
              "                               'pods': 1,\n",
              "                               'replicas': 1,\n",
              "                               'shards': 1}},\n",
              "              'status': {'ready': True, 'state': 'Ready'}}]}"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeded_query = embedding.embed_query(query)\n",
        "len(embeded_query), embeded_query[:15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKeG5UZeKgYS",
        "outputId": "0415829e-87d0-495a-dc9d-5d2eee214bca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1536,\n",
              " [-0.027967285621545507,\n",
              "  0.007272935520456191,\n",
              "  0.00372656855753541,\n",
              "  -0.036588130280438405,\n",
              "  -0.030850511135379583,\n",
              "  0.01670829110761046,\n",
              "  -0.006833243722728746,\n",
              "  -0.011114833238243343,\n",
              "  -0.0013605219229251401,\n",
              "  -0.02120612253666261,\n",
              "  0.03330125095949351,\n",
              "  0.025934610889234464,\n",
              "  -0.02910615895445195,\n",
              "  -0.0020831302940467426,\n",
              "  -0.019865422300200757])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = index.query(\n",
        "    # namespace=\"ns1\",\n",
        "    vector=embeded_query,\n",
        "    top_k=3,\n",
        "    include_values=True\n",
        ")"
      ],
      "metadata": {
        "id": "Ovf4ZeYLJ-5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(result.matches), \\\n",
        "result.matches[0].id, \\\n",
        "result.matches[0].score, \\\n",
        "result.matches[0].values[:15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Xv23QcBKqaQ",
        "outputId": "0afe8c8f-ca26-4967-ff83-5e656cc822a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3,\n",
              " '6127f943-c2e2-4a09-9d60-357eec482557',\n",
              " 0.796478271,\n",
              " [-0.0240785182,\n",
              "  0.0146332774,\n",
              "  0.012422544,\n",
              "  -0.0345504135,\n",
              "  0.0149207413,\n",
              "  0.00992434658,\n",
              "  -0.0147154108,\n",
              "  0.00101125659,\n",
              "  0.00319119077,\n",
              "  -0.00310905813,\n",
              "  0.0283357203,\n",
              "  0.0291296691,\n",
              "  0.00343587715,\n",
              "  0.00145614112,\n",
              "  -0.00544127962])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index.fetch([result.matches[0].id]) \\\n",
        "  .vectors[result.matches[0].id]['metadata'][\"text\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "Ud5w8dgkMKvW",
        "outputId": "8ffea901-1b5f-4c31-b6e5-eeb5f6a113c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Decoder: The decoder is also composed of a stack of N= 6identical layers. In addition to the two\\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\\nattention over the output of the encoder stack. Similar to the encoder, we employ residual connections\\naround each of the sub-layers, followed by layer normalization. We also modify the self-attention\\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions. This'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ChromaDB"
      ],
      "metadata": {
        "id": "kD8z-5adnZ4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q chromadb openai langchain tiktoken langchain-openai"
      ],
      "metadata": {
        "id": "MZG9y6-P7-tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://www.dropbox.com/s/vs6ocyvpzzncvwh/new_articles.zip\n",
        "!unzip -q new_articles.zip -d new_articles\n",
        "!rm -f new_articles/05-03** new_articles/05-04** new_articles/05-05**"
      ],
      "metadata": {
        "id": "4hzdK-o_8D3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "openai_api_key = \"\" # @param {type:\"string\"}\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
      ],
      "metadata": {
        "id": "zep2gqAm93yK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain_openai import OpenAI\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.document_loaders import TextLoader"
      ],
      "metadata": {
        "id": "XjPlqPvD_Lu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = DirectoryLoader(\"./new_articles\", glob=\"./*.txt\", loader_cls=TextLoader)"
      ],
      "metadata": {
        "id": "M9ASBhRdAGWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document = loader.load()\n",
        "\n",
        "len(document), document[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcY-rZuJAJVU",
        "outputId": "8cc722de-70ed-4282-8160-a1340b1330ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6,\n",
              " Document(page_content='Welcome back to This Week in Apps, the weekly TechCrunch series that recaps the latest in mobile OS news, mobile applications and the overall app economy.\\n\\nThe app economy in 2023 hit a few snags, as consumer spending last year dropped for the first time by 2% to $167 billion, according to data.ai’s “State of Mobile” report. However, downloads are continuing to grow, up 11% year-over-year in 2022 to reach 255 billion. Consumers are also spending more time in mobile apps than ever before. On Android devices alone, hours spent in 2022 grew 9%, reaching 4.1 trillion.\\n\\nThis Week in Apps offers a way to keep up with this fast-moving industry in one place with the latest from the world of apps, including news, updates, startup fundings, mergers and acquisitions, and much more.\\n\\nDo you want This Week in Apps in your inbox every Saturday? Sign up here: techcrunch.com/newsletters\\n\\nTop Stories\\n\\nDorsey criticizes Twitter, Musk on the alternative social networks he’s backing\\n\\nAs demand for Bluesky, the Jack Dorsey-backed decentralized Twitter rival grows, the former Twitter CEO took to the app to share his thoughts on Twitter’s future, Elon Musk and the decision to take the company private. As TechCrunch’s Darrell Etherington reported, Dorsey responded to questions posed to him from other users and reporters on Bluesky, including one where he was asked if Musk has proven to be the best possible steward for the social network.\\n\\nDorsey said he had not:\\n\\nNo. Nor do I think he acted right after realizing his timing was bad. Nor do I think the board should have forced the sale. It all went south. But it happened and all we can do now is build something to avoid that ever happening again. So I’m happy Jay and team and nostr devs exist and building it.\\n\\nHowever, the Twitter co-founder stressed that Twitter would have never survived as a public company and defended himself from an accusation that he was deflecting blame for Twitter’s current situation.\\n\\nThough Bluesky is having a moment, particularly as a haven for marginalized groups, sex workers and trans users, it’s not the only Twitter alternative Dorsey is now backing. In fact, he’s been more active in recent days on the social network nostr (which he also financially backed), where he’s also been critical of some of Musk’s recent decisions. For example, as The NYT reported, Dorsey posted last month “This is weak,” in response to Musk’s move to stop Twitter users from linking to Substack after it launched a Twitter-like service for its own community of writers and readers.\\n\\nDorsey also touted his belief in these platforms during Block’s recent earnings call, suggesting on his nostr profile this may be the first time the network’s name had been mentioned during a public earnings event.\\n\\n“Open protocols represent another fork in the road moment for people and companies,” Dorsey told investors. “Bitcoin, nostr, Bluesky, web5 and others are all working to level the playing field for competition and give individuals and organizations entirely new capabilities,” he added.\\n\\nOver the past few weeks, Bluesky has been gaining traction, but the network has been difficult to access due to its invite-only nature. That’s turned Bluesky invites into hot commodities, where they’re even selling for hundreds of dollars on eBay, as most users have to wait to receive only one invite every two weeks.\\n\\nBluesky leadership will also sometimes gift a user with a larger number of invites in order to have them invite members of a specific community. Developers who can demonstrate they’re building a Bluesky app may also request additional invites, we understand.\\n\\nThe network has received outsized press coverage relative to its size — just 50,000+ users — possibly because of the heavy infusion of tech journalists on there and Dorsey’s name attached. But the reality is that Bluesky’s future remains uncertain. The company, for now, is able to build and grow thanks to the $13 million in initial funds it received from Twitter, where it was incubated under Dorsey’s leadership. It has since spun out into its own, independent company (a public benefit LLC). It’s unclear how Bluesky intends to maintain its operations in the long term, not to mention its freewheeling culture and accepting community. Networks can often be pleasant and welcoming when small, like Bluesky — or early Twitter, for that matter — but face challenges once they scale to millions of users.\\n\\nNewFronts round-up\\n\\nThis week was IAB’s NewFronts, where digital media companies and social networks pitched their platforms to advertisers looking to reach online audiences. The event saw major brands introducing a range of new offerings, including both ad products and formats, as well as touting their latest features, in some cases, as Snap did with its My AI integration.\\n\\nHere’s what you may have missed from the app makers’ NewFronts this week:\\n\\nSnap said it’s beginning to test a feature that lets partners leverage its new My AI chatbot to place sponsored links in front of users. Snap also announced new ad slots, including the option to reserve the first video ad seen in Snapchat’s Friend Stories and the ability to advertise within its TikTok-like Spotlight feature.\\n\\nSnap also announced including the option to reserve the and the ability to YouTube introduced new ad opportunities for Shorts, including the expansion of Shorts into Video reach campaigns that leverage Google AI to serve the best combination of ads and improve reach on YouTube. Plus, YouTube Select is now coming to Shorts, allowing advertisers to place their ads alongside the most popular YouTube Shorts’ content, similar to TikTok Pulse. Another option, First Position on Shorts, will let advertisers be the first ad Shorts users see in their viewing session.\\n\\nincluding the that leverage Google AI to serve the best combination of ads and improve reach on YouTube. Plus, allowing advertisers to place their ads alongside the most popular YouTube Shorts’ content, similar to TikTok Pulse. Another option, will let advertisers be the first ad Shorts users see in their viewing session. TikTok announced partnerships with big-name publishers, including NBCU, Condé Nast, DotDash Meredith, BuzzFeed and others, in an effort to pull in more premium ad dollars. The new premium ad product, Pulse Premiere, would allow marketers, for the first time, to position their brand ads directly after TikTok’s publisher and media partners’ content in over a dozen categories, including lifestyle, sports, entertainment, education and more. Publisher partners would receive a rev share as a result.\\n\\nThe would allow marketers, for the first time, to position their brand ads directly after TikTok’s publisher and media partners’ content in over a dozen categories, including lifestyle, sports, entertainment, education and more. Publisher partners would receive a rev share as a result. Meta announced AR would become available to Reels Ads and Facebook Stories. They had previously been available only to the Facebook Feed, Instagram Feed and Instagram Stories. It also announced features to make Reels Ads more interactive, including a t est of a larger “call to action” button with additional advertiser information on Facebook and Instagram Reels ads. Other updates included multi-destination product ads, the ability to pause a video ad to preview a link’s destination and support for Reels Ads campaigns with select third-party measurement firms .\\n\\nThey had previously been available only to the Facebook Feed, Instagram Feed and Instagram Stories. It also announced features to make Reels Ads more interactive, including a t with additional advertiser information on Facebook and Instagram Reels ads. Other updates included the ability to and support for . NBCU will let Peacock users shop products that appear in its content through “Must ShopTV,” which puts a QR code on the screen when a shoppable product appears.\\n\\nApple & Google team up on Bluetooth tracker safety\\n\\nAfter numerous cases of Bluetooth trackers like Apple’s AirTag being used for stalking or other criminal apps, Apple and Google this week released a joint announcement saying they will work together to lead an industry-wide initiative to draft a specification that would alert users in the case of unwanted tracking from Bluetooth devices. The companies said they’re seeking input from other industry participants and advocacy groups in the matter, and noted that other tracker makers like Samsung, Tile, Chipolo, eufy Security and Pebblebee have also expressed interest in the draft.\\n\\nThe companies submitted a proposed specification as an Internet-Draft via a standards development organization, the Internet Engineering Task Force (IETF). Other interested parties are now being invited to review and comment over the next three months. After this time, Apple and Google will offer feedback and will release a production implementation of the specification by year’s end that will be supported in future versions of iOS and Android, they said.\\n\\nThe spec would build on the AirTag protections Apple had already released but also, critically, would ensure that users would be able to combat unwanted tracking by offering tools across both iOS and Android platforms.\\n\\nGoogle’s participation could signal more than a desire to protect its users — it’s been rumored the company may also be developing an AirTag rival.\\n\\nPlatforms\\n\\nApple\\n\\nGoogle — I/O Preview\\n\\nGoogle I/O kicks off next week and we already know at least one of the announcements — because Google leaked it. The company plans to introduce its first foldable smartphone with the Pixel Fold. The device shares Pixel’s familiar camera bar and features an interface that showcases Material UI design. We expect to learn more at the event.\\n\\nIn addition, Google I/O 2023 should bring a Pixel 7a , a budget device that could also help address Pixel demand in emerging markets, plus possibly a Pixel tablet, an AirTag rival, a Wear OS update, and a lot of new developer tools and features. We also expect to hear quite a bit about Google’s AI plans, with generative AI (like Bard) appearing across Google’s line of products.\\n\\n, a budget device that could also help address Pixel demand in emerging markets, plus possibly a Pixel tablet, an AirTag rival, a Wear OS update, and a lot of new developer tools and features. We also expect to hear quite a bit about Google’s AI plans, with generative AI (like Bard) appearing across Google’s line of products. To get ready for I/O, even if you’re attending virtually, Google offered a new planning guide and a playlist of developer content to help attendees prepare.\\n\\nto help attendees prepare. Checks, Google’s AI-powered data protection project, exited to Google from its in-house incubator Area 120. The tool uses AI to check mobile apps for compliance with various privacy rules and regulations.\\n\\nApp Updates\\n\\nSocial\\n\\nSocial networking app IRL’s CEO Abraham Shafi stepped down following allegations he used bots to inflate the number of users IRL reported publicly and to its investors , The Information reported. A former employee had alleged he was fired after expressing concern over the use of bots. The SEC is now investigating if the company violated securities laws. IRL raised around $200 million from SoftBank Vision Fund, Founders Fund and others.\\n\\n, The Information reported. A former employee had alleged he was fired after expressing concern over the use of bots. The SEC is now investigating if the company violated securities laws. IRL raised around $200 million from SoftBank Vision Fund, Founders Fund and others. After laying off 50% of staff, declining audio social network Clubhouse says it’s building “Clubhouse 2.0,” but hasn’t shared exactly what that plan may involve. Last year, the company began shifting its focus away from public audio to private rooms but it’s not clear there’s much demand for audio social networking in the post-pandemic market.\\n\\nbut hasn’t shared exactly what that plan may involve. Last year, the company began shifting its focus away from public audio to private rooms but it’s not clear there’s much demand for audio social networking in the post-pandemic market. Once-hot viral app Poparazzi shuts down and returns remaining funds to investors. The app had let friends tag others to build out their social profiles of real moments, not polished images, but had been on the decline, with only a few thousand MAUs down from a height of 4 million MAUs previously.\\n\\nA Twitter bug saw users able to regain their blue Verification checks just by editing their bio. Shortly afterward, the Twitter desktop website began randomly logging out users. Later in the week, the mobile website was also down.\\n\\nShortly afterward, the Twitter desktop website began randomly logging out users. Later in the week, the mobile website was also down. As Bluesky gains attention, rival decentralized social platform Mastodon announced a new, simpler onboarding experience that provides new users with an account on mastodon.social by default , instead of requiring them to pick a server. This doesn’t eliminate server choice, it simply means that joining another server requires a few extra clicks.\\n\\n, instead of requiring them to pick a server. This doesn’t eliminate server choice, it simply means that joining another server requires a few extra clicks. Neighborhood social network Nextdoor added new features powered by generative AI, including an Assistant feature aimed at helping users write posts that are more likely to drive positive community engagement. The Assistant will offer writing suggestions that users can review and optionally adopt. The company says it will also use AI to better match content to users when providing recommendations.\\n\\nincluding an Assistant feature aimed at helping users write posts that are more likely to drive positive community engagement. The Assistant will offer writing suggestions that users can review and optionally adopt. The company says it will also use AI to better match content to users when providing recommendations. BeReal is testing another new feature in the U.K., “RealPeople,” that shows users a timeline of the “world’s most interesting people” — that is, athletes, artists, activists and other public figures. The company also recently began testing the option to post more often as usage has declined.\\n\\nand other public figures. The company also recently began testing the option to post more often as usage has declined. Meta introduced new discovery and personalization options for Facebook Reels. Users can now choose “Show More” or “Show Less” options to control what sort of Reels they want to see. Facebook will also explain why it’s showing you a Reel, like if a friend viewed it, and is adding Reels to the main navigation at the top of Facebook Watch.\\n\\nWordPress drops Twitter integration, says sharing to Instagram and Mastodon is coming instead. The Automattic-owned publishing platform said the Twitter connection on Jetpack and WordPress.com will cease to work, meaning users’ blog posts will no longer be auto-shared to Twitter as before. The company said Elon Musk’s decision to “dramatically change the terms and pricing” for Twitter’s API was to blame for this decision. The API now starts at $42,000/month for 50 million tweets. The move will likely hurt Twitter more than WordPress, as the latter powers over 40% of the global internet, including WordPress.com blogs.\\n\\nThe Automattic-owned publishing platform said the Twitter connection on Jetpack and WordPress.com will cease to work, meaning users’ blog posts will no longer be auto-shared to Twitter as before. The company said Elon Musk’s decision to “dramatically change the terms and pricing” for Twitter’s API was to blame for this decision. The API now starts at $42,000/month for 50 million tweets. The move will likely hurt Twitter more than WordPress, as the latter powers over 40% of the global internet, including WordPress.com blogs. Mozilla announced it’s opening up its own Mastodon server — or “instance,” in Mastodon lingo — into private beta testing. The company had said last year it planned to create and begin testing a publicly accessible instance at mozilla.social. It explains its approach to Mastodon will involve high levels of moderation.\\n\\nThe company had said last year it planned to create and begin testing a publicly accessible instance at mozilla.social. It explains its approach to Mastodon will involve high levels of moderation. Twitter announced it would make its API free for public service announcements after New York’s Metro Transit Service (MTS) abandoned the service and the National Weather Services (NWS) said it would no longer auto-post warnings.\\n\\nafter New York’s Metro Transit Service (MTS) abandoned the service and the National Weather Services (NWS) said it would no longer auto-post warnings. TikTok’s U.S. head of trust and safety Eric Han is leaving the company on May 12 as lawmakers weigh a TikTok ban. Han had played a key role in TikTok’s strategy to avoid a U.S. ban.\\n\\nas lawmakers weigh a TikTok ban. Han had played a key role in TikTok’s strategy to avoid a U.S. ban. Discord is making all users change their usernames, the company announced this week. Originally, Discord users had been identified by a name and random number separated by a hash sign, but now it wants to adopt a simpler format so people can more easily share their usernames with others. The new plan will include a unique alphanumeric username with the @ symbol in front of it, plus a freely assignable display name that can be changed at any time.\\n\\nAI\\n\\nSlack introduced SlackGPT, its own generative AI built on Slack’s platform which developers can use to create AI-driven experiences.\\n\\nwhich developers can use to create AI-driven experiences. Microsoft launched its Bing chatbot to all users globally, meaning there’s no more waitlist to get started. It’s also adding more image- and graphic-centric answers in Bing Chat, including by creating graphs and charts and generating images from text prompts. It will also allow users to export their Bing Chat histories. And it will embrace multimodality, meaning it can understand queries with images and text combined. Bing now sees more than 100 million daily active users and says visitors have engaged in over half a billion chats.\\n\\nIt’s also adding more image- and graphic-centric answers in Bing Chat, including by creating graphs and charts and generating images from text prompts. It will also allow users to export their Bing Chat histories. And it will embrace multimodality, meaning it can understand queries with images and text combined. Bing now sees more than 100 million daily active users and says visitors have engaged in over half a billion chats. Plexamp, the music player originally incubated by the Labs division of media company Plex, is tapping into ChatGPT with its latest update. The new feature called “Sonic Sage,” powered by OpenAI’s ChatGPT, will build unique music playlists by scanning users’ libraries and leveraging their TIDAL subscription.\\n\\nMedia & Entertainment\\n\\nFintech\\n\\nYC-backed Kenyan fintech Fingo launched its neobanking app, developed in collaboration with Pan-African financial institution Ecobank Kenya. The company raised $4 million in seed funding after its YC S21 participation. Fingo offers users a bank account, paired with free peer-to-peer transactions and access to savings, financial education and smart spending analytics.\\n\\nThe company raised $4 million in seed funding after its YC S21 participation. Fingo offers users a bank account, paired with free peer-to-peer transactions and access to savings, financial education and smart spending analytics. The FDIC is looking into Tellus, an Andreessen Horowitz-backed fintech company that claims it can offer people higher yields on their savings balances by using that money to fund certain U.S. single-family-home loans. U.S. Senator Sherrod Brown, chairman of the Senate Banking, Housing, and Urban Affairs Committee, wrote a letter to FDIC Chairman Martin Gruenberg expressing concerns about Tellus, and asking the FDIC to review Tellus’s business practices which may put customers at risk.\\n\\nMessaging\\n\\nWhatsApp now lets users create single-vote polls and forward media with captions, Meta announced this week. Single-vote polls let users run a poll where people are only allowed to vote once, including multiple choice, as has been the default.\\n\\nMeta announced this week. Single-vote polls let users run a poll where people are only allowed to vote once, including multiple choice, as has been the default. Reddit’s latest update provides link previews for messaging apps. Now, when you share a Reddit link via a messaging app, it will include a visual preview of the content, the subreddit name, the total upvotes tally and the number of comments. The update also includes the ability to share directly to IG Stories and other tools for publishers.\\n\\nTravel & Transportation\\n\\nFollowing its acquisition by Via, Citymapper said it’s lowering the paywall for its premium features while also introducing a new subscription plan ($1.49/mo) purely for removing ads.\\n\\nwhile also introducing a new subscription plan ($1.49/mo) purely for removing ads. Uber reported a Q1 earnings beat with its revenue up 29% YoY to $8.82 billion, gross bookings up 19% YoY to $31.4 billion and adjusted EBITDA up 353% YoY to $761 million. It also reported a $157 million net loss.\\n\\ngross bookings up 19% YoY to $31.4 billion and adjusted EBITDA up 353% YoY to $761 million. It also reported a $157 million net loss. Uber Eats is also planning to offer support for Live Activities and Dynamic Island on iPhone and integrated with Alexa for order updates.\\n\\nfor order updates. Lyft shared worrisome Q2 guidance sending its stock down after Q1 earnings where it had reported a 14% YoY increase in revenue to $1 billion and a net loss drop of 5% to $187.6 million. Ridership was up 9.8% YoY to 19.5 million.\\n\\nGaming\\n\\nSnowman, the mobile game studio behind Alto’s Adventure and Alto’s Odyssey, launched its newest title, Laya’s Horizon, exclusively with Netflix. The wingsuit game sees players mastering the art of flying, diving off mountains, weaving across forests and gliding over rivers to unlock new abilities as they explore a vast and peaceful world.\\n\\nCross-platform game engine Unity announced layoffs of 8% of its workforce, or around 600 jobs, after laying off 500+ in January and last June.\\n\\nafter laying off 500+ in January and last June. Amazon announced that customers in the United States, Canada, Germany and the United Kingdom can now play Fortnite on their Fire TVs via its Amazon Luna cloud gaming service.\\n\\nCommerce & Food Delivery\\n\\nAmazon Inspire, the e-commerce giant’s in-app TikTok-like shopping feed has rolled out to all customers in the United States. The company had been experimenting since last year with the new feed, which features content creators by influencers.\\n\\nThe company had been experimenting since last year with the new feed, which features content creators by influencers. DoorDash revenue was up 40% YoY in Q1, reaching $2.04 billion, beating estimates of $1.93 billion. Its net loss also declined 3% to $162 million and orders were up 27% to 512 million.\\n\\nEtc.\\n\\nAmazon rolled out a Matter update for Alexa that includes support for Thread, setup on iOS, and a new version of its Works with Alexa program.\\n\\nand a new version of its Works with Alexa program. Match Group posted a Q1 earnings miss with revenue down by 1% YoY to $787 million and paying users down 3% to 15.9 million. The company, however, said it’s “very possible” the recent Apple-Epic court decision could result in App Store fee relief.\\n\\nMedtech startup Healthy.io, which provides urine analysis through a mobile app, is laying off a third of its staff, or around 70 people. The company had just raised $50 million in Series D funding.\\n\\nThe company had just raised $50 million in Series D funding. Airbnb announced Rooms, a feature that focuses on the ability to book single rooms averaging $67 per night as users complain about excessive fees, onerous checkout procedures and rising Airbnb prices.\\n\\naveraging $67 per night as users complain about excessive fees, onerous checkout procedures and rising Airbnb prices. Google’s smart home app, Google Home, added support for smart garage door openers.\\n\\nSecurity\\n\\nGoogle announced that passkeys are now rolling out to Google Account users globally. Passkey let users sign in to websites and apps using the same biometrics or screen-lock PIN they use to unlock their devices.\\n\\nPasskey let users sign in to websites and apps using the same biometrics or screen-lock PIN they use to unlock their devices. Google announced that in 2022, it prevented 1.43 million policy-violating apps from being published on Google Play “in part due to new and improved security features and policy enhancements.”\\n\\nGovernment, Policy and Lawsuits\\n\\nThe EU’s Digital Markets Act (DMA) became applicable on May 2, but enforcement is not expected until spring 2024. The act focused on gatekeepers like Apple, Google, Meta and Microsoft. It limits how they can use third-party data, bans self-preferencing, introduces interoperability requirements, bans tracking users for targeted ads without consent and more. It also says app stores can’t require the use of their own payment services and permits app sideloading.\\n\\nBipartisan U.S. lawmakers reintroduced the Kids Online Safety Act with updates aimed at fixing earlier issues. The bill says platforms have to take reasonable steps to stop the spread of posts that promote eating disorders, suicide, substance abuse and more and undergo independent analysis about their safety for minors. It now also includes protections for support services, like the National Suicide Hotline, substance abuse groups and LGBTQ+ youth centers. However, critics, including the ACLU, say the changes are not enough and they remain opposed to the increased surveillance of kids this bill would require and other matters.\\n\\nThe bill says platforms have to take reasonable steps to stop the spread of posts that promote eating disorders, suicide, substance abuse and more and undergo independent analysis about their safety for minors. It now also includes protections for support services, like the National Suicide Hotline, substance abuse groups and LGBTQ+ youth centers. However, critics, including the ACLU, say the changes are not enough and they remain opposed to the increased surveillance of kids this bill would require and other matters. France’s competition watchdog announced interim measures against Meta, saying it suspects Meta of abusing its dominant position in the French market for ads on social media and across the broader (non-search-related) online ads market.\\n\\nsaying it suspects Meta of abusing its dominant position in the French market for ads on social media and across the broader (non-search-related) online ads market. The U.S. Federal Trade Commission (FTC) says Meta has “repeatedly violated” privacy rules and proposed to tighten its 2020 privacy order against the company, which would completely bar it from monetizing data from anyone under 18 in any way, among other new restrictions. The FTC also accused Meta of COPPA, a children’s privacy law, by misrepresenting its Messenger Kids parental controls, which allowed group chats and group calls with unapproved contacts.\\n\\nFunding and M&A\\n\\nAmazon acquired a small audio-focused artificial intelligence firm called Snackable.AI in 2022, The Post reported. Deal terms weren’t disclosed but Mari Joller, the founder and CEO of Snackable, is now the artificial intelligence and machine learning product leader at Amazon.\\n\\nDownloads\\n\\nRTRO\\n\\nNew social networking startup RTRO launched its app this week with the goal of connecting brands, creators and their fans and followers in a more positive environment focused on human connections and communities, not algorithm-driven content. To accomplish this, RTRO divides its social experience into two parts — on one side, you can keep up with friends or family in RTRO’s “circles.” On the other side, users can switch over to see content from creators and brands in their own space, dubbed RTRO TV.\\n\\nDistroKid\\n\\nMusic distribution service DistroKid this week launched its first mobile app, initially only for iPhone. The new app lets artists upload new releases, receive instant payment alerts, access stats from Apple and Spotify, edit metadata and more from their phones. The company said the mobile app had been the number one request from DistroKid members.', metadata={'source': 'new_articles/05-06-this-week-in-apps-apple-and-google-team-up-on-trackers-google-i-o-preview-apps-hit-newfronts.txt'}))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "text = text_splitter.split_documents(document)"
      ],
      "metadata": {
        "id": "bsw-Ma2p7OWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text), text[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSF5nCpp8WUU",
        "outputId": "57a1cbe4-bead-46b5-d385-9c4f354a113b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80,\n",
              " Document(page_content='Welcome back to This Week in Apps, the weekly TechCrunch series that recaps the latest in mobile OS news, mobile applications and the overall app economy.\\n\\nThe app economy in 2023 hit a few snags, as consumer spending last year dropped for the first time by 2% to $167 billion, according to data.ai’s “State of Mobile” report. However, downloads are continuing to grow, up 11% year-over-year in 2022 to reach 255 billion. Consumers are also spending more time in mobile apps than ever before. On Android devices alone, hours spent in 2022 grew 9%, reaching 4.1 trillion.\\n\\nThis Week in Apps offers a way to keep up with this fast-moving industry in one place with the latest from the world of apps, including news, updates, startup fundings, mergers and acquisitions, and much more.\\n\\nDo you want This Week in Apps in your inbox every Saturday? Sign up here: techcrunch.com/newsletters\\n\\nTop Stories\\n\\nDorsey criticizes Twitter, Musk on the alternative social networks he’s backing', metadata={'source': 'new_articles/05-06-this-week-in-apps-apple-and-google-team-up-on-trackers-google-i-o-preview-apps-hit-newfronts.txt'}))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating ChromaDB"
      ],
      "metadata": {
        "id": "glV_-rzq8mBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import embeddings\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "persist_directory = 'db'\n",
        "\n",
        "embedding = OpenAIEmbeddings()\n",
        "\n",
        "vectordb = Chroma.from_documents(\n",
        "    documents=text,\n",
        "    embedding=embedding,\n",
        "    persist_directory=persist_directory\n",
        ")"
      ],
      "metadata": {
        "id": "sO_G_7v18lkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To persiste the data to disk\n",
        "vectordb.persist()"
      ],
      "metadata": {
        "id": "B3N67ATj9MHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb = None\n",
        "# Loading the persisted database from disk\n",
        "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)"
      ],
      "metadata": {
        "id": "4m-7AjWt9-tD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HREi_Mfb-LnF",
        "outputId": "342b82cf-67f1-4ff0-d9e5-86bb3cf72f78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_community.vectorstores.chroma.Chroma at 0x78d85f4af910>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrieval"
      ],
      "metadata": {
        "id": "EtSO9IhK-iZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectordb.as_retriever()"
      ],
      "metadata": {
        "id": "rfwX56TA-lL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = retriever.get_relevant_documents(\n",
        "    \"When did Google rolled out passkeys to Google Account users globally\"\n",
        ")\n",
        "\n",
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAEiAiUC-sHT",
        "outputId": "0cbea1a1-d434-4f0a-d75b-695f4eefe357"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='Google ditches passwords for passkeys: This week Google rolled out passkeys to Google Account users globally, roughly a year after the company — alongside Apple, Microsoft and the FIDO Alliance — announced a partnership to broadly advance passkey adoption. With passkeys, users’ authentication synchronizes across devices through the cloud using cryptographic key pairs, allowing them to sign in to websites and apps using the same biometrics or screen-lock PIN they use to unlock their devices.\\n\\nMicrosoft debuts Pegasus: Microsoft this week announced that it’ll extend the Startup Founders Hub, its self-service platform that provides founders with free resources, including Azure credits, with a new incubator program called the Pegasus Program. Pegasus will select startups with products that “fill a market need” and give them up to $350,000 in Azure, GitHub and LinkedIn credits plus backing from advisors, as well as “access to the best Microsoft tech,” Microsoft says.', metadata={'source': 'new_articles/05-06-amazon-launches-free-channels-check-marks-come-to-gmail-and-openai-raises-more-moolah.txt'}),\n",
              " Document(page_content='Google ditches passwords for passkeys: This week Google rolled out passkeys to Google Account users globally, roughly a year after the company — alongside Apple, Microsoft and the FIDO Alliance — announced a partnership to broadly advance passkey adoption. With passkeys, users’ authentication synchronizes across devices through the cloud using cryptographic key pairs, allowing them to sign in to websites and apps using the same biometrics or screen-lock PIN they use to unlock their devices.\\n\\nMicrosoft debuts Pegasus: Microsoft this week announced that it’ll extend the Startup Founders Hub, its self-service platform that provides founders with free resources, including Azure credits, with a new incubator program called the Pegasus Program. Pegasus will select startups with products that “fill a market need” and give them up to $350,000 in Azure, GitHub and LinkedIn credits plus backing from advisors, as well as “access to the best Microsoft tech,” Microsoft says.', metadata={'source': 'new_articles/05-06-amazon-launches-free-channels-check-marks-come-to-gmail-and-openai-raises-more-moolah.txt'}),\n",
              " Document(page_content='averaging $67 per night as users complain about excessive fees, onerous checkout procedures and rising Airbnb prices. Google’s smart home app, Google Home, added support for smart garage door openers.\\n\\nSecurity\\n\\nGoogle announced that passkeys are now rolling out to Google Account users globally. Passkey let users sign in to websites and apps using the same biometrics or screen-lock PIN they use to unlock their devices.\\n\\nPasskey let users sign in to websites and apps using the same biometrics or screen-lock PIN they use to unlock their devices. Google announced that in 2022, it prevented 1.43 million policy-violating apps from being published on Google Play “in part due to new and improved security features and policy enhancements.”\\n\\nGovernment, Policy and Lawsuits', metadata={'source': 'new_articles/05-06-this-week-in-apps-apple-and-google-team-up-on-trackers-google-i-o-preview-apps-hit-newfronts.txt'}),\n",
              " Document(page_content='averaging $67 per night as users complain about excessive fees, onerous checkout procedures and rising Airbnb prices. Google’s smart home app, Google Home, added support for smart garage door openers.\\n\\nSecurity\\n\\nGoogle announced that passkeys are now rolling out to Google Account users globally. Passkey let users sign in to websites and apps using the same biometrics or screen-lock PIN they use to unlock their devices.\\n\\nPasskey let users sign in to websites and apps using the same biometrics or screen-lock PIN they use to unlock their devices. Google announced that in 2022, it prevented 1.43 million policy-violating apps from being published on Google Play “in part due to new and improved security features and policy enhancements.”\\n\\nGovernment, Policy and Lawsuits', metadata={'source': 'new_articles/05-06-this-week-in-apps-apple-and-google-team-up-on-trackers-google-i-o-preview-apps-hit-newfronts.txt'})]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectordb.as_retriever(search_kwargs={\"k\":2})\n",
        "docs = retriever.get_relevant_documents(\n",
        "    \"What did Amazon CEO Andy Jassy during the company’s first-quarter earnings call\"\n",
        ")\n",
        "\n",
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bmZk2yX_CYD",
        "outputId": "afa4dbcb-cc80-470d-a047-474798407b06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='A new LLM for Alexa: Amazon is building a more “generalized and capable” large language model to power Alexa, said Amazon CEO Andy Jassy during the company’s first-quarter earnings call this week. He added that although Amazon has had an LLM powering Alexa, Amazon is working on one that’s more capable than the current one.\\n\\naudio', metadata={'source': 'new_articles/05-06-amazon-launches-free-channels-check-marks-come-to-gmail-and-openai-raises-more-moolah.txt'}),\n",
              " Document(page_content='A new LLM for Alexa: Amazon is building a more “generalized and capable” large language model to power Alexa, said Amazon CEO Andy Jassy during the company’s first-quarter earnings call this week. He added that although Amazon has had an LLM powering Alexa, Amazon is working on one that’s more capable than the current one.\\n\\naudio', metadata={'source': 'new_articles/05-06-amazon-launches-free-channels-check-marks-come-to-gmail-and-openai-raises-more-moolah.txt'})]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making a Chain"
      ],
      "metadata": {
        "id": "Rz1W-meADHuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI()\n",
        "llm"
      ],
      "metadata": {
        "id": "1B_98nswALHf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5deff13a-116f-4985-9e93-c0eaae90ae3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OpenAI(client=<openai.resources.completions.Completions object at 0x78d8651c86a0>, async_client=<openai.resources.completions.AsyncCompletions object at 0x78d8651cb610>, openai_api_key=SecretStr('**********'), openai_proxy='')"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True\n",
        ")"
      ],
      "metadata": {
        "id": "jh-X0KV5DtiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_llm_response(llm_response):\n",
        "  print(llm_response['result'])\n",
        "  print('\\nSources:')\n",
        "  for source in llm_response['source_documents']:\n",
        "    print(source.metadata[\"source\"])"
      ],
      "metadata": {
        "id": "UAR6vFu8ELuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usage Example\n",
        "query = \"What was the Apple and Google joint announcement?\"\n",
        "process_llm_response(qa_chain(query))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEb5RSFMEZoB",
        "outputId": "8ac8beb7-7f1f-44a3-ee63-33a7d3266f1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " They announced that they will be working together to draft a specification that would alert users in the case of unwanted tracking from Bluetooth devices.\n",
            "\n",
            "Sources:\n",
            "new_articles/05-06-this-week-in-apps-apple-and-google-team-up-on-trackers-google-i-o-preview-apps-hit-newfronts.txt\n",
            "new_articles/05-06-this-week-in-apps-apple-and-google-team-up-on-trackers-google-i-o-preview-apps-hit-newfronts.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Removing ChromaDB"
      ],
      "metadata": {
        "id": "nTnNTxUCHD2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Zipping to save the DB\n",
        "!zip -r db.zip ./db"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NN24SA89HIGe",
        "outputId": "3d97d71c-f94f-4750-f029-a56f2bad0086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: db/ (stored 0%)\n",
            "  adding: db/chroma.sqlite3 (deflated 45%)\n",
            "  adding: db/3b591d91-cf4f-4043-9482-ec2227d3efd2/ (stored 0%)\n",
            "  adding: db/3b591d91-cf4f-4043-9482-ec2227d3efd2/header.bin (deflated 61%)\n",
            "  adding: db/3b591d91-cf4f-4043-9482-ec2227d3efd2/link_lists.bin (stored 0%)\n",
            "  adding: db/3b591d91-cf4f-4043-9482-ec2227d3efd2/length.bin (deflated 84%)\n",
            "  adding: db/3b591d91-cf4f-4043-9482-ec2227d3efd2/data_level0.bin (deflated 100%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb.delete_collection()\n",
        "vectordb.persist()"
      ],
      "metadata": {
        "id": "_UDIlgLoHL6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Serving LLMs"
      ],
      "metadata": {
        "id": "revomOFbe7lN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Generation"
      ],
      "metadata": {
        "id": "TnghqQQsfv96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer"
      ],
      "metadata": {
        "id": "qGcfb6SYfVgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"openai-community/gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "Nvb9HV4ve-wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2_g-vGefbj2",
        "outputId": "8f25932b-b4a8-4d99-97a9-40211b64ab38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT2LMHeadModel(\n",
            "  (transformer): GPT2Model(\n",
            "    (wte): Embedding(50257, 768)\n",
            "    (wpe): Embedding(1024, 768)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-11): 12 x GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"The quick brown fox jumped over the\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnu-8YzufqpS",
        "outputId": "8609e899-af20-4b5c-f7a0-43109e526be5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  464,  2068,  7586, 21831, 11687,   625,   262]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "logits = outputs.logits\n",
        "print(logits.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h25cBma9f2u0",
        "outputId": "00af0cde-1680-449c-976f-a2aef7af3606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 7, 50257])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "last_logits = logits[0, -1, :]\n",
        "next_token_id = last_logits.argmax()\n",
        "next_token_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gToZnCvof2sf",
        "outputId": "5099d463-c490-4cab-d63a-d84b7ef76dae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(13990)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(next_token_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "UeCMg7h4f2pj",
        "outputId": "418f3ae6-b7f8-41db-8579-c6a6b8f6801b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' fence'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_k = torch.topk(last_logits, k=10)\n",
        "tokens = [tokenizer.decode(tk) for tk in top_k.indices]\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jGYqRz-f2nR",
        "outputId": "76e3df05-6ac8-4620-935d-cec0bebaca19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' fence',\n",
              " ' edge',\n",
              " ' railing',\n",
              " ' wall',\n",
              " ' table',\n",
              " ' tree',\n",
              " ' top',\n",
              " ' counter',\n",
              " ' ground',\n",
              " ' side']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Concatenate the input and most likely tokens"
      ],
      "metadata": {
        "id": "QyljVNuuf-L4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "next_inputs = {\n",
        "    \"input_ids\": torch.cat(\n",
        "        [inputs[\"input_ids\"], next_token_id.reshape((1, 1))],\n",
        "        dim=1\n",
        "    ),\n",
        "    \"attention_mask\": torch.cat(\n",
        "        [inputs[\"attention_mask\"], torch.tensor([[1]])],\n",
        "        dim=1\n",
        "    ),\n",
        "}"
      ],
      "metadata": {
        "id": "zC56Kn0yf2jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(next_inputs[\"input_ids\"],\n",
        "      next_inputs[\"input_ids\"].shape)\n",
        "print(next_inputs[\"attention_mask\"],\n",
        "      next_inputs[\"attention_mask\"].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZR9evM1vf0-4",
        "outputId": "5c8f3f59-ee78-4f42-f3f0-a699f8bee06b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  464,  2068,  7586, 21831, 11687,   625,   262, 13990]]) torch.Size([1, 8])\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1]]) torch.Size([1, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text generation helper function**"
      ],
      "metadata": {
        "id": "edi636Lvgf0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_token(inputs):\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    last_logits = logits[0, -1, :]\n",
        "    next_token_id = last_logits.argmax()\n",
        "    return next_token_id"
      ],
      "metadata": {
        "id": "x9_awDmCgghs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_tokens = []\n",
        "next_inputs = inputs\n",
        "durations_s = []\n",
        "for _ in range(10):\n",
        "    t0 = time.time()\n",
        "    next_token_id = generate_token(next_inputs)\n",
        "    durations_s += [time.time() - t0]\n",
        "\n",
        "    next_inputs = {\n",
        "        \"input_ids\": torch.cat(\n",
        "            [next_inputs[\"input_ids\"], next_token_id.reshape((1, 1))],\n",
        "            dim=1),\n",
        "        \"attention_mask\": torch.cat(\n",
        "            [next_inputs[\"attention_mask\"], torch.tensor([[1]])],\n",
        "            dim=1),\n",
        "    }\n",
        "\n",
        "    next_token = tokenizer.decode(next_token_id)\n",
        "    generated_tokens.append(next_token)\n",
        "\n",
        "print(f\"{sum(durations_s)} s\")\n",
        "print(generated_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkVsLL-jggnv",
        "outputId": "6a41cf00-02a6-4b20-9575-e302b7b01b56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.5023064613342285 s\n",
            "[' fence', ' and', ' ran', ' to', ' the', ' other', ' side', ' of', ' the', ' fence']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot token generation time\n",
        "- The x-axis here is the token number\n",
        "- The y-axis is the time to generate a token in millisenconds (ms)"
      ],
      "metadata": {
        "id": "CfwB3mnpglJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(durations_s)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "_9gsJzslggkt",
        "outputId": "b6896ae6-c1a9-40bf-eaa6-ec0e601089d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimizing text generation with KV-caching\n",
        "\n",
        "KV-caching is a technique to speed up token generation by storing some of the tensors in the attention head for use in subsequent generation steps\n",
        "- Modify the generate helper function to return the next token and the key/value tensors"
      ],
      "metadata": {
        "id": "1lj8HSS1gwsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_token_with_past(inputs):\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    last_logits = logits[0, -1, :]\n",
        "    next_token_id = last_logits.argmax()\n",
        "    return next_token_id, outputs.past_key_values"
      ],
      "metadata": {
        "id": "QEBV6nkagxL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_tokens = []\n",
        "next_inputs = inputs\n",
        "durations_cached_s = []\n",
        "for _ in range(10):\n",
        "    t0 = time.time()\n",
        "    next_token_id, past_key_values = generate_token_with_past(next_inputs)\n",
        "    durations_cached_s += [time.time() - t0]\n",
        "\n",
        "    next_inputs = {\n",
        "        \"input_ids\": next_token_id.reshape((1, 1)),\n",
        "        \"attention_mask\": torch.cat(\n",
        "            [next_inputs[\"attention_mask\"], torch.tensor([[1]])],\n",
        "            dim=1),\n",
        "        \"past_key_values\": past_key_values,\n",
        "    }\n",
        "\n",
        "    next_token = tokenizer.decode(next_token_id)\n",
        "    generated_tokens.append(next_token)\n",
        "\n",
        "print(f\"{sum(durations_cached_s)} s\")\n",
        "print(generated_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSGC5KtlhaO7",
        "outputId": "14120120-cc8f-4adb-aa06-adae2400fbba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6952714920043945 s\n",
            "[' fence', ' and', ' ran', ' to', ' the', ' other', ' side', ' of', ' the', ' fence']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Compare the execution time for the KV-cache function with the original helper function"
      ],
      "metadata": {
        "id": "yLaHNmKnhfga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(durations_s)\n",
        "plt.plot(durations_cached_s)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "Nz3XF9xlhfxd",
        "outputId": "2b951c5a-00f8-4e87-f000-e5f6cf47b5fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batching"
      ],
      "metadata": {
        "id": "XxoSxWcQi-wj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "YdAvAOF7jH_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"openai-community/gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "OLfJ-I-NjH_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reuse KV-cache text generation"
      ],
      "metadata": {
        "id": "ZV4_D1yMjRiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"The quick brown fox jumped over the\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "\n",
        "def generate_token_with_past(inputs):\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    last_logits = logits[0, -1, :]\n",
        "    next_token_id = last_logits.argmax()\n",
        "    return next_token_id, outputs.past_key_values\n",
        "\n",
        "\n",
        "def generate(inputs, max_tokens):\n",
        "    generated_tokens = []\n",
        "    next_inputs = inputs\n",
        "    for _ in range(max_tokens):\n",
        "        next_token_id, past_key_values = \\\n",
        "        generate_token_with_past(next_inputs)\n",
        "        next_inputs = {\n",
        "            \"input_ids\": next_token_id.reshape((1, 1)),\n",
        "            \"attention_mask\": torch.cat(\n",
        "                [next_inputs[\"attention_mask\"], torch.tensor([[1]])],\n",
        "                dim=1\n",
        "            ),\n",
        "            \"past_key_values\": past_key_values,\n",
        "        }\n",
        "\n",
        "        next_token = tokenizer.decode(next_token_id)\n",
        "        generated_tokens.append(next_token)\n",
        "    return \"\".join(generated_tokens)\n",
        "\n",
        "\n",
        "tokens = generate(inputs, max_tokens=10)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "add309e5-7d47-422c-898a-4d0b878cfd24",
        "id": "BNQcALdijH_n"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " fence and ran to the other side of the fence\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Add padding tokens to the model to prepare batches of prompts**"
      ],
      "metadata": {
        "id": "CXpJ28QZjXQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define PAD Token = EOS Token = 50256\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model.config.pad_token_id = model.config.eos_token_id"
      ],
      "metadata": {
        "id": "qIkHTObjjZvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pad on the left so we can append new tokens on the right\n",
        "tokenizer.padding_side = \"left\"\n",
        "tokenizer.truncation_side = \"left\""
      ],
      "metadata": {
        "id": "0SJ09-IqjAuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Tokenize list of prompts\n",
        "- Add padding so that all prompts have the same number of tokens as the longest prompt"
      ],
      "metadata": {
        "id": "fhYyN2bYkCi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# multiple prompts of varying lengths to send\n",
        "# to the model at once\n",
        "prompts = [\n",
        "    \"The quick brown fox jumped over the\",\n",
        "    \"The rain in Spain falls\",\n",
        "    \"What comes up must\",\n",
        "]\n",
        "\n",
        "# note: padding=True ensures the padding token\n",
        "# will be inserted into the tokenized tensors\n",
        "inputs = tokenizer(prompts, padding=True, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "uONrOg9AkCJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"input_ids:\", inputs[\"input_ids\"])\n",
        "print(\"shape:\", inputs[\"input_ids\"].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-bSxYhIkJAo",
        "outputId": "f9431d70-3089-45a9-9362-70713c94a0e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids: tensor([[  464,  2068,  7586, 21831, 11687,   625,   262],\n",
            "        [50256, 50256,   464,  6290,   287,  8602,  8953],\n",
            "        [50256, 50256, 50256,  2061,  2058,   510,  1276]])\n",
            "shape: torch.Size([3, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"attention_mask:\", inputs[\"attention_mask\"])\n",
        "print(\"shape:\", inputs[\"attention_mask\"].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljehqNPEkKpl",
        "outputId": "a8702a87-340b-4f1d-9c8c-68db2f365d68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attention_mask: tensor([[1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 1, 1, 1, 1]])\n",
            "shape: torch.Size([3, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Add position ids to track original order of tokens in each prompt\n",
        "- Padding tokens are set to `1` and then first real token starts with position `0`"
      ],
      "metadata": {
        "id": "0AEj1yB0kpPI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# position_ids tell the transformer the ordinal position\n",
        "# of each token in the input sequence\n",
        "# for single input inference, this is just [0 .. n]\n",
        "# for n tokens, but for batch inference,\n",
        "# we need to 0 out the padding tokens at the start of the sequence\n",
        "attention_mask = inputs[\"attention_mask\"]\n",
        "position_ids = attention_mask.long().cumsum(-1) - 1\n",
        "position_ids.masked_fill_(attention_mask == 0, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rm1S-uWXkpt0",
        "outputId": "7bdf56bf-79e8-4ccf-ae98-05b26015e9ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1, 2, 3, 4, 5, 6],\n",
              "        [1, 1, 0, 1, 2, 3, 4],\n",
              "        [1, 1, 1, 0, 1, 2, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# same as before, but include the position_ids\n",
        "with torch.no_grad():\n",
        "    outputs = model(position_ids=position_ids, **inputs)\n",
        "logits = outputs.logits"
      ],
      "metadata": {
        "id": "3D024qlik7ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_logits = logits[:, -1, :]\n",
        "next_token_ids = last_logits.argmax(dim=1)\n",
        "\n",
        "print(next_token_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0V9K9kEWlDdn",
        "outputId": "4c9067bc-8d27-4d75-f43e-d424b10872ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([13990,   319,   307])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next_tokens = tokenizer.batch_decode(next_token_ids)\n",
        "next_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbDGRcN0lIe1",
        "outputId": "7e476b27-3895-42a0-d6d7-5328bbc23e5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' fence', ' on', ' be']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**put it all together**"
      ],
      "metadata": {
        "id": "099lvQpslRlp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_batch_tokens_with_past(inputs):\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    last_logits = logits[:, -1, :]\n",
        "    next_token_ids = last_logits.argmax(dim=1)\n",
        "    return next_token_ids, outputs.past_key_values"
      ],
      "metadata": {
        "id": "mLaWaj9wlT2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_batch(inputs, max_tokens):\n",
        "    # create a list of tokens for every input in the batch\n",
        "    generated_tokens = [\n",
        "        [] for _ in range(inputs[\"input_ids\"].shape[0])\n",
        "    ]\n",
        "\n",
        "    attention_mask = inputs[\"attention_mask\"]\n",
        "    position_ids = attention_mask.long().cumsum(-1) - 1\n",
        "    position_ids.masked_fill_(attention_mask == 0, 1)\n",
        "\n",
        "    next_inputs = {\n",
        "        \"position_ids\": position_ids,\n",
        "        **inputs\n",
        "    }\n",
        "\n",
        "    for _ in range(max_tokens):\n",
        "        next_token_ids, past_key_values = \\\n",
        "            generate_batch_tokens_with_past(next_inputs)\n",
        "\n",
        "        next_inputs = {\n",
        "            \"input_ids\": next_token_ids.reshape((-1, 1)),\n",
        "            \"position_ids\": next_inputs[\"position_ids\"][:, -1].unsqueeze(-1) + 1,\n",
        "            \"attention_mask\": torch.cat([\n",
        "                next_inputs[\"attention_mask\"],\n",
        "                torch.ones((next_token_ids.shape[0], 1)),\n",
        "            ], dim=1),\n",
        "            \"past_key_values\": past_key_values,\n",
        "        }\n",
        "\n",
        "        next_tokens = tokenizer.batch_decode(next_token_ids)\n",
        "        for i, token in enumerate(next_tokens):\n",
        "            generated_tokens[i].append(token)\n",
        "    return [\"\".join(tokens) for tokens in generated_tokens]"
      ],
      "metadata": {
        "id": "Kkp-ITlDlTv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_tokens = generate_batch(inputs, max_tokens=10)"
      ],
      "metadata": {
        "id": "qm2iuVAilZzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for prompt, generated in zip(prompts, generated_tokens):\n",
        "    print(prompt, f\"\\x1b[31m{generated}\\x1b[0m\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rRaW4C4lbGD",
        "outputId": "17c3587a-27d5-4e6c-9ae1-368054185a9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The quick brown fox jumped over the \u001b[31m fence and ran to the other side of the fence\u001b[0m\n",
            "\n",
            "The rain in Spain falls \u001b[31m on the first day of the month, and the\u001b[0m\n",
            "\n",
            "What comes up must \u001b[31m be a good idea.\n",
            "\n",
            "\"I think\u001b[0m\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Throughput vs Latency\n",
        "\n",
        "> **Throughput**: the number of tokens we can generate at the same time\n",
        "\n",
        "> **Latency**: How long it takes to generate each token\n",
        "\n",
        "- Explore the effect of batching on latency (how long it takes to generate each token).\n",
        "- Observe the fundamental tradeoff that exists between throughput and latency."
      ],
      "metadata": {
        "id": "l5kHfIoDoMwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# constants\n",
        "max_tokens = 10\n",
        "\n",
        "# observations\n",
        "durations = []\n",
        "throughputs = []\n",
        "latencies = []\n",
        "\n",
        "batch_sizes = [2**p for p in range(8)]\n",
        "for batch_size in batch_sizes:\n",
        "    print(f\"bs= {batch_size}\")\n",
        "\n",
        "    # generate tokens for batch and record duration\n",
        "    t0 = time.time()\n",
        "    batch_prompts = [\n",
        "        prompts[i % len(prompts)] for i in range(batch_size)\n",
        "    ]\n",
        "    inputs = tokenizer(\n",
        "        batch_prompts, padding=True, return_tensors=\"pt\"\n",
        "    )\n",
        "    generated_tokens = generate_batch(inputs, max_tokens=max_tokens)\n",
        "    duration_s = time.time() - t0\n",
        "\n",
        "    ntokens = batch_size * max_tokens\n",
        "    throughput = ntokens / duration_s\n",
        "    avg_latency = duration_s / max_tokens\n",
        "    print(\"duration\", duration_s)\n",
        "    print(\"throughput\", throughput)\n",
        "    print(\"avg latency\", avg_latency)\n",
        "    print()\n",
        "\n",
        "    durations.append(duration_s)\n",
        "    throughputs.append(throughput)\n",
        "    latencies.append(avg_latency)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpCnmOpIoT7C",
        "outputId": "cc0e3aac-7408-4a2c-f4d6-06fa492232f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bs= 1\n",
            "duration 0.7290999889373779\n",
            "throughput 13.715539914593107\n",
            "avg latency 0.0729099988937378\n",
            "\n",
            "bs= 2\n",
            "duration 1.1314568519592285\n",
            "throughput 17.676325849605345\n",
            "avg latency 0.11314568519592286\n",
            "\n",
            "bs= 4\n",
            "duration 1.228811264038086\n",
            "throughput 32.55178494096245\n",
            "avg latency 0.12288112640380859\n",
            "\n",
            "bs= 8\n",
            "duration 1.7085089683532715\n",
            "throughput 46.82445423573466\n",
            "avg latency 0.17085089683532714\n",
            "\n",
            "bs= 16\n",
            "duration 2.3915843963623047\n",
            "throughput 66.90125602231156\n",
            "avg latency 0.23915843963623046\n",
            "\n",
            "bs= 32\n",
            "duration 3.4378533363342285\n",
            "throughput 93.08134137601546\n",
            "avg latency 0.34378533363342284\n",
            "\n",
            "bs= 64\n",
            "duration 4.508948564529419\n",
            "throughput 141.9399646814987\n",
            "avg latency 0.4508948564529419\n",
            "\n",
            "bs= 128\n",
            "duration 9.249368906021118\n",
            "throughput 138.38782007783803\n",
            "avg latency 0.9249368906021118\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's plot the throughput and latency observations against the batch size**"
      ],
      "metadata": {
        "id": "ps-ne0MtsEkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def render_plot(x, y1, y2, x_label, y1_label, y2_label):\n",
        "    # Create a figure and a set of subplots\n",
        "    fig, ax1 = plt.subplots()\n",
        "\n",
        "    # Plot the first line (throughput)\n",
        "    color = 'tab:red'\n",
        "    ax1.set_xlabel(x_label)\n",
        "    ax1.set_ylabel(y1_label, color=color)\n",
        "    ax1.plot(x, y1, color=color)\n",
        "    ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "    # Set the x-axis to be log-scaled\n",
        "    ax1.set_xscale('log', base=2)\n",
        "\n",
        "    # Instantiate a second axes that shares the same x-axis\n",
        "    ax2 = ax1.twinx()\n",
        "    color = 'tab:blue'\n",
        "    ax2.set_ylabel(y2_label, color=color)  # we already handled the x-label with ax1\n",
        "    ax2.plot(x, y2, color=color)\n",
        "    ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "PDt0ppeasFSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "render_plot(\n",
        "    batch_sizes,\n",
        "    throughputs,\n",
        "    latencies,\n",
        "    \"Batch Size\",\n",
        "    \"Throughput\",\n",
        "    \"Latency\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "niWPkHj4sHQ6",
        "outputId": "1296ae34-d971-43a6-a2f3-60fc153f4276"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm4AAAG1CAYAAABAuXhiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB0QklEQVR4nO3dd3gU5cLG4d+WZNN7b4QivYogiB27YsN6PHos2LtiARWsYD0ee8Pu+ewdyxFFsVAUld5rCukhPdnN7s73RyASqYEks5t97uvKpZndnTyzQPLknXnfsRiGYSAiIiIiPs9qdgARERER2TMqbiIiIiJ+QsVNRERExE+ouImIiIj4CRU3ERERET+h4iYiIiLiJ1TcRERERPyEipuIiIiIn7CbHcAXuN1u/vzzT5KTk7Fa1WVFRET8gdfrpaioiCFDhmC3B0alCYyj3I0///yT4cOHmx1DRERE9sKvv/7KsGHDzI7RIVTcgOTkZKDpDz41NdXkNCIiIrInCgoKGD58ePPP8UCg4gbNp0dTU1PJyMgwOY2IiIi0RiBd5hQ4RyoiIiLi51TcRERERPyEipuIiIiIn1BxExEREfETKm4iIiIifkLFTURERMRPqLiJiIiI+AkVNxERERE/oeImIiIi4idU3ERERET8hIqbiIiIiJ9QcRMREZF2YxiG2RE6Fd1kXkREpJ14Kioomvog2GwEd+nS9JHdheCsLKxhYWbH6xBX/98f2K1Wrhu9Hz2SIsyO4/dU3ERERNpJyTPPUvnppzt8zJ6U9FeR69KFoK3FLisLa0hIBydtH+W1Lv63tAiP1+CGo/YzO06nYGpxq/vtN8pefoWGpUtxl5SQ8fRTRB511A6fWzD5birefZfkCbcT969/NW/3VFRQeP8D1Hz/PVitRB5zNCkTJ2IND++owxAREdlOY1ERFe++C0DsP/6Bp6Ya18aNNG7YiKeyEndxMe7iYup++63lCy0W7Ckpf43QbVvuMjOxBgebcDR756slBXi8Bv3To+iWqNG2tmBqcfPW1+Po3YvosaeTf+11O31e1YwZ1C9ciD0pabvH8m+5FXdJCVmvvIzhdrNp4kQKJk0m/bFH2zO6iIjILpW9+BKGy0Xo0KEk33UnFoul+TFPRQWujRubPjZs/Ov/N27EW12Nu6AAd0EBdXPnttyp1UpQauqOR+oyMrAEBXXwUe7aZws2AXDyoDSTk3Qepha3iEMPJeLQQwHI38lzGouKKLr/AbKmvUTu5Ve0eMy5di21P/1E9vvvEzqgPwApd95J7mWXk3TrrQQlb1/0RERE2ltjUREV770HQOK117QobQC2mBhCY2IIHTSoxXbDMPBs3rxNmdvQXOgaN2zEW1dHY34+jfn51M6e3fKL2mwEpafveKQuLQ2LvWN/5BdWNvDrhnIAThyo4tZWfPoaN8PrZdOttxF/ycU49tv+3Hj9ggVYo6KaSxtA+MiRYLVSv2ghQUcfvcP9Op1OnE5n8+fV1dVtH15ERAJW2QsvYjQ2EnbAAYQdeOAev85isWCPi8MeF0fY/kNaPGYYBp7S0h2P1OXkYNTX05iTQ2NODrU//dRyx0FBBG8tddnbjNJ1ySYoNQWLzdYWh93CF4sLMAw4oEss6TGhbb7/QOXTxa3spWlYbDZizz9/h4+7S0qxx8W12Gax27FFR+MpLd3pfqdOnco999zTpllFREQAGgsKqHj/fQASrtl+tG1vWSwW7ImJ2BMTCTvggBaPGYaBu7h4S5nbZpRuY05TqXM6cW3YgGvDBpj1t/0GBRGUlbXDkTp7cjIW696tHPb5wqbTpGN0mrRN+Wxxq1+ylPI336Trhx+22V/6rSZMmMBNN93U/Hl+fj59+/Zt068hIiKBqfTFLaNtw4YRPmLPR9v2hcViISg5maDkZMIPHN7iMcPrxV1UtMPr6RpzcjAaG3GtXYtr7drt9xsSQnBm5vbX03XJxp6UuNOfzzlldSzIrcBqgRMGpLbLMQcq3y1uv8/HU1bGmiOP/Gujx0PRQw9T/vob9Jj5HfbEBNzl5S1eZ7jdeCorsSUk7HTfDocDh8PR/HlVVVWb5xcRkcDTuGkTFR98CEDCtdeYnKaJZcuEhqDUVMJHjGjxmOHx0FhQ2DxK17htucvLw2howLl6Nc7Vq7ffb1gYwTsZqft88WYADuqeQGKkY7vXyt7z2eIWdfLJhI0c2WJb7rhLiT7lZKJPOx2A0MGD8VZVUb9kKaH9+wFQO3ceeL2EDhy03T5FRETaU+mLL0JjI2EHHkj48OG7f4HJLDYbwRnpBGekw6hRLR4z3G4aN23a8Uhdfj5GXR3OFStwrlix3X4/GD0eIlM4eMWPFD8xl+AuXYg47DDssbEddWidlrnLgdTW4srJaf7clZdHw/Ll2KKjCUpL2+4P2GK3Y09IwNGtKwCO7t0JP+QQCibdRerdd2O43RTddx9RJ5ygGaUiItKhGvPzqfjwIwASr7na5DT7zmK3N42oZWXBIYe0eMxwuXDl5/81SrdNuVtT7WZ9ZAp2r5v9//c2ZY31AHT99BMVtzZganGrX7KUnG0W0y1+8CEAok89lbQHp+7RPtIfeZjC++4n58KLtizAewwpd0xsl7wiIiI7U/rCltG2ESMIGzbM7DjtyhIcjKNrVxxdu2732KdfL4cf1jEqKZjuN17bPEoXnJVlQtLOx9TiFn7gcPqsWL7Hz+8x87vtttliYrTYroiImMqVl0/FR1tG23zk2jYzGIbB9CVFAJw2eiDxQ443OVHns3dzfEVERKRZ2QvPg9tN+EEjCRs61Ow4plm6qYr1pbWEBFk5um+y2XE6JRU3ERGRfeDKy6Pi408ASLjmWnPDmGzr2m2jeycT7vDZ+Y9+TcVNRERkH5Q+v2W0bdSo7e52EEi8XoPpiwoAGDNIa7e1FxU3ERGRveTKzaWyebTN/2eS7os/czeTX1FPhMPO4b20skN7UXETERHZS6XPPQ8eD+EHH0zYkMAdbQP4bEHTadJj+iYTEtT29z6VJipuIiIie8G1cSOVn34KBPZMUgC3x8sXi7ecJh2se5O2JxU3ERGRvVD6/AtNo22HHkLooMC+W8+89eWU1riICQvi4B47v+Wk7DsVNxERkVZybdxI5WefAZB4TWCPtsFfs0mP759KkE3Voj3p3RUREWml0mefaxptO+xQQgcONDuOqVxuL18tKQQ0m7QjqLiJiIi0gnP9eio//xzQaBvAT6tLqKxvJCnSwYFd482O0+mpuImIiLRC6XPPgddLxOGHEzpggNlxTLf1NOmJA1OxWS0mp+n8VNxERET2kHPdeqqmfwFAgkbbqHd5mLGs6d6kYwZpNmlHUHETERHZQ82jbUceSWj/fmbHMd33K4updXlIjwllSGaM2XECgoqbiIjIHnCuW0fVF1tG266+yuQ0vmHradIxg9KwWHSatCOouImIiOyB0meebRptGz2a0H4abatuaOS7FcUAnKzTpB1GxU1ERGQ3nGvWUPXllwAkBvg9SbeasawIl9tL98Rw+qRGmh0nYKi4iYiI7Ebps8+BYRB59FGE9OljdhyfoNOk5lBxExER2QXn6tVUffUVAAlXa7QNYHOti59WlwJw0kCdJu1IKm4iIiK7UPLss1tG244mpHdvs+P4hK+WFOL2GvRNjaJHUoTZcQKKipuIiMhONKxaRfXX/wMgQde2Ndt6mvTkwRpt62gqbiIiIjtR+syW0bZjjyWkVy+z4/iE4qoG5q4vA+DEAbo3aUdTcRMREdmBhpWrqP7f/8Bi0bpt2/hicQGGAftnxZAZF2Z2nICj4iYiIrIDpc88A0DkcccS0rOnyWl8x7azSaXjqbiJiIj8TcOKFVR/8w1YLCRepdG2rXLL6/gjpwKrRadJzaLiJiIi8jdbR9uijj8Ox377mZzGd0xfVADAiG7xJEWFmJwmMKm4iYiIbKNh+XKqZ3zbdG2bRtta0GlS86m4iYiIbKNk62jbCSfg6NHD5DS+Y01xDcsKqrBbLRzXL8XsOAFLxU1ERGSLhmXLqPn2O80k3YHpi5pG2w7ZL4HY8GCT0wQuFTcREZEtSp7eMtp24ok4unUzOY3vMAyDz7Tork9QcRMREQHqlyylZuZMsFp1bdvfLCuoYl1JLQ67laP6JJsdJ6CpuImIiAClTz8NQNRJJ+Lo1tXkNL7l84VNs0mP7J1EZEiQyWkCm4qbiIgEvPrFS6j54Yem0bYrrzQ7jk8xDEOzSX2IipuIiAS8raNt0WPG4Oiq0bZt/ZlbQX5FPeHBNo7snWR2nICn4iYiIgGtftEiambNApuNhCuvMDuOz/lsQdNo2zH9UggJspmcRuxmBxARETFTyTajbcHZ2eaG8TEer8EXi5uubxszqHPc4uqNORt4YdY6Smqc9EmN4p6T+zE4M2anz3/55/X8d+5G8ivqiQsP5vj+qdx6XC/TSqxG3EREJGDVL1hA7Y8/NY22XaVr2/5u3voySqqdRIcGcXCPRLPj7LPPF27i/unLuf6o/fji2oPpmxrJBS/Po7TGucPnf7ogn4e+XsH1R+3HtzcdxkNjBzJ90SYe+d/KDk7+FxU3EREJWCXPPAtA9CmnEJyVZXIa37N1Nunx/VMItvt/ZZj283rOGZ7JWQdksl9yJA+cOoDQYBvvzc/d4fN/37iZA7rEcsrgdDLjwji0ZyInD0pjYW5Fxwbfhv//KYiIiOyFuj//pPann3Rt2040erx8tWTraVLfnk1aXV1NVVVV84fTuf0ImsvtZUl+JaN6JDRvs1otjOqRwB8bK3a436FdYlmcX8mCLUUtp6yO71cWc4SJkzR0jZuIiASk0i13SYg+9RSCMzNNTuN7fl5dSkVdIwkRDkZ0izc7zi717du3xeeTJ0/m7rvvbrFtc50Lj9cgIcLRYntihIO1JbU73O8pg9Mpr3Vx5vOzMQxwew3OOzCLq48w7x62Km4iIhJw6v74k9pffgG7Xeu27cTWtdtOGpiKzWoxOc2uLVu2jPT09ObPHQ7HLp695+asLeOZ79dy3yn9GZwVw4bSOu79fClPfrea60bv1yZfo7VU3EREJOCUPv0UADGnnUpwRobJaXxPQ6OHb5YVAf4xmzQyMpKoqKhdPic2LBib1bLdRISSGieJETsuev+esZLT90/nnOFN1z/2TomivtHNhI8Wc80RPbCaUGh1jZuIiASUut9/p3b2HLDbib9c17btyA8ri6lxukmPCWVIZqzZcdpEsN1K//RoZq8pbd7m9RrMXlPG/l1idvia+kYPlr91M+uWDUZ7Bd0NU0fc6n77jbKXX6Fh6VLcJSVkPP0UkUcdBYDR2EjJE09QM+tHXHl52CIiCD9oJIk33UxQ8l8XBXoqKii8/wFqvv8erFYijzmalIkTsYaHm3VYIiLiw7au2xZz+ukEZ6Tv5tmB6bNtTpOaMarUXsYd3JWb31/IgIwYBmdG8/LPG6hzuTlzaNM1jje9u4Dk6BBuO643AKN7J/Pyz+vplxbNkMwYNpTV8u8ZqxjdJ9m008emFjdvfT2O3r2IHns6+dde1/KxhgYali0j4aorcfTqjbeqksIpU8m76iq6fvhB8/Pyb7kVd0kJWa+8jOF2s2niRAomTSb9sUc7+nBERMTH1c2fT92cuRAURMLll5kdxyfVON18t7wY8P3ZpK01ZlAa5bUuHp+xipJqJ33Sonj94uEkRjadKs2vqMeyzRDbtUf2wGKBx75ZSWFlA/HhwYzuk8z4Y3uZdQjmFreIQw8l4tBDAcj/22O2yEiyXnmlxbaUu+5kw5ln0bhpE0FpaTjXrqX2p5/Ifv99Qgf0b3rOnXeSe9nlJN16a4uRORERkZKn/hptC0rXaNuOfLusCKfbS7eEcPql7fq6MX/0r4Oy+ddB2Tt87N3LR7b43G6zcsNRPbnhqJ4dkGzP+NU1bt7qarBYsG65ALF+wQKsUVHNpQ0gfORIsFqpX7Rwp/txOp0t1nuprq5u9+wiImKu2l9/pW7ePI227UbzbNJBaS1Gn8Q3+E1x8zqdFD/6GFEnnogtIgIAd0kp9ri4Fs+z2O3YoqPxlJbuaDcATJ06lejo6OaPv6//IiIinc/WddtizhhLUFrnOgXYVirqXPy4ugSAk/1gNmkg8oviZjQ2kn/DjRgYpNw9eZ/3N2HCBCorK5s/li1b1gYpRUTEV9XO+5W6X3/FEhREwmUabduZr5cU0ugx6JMaRY+kSLPjyA74/DpuRmMjeTfeSOOmTWS99mrzaBuAPTEBd3l5y+e73XgqK7ElJPx9V80cDkeLxfmqqqraPriIiPgEwzAofWrLum1nnkFQqkaSdubzRU2nSf1h7bZA5dMjbs2lbeNGsl59BXtsy7VkQgcPxltVRf2Spc3baufOA6+X0IGDOjquiIj4oLp586ibPx9LUBDxGm3bqeLqBuasLQNgzECdSvZV5i4HUluLKyen+XNXXh4Ny5dji47GnphI3vU30LBsGZnPPwceD+6SpvPutuhoLMHBOLp3J/yQQyiYdBepd9+N4XZTdN99RJ1wgmaUiogIhmH8NZP0rLMISkkxOZHv+mpxIV4DBmfGkBkXZnYc2QlTi1v9kqXk/OtfzZ8XP/gQANGnnkrCNddQM3MmAOtPPa3F67Jef53wA4cDkP7IwxTedz85F160ZQHeY0i5Y2IHHYGIiPiyurlzqf/9dyzBwRpt242ts0k729ptnY2pxS38wOH0WbF8p4/v6rGtbDExWmxXRES202K07eyzdSZmF/Ir6pm/cTMWS9PdEsR3+fQ1biIiInurdvZs6v/4A4vDQfy4cWbH8WnTt4y2Hdg1juSoEJPTyK6ouImISKfTNJN062jbWRpt242/ZpPqNKmvU3ETEZFOp/bnX6hfsECjbXtgXUkNS/KrsFktHN9fp0l9nYqbiIh0KoZhUPp002hb7DnnEJSk0bZdmb6oAICDeyQQFx5schrZHRU3ERHpVGp//pn6hQuxhIQQP+4Ss+P4NMMw+GzL9W0n6zSpX1BxExGRTmPbmaSx55yDPTHR5ES+bUVhNWuKawi2Wzm6X7LZcWQPqLiJiEinUfvjjzQsWqTRtj20de22I3olEhUSZHIa2RMqbiIi0im0GG37xz+w7+Ke1dL0fmk2qf9RcRMRkU6hZtYsGpYswRIaSvwlF5sdx+ctzKskt7yesGAbo3vrNKm/UHETERG/1zST9BkA4s77B/b4eJMT+b7PFjSNth3dN5nQYJvJaWRPqbiJiIjfq/n+h6bRtrAw4i7WaNvueLwG07eeJh2o06T+RMVNRET82rbrtsWd9w/scXEmJ/J9v20op7jaSVSInUN66lpAf6LiJiIifq1m5kwali3DqtG2PbZ1Nulx/VNw2HWa1J+ouImIiN8yDIOSLde2xf7zn9hjY01O5PsaPV6+XNx0t4STB6WbnEZaS8VNRET8Vs133+FcvrxptO2iC82O4xd+WVPK5rpGEiKCGdFNp5X9jYqbiIj4JcPr/Wu07fzzNdq2hz5f2DTadsKAVOw21QB/oz8xERHxS9XffotzxQqs4eHEa7RtjzQ0evhmaSGgRXf9lYqbiIj4HcPrbV63LfaC87HFxJgbyE/MWlVCtdNNanQIQ7M0QumPVNxERMTvVM/4FueqVVgjIoi/8EKz4/iNzxb+dYsrq9VichrZGypuIiLiV5pG27as23bBBdiio01O5B9qnW6+W14EaNFdf6biJiIifqX6m29wrl6NNTKSuH9dYHYcv/Ht8iIaGr1kx4fRPz3K7Diyl1TcRETEbxheL6XPbLknqUbbWmXrbNIxg9KwWHSa1F+puImIiN+o/vprnKvXaLStlSrrGpm1qhjQbFJ/p+ImIiJ+wfB4KHn2WQDiLvwXtiid7ttT/1taSKPHoHdKJD2TI82OI/tAxU1ERPxC1ddf41qzFmtUFHEXaLStNT5f9NdsUvFvKm4iIuLzDI+H0me2GW2L1KjRniqtcfLLmlIAThqYanIa2VcqbiIi4vOqvvwK17p1WKOjNdrWSl8tLsBrwKCMaLrEh5sdR/aRipuIiPg0w+OhdMu1bfEXXYgtIsLkRP5l29mk4v9U3ERExKdVffklrvXrsUVHE/vPf5odx69sqqjn1w3lWCxwkhbd7RRU3ERExGcZbvdf17ZdfLFG21rpi0VNo23DsuNIiQ4xOY20BRU3ERHxWVVffIFrwwZsMTHEnnee2XH8jmaTdj4qbiIi4pMMt/uvddsuvhhbhC6sb40NpbUsyqvEZrVwQv8Us+NIG1FxExERn1T5+XQaN+Zgi40l7rx/mB3H70zfMto2qkcC8REOk9NIW1FxExERn2O43ZQ+9xwA8ZdcjDVco22t9dnCLadJtXZbp6LiJiIiPqfys89pzGkabYv9h0bbWmtlYTWrimoItlk5pp9Ok3YmKm4iIuJTjMbGv0bbxl2CNSzM5ET+5/Mto22H9UokOjTI5DTSllTcRETEp1R+9hmNubnY4uOJPfdcs+P4HcMwNJu0E1NxExERn9E02vY8APGXaLRtbyzKq2RjWR2hQTaO6pNkdhxpYypuIiLiMyo//ZTGvDxsCQnEnnuO2XH80tbTpEf1TSYs2G5yGmlrKm4iIuITDJfrr9G2cZdgDQ01OZH/8XoNpm+5W4Jmk3ZOKm4iIuITKj75hMb8/KbRtrPPNjuOX5q/cTOFVQ1Ehtg5rFei2XGkHZha3Op++43cK65k9SGHsrx3H6q//bbF44ZhUPLkk6w65BBWDBrMxosuwrVhQ4vneCoqyB9/CyuHHsDKYcPZdMcdeGtrO/AoRERkXxkuF6XPN422JVw6TqNte2nradJj+6XgsNtMTiPtwdTi5q2vx9G7F8mT7trh42XTplH+5luk3n032e+9izU0jJxxl+J1Opufk3/LrTjXrCHrlZfJfP456ubPp2DS5I46BBERaQMVH32Me1MB9sREYjTatlfcHi9fLm46TXqyZpN2WqYWt4hDDyXphhuIOvro7R4zDIPyN94g4YoriBw9mpBevUh76EHcxcXNI3POtWup/eknUu+7j9BBgwgbOpSUO++k6ssvaSwq7ujDERGRvWC4XJS+8AIA8ZdeijUkxORE/mn22jLKal3EhQdzUPd4s+NIO/HZa9wa8/LwlJQSftDI5m22yEhCBw6kfsFCAOoXLMAaFUXogP7NzwkfORKsVuoXLdzpvp1OJ1VVVc0f1dXV7XcgIiKySxUffYS7YOto21lmx/FbW0+TnjAgBbvNZ3+8yz7y2T9Zd0kpALb4lr812BIScJeWND/HHhfX4nGL3Y4tOhpPaelO9z116lSio6ObP/r27dvG6UVEZE94XS5Kn98y2nbZZVgduhn63nC6PXy9tBCAMQN1mrQz89ni1p4mTJhAZWVl88eyZcvMjiQiEpAqPvgAd2Eh9uRkYs460+w4fuvHVaVUN7hJiQphWHbc7l8gfstnV+azJyYA4CkrIyjpr5WfPaWlOPr0aX6Ou7y8xesMtxtPZSW2hISd7tvhcODY5re6qqqqtowuIiJ7wOt0UvbCiwDEX3apRtv2wWdbTpOeNDAVq9VichppTz474haUkYEtMYHaOXObt3lqaqhftIjQwYMACB08GG9VFfVLljY/p3buPPB6CR04qMMzi4jInqv44APcRUXYU1KIOVOjbXurzuXm22VFgO5NGghMHXHz1tbiyslp/tyVl0fD8uXYoqMJSksj7oILKH3+eYKzuxCUnkHJk09iT0oi8qijAHB07074IYdQMOkuUu++G8Ptpui++4g64QSCknV/NhERX7XtaFvC5ZdhDQ42OZH/+m55MfWNHrLiwhiYEW12HGlnpha3+iVLyfnXv5o/L37wIQCiTz2VtAenEj9uHEZ9PQWTJuOtqiJ06P5kvvRii+H09EcepvC++8m58CKwWok85hhS7pjY4cciIiJ7ruK993EXF2NPTSV67Fiz4/i1rbNJxwxKxWLRadLOztTiFn7gcPqsWL7Txy0WC4nXXUfiddft9Dm2mBjSH3u0PeKJiEg78DY0UPaiRtvaQlVDIz+sbFpp4eRB6SankY7gs9e4iYhI51Tx3nu4S0qwp6USc/rpZsfxa/9bUojL46VncgS9UiLNjiMdQMVNREQ6jLehgdKXXgIg4fIrsGi0bZ98vqjpFldauy1wqLiJiEiHqXj3XTwlpQSlpRFz2qlmx/FrZTVOflnTtNj8SZpNGjBU3EREpEN46+spfWkaAPFXXK7Rtn301ZJCPF6DAenRdE0INzuOdBAVNxER6RCb33kXT2kpQenpxJx2mtlx/N7W2aQna7QtoKi4iYhIu/PW1VE2rWm0LeHKK7AEBZmcyL8VVjbw64amOwedODDV5DTSkVTcRESk3W1+592mWxhmZhJ9yilmx/F70xdtwjBgWHYsaTGhZseRDuSz9yoVEZHOocVo2xUabWsLzbNJdZq01d6Ys4EXZq2jpMZJn9Qo7jm5H4MzY3b6/Mr6Rh7930q+XlpIZV0j6bGhTDqpL0f0NucOTSpuIiLSrja//Tae8vKm0baTx5gdx+/llNWxMLcCqwWO76/TpK3x+cJN3D99Ofef1p8hmTG88st6Lnh5HjPHH05ChGO757vcXs5/eR7x4cE8d97+JEeFkF9RT1SIeb98qLiJiEi78dbWUjbtZQASrrxSo21t4PNFTZMSRvVIIDFy+7IhOzft5/WcMzyTsw7IBOCBUwcwc0Ux783P5arDe2z3/Pfm51JR18iHVx5EkK3p6rLMuLAOzfx3Km4iItJuyt98C8/mzQR1ydJoWxtpvjepFt1tVl1dTVVVVfPnDocDh6NlqXW5vSzJr+Sqw7s3b7NaLYzqkcAfGyt2uN9vlxexf1YMkz5dwoxlRcSFB3PK4HSuOKw7Nqs594XV5AQREWkX1d9+S8lTTwFbRtvsGivYV6uKqllRWE2QzcKx/VLMjuMz+vbtS3R0dPPH1KlTt3vO5joXHq+x3SnRxAgHJTXOHe43p7yOL7esl/fqhcO59sj9eOmndTw1c3W7HMeeaPW/oopPPiHqhBO2uymw4XJR+eWXxJx6altlExERP1U7Zw75N94EHg/Rp51G9Mknmx2pU5i+ZbTtsJ6JRIfptPNWy5YtIz09vfnzv4+27S3DgITwYKaePhCb1cKAjGiKqhp44cd13HBUzzb5Gq3V6hG3gol34K2u3m67p7aWgol3tEkoERHxX3V//knu1ddgNDYSefTRpN53LxarTvDsK8MwNJt0JyIjI4mKimr+2FFxiw0Lxma1UPq30bWSGieJO5iYAJAY6aBrYniL06LdkyIoqXbicnvb9iD2UOv/JRkGWLY/r+suKsIaGdkWmURExE81rFxJ7uVXYNTVET5qFGmPPapTpG1kSX4V60trCQmyclSfZLPj+J1gu5X+6dHM3nJ/VwCv12D2mjL27xKzw9cc0CWWDaV1eL1G87b1JbUkRToItpvzy8ge/2tad9rpYAEsFnIuvAjstr8e9HhpzMsj/JBD2iGiiIj4A9eGDeRcMg5vVRWhQ4aQ8dST211WI3tv62zS0X2SCXeoDO+NcQd35eb3FzIgI4bBmdG8/PMG6lxuzhzaNMv0pncXkBwdwm3H9QbgnyO68Macjdzz+VL+dVA2G8pqefaHNVx4ULZpx7DHf/KRo0cD4Fy+gvCDD8Ya9td0WEtQEEHp6UQdc3TbJxQREZ/XWFDAxosvxlNaiqNPHzJfeL7FzwnZN16v0Xx9m2aT7r0xg9Ior3Xx+IxVlFQ76ZMWxesXD29eViW/oh7LNmcV02JCef3i4dw3fRnHPfETKVEhXDSqK1cc1n1nX6LdWQzDMHb/tL9UfPwJUSccj7WNLvzzBXl5eWRmZpKbm0tGRobZcURE/Iq7rIyN/zwf1/r1BGdn0+W/b2GPjzc7Vqcyf0M5Zzw/hwiHnfl3HkVIkG33LwoAgfjzu9VjrTGnndoOMURExB95qqrIGXcprvXrsaelkvXqKypt7WDr2m3H9EtWaQtwrS5uy/v03eHkhK36LFu6T4FERMQ/eOvqyL3iSpzLl2OLjyfr5ZcJStUtmNqa2+Pli8VNs0lP1mzSgNfq4pbx1JMtipvR6KZh+XIqP/mExGuvadNwIiLim7wuF3nXXkf9H39gjYoi65WXcXTtanasTmnuunJKa1zEhgUxqkeC2XHEZK0ubpFHHbXdtqjjjsXRowdVX31FzBlntEkwERHxTYbbzabxt1D7yy9YQkPJfOF5Qnr1MjtWp7X1NOnxA1Kb75cpgavN/gaEDh5E7dy5bbU7ERHxQYbXS8Fdk6j+5hssQUFkPvM0YUOGmB2r03K5vXy1ZMuiu5pNKrRRcfM2NFD+5psEJSW1xe5ERMQHGYZB0YMPUvnxx2Czkfbvxwg/6CCzY3VqP60uoarBTXKUg+Fd48yOIz6g1adKVw4/sOXkBMPAW1uLNSSEtEcebstsIiLiQ0qffobNb7wJQOoD9xN1tNbubG+fbTlNeuKAtBa3XZLA1eriljxhQovPLVYLtrg4QgcOxBYd3WbBRETEd5S99hqlzzwDQPKddxJz6qnmBgoA9S4PM5YVATBmkGbrShOt4yYiIrtU8eGHFD/4EACJN1xP3D/PMzlRYJi5opg6l4eM2FAGZ8aYHUd8xF7d7MxTWUnFBx/iXLcWAEf3HsScfhq2mJi2zCYiIiar+vprCu6aBEDcxRcTf/nlJicKHFtnk44ZlNbiNkziX96bn8uYgWmEBrfNwsmtnpxQ99tvrBl9FOVvvYW3qgpvVRXlb73JmqOOpu6339oklIiImK/mp5/Iv+VW8HqJOfNMkm4ZrwLRQaobGpm5shjQorv+7uGvVzDsgW+59YOF/L6xfJ/31+oRt8J77yPq+ONJuXsyFltTezQ8HgrvuZfCe++j2+ef7XMoERExV938+eRdex00NhJ1wpbv+SptHeabpUW43F56JEXQOyXS7DiyD+ZOGM23y4v54Pc8znlxLplxYZw5NJOxQ9NJigxp9f5aXdxcOTmkP/FEc2kDsNhsxF14Ies//bTVAURExLfUL11K7hVXYjQ0EH7YoaQ9+GCL7/nS/j5ftOU06UCdJvV3dpuV4/qncFz/FEqqnXzyZz4f/pHHv2es5LCeiZx1QCZH9UnGuoezhlt9qjSkb19cW65t25Zr3VocvbVytoiIP3OuXUvuuEvx1tQQdsABZDzxBJbgYLNjBZTyWhc/ry4F4CTNJu1UEiMdHJAdy5CsWCwWCysKq7n5/YUc+sj3zFlbtkf7aPWIW9z5/6RwyhRcG3MIHTwIgPoFC9n8f/9H0s030bByZfNzdQsUERH/4crLJ+fiS/Bs3kxIv35kPP8c1pDWn8qRffP1kkLcXoN+aVF0T4wwO460gZJqJx//mcf78/PIKa/jmH4pvPKvYRy8XwJ1LjdPfLea8e8v5Jfbj9ztvlpd3PJvHg9A8aOP7vgxiwUMAywW+ixb2trdi4iICRqLi8m5+GLcRUUE9+hO5rSXsEWoNJjhs4X5gCYldBaXvPYbP64uoWtCOOcMz2Ls/unEhP01ih0WbOfSQ7rx4o/r9mh/rS5uPb6d0dqXiIiID/NUVJB7yTgac3IIysgg6+WXscfGmh0rIBVVNTBvfdPMwxMH6jRpZxAfEcw7l41kaJed/5uKDw/mp1uP2KP9tbq4BaWnt/YlIiLiozw1teRcdjnO1auxJyaS9eorBCUnmx0rYH2xqADDgKFdYsmIDTM7jrSBh88YtNvnWCyWPf7z3qsFeF0bNlA771c85WUYXm+LxxKvvnpvdikiIh3M63SSd801NCxahC06mqxXXiY4M9PsWAHtr9mkGm3rLO7+bCld4sO4aFTXFttfn72BDWW1TB7Tr1X7a3Vx2/zeexTecy+22FjsCQktbzhvUXETEfEHRmMj+TfeRN3cuVjDwsic9hKO/fYzO1ZAyy2v48+cCqwWOEHFrdP4akkB0y4Ytt32oV1iee6Hte1f3Eqff57EG64n4dJLW/tSERHxAYbXy6aJd1AzcyYWh4OM554jdMAAs2MFvK2jbSO7x+/VwqzimzbXNRIZsn3dinDYKa9ztXp/rV7HzVtZRdRxx7X6C4mIiPkMw6Dwvvuo+vxzsNtJf+I/hB843OxYAny+sABoWnRXOo/s+DBmrSrZbvsPK4vJimv9dYytHnGLPO5Yan/5heBzzmn1FxMREXOVPP4fKt5+BywW0h58kMjDDzc7kgBriqtZXlCF3WrhuP4pZseRNjTu4G5M+mwJZbUuDuoeD8DsNaW89NN6Jo3p2+r97VFxK3/jzeb/D87qQskTT1K/YCGOnj2x2FvuIu6C81sdQkRE2l/pSy9R9uKLAKTcfTfRJ51ociLZauto26E9E1us8SX+76xhmTg9Xp6ZuYanZq4GICM2lPtP7c/YoRmt3t+eFbfXX2/xuTUsjLrffqPut99aPtFiadPiZng8lDz9NFWffY67tBR7UhLRp51KwpVXNt+7zTAMSp96is3vv4+3qprQ/YeQOnkywdnZbZZDRMTfbX7nHUoe+zcASbeMJ/bss0xOJFsZhtF8fZsW3e2czh/RhfNHdKGsxklIkI1wx14t6gHsYXHr8d23e/0F9kXZS9OoePsdUh+ciqPHfjQsWULBxInYIiKbC2LZtGmUv/kWaQ9OJSgjg5InniRn3KV0+2I6VofDlNwiIr6k8vPpFN5zLwDxl19O/CWXmJxItrV0UxXrSmpx2K0c1Vdr6HVm8RH73kv2vvJ1gPo//yRi9JHN12AEZ6RT9cUX1C9eDDT9llL+xhskXHEFkaNHA5D20IOsHnUw1d9+S/SJOg0gIoGteub3bLr9djAMYv/xDxJvuN7sSPI3W0fbRvdJImIfRmLEN5VUO5ny5XJ+WVNKWa0LwzBaPL5uauu6Sqv/hhRNfXDHD1gsWBwOgrOyiBx9JLaYmNbuejuhQ4ZQ8d57ONevx9G1Kw0rVlD3xx8k334bAI15eXhKSgk/aGTza2yRkYQOHEj9goU7LW5OpxOn09n8eXV19T5nFRHxNbVz55F/ww3g8RB18hiS77yj+TIT8Q2GYTBds0k7tfHvL2RTRT3Xjt6PpEgH+/ovsNXFrWH5chqWLcPwenFsuY7MtWED2GwEd+vK5rffpujhh8n+71s4evTYp3Dxl12Kt7aGdSecCDYbeDwk3nAD0WPGAOAuKQXAFh/f4nW2hATcpdtPvd1q6tSp3HPPPfuUTUTEl9UvWkTeVVdhuFxEjB5N2pQpWKytXgFK2tkfORXkV9QT4bBzRO8ks+NIO5i/oZz3rhhJv7ToNtlfq/8VR44+kvCRI9nvx1l0/ehDun70IT1m/UD4QQcRfeKJ7DfrB8IOOGDnI3OtUPXVV1R+Pp20Rx+h64cfkvbgVMpfeYWKjz/Zp/1OmDCBysrK5o9ly5btc1YREV/RsGoVOZdehreujrCRI0j/92PbrQAgvuHzhU2nSY/pm0xIkM3kNNIeUmNC+dvZ0X3S6uJW9vIrJF5/HbaIiOZttshIEq+5mrJpL2MNDSXhqitpWLp0n8MVP/Io8ZeOI/rEEwnp1ZPoU04h7sJ/NU9ntycmAOApK2vxOk9pKfaExJ3u1+FwEBUV1fwRGRm5z1lFRHyBKyeHnEsuwVtZSciggWQ+/bQmavkoj9fgi8VbTpNqNmmnNemkvjz09Qpyy+vaZH+t/hXMU1ODu6wcx9/OgrrLN+OtqQHAFhWF0di4z+GM+vrth/atNthyY/ugjAxsiQnUzplLSJ8+zfnqFy0i5lwtECwigaWxqIiciy7GU1KKo2dPsl54AWt4uNmxZCfmrSujpNpJTFgQo3okmB1H2sk1//cHDY1eDnvke0KDbNhtLXvNwsnHtGp/rb9zwpFHUnDHHSTddmvzve3qFy+m+OFHiDiqaWZn/aJFbbKOWsQRR1D6/AvYU1OblgNZvozy114jZuzpAFgsFuIuuIDS558nOLsLQekZlDz5JPakJCKPOmqfv76IiL9wl5eTc/ElNObnE9Qli6yXp7XJJDFpP1tnkx7fP4Vgu64/7KwmtfIm8rvT6uKWes/dFD34IJtuuhnD4wHAYrMRfeqpJE+4HQBHt26k3n/fPodLvvNOSp58gsJ778VTVo49KYmYs88i8aqrmp8TP24cRn09BZMm462qInTo/mS+9KJODYhIwPBUV5M77lJca9diT0mhyyuvYE/c+eUiYj6X28tXSwoBzSbt7M7Yi7sj7IrF+PuCInvIW1uLKy8PgOCMDL8ejs/LyyMzM5Pc3FwyMtr2DRYRaU/e+npyLr2U+vm/Y4uLo8tbb+Lo1s3sWLIb368o5qLXfiMx0sHcCaOxWbVMy97wl5/fG8tqeX9+HhvL65g8pi8JEQ6+X1lMekwoPZNbd539Xo/NWsPDCenVi5Bevfy6tImI+CvD5SLv+uupn/871ogIsqa9pNLmJz7bMpv0xAGpKm2d3Nx1ZRz7nx9ZkFvB/5YUUudsOlu5vKCKx2esavX+Wn2qdOMF/4JdLODY5fXXWh1CRERax/B4yL/tNmp//AlLSAiZLzxPSN++ZseSPdDQ6OGbpVtOk2o2aaf30NcrGH9ML8Yd0o1+k75u3n5Q9wTemL2x1ftrdXEL6dO7xedGo5uGFStwrl5N9KmntjqAiIi0jmEYFN59N9VffQ1BQWQ89RRhQ4eaHUv20Pcriql1eUiPCWX/rBiz40g7W1lYzZPnDNlue3x4MOV1rlbvr9XFLXnChB1uL3nqabx1bbNGiYiI7JhhGBQ/9DAV738AVivpjzxCxCEHmx1LWmHrbNKTBqXqFmQBICokiOLqBjLjwlpsX7qpipSokFbvr83mH0efPIaKjz5qq92JiMgOlD3/POWvvQZA6n33EXXcseYGklapbmjku+XFAJys06QBYcygVB78agXF1Q1YLBa8hsH8DeVM+XI5p++f3ur9tdk9UOoXLMAaHNxWuxMRkb8pf+NNSp54EoDkiROa17QU//Ht8iKcbi/dEsPpmxpldhzpALcc25tJny7hoKkz8RgGRz8+C4/X4JTB6Vx75H6t3l+ri1vetde2+NwwDNwlJTQsWUrClVe2OoCIiOxexcefUDRlCgAJ11xD3AUXmJxI9sbnC7fc4mpgmk6TBohgu5UHxw7kutH7sbKwmlqXm35p0XRN2LsVOVpd3KwRf1tvxGrB0bUriddeR8TBo/YqhIiI7FzVN99QcMcdAMT96wISrr5qN68QX1RR5+LHVSWAZpMGkie+Xc1lh3YjLSaUtJjQ5u0NjR5emLWO649q3ahbq4tb2tQprX2JiIjspZqffyH/5vHg9RI99nSSbr9dIzV+6uslhbi9Bn1To+iRFGF2HOkgT3y3ivNGZBEabGuxvd7l4YnvVrV/cWv+gkuW4lq3FgBHjx5aP0hEpI3V/fFn0+UpjY1EHnssqffeq9Lmx7YuuqvRtsBiADv6V7u8oIqYsNbPDWh1cXOXlZF/083U/for1qimCyu9VVWEHXgg6f9+DHtcXKtDiIhISw3Ll5N7+eUY9fWEH3II6Y88jMVm2/0LxScVVzUwZ10ZACcNTDU5jXSEgXf/D4vFggU44tEfWvzS5fUa1LrcnHdgl1bvt9XFrfD++/HW1tJt+uc4uncHwLlmDZtun0DR/Q+Q/u/HWh1CRET+4ly/npxLxuGtriZ06FAynnwCi2bt+7UvFxdgGDAkK2a79bykc5o0ph+GYXDrh4u48eieRIYENT8WZLOQERvG0C6xrd5vq4tb7U8/k/XqK82lDZpOlaZMuoucS8a1OoCIiPylcdMmci6+BE95OY6+fch8/jmsoaG7f6H4tM8X/TWbVALDGUObbnqfGddU0IJsbbN0buuvcfN6sdi3f5nFbgevty0yiYgEJHdpKTkXXYy7oIDgbt3ImjYNW2Tk7l8oPi1vcx2/b9yMxaLTpIFoRLf45v9vaPTQ6GnZlbYdidsTrS5uYSNGUPTAFNIee4yg5CQAGouKKJr6IGEjR7R2dyIiAngqK8kZdymujRsJSksj65WXdc1wJzF9y2jbiK7xJO3FLY7Ev9W7PEz9ajlfLCpg8w7uTbpu6omt2l+rx+1S7roTT20ta446ijVHH9P0cdTReGprSLnzztbuTkQk4Hlra8m9/AqcK1ZgS0gg65WXCUpJMTuWtJHPNZs0oE35cjmz15Zx/6n9mxfjvfGoniRHhfDvswa3en+tHnELSk2l60cfUjt7Nq516wFwdO9G+EEHtfqLi4gEOq/LRd611zbdNjA6mqyXXyY4O9vsWNJG5qwtY+mmKuxWC8f1VxkPRN8tL+KxswYzsns8t3ywiOHZcWQnhJMeG8onC/I5dUjr7lfaquJmNDayYvAQun78ERGjRsEo3SlBRGRvGW43m26+mdrZc7CEhZH1wvOE9OppdixpA/UuD499s5JXfmka4BjdJ4m4cM0MDkQV9Y1kxTfNJI5w2KmobwRgWHYcd36ypNX7a9WpUktQEEGpqZqEICKyjwyvl4I77qR6xrdYgoPJfPYZQgcPNjuWtIG568o47okfmfbzerwGnL5/Og+PHWR2LDFJVlwYueV1AHRPCueLRU2nzr9dXkRkSOvniLb6FQlXXE7x44+T/tBD2GJiWv0FRUQCnWEYFE2ZSuWnn4LNRvrj/yZ8hCZ3+bsap5uHvlrBm3M3ApAaHcKU0wZwRO8kk5OJmc4YmsHygipGdIvnysN6cMnrv/H6nI24PV7uPLH1d51qdXEr/+//0bhxI6sPPYygtDQsYS3XF+r20UetDiEiEkhKnnySzW+9BTTd/zly9GiTE8m++nFVCRM+Wkx+RT0A5w7PYsIJvYlq5VIP0vmMO6Rb8/8fvF8C3918GEvyK4kNC+aTBfmt3l+ri5u+wYiI7L2yl1+h7LnnAUiedBfRJ59sciLZF5X1jTzwxTLem58HQGZcKA+ePpBRPRJMTia+KiM2jIzYMJZtquLd33KZevrAVr2+1cUt8ZqrW/sSEREBNr/3HsWPPAJA4o03EvePf5icSPbFjGVF3PHxYoqrnVgscOFB2dxybC/Cglt/3ZLIntrrv12Gy4W7vHy7iQpBaVqnRkTk76q+/JLCyXcDED/uEuIvu9TcQLLXymtd3P3ZUj7bsj5bt4RwHj5jIAdka8FkaX+tLm7O9espuPMu6v/8s+UDhgEWC32WLW2rbCIinULNrFnk33obGAYxZ59N4s03Y7FYzI4lrWQYBl8sLmDyp0spq3VhtcBlh3bnhqP2IyTIZnY8CRCtLm4FE+/AYrOR+fxz2BMTQd98RER2qu6338i77npwu4k66SRSJt2l0uaHiqsauOvTJfxvaREAvZIjefiMgQzKjDE3mPisy9+cv8vHq+rde7XfVhe3hhUr6PrhBzi6ddv9k0VEAlj1Dz+w6aabMZxOIg4/nLSpU7DYNDLjTwzD4KM/8rl3+jIq6xuxWy1cfUQPrj6iB8H2Vt81UgLI7m4eHxkSxOmxGa3eb6uLm6N7dzybN7f6C4mIBArDMCibNo2Sfz8OhkHYyBGk/+dxLEFaGsKfbKqoZ+LHi/lhZQkAA9KjefiMgfRJjTI5mfiDR89sn0WX96i4eWpqmv8/afzNFD/yKIk33oij537bfSOyRUS0bUIRET/ira+n4M67qPriCwBizj6blDsmYgnW7Y78hddr8PZvOUz9cgU1TjfBdis3HtWTSw/pit2mUTYx1x4Vt1XDhre8ls0wyLnoopZP0uQEEQlwjYWF5F19DQ1Ll4LdTsodE4k991yzY0kr5JTVcduHi5izrgyA/bNiePiMQfRI0qCE+IY9Km5Zr7/WzjFERPxb3R9/knfddXhKS7HFxpL+xH8IHz7c7Fiyhzxeg9dnb+CR/62kvtFDaJCNW47txb8OysZm1WQS8R17VNzChw+n5JlniL/4Yqyhobt/gYhIAKn48EMK7r4HGhtx9OpFxjPPEJyRbnYs2UNrimu47cNF/L6x6frtkd3ieWjsQLLiw0xOJrK9PZ6cUPrMs8Sec46Km4jIFobbTdFDD7P5zTcBiDzmGNKmTsEaHm5yMtkTbo+Xl35az+PfrsLl9hLhsDPxhD6cMywTq0bZxEft+axSw2jHGCIi/sW9eTP5N91E3Zy5ACRcew0JV16JxaqL1/3B8oIqbv1gEYvzKwE4vFciU04bQFqMBic6uzfmbOCFWesoqXHSJzWKe07ux+A9WI/vs4WbuO7tPzm6bzIvXXBA+wfdidYtB6JFI0VEcK5eTe5VV9OYm4slLIy0hx4k6uijzY4le8Dl9vLM92t45vs1uL0GUSF2Jo/px+n7p2th5ADw+cJN3D99Ofef1p8hmTG88st6Lnh5HjPHH05ChGOnr8str2PKF8sZ7gO3NWtVcVt73PG7LW+95s3dp0AiIr6s+rvv2HTLrXjr6gjKyCDjmWcI6dXT7FiyBxblVXDrB4tYUVgNwLH9krnvlP4kRYWYnEw6yrSf13PO8EzOOiATgAdOHcDMFcW8Nz+Xqw7vscPXeLwGN7y7gBuP3o9f12+mqqGxIyNvp1XFLfGaa7BGRrZXFhERn2UYBmUvvEDJf54AIOzAA0n/z+PYY2NNTia709Do4T/frubFH9fiNSA+PJh7TunHiQNSNcrWSVRXV1NVVdX8ucPhwOFoOYLmcntZkl/JVYd3b95mtVoY1SOBPzZW7HTfT3y3mvjwYM4elsWv682/AUGrilvUiSdgj49vrywiIj7JW1fHpol3UP311wDEnnceybffpjsh+IH5G8q59cNFrCupBeDkQWlMHtOX+F2cFhP/07dv3xafT548mbvvvrvFts11LjxeY7tTookRDtZu+fvxd79tKOe933L58vpD2jTvvtjz4qbfSkQkADXm55N7zbU4ly+HoCBS7rqT2LPOMjuW7Eady83DX6/k9TkbMAxIinTwwGkDOLpvstnRpB0sW7aM9PS/luD5+2jb3qhxurnx3QVMHTuAuHDfufOJZpWKiOxE3fz55F13PZ7ycmxxcWQ89SRhQ4eaHUt2Y/aaUm77aBG55fUAnHVABnec2JfoUI2QdlaRkZFERe36HrKxYcHYrBZKa5wttpfUOEncwQjsxrJa8jbXM+71+c3bvFu6UPeJXzLz5sPoEt/xS//scXHrs3xZe+YQEfEpm999j8L77gO3G0ffPmQ+/TRBaWlmx5JdqGpoZOqXK3j71xwA0mNCmXr6AA7tmWhyMvEFwXYr/dOjmb2mlGP7pQBN96WdvaaMCw7qst3zuydG8L8bDm2x7dFvVlLrdDN5TD9So81ZOqZ1y4GYoLGoiOJHH6P2xx/xNjQQnJVF6pQphA7oDzRdMFz61FNsfv99vFXVhO4/hNTJkwnOzjY3uIj4JaOxkaKpU9n8f28DEHn8caRNmaLFx33c9yuKmfjxYgoqGwA4f0QXbju+NxEOn/8xJx1o3MFdufn9hQzIiGFwZjQv/7yBOpebM4c2zTK96d0FJEeHcNtxvQkJstErpeWEzKiQplHbv2/vSD79N9pTWcnGc/9B2IEHkvnSi9ji4nBt2Igt+q/h0LJp0yh/8y3SHpxKUEYGJU88Sc64S+n2xXSsbXCOW0QCh3vzZvKvv4G6X38Fi4XE668n/vLLNPPQh1XUubh3+jI++iMfgC7xYTw0diAjumkinWxvzKA0ymtdPD5jFSXVTvqkRfH6xcNJjGzqC/kV9T7/791iGL578VrxY49R98efZP/3rR0+bhgGqw89lPgLLyL+kosB8FRXs3rUwaROnUL0iSfu0dfJy8sjMzOT3NxcMjIy2iy/iPiPhpUrybvqahrz87GGhZH26KNEHnmE2bFkF75eUsCdnyyltMaJ1QKXHNyVm47uRWiwzexo0kEC8ee3T4+4Vc/8noiDR5F3/Q3U/fYb9uRkYs89p3lGV2NeHp6SUsIPGtn8GltkJKEDB1K/YOFOi5vT6cTp/OvixOrq6vY9EBHxaVXffMOm2ydg1NURlJVF5jNP49hvP7NjyU6U1jiZ/OlSvlhcAECPpAgePmMg+2dpTT3p/Hy6uDXm5rL57XeIu/BCEi6/jPrFSyh6YAqWoGBiTjsVd0kpALa/rS1nS0jAXVqy0/1OnTqVe+65p12zi4jvM7xeSp95ltJnngEg/KCRpP/739hiYswNJjtkGAafLdzE3Z8tZXNdIzarhSsP6861o3vgsGuUTQKDTxc3wzAI7dePpJtuBCCkb1+cq1dT8c47xJx26l7vd8KECdx0003Nn+fn52+3eJ+IdG7e2lo23X471TO+BSDuXxeQdMstWOw+/W0xYBVWNnDnJ4v5dnkxAH1So3jkjIH0T482OZlIx/Lp71D2xASCe3Rvsc3RvRvV33zT/DiAp6yMoKSk5ud4Sktx9Omz0/3+/VYY294mQ0Q6P1deHnlXXY1z1SosQUGk3H03MWNPNzuW7IBhGLw/P4/7vlhGdYObIJuF647cjysO706QzWp2PJEO59PFLWzI/rjWb2ixzbVhQ/NaSkEZGdgSE6idM5eQLUXNU1ND/aJFxJx7TkfHFRE/UDt3Hvk33ICnogJbQkLTorpDhpgdS3Ygt7yOiR8v5qfVTZfFDMqM4ZEzBtIzWffMlsDl08Ut7sJ/seHcf1D6/AtEHX8c9YsWs/m990m9t+n6NIvFQtwFF1D6/PMEZ3chKD2DkiefxJ6URORRR5mcXkR8iWEYbH77bYoemAIeDyH9+pHxzNMEpaSYHU3+xus1eGveRh78agV1Lg8Ou5Xxx/Ti4oO7YrP69lINIu3Np4tb6IABZDz1JCX/fpzSZ58lKCOD5Am3Ez1mTPNz4seNw6ivp2DSZLxVVYQO3Z/Ml17UGm4i0sxwuSi8/wEq3nsPgKiTTiL1/vuwhoSYnEz+bn1pLbd9sIhfN5QDMDw7jofOGEjXhI6/tZCIL/Lpddw6SiCuAyMSKNxlZeRddz31v/8OFgtJN99E3CWX+Pwim4HG4zV45ef1PPrNSpxuL2HBNm4/vjf/PLALVo2yyU4E4s9vnx5xExHZFw3LlpF7zTW4NxVgjYgg/bFHiTjsMLNjyd+sKqrmlg8WsTC3AoCDeyQw9fQBZMaFmRtMxAepuIlIp1T11VdsmjARo6GB4OxsMp59Bke3bmbHkm00ery8MGstT363BpfHS2SInTtP7MNZB2RqRFRkJ1TcRKRTMbxeSp58krLnXwAg/OCDSf/3Y9iionbzSulIS/IrufWDRSwraFqOaXTvJB44bQAp0bruUGRXVNxEpNPw1NSw6dbbqJk5E4C4iy8m6eabsNi0qr6vcLo9PPXdGp6btRaP1yA2LIi7T+7HyYPSNMomsgdU3ESkU3Dl5JB71VW41qzFEhxM6n33En3KKWbHkm38mbOZWz9YxOriGgBOHJDKPaf0IyFCqwCI7CkVNxHxe7WzZ5N34014KyuxJyaS8czThA4caHYs2aLe5eHfM1by8s/r8RqQEOHgvlP6cfyAVLOjifgdFTcR8VuGYbD5zbcoeuihpkV1Bw4k46mnCEpO2v2LpUPMXVfG7R8uYkNZHQCn75/OpJP6EhMWbHIyEf+k4iYifsnrclF4zz1UfvgRANGnnELKvfdo8W0fUVnfyINfLeftX3MBSI0OYcppAziit0q1yL5QcRMRv+MuKSHv2uuoX7AArFaSbrmFuAv/pYvbfcTXSwqZ9OkSiqudAJw7PIsJJ/QmKiTI5GQi/k/FTUT8Sv3iJeRdey3uwkKsUVGkP/YYEYccbHYsAYqqGpj86VK+XloIQLeEcKaePoADu8WbnEyk81BxExG/Ufn5dAruvBPD6SS4WzcynnkaR9euZscKeF6vwTu/5TL1q+VUN7ixWy1ceXh3rj6iByFBWopFpC2puImIzzM8Hkr+8x/KXpoGQMRhh5H26CPYIiNNTibrSmqY8NFi5q1vuin8oMwYHho7gN4pWvBYpD2ouImIT/NUV5M/fjy1s34EIP7SS0m84XotqmuyRo+XF39cxxPfrcbl9hIaZGP8sb248KBsbLopvEi7UXETEZ/lXL+evKuvwbVuHRaHg9QHHiD6pBPNjhXwFuZWcNuHi1hRWA3AoT0TeeDU/ropvEgHUHETEZ9U89PP5N90E97qauzJyWQ8/TShA/qbHSug1bncPPbNKl79pWkh3diwICaP6ccpg3W7KpGOouImIj7FMAzKX32N4kcfBa+X0MGDyXjqSeyJiWZHC2izVpVwx8eLydtcD8BpQ9K588Q+xOt2VSIdSsVNRHyG1+mkcNIkKj/9DIDosaeTMnky1mCtsm+W8loX909fxkd/5gOQHhPKA6f15/BeWkhXxAwqbiLiExqLism79loaFi0Cm43k224j9vx/6hScSQzD4LOFm7jn82WU17qwWOCig7py8zE9CXfoR4eIWfSvT0RMV79wIXnXXIu7pARrdDQZ/3mc8JEjzY4VsPI213HnJ0v4YWUJAL2SI3lw7ACGZMWanExEVNxExFQVn3xC4aTJGC4Xjv16kPHMMwRnZZkdKyB5vAZvzNnAI/9bSZ3LQ7DNynWje3DZod0JtlvNjiciqLiJiEkMt5vix/5N+auvAhBx5JGkPfwwtohwk5MFppWF1dz24SIW5FYAMDw7jimnD6BHUoS5wUSkBRU3EelwnspK8m8eT+3PPwMQf+UVJF57LRarRnU6mtPt4ZmZa3hu1loaPQaRDju3n9Cbc4dlYdVCuiI+R8VNRDqUc9068q68CtfGjVhCQkh7cCpRxx1ndqyA9NuGcm7/cBFrS2oBOLpvMved0p+U6BCTk4nIzqi4iUiHqZk1i/ybx+OtqcGemkrmM08T0rev2bECTlVDIw9/vYK35uYAkBjp4N6T+3Fc/xTN4hXxcSpuItLuDMOgbNo0Sv79OBgGoUOHkvHkE9jj482OFnBmLCvirk+WUFjVAMA5wzKZcHwfosOCTE4mIntCxU1E2pW3oYGCO++iavp0AGLOOouUO+/AokV1O1RxdQP3fLaMLxYXAJAdH8aU0wdwUPcEk5OJSGuouIlIu3Hl5pJ/w400LF0KdjvJEycQe+65Oh3XgQzD4P35edz/xTKqGtzYrBYuO7Qb14/ej5Agm9nxRKSVVNxEpM156+ooffFFyl95FcPlwhYTQ/oTTxB+4HCzowWUDaW1TPhoMXPWlQEwID2aB8cOoF9atMnJRGRvqbiJSJsxDIOq6dMpfvQx3EVFAISNGEHq/fcRnJFhcrrA4fZ4mfbzeh6fsQqn20tIkJWbj+7FRaOysdu05IqIP1NxE5E2Ub94CUVTplD/558ABGVkkHTbrUQedZROjXagJfmV3PbhIpZuqgLg4B4JTDltAFnxYSYnE5G2oOImIvvEXVpK8eOPU/nRx2AYWEJDSbj8cuIuuhCrw2F2vIBR7/Lw+LermPbTOrwGRIcGcddJfRm7f7qKs0gnouImInvFcLkof/MtSp99Fm9t0wKuUWPGkDT+ZoKSk01OF1h+WVPKhI8Wk1NeB8CYQWlMOqkviZEqziKdjYqbiLRa9Q8/UDz1QVwbNwIQ0r8/yRMnErb/EJOTBZaKOhf3f7GcD37PAyA1OoT7T+3P6D4qziKdlYqbiOwx57r1FD04ldoffwLAlpBA0o03En3aqbrPaAcyDIPpiwq45/OllNa4sFjgghFduOW43kQ49G1dpDPTv3AR2S1PdTWlzzxL+VtvgdsNQUHEnX8+CVddiS0iwux4AWVTRT2TPl3Ct8uLAeiRFMFDYwcwtEucyclEpCOouInIThkeD5Uff0zx4//BU9a0FljEYYeRdPttOLp2NTldYPF6Dd6at5GHvlpBrctDkM3C1Uf04MrDu+OwayFdkUCh4iYiO1T3xx8U3f8ADcuWARDctSvJE24n4tBDTU4WeFYXVXP7R4v5feNmAPbPiuGhsQPZLznS5GQi0tFU3ESkhcbCQoofeZSqL74AwBoRQcLVVxN33j90f9EO5nR7eO6HtTz7/VpcHi/hwTZuO743/zywC1arlvgQCUQqbiICNN0MvvzVVyl98SWM+nqwWIg5YyyJN9yAPT7e7HgB5/eNm7n9w0WsLq4BYHTvJO47tT9pMaEmJxMRM6m4iQQ4wzCo/mYGxQ8/TGN+PgCh++9P8h0TCe3Xz+R0gafG6eaRr1fwxtyNGAYkRAQzeUw/ThqYqoV0RUTFTSSQNaxcRdGUKdTNmweAPSWFpPHjiTrxBJUEE8xcUcQdHy+hoLIBgDOGZnDniX2ICdMpahFp4lfFrfTFlyj597+JveB8UiZOBMDrdFL80ENUffEl3sZGIkaNImXyJOwJCSanFfFd7s2bKX3qKTa/8y54vViCg4kfdwnx48ZhDdM9LTtaaY2Tez5fxucLNwGQGRfK1NMGcvB++j4mIi35TXGrX7yYinffxdGrV4vtRVOnUjPrR9Kf+A/WiEiK7ruPvGuvI/vt/zMpqYjvMtxuNr/zLiVPPYW3shKAyGOOIenWWwnOSDc5XeAxDIMP/8jn/i+WUVHXiNUClx7SjRuO6klosJb4EJHt+UVx89bWsmn8LaTedy+lzz3fvN1TXU3Fhx+R/sgjhI8YAUDq1CmsO+FE6hcsIHTwYJMSi/ie2rlzKXpgCs7VqwFw9OxJ8sSJhI840ORkgSmnrI6JHy/m5zWlAPRNjeKhsQMZkBFtcjIR8WV+UdwK772PiMMPI/ygg1oUt4alS6GxkfCDRjZvc3Trhj0tlbpdFDen04nT6Wz+vLq6ut2yi5jNlZdH8UMPUT3jWwBs0dEk3nA9MWeeicXuF98COhW3x8urv2zgsRkraWj04rBbueGonow7pCtBNt02TER2zee/a1d+8QUNy5aR/cH72z3mLinFEhSELSqqxXZ7fAKe0tKd7nPq1Kncc889bZ5VxJd4a2spffElyl99FcPlApuN2HPOIfHaa7DFxJgdLyAt3VTJ7R8uZnF+02nqkd3imXr6ALITwk1OJiL+wqeLW2NBAUVTppL1ystYHY422++ECRO46aabmj/Pz8+nb9++bbZ/ETMZhkHV9OkUP/Io7uKm+1mGjRxB8oQJhPTsaXK6wNTQ6OGJ71bz4o/r8HgNokLs3HliX848IEOzd0WkVXy6uDUsXYqnrIz1p4/9a6PHQ938+Wz+7/+RNe0ljMZGPFVVLUbd3GWl2HYxq9ThcODYpghWVVW1S36Rjla/eAlFDzxA/YIFAARlZJB8+21EjB6tgmACwzCYvbaMOz5ezIayOgBOHJDK5JP7khQZYnI6EfFHPl3cwkaMpOtnn7bYVjDxDoK7dSV+3DiCUlMhKIjaOXOJOvYYAJzr1uPeVECYJiZIAHGXlFD8+H+o/PhjMAwsYWEkXHYZcRdd2Kaj1bJn6l0ePl+4idfnbGDppqZfDJOjHNx3Sn+O6ZdicjoR8Wc+XdxsEeHY/nZqxxoaii0mpvmUT8zY0yl66EFs0dFYIyIouv9+QgcP1oxSCQiGy0X5m29R+uyzeGtrAYg6eQxJN99MUHKyyekCz8ayWt6au5H35udRWd8IQLDdyjnDMhl/bC+iQoJMTigi/s6ni9ueSJ4wAYvVSt7112O4XEQcPIqUSZPMjiXS7qp/+IHiqQ/i2rgRgJD+/Um+YyJhQ4aYnCyweLwGs1YV88acjcxaVYJhNG3PiA3lnyO6cNYBmcSF684HItI2LIax9dtM4MrLyyMzM5Pc3FwyMjLMjiOyS8516yl6cCq1P/4EgC0hgaQbbyT6tFOxWLWcREfZXOvivfm5vDVvI7nl9c3bD++VyPkjunB4ryRsVl1XKNKeAvHnt9+PuIkECk91NaXPPEv5W2+B2w1BQcRdcD4JV16JLSLC7HgBY1FeBW/M2cjnCzfhdHsBiAqxc9YBmfxzRBct7SEi7UrFTcTHGR4PlR9/TPHj/8FTVgZAxGGHkXT7bTi6djU5XWBoaPTwxaIC3pi7kYW5Fc3b+6VFccHILpw8KF23qBKRDqHiJuLD6v74g6L7H6Bh2TIAgrt2JXnC7UQceqjJyQJDbnkd/52Xw3vzcymvdQEQbLNywoAUzh+Zzf5ZMVpmRUQ6lIqbiA9qLCyk+JFHqfriCwCsEREkXH01cef9A0uwLnRvT16vwc9rSnljzkZmrijCu+Uq4LToEM4b0YWzh2WSEKElVkTEHCpuIj7E29BA+auvUvriSxj19WCxEHPGWBJvuAF7fLzZ8Tq1yrpGPvgjj7fmbmR9aW3z9oN7JHD+yC6M7p2EXfcSFRGTqbiJ+ADDMKj+ZgbFDz9MY34+AKH770/yHRMJ7dfP5HSd27JNVbw5dwMf/5lPQ2PTZINIh52xQzP454gu9EjSxA8R8R0qbiIma1i5kqIpU6mbNw8Ae0oKSePHE3XiCbp+qp243F6+WlLAm3M2Mn/j5ubtvVMiOX9kF04dnE64Q98eRcT36DuTiEncmzdT+tRTbH7nXfB6sTgcxF9yMfHjxmENCzM7XqdUUFnP/83L4e1fcymtcQJgt1o4tn8K/xqZzbDsWJVlEfFpKm4iHcxwu9n8zruUPPUU3spKACKPPZakW24hOCPd5HSdj2EYzFlbxhtzNjJjeRGeLbMNkiId/OPALP4xPIukKN3wXSRQvDFnAy/MWkdJjZM+qVHcc3I/BmfG7PC5b/+aw0d/5LGysBqAARnR3HJs750+vyOouIl0oNq5cyl6YArO1asBcPTsSfLEiYSPONDkZJ1PdUMjH/2Rz5tzN7KmuKZ5+4Fd47hgZDbH9EsmSJMNRALK5ws3cf/05dx/Wn+GZMbwyi/rueDlecwcf/gOZ4vPXVfGyYPS2P/kWBx2G8/PWsv5L89jxo2HkRJtzi98Km4iHcCVl0fxQw9RPeNbAGzR0STecD0xZ56Jxa5/hm1pVVE1b8zZwMd/5FPr8gAQFmzj9P3TOX9ENr1SIk1OKCJmmfbzes4ZnslZB2QC8MCpA5i5opj35udy1eE9tnv+E+e0vPfzQ2MH8vWSQn5ZU8rYoebcYks/MUTakbe2ltIXX6L81VcxXC6w2Yg991wSr7kaW0yM2fE6jUaPl2+WFvHGnA3MW1/evL17YjgXjMzm9P3TiQwJMjGhiLSn6upqqqqqmj93OBw4HC1H0FxuL0vyK7nq8O7N26xWC6N6JPDHxoo9+jr1jR4aPV5iwsz7fqLiJtIODMOg+n//o2jqg7iLigAIGzmC5AkTCOnZ0+R0nUdxVQNv/5rL//26kaKqpskGNquFo/skc8HILozsHq/JBiIBoG/fvi0+nzx5MnfffXeLbZvrXHi8xnanRBMjHKwtqWVPPPjVcpKjQhjVI2Gf8u4LFTeRNuZct56i+++ndvZsAIIyMki+/TYiRo9WiWgDhmHw24bNvDFnA18vKcS9ZbJBQkQw5w7P4h8HZpEaHWpyShHpSMuWLSM9/a/JXX8fbWsLz/6whs8XFvDOZSMICTLv3sQqbiJtxFtfT+nzL1D2yivQ2IglOJj4Sy8l/tJxWEM0a3Ff1TrdfLIgnzfnbGTFlhleAEO7xHLByC4c3z+VYLsmG4gEosjISKKionb5nNiwYGxWS/NSQFuV1DhJ3M1t7F78cS3P/bCW/447kD6pu/467U3FTWQfGYZBzcyZFD0whcZNmwAIP/QQUu64g+AuXUxO5//WltTw5pyNfPh7HtVONwAhQVZOHZzO+SO70C8t2uSEIuIPgu1W+qdHM3tNKcf2SwGa7k08e00ZFxy08+/Vz89ayzMz1/D6JcMZmBHTQWl3TsVNZB+4cnMpuv8BambNAsCemkryxAlEHnWUTovuA7fHy3crinlzzkZ+XlPavD07Pox/jujCmUMziTbx4mAR8U/jDu7Kze8vZEBGDIMzo3n55w3UudycObRplulN7y4gOTqE247rDcBzP6zl8RmreOKcwWTEhlJc3QBAeLDdtLurqLiJ7AWv00nZtGmUvfgShtMJQUHEX3ghCVdeobse7IPSGifv/pbLf+duZFNl0zdIiwVG907i/JHZHNIjAatVhVhE9s6YQWmU17p4fMYqSqqd9EmL4vWLh5MY2XSqNL+ivsUv3W/N3YjL4+XK//7RYj/Xj96PG482Z6KZxTAMw5Sv7EPy8vLIzMwkNzeXjAxz1mUR/1Hz008U3nc/jTk5AISNGEHKpLtwdOtmcjL/ZBgGf+RU8OacDXy5uBCXp+lG77FhQZw9LIvzDswiM05lWES2F4g/vzXiJrKHGjdtomjqg1TPmAGAPTGRpNtvI+oE3Qx+b9S7PHy+cBOvz9nA0k1/rb80KDOGC0Z04cSBqabO3BIR8UUqbiK7YbhclL32OqXPPYdRXw82G3H//CcJ116DLSLC7Hh+Z0NpLf+dt5H35udRWd8INF00fPKgNC4Y2cUnLv4VEfFVKm4iu1A7dy6F996Ha906AEKHDiVl0iRCemkR3dbweA1mrSrmjTkb+WFlSfP2jNhQ/jmiC2cdkElceLCJCUVE/IOKm8gONBYVU/zQQ1R9+SUAtvh4km4ZT/Qpp+i0aCtsqqjn84WbeGveRnLL65u3H9YzkQtGduHwXknYNNlARGSPqbiJbMNwuyl/6y1Kn3oab20tWK3EnnMOiTdcj203iztK0zIef+ZWMHNFMd+vKG6xUG5UiJ2zDsjknyO6kJ0QbmJKERH/peImskXd779TeM+9OFetAiBk0EBSJk0itF8/k5P5too6F7NWlTBzRTGzVpVQUdfY/JjVAvtnxXLmARmcPCid0GBNNhAR2RcqbhLw3KWlFD/6GJWffAKALTqaxPE3EzN2LBarbqH0d4ZhsLKomu+WN42q/ZGzGe82iwpFhwZxWM9EjuydxGE9E4nVtWsiIm1GxU0CluHxsPmddyj5zxN4q5tO6cWceSaJN92IPTbW5HS+pd7lYfba0uZToFsXx92qV3IkR/RO4sjeSeyfFYPdpsIrItIeVNwkINUvXEjhPffSsGwZAI6+fUidPJnQQYNMTuY78jbX8f2KYmauKGb22jKcbm/zYw67lVE9EjiidxJH9EokI1YL5IqIdAQVNwko7s2bKfn341R88AEYBtbISBJvuJ7Yc87BYgvs66/cHi+/b9zMzJVNo2qrimpaPJ4eE8oRvZtOgY7slqDr1URETKDiJgHB8Hqp+PBDSh77N56KCgCiTzmFpFvGY09IMDecicprXcxaVczMFSXMWllMVYO7+TGrBYZ2iW0+BdorOVJLoYiImEzFTTq9hmXLKLznXuoXLgTAsd9+pEyeRNgBB5icrOMZhsHygmpmrihi5opi/sytYNu7FceEBXF4z0SO2DKxICZMEwtERHyJipt0Wp6qKkqeeJLNb78NXi/WsDASrr2WuH+ehyUoyOx4HabO5eaXNWXMXFHMDyuLKfjbxILeKZEcuWVUbUhWrBbEFRHxYSpu0ukYhkHlp59S/MijeMrKAIg64XiSbruNoORkk9N1jNzyOmauKOa7FcXMXVeGa5uJBSFBVkZ13zKxoHcS6TGhJiYVEZHWUHGTTqVh1SoK772X+vm/AxDctSspk+4ifORIk5O1r0aPl/kbNvP9yqZZoGuKW04syIgN5cgtRW1kt3hCgjSxQETEH6m4Safgqaml9OmnKX/zTfB4sISGknDllcRf+C8swZ3zOq2yGic/rCxh5spiflxVQvU2EwtsVgtDu8RyZO8kRvdOokdShCYWiIh0Aipu4tcMw6D6q68oevAh3MXFAEQefRTJEyYQlJZmcrq2ZRgGSzdVMXPL2moL81pOLIgNC+LwXk3Xqh26XyLRYYFzHZ+ISKBQcRO/5Vy3nqL776N29hwAgrKySLnzDiIOPdTkZG2n1unm5zWlfL+imO9XFlNU5WzxeN/UqOZToIMzYzSxQESkk1NxE7/jrauj9PkXKHv1VWhsxBIcTPxllxF/6TisDofZ8fbZxrLa5lG1eevKcXn+mlgQGmRjVI+ELWUtkdRoTSwQEQkkKm7iNwzDoPrbbymaOhX3pgIAwg87lJQ77iA4K8vkdHvP5fYyf0N5U1lbWcy6ktoWj2fGhTK6dzJH9E7iwK5xmlggIhLAVNzEL7hycii8/35qf/wJAHtaKikTJxIxerRfXnRfUu3kh5VNpz9/XFVKjfOviQV2q4UDsmOb11brnqiJBSIi0kTFTXyat6GBspemUfbSSxguFwQFEX/RRSRccTnWMP+5sbnX2zSx4LsVRXy/opiFeZUtHo8PD+awXomM7p3MIT0TiArRxAIREdmeipv4rJpZsyi8/wEac3MBCBs5gpS77sLRrZvJyVoyDIP6Rg/VDW6q6hupanBT3dDY9HlDIwtzK/h+ZQkl1S0nFvRPj+LIXk0TCwZlxGDVxAIREdkNny5upS+8SPWMGbjWrcMSEkLokCEk3Xwzjm5dm5/jdTopfughqr74Em9jIxGjRpEyeVJA3zjc3zXm51M4dSo1334HgD0pieTbbyPy+OPb5ZRhw5bStW3ZavF5cxnb+tjWx/96rsdr7PbrhAXbOLh5YkESyVEhbX4sIiLSufl0cav77Tdi//EPQgf0x/B4KH78cXLGXUL36dObT5MVTZ1KzawfSX/iP1gjIim67z7yrr2O7Lf/z+T00lqGy0XZq69R+txzGA0NYLMRd8EFJFx9NbaI8B2+ptHj3a50VdW7d1Cuti9b1Q1NhWzb20HtC6sFIkOCiAyxE7Xlv5EhQWTFhXFE70SGd43DYdfEAhER2Xs+Xdyypr3U4vO0qVNZfdAoGpYuJWzYMDzV1VR8+BHpjzxC+IgRAKROncK6E06kfsECQgcPNiG17CmP16DG2VSgiubOJ+fl16koraAuoS+u7r2wjD6G+ohoqr5Z2zziVd3QSFX9XyWsvtHTZnkiHfbmshUVam8uYX8VsW0+Dw0iKsTeoqiFBds0iUBERNqVTxe3v/NWVwNgjY4GoGHpUmhsJPygv+5D6ejWDXtaKnW7KG5OpxOn86/rjaq37FfaTlFVA3PXlbEgt4LyWleLsrV1pGvbmZQA9Dgdemzz+R9lQNkefb2wYFtz6fr7iFfUlqK1tXRFOoJafh4SRITDrsVrRUTE5/lNcTO8XoqmTCV0//0J6dkTAHdJKZagIGxRUS2ea49PwFNautN9TZ06lXvuuadd8waa/Ip65q0rY966cuatL2NDWd0evzbI00hEYwORoUHEpCQQFR7SNOLlCNrlCNjWchYRYifIZm3HoxMREfENflPcCu+9F+fq1XT5v//u874mTJjATTfd1Px5fn4+ffv23ef9BgrDMMjbXM/cdWXMW99U1HLL61s8x2qBvmlRDMuOIz0mtMUIWNC6VThffJag1SsJc9cTPaA/KZMnEaI/AxERkV3yi+JWeO991Pwwiy5vvUlQSkrzdntiAkZjI56qqhajbu6yUmy7mFXqcDhwbHNrpKqqqvYJ3kkYhsGGsrqmEbX15cxbV8amyoYWz7FZLfRPj2ZE1zgO7BbHAdlx261F5i4tpfiRR6j89LOm18TEkDT+bqJPPx2LVSNmIiIiu+PTxc0wDIruu5/qb7+lyxuvE5yR0eLxkH79ICiI2jlziTr2GKDpxuPuTQWEaWLCXjMMg7UlNcxdV95c1Ir/tgZZkM3CwIwYDuwax4Hd4hnaJZYIx47/OhluN5vfeZeSJ55ouk7RYiHmzDNJvPEG7LGxHXFIIiIinYJPF7fCe++lavoXZDzzNNbwcNwlJQBYIyOxhoRgi4wkZuzpFD30ILboaKwRERTdfz+hgwdrRmkreL0Gq4qrm69P+3V9OaU1rhbPCbZZGZwZw4Hd4hjRLZ79s2IJDd710haGYVD/5wIK77sP5/LlAIT07UvK3ZMJHTiw3Y5HRESks/Lp4lbx9jsA5FzwrxbbU6dMIeb00wBInjABi9VK3vXXY7hcRBw8ipRJkzo8qz/xeA1WFFY1jaitK+O3DeVsrmts8RyH3cr+WbEc2C2OA7vGMyQrZqc3Nze8Xhrz83GuXYtr7bot/12Lc926v2YCR0WReMP1xJ59Nhab1jITERHZGxbDMHa/5Hsnl5eXR2ZmJrm5uWT87XRsZ+D2eFlWUNViRK2qoeVSHKFBNg7Ijm0+9TkwI3q7xWINlwtXTg7ONWtxrttS0tatw7VuHYaz5anUZjYb0WPGkHTLeOzx8e11iCIiEoA6+8/vHfHpETfZO40eL4vzK5uL2vwNm7dbMy3CYd9S1OI5sFscA9Kjm5fU8NbV4Vyxgsp1a3GuXYdr3Vqca9biyskBz44XvLUEBRGcnU1wj+44unXH0b0bwd27E5ydjXWbiSAiIiKy91TcOgGn28OivMrmWZ+/b9xMnatlwYoMsTM8O675GrW+qVFYqqtwrluHc94flK9pOrXpWruWxk2bdvq1rGFhBHfvjqNbUzFz9Gj6/6CMDCx2/XUSERFpT/pJ64caGj38mVPBvPVNC97+kbMZ59/utxkTFtRU1LrGMTTGQreqTbjXrcT5/Vpc09axbu1aPGU7vyuBLTaW4O7dcHTv0TR6tmUUzZ6Sots6iYiImETFzQ/Uuzz8kbO5acHbdeUsyK3A5WlZ1OLDgxmWEsKQoHoG1RWQkbOSxi+arkPz1tSQv5N921NTt4yedWs6xdmjO8Hdu2uZDhERER+k4uaDapxuft+4ufnU56K8Cho9LeeQJAbDEHsNA6vy6JezhJSVf8K291/d9slWK8GZmQT36PFXSeveneCu3bBFhHfMQYmIiMg+U3HzAVUNjczfUM68deXMXV/OkvxKPN6WRS3JW8+Aihz65y5mQPEa0mpL+fsJS0twMMFdu/51arNHd4K7dWuaIBAc3HEHJCIiIu1Cxc0EFXUufl3fdFeCuauLWV5Ui/dvz0muLWdA2VoGlK5jQOlaUurKm4uaNTyc4EED/5q9uaWkBaWna400ERGRTkzFrQOUVjcwZ+EG5i7N49dNtaxx2jD+Nl6WVlPSVNK2lLWk+gps8fFNpzYPOvqvSQLdu2NPStIEARERkQCk4tZOPF6DW+98lfkNDjYGx2zzSNNbnlFdzMDStQwoXctgey3pWSk4BnUjuPspTdefdeumCQIiIiLSgopbO7FZLcyvC2JjSAwAXaoKGeQqYWiEm2HpUaQflE1wt+E4umZjDdcEAREREdk9Fbd2dO3+CVgtMHJwV1J6HY1FEwRERERkH6i4taMzLjje7AgiIiLSiVjNDiAiIiIie0bFTURERMRPqLiJiIiI+AkVNxERERE/oeImIiIi4idU3ERERET8hIqbiIiIiJ9QcRMRERHxEypuIiIiIn5CxU1ERETET6i4iYiIiPgJFTcRERERP6HiJiIiIuIn7GYH8AVerxeAgoICk5OIiIjIntr6c3vrz/FAoOIGFBUVATB8+HCTk4iIiEhrFRUVkZWVZXaMDmExDMMwO4TZ3G43f/75J8nJyVitbXf2uLq6mr59+7Js2TIiIyPbbL/+JNDfAx1/YB8/6D0I9OMHvQftefxer5eioiKGDBmC3R4YY1Eqbu2oqqqK6OhoKisriYqKMjuOKQL9PdDxB/bxg96DQD9+0HsQ6Mff1jQ5QURERMRPqLiJiIiI+AkVt3bkcDiYPHkyDofD7CimCfT3QMcf2McPeg8C/fhB70GgH39b0zVuIiIiIn5CI24iIiIifkLFTURERMRPqLiJiIiI+AkVNxERERE/oeImIiIi4idU3DrI9OnT6dWrF/vttx/Tpk0zO44pTjvtNGJjYznjjDPMjtLhcnNzOfzww+nbty8DBw7k/fffNztSh6qoqOCAAw5g8ODB9O/fn5deesnsSKapq6ujS5cujB8/3uwoHS47O5uBAwcyePBgjjjiCLPjdLj169dzxBFH0LdvXwYMGEBtba3ZkTrUypUrGTx4cPNHaGgon3zyidmx/I6WA+kAbrebvn378v333xMdHc3QoUOZPXs28fHxZkfrUD/88APV1dW8/vrrfPDBB2bH6VAFBQUUFRUxePBgCgsLGTp0KKtWrSI8PNzsaB3C4/HgdDoJCwujtraW/v37M3/+/ID7NwBwxx13sGbNGjIzM3n00UfNjtOhsrOzWbJkCREREWZHMcVhhx3G/fffzyGHHEJ5eTlRUVEBc3/Nv6upqSE7O5uNGzcGzPfBtqIRtw7w66+/0q9fP9LT04mIiOD444/nm2++MTtWhzv88MMD8gbLAKmpqQwePBiAlJQUEhISKC8vNzdUB7LZbISFhQHgdDoxDINA/J1x9erVrFixguOPP97sKNLBli5dSlBQEIcccggAcXFxAVvaAD777DNGjx6t0rYXVNzayNSpUxk2bBiRkZEkJSVx6qmnsnLlSgA2bdpEenp683PT09PJz883K2q72dV7EAj29Ph///13PB4PmZmZJqRsP7s7/oqKCgYNGkRGRga33HILCQkJJqZtH7t7D8aPH8/UqVNNTNi+dnf8FouFww47jGHDhvHf//7XxKTtY1fHv3r1aiIiIhgzZgz7778/U6ZMMTlt+9jT74PvvfceZ599tgkJ/Z+KWxuZNWsWV199NXPnzmXGjBk0NjZyzDHHBNQ1DIH+HuzJ8ZeXl3PBBRfw4osvmpi0fezu+GNiYli4cCHr16/n//7v/ygqKjI5cdvb1Xvw6aef0rNnT3r27Gl2zHazu78DP//8M7///jufffYZU6ZMYdGiRSYnblu7On63281PP/3Es88+y5w5c5gxYwYzZswwO3Kb25Pvg1VVVcyePZsTTjjBxKR+zJB2UVxcbADGrFmzjF9++cU49dRTmx+7/vrrjf/+978mpusY274HW33//ffG2LFjTUzVcf5+/A0NDcYhhxxivPHGGyYn6xg7+vPf6sorrzTef/99E1J1rG3fg9tvv93IyMgwunTpYsTHxxtRUVHGPffcY3bEdrWrvwPjx483Xn311Y4P1YG2Pf7Zs2cbxxxzTPNjDz/8sPHwww+bmK5j7OjvwBtvvGGcd955JqbybxpxayeVlZVA03UMw4cPZ8mSJeTn51NTU8NXX33Fsccea3LC9rftexCItj1+wzC48MILOfLIIzn//PNNTtYxtj3+oqIiqqurm7f/+OOP9OrVy8x4HWLb92Dq1Knk5uayYcMGHn30US699FImTZpkcsL2te3x19bWNv8dqKmpYebMmfTr18/MeO1u2+MfNmwYxcXFbN68Ga/Xy48//kifPn1MTtj+dvRzQKdJ95HZzbEz8ng8xoknnmiMGjWqedunn35q7Lfffkb37t2NF154wcR0HWNH78Ho0aONhIQEIzQ01EhPTzdmz55tYsL29ffj/+mnnwyLxWIMGjSo+WPRokUmp2w/fz/+efPmGYMGDTIGDhxoDBgwwHj++edNTtj+dvRvYKtXX33VuPnmm01I1XH+fvxr1641Bg4caAwcONDo16+f8Z///MfkhO1rR3/+X375pdG/f3+jX79+xo033mhiuo6xo/egoqLCSEpKMpxOp4nJ/JuKWzu44oorjC5duhi5ublmRzFNoL8HOv7APn7D0Hug4w/s4zcMvQftRcWtjV199dVGRkaGsW7dOrOjmCbQ3wMdf2Afv2HoPdDxB/bxG4beg/ak4tZGvF6vcfXVVxtpaWnGqlWrzI5jikB/D3T8gX38hqH3QMcf2MdvGHoPOkLgrv7Xxq6++mr+7//+j08//ZTIyEgKCwsBiI6OJjQ01OR0HSPQ3wMdf2AfP+g90PEH9vGD3oMOYXZz7CyAHX509unu2wr090DHH9jHbxh6D3T8gX38hqH3oCPoXqUiIiIifkLruImIiIj4CRU3ERERET+h4iYiIiLiJ1TcRERERPyEipuIiIiIn1BxExEREfETKm4iIiIifkLFTURERMRPqLiJSKfy2muvERMT0+b7vfvuuxk8eHCb71dEpDVU3ESkzV144YVYLJbmj/j4eI477jgWLVrUqv10ZFn6+OOPGTFiBNHR0URGRtKvXz9uuOGG5sfHjx/Pd9991yFZRER2RsVNRNrFcccdR0FBAQUFBXz33XfY7XZOOukks2Pt0HfffcfZZ5/N2LFj+fXXX/n999954IEHaGxsbH5OREQE8fHxJqYUEVFxE5F24nA4SElJISUlhcGDB3P77beTm5tLSUlJ83Nuu+02evbsSVhYGN26deOuu+5qLkuvvfYa99xzDwsXLmweuXvttdcAqKio4PLLLyc5OZmQkBD69+/P9OnTW3z9//3vf/Tp04eIiIjmErkzn3/+OaNGjeKWW26hV69e9OzZk1NPPZVnnnmm+Tl/H/3bdkRx60d2dnbz40uWLOH4448nIiKC5ORkzj//fEpLS/fhHRURUXETkQ5QU1PDW2+9RY8ePVqMWkVGRvLaa6+xbNkynnjiCV566SUef/xxAM4++2xuvvlm+vXr1zxyd/bZZ+P1ejn++OP55ZdfeOutt1i2bBkPPvggNputeb91dXU8+uijvPnmm/z444/k5OQwfvz4neZLSUlh6dKlLFmyZI+PaWumgoIC1qxZQ48ePTj00EOBpmJ55JFHMmTIEObPn8/XX39NUVERZ511VmvfOhGRFuxmBxCRzmn69OlEREQAUFtbS2pqKtOnT8dq/ev3xTvvvLP5/7Ozsxk/fjzvvPMOt956K6GhoURERGC320lJSWl+3jfffMOvv/7K8uXL6dmzJwDdunVr8bUbGxt5/vnn6d69OwDXXHMN9957706zXnvttfz0008MGDCALl26MGLECI455hjOO+88HA7HDl+zNZNhGIwdO5bo6GheeOEFAJ5++mmGDBnClClTmp//yiuvkJmZyapVq5pzi4i0lkbcRKRdHHHEESxYsIAFCxbw66+/cuyxx3L88cezcePG5ue8++67jBo1ipSUFCIiIrjzzjvJycnZ5X4XLFhARkbGLstPWFhYc2kDSE1Npbi4eKfPDw8P54svvmDNmjXceeedREREcPPNNzN8+HDq6up2mWfixInMmTOHTz/9lNDQUAAWLlzI999/T0RERPNH7969AVi7du0u9ycisisqbiLSLsLDw+nRowc9evRg2LBhTJs2jdraWl566SUA5syZw3nnnccJJ5zA9OnT+fPPP7njjjtwuVy73O/WcrQrQUFBLT63WCwYhrHb13Xv3p1x48Yxbdo0/vjjD5YtW8a777670+e/9dZbPP7443z88cekp6c3b6+pqWHMmDHNxXXrx+rVq5tPp4qI7A2dKhWRDmGxWLBardTX1wMwe/ZsunTpwh133NH8nG1H4wCCg4PxeDwttg0cOJC8vLx2P+WYnZ1NWFgYtbW1O3x8zpw5jBs3jhdeeIERI0a0eGz//ffnww8/JDs7G7td32ZFpO1oxE1E2oXT6aSwsJDCwkKWL1/Otdde2zwSBbDffvuRk5PDO++8w9q1a3nyySf5+OOPW+wjOzub9evXs2DBAkpLS3E6nRx22GEceuihjB07lhkzZrB+/Xq++uorvv76673Oevfdd3Prrbfyww8/sH79ev78808uvvhiGhsbOfroo7d7fmFhIaeddhrnnHMOxx57bPNxbp0xe/XVV1NeXs65557Lb7/9xtq1a/nf//7HRRddtF0RFRFpDRU3EWkXX3/9NampqaSmpnLggQfy22+/8f7773P44YcDcPLJJ3PjjTdyzTXXMHjwYGbPns1dd93VYh9jx47luOOO44gjjiAxMZG3334bgA8//JBhw4Zx7rnn0rdvX2699dZ9KkSHHXYY69at44ILLqB3794cf/zxFBYW8s0339CrV6/tnr9ixQqKiop4/fXXm48xNTWVYcOGAZCWlsYvv/yCx+PhmGOOYcCAAdxwww3ExMS0mJwhItJaFmNPLvwQEREREdPpVz8RERERP6HiJiIiIuInVNxERERE/ISKm4iIiIifUHETERER8RMqbiIiIiJ+QsVNRERExE+ouImIiIj4CRU3ERERET+h4iYiIiLiJ1TcRERERPyEipuIiIiIn/h/StF5b1YZDKwAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Continuous Batching\n",
        "\n",
        "- The key idea behind continuous batching is constantly swap out requests from the batch that have completed generation for requests in the queue that are waiting to be processed."
      ],
      "metadata": {
        "id": "M6VLBm8Wtom0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer"
      ],
      "metadata": {
        "id": "G1DF2YeauLAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_next_inputs(batch, next_token_ids, past_key_values, next_tokens):\n",
        "    return {\n",
        "        # '-1' here means the remaining elements for this dim\n",
        "        \"input_ids\": next_token_ids.reshape((-1, 1)),\n",
        "        # increment last, discard the rest\n",
        "        \"position_ids\": batch[\"position_ids\"][:, -1].unsqueeze(-1) + 1,\n",
        "        # concatenate vector of 1's with shape [batch_size]\n",
        "        \"attention_mask\": torch.cat([\n",
        "            batch[\"attention_mask\"],\n",
        "            torch.ones((next_token_ids.shape[0], 1)),\n",
        "        ], dim=1),\n",
        "        \"past_key_values\": past_key_values,\n",
        "        \"responses\": [\n",
        "            r1 + r2 for r1, r2\n",
        "            in zip(batch[\"responses\"], next_tokens)],\n",
        "        \"tokens_remaining\": [\n",
        "            v - 1 for v in batch[\"tokens_remaining\"]],\n",
        "    }\n",
        "\n",
        "\n",
        "def init_batch(requests):\n",
        "    prompts = [r[0] for r in requests]\n",
        "    inputs = tokenizer(prompts, padding=True, return_tensors=\"pt\")\n",
        "\n",
        "    attention_mask = inputs[\"attention_mask\"]\n",
        "    position_ids = attention_mask.long().cumsum(-1) - 1\n",
        "    position_ids.masked_fill_(attention_mask == 0, 1)\n",
        "\n",
        "    return {\n",
        "        \"position_ids\": position_ids,\n",
        "        \"responses\": copy.copy(prompts),\n",
        "        \"tokens_remaining\": [r[1] for r in requests],\n",
        "        **inputs\n",
        "    }\n",
        "\n",
        "\n",
        "def generate_next_token(batch):\n",
        "    inputs = copy.copy(batch)\n",
        "    inputs.pop(\"responses\")\n",
        "    inputs.pop(\"tokens_remaining\")\n",
        "\n",
        "    next_token_ids, past_key_values = \\\n",
        "        generate_batch_tokens_with_past(inputs)\n",
        "    next_tokens = tokenizer.batch_decode(next_token_ids)\n",
        "    return get_next_inputs(\n",
        "        batch, next_token_ids, past_key_values, next_tokens)\n",
        "\n",
        "\n",
        "def merge_batches(batch1, batch2):\n",
        "    # first find the max sequence length of the two batches\n",
        "    # this can be obtained from the second dimension\n",
        "    # of the attention mask\n",
        "    attn_mask1 = batch1[\"attention_mask\"]\n",
        "    attn_mask2 = batch2[\"attention_mask\"]\n",
        "    max_seq_len = max(attn_mask1.shape[1], attn_mask2.shape[1])\n",
        "\n",
        "    # pad each mask (on the left) to the max sequence length\n",
        "    # attention mask uses 0 for padding\n",
        "    padding1 = max_seq_len - attn_mask1.shape[1]\n",
        "    padding2 = max_seq_len - attn_mask2.shape[1]\n",
        "    attn_mask1 = F.pad(attn_mask1, (padding1, 0), \"constant\", 0)\n",
        "    attn_mask2 = F.pad(attn_mask2, (padding2, 0), \"constant\", 0)\n",
        "\n",
        "    # because we only append batches post decoding,\n",
        "    # we don't need to pad input_ids\n",
        "    # or position_ids. these are always length 1\n",
        "    # in the sequence dimension\n",
        "    # however, we do need to pad the\n",
        "    # past_key_values, which have shape:\n",
        "    # [batch_size, num_heads, sequence_length, head_dim]\n",
        "    past_kv1 = batch1[\"past_key_values\"]\n",
        "    past_kv2 = batch2[\"past_key_values\"]\n",
        "\n",
        "    padded_kv1 = []\n",
        "    for i in range(len(past_kv1)):\n",
        "        k, v = past_kv1[i]\n",
        "        k = F.pad(k, (0, 0, padding1, 0), \"constant\", 0)\n",
        "        v = F.pad(v, (0, 0, padding1, 0), \"constant\", 0)\n",
        "        padded_kv1.append((k, v))\n",
        "\n",
        "    padded_kv2 = []\n",
        "    for i in range(len(past_kv2)):\n",
        "        k, v = past_kv2[i]\n",
        "        k = F.pad(k, (0, 0, padding2, 0), \"constant\", 0)\n",
        "        v = F.pad(v, (0, 0, padding2, 0), \"constant\", 0)\n",
        "        padded_kv2.append((k, v))\n",
        "\n",
        "    # now that everything has been padded to have\n",
        "    # consistent shapes, let's merge\n",
        "    input_ids = torch.concat(\n",
        "        [batch1[\"input_ids\"], batch2[\"input_ids\"]], dim=0)\n",
        "    position_ids = torch.concat(\n",
        "        [batch1[\"position_ids\"], batch2[\"position_ids\"]], dim=0)\n",
        "    attn_mask = torch.concat([attn_mask1, attn_mask2], dim=0)\n",
        "\n",
        "    past_kv = []\n",
        "    for i in range(len(padded_kv1)):\n",
        "        k1, v1 = padded_kv1[i]\n",
        "        k2, v2 = padded_kv2[i]\n",
        "        k = torch.concat([k1, k2], dim=0)\n",
        "        v = torch.concat([v1, v2], dim=0)\n",
        "        past_kv.append((k, v))\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"position_ids\": position_ids,\n",
        "        \"attention_mask\": attn_mask,\n",
        "        \"past_key_values\": past_kv,\n",
        "        \"responses\": batch1[\"responses\"] + batch2[\"responses\"],\n",
        "        \"tokens_remaining\": batch1[\"tokens_remaining\"] + batch2[\"tokens_remaining\"],\n",
        "    }\n",
        "\n",
        "\n",
        "def filter_batch(batch):\n",
        "    # mark all rows with 0 tokens remaining for removal\n",
        "    remove_indices = []\n",
        "    for i, tokens_remaining in enumerate(batch[\"tokens_remaining\"]):\n",
        "        if tokens_remaining <= 0:\n",
        "            remove_indices.append(i)\n",
        "\n",
        "    # first, define a mask used to subselect the indices to keep\n",
        "    # from each tensor, given the indices to remove\n",
        "    batch_size = batch[\"input_ids\"].size(0)\n",
        "    mask = torch.ones(batch_size, dtype=torch.bool)\n",
        "    mask[remove_indices] = False\n",
        "\n",
        "    # index into the tensors using the mask to remove rows\n",
        "    input_ids = batch[\"input_ids\"][mask]\n",
        "    position_ids = batch[\"position_ids\"][mask]\n",
        "    attention_mask = batch[\"attention_mask\"][mask]\n",
        "    responses = [\n",
        "        r\n",
        "        for i, r in enumerate(batch[\"responses\"])\n",
        "        if i not in remove_indices\n",
        "    ]\n",
        "    tokens_remaining = [\n",
        "        v\n",
        "        for i, v in enumerate(batch[\"tokens_remaining\"])\n",
        "        if i not in remove_indices\n",
        "    ]\n",
        "\n",
        "    past_key_values = batch[\"past_key_values\"]\n",
        "    new_past_key_values = []\n",
        "    for i in range(len(past_key_values)):\n",
        "        k, v = past_key_values[i]\n",
        "        k = k[mask]\n",
        "        v = v[mask]\n",
        "        new_past_key_values.append((k, v))\n",
        "    past_key_values = new_past_key_values\n",
        "\n",
        "    if input_ids.size(0) > 0:\n",
        "        # next, as an optimization to avoid wasting\n",
        "        # compute cycles on padding tokens,\n",
        "        # we will left truncate the attention_mask\n",
        "        # and past_key_values to the longest\n",
        "        # remaining sequence length\n",
        "        # we obtain the longest sequence length by\n",
        "        # looking for the min first non-zero index\n",
        "        # of the attention mask\n",
        "        # cumprod ensures we stop accumulating when we see a 1\n",
        "        zero_mask = attention_mask == 0\n",
        "        cumprod = zero_mask.cumprod(dim=1)\n",
        "        leading_zeros_count = cumprod.sum(dim=1)\n",
        "        min_leading_zeros = torch.min(leading_zeros_count)\n",
        "        truncation_offset = min_leading_zeros.item()\n",
        "\n",
        "        # do the trunction\n",
        "        attention_mask = attention_mask[:, truncation_offset:]\n",
        "        past_key_values = past_key_values\n",
        "        new_past_key_values = []\n",
        "        for i in range(len(past_key_values)):\n",
        "            k, v = past_key_values[i]\n",
        "            k = k[:, :, truncation_offset:, :]\n",
        "            v = v[:, :, truncation_offset:, :]\n",
        "            new_past_key_values.append((k, v))\n",
        "        past_key_values = new_past_key_values\n",
        "\n",
        "    # return the new batch\n",
        "    return {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"position_ids\": position_ids,\n",
        "        \"attention_mask\": attention_mask,\n",
        "        \"past_key_values\": past_key_values,\n",
        "        \"responses\": responses,\n",
        "        \"tokens_remaining\": tokens_remaining,\n",
        "    }, remove_indices"
      ],
      "metadata": {
        "id": "x5ov2hCMulbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"openai-community/gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "A_9MmtdVu4ST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Add padding tokens to the model to prepare batches of prompts**"
      ],
      "metadata": {
        "id": "7U-tRkXTu8V6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define PAD Token = EOS Token = 50256\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model.config.pad_token_id = model.config.eos_token_id\n",
        "\n",
        "# pad on the left so we can append new tokens on the right\n",
        "tokenizer.padding_side = \"left\"\n",
        "tokenizer.truncation_side = \"left\""
      ],
      "metadata": {
        "id": "j-1bgXdYu9MD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# multiple prompts of varying lengths to send to the model at once\n",
        "prompts = [\n",
        "    \"The quick brown fox jumped over the\",\n",
        "    \"The rain in Spain falls\",\n",
        "    \"What comes up must\",\n",
        "]\n",
        "\n",
        "# note: padding=True ensures the padding token will be inserted into the tokenized tensors\n",
        "inputs = tokenizer(prompts, padding=True, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "x8CFr46hu9h3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define needed functions for batching**"
      ],
      "metadata": {
        "id": "uOzK2hyEvB9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_batch_tokens_with_past(inputs):\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    last_logits = logits[:, -1, :]\n",
        "    next_token_ids = last_logits.argmax(dim=1)\n",
        "    return next_token_ids, outputs.past_key_values\n",
        "\n",
        "\n",
        "def generate_batch(inputs, max_tokens):\n",
        "    # create a list of tokens for every input in the batch\n",
        "    generated_tokens = [[] for _ in range(inputs[\"input_ids\"].shape[0])]\n",
        "\n",
        "    attention_mask = inputs[\"attention_mask\"]\n",
        "    position_ids = attention_mask.long().cumsum(-1) - 1\n",
        "    position_ids.masked_fill_(attention_mask == 0, 1)\n",
        "\n",
        "    next_inputs = {\n",
        "        \"position_ids\": position_ids,\n",
        "        **inputs\n",
        "    }\n",
        "    for _ in range(max_tokens):\n",
        "        next_token_ids, past_key_values = generate_batch_tokens_with_past(next_inputs)\n",
        "        next_inputs = {\n",
        "            \"input_ids\": next_token_ids.reshape((-1, 1)),  # '-1' here means the remaining elements for this dim\n",
        "            \"position_ids\": next_inputs[\"position_ids\"][:, -1].unsqueeze(-1) + 1,  # increment last, discard the rest\n",
        "            \"attention_mask\": torch.cat([\n",
        "                next_inputs[\"attention_mask\"],\n",
        "                torch.ones((next_token_ids.shape[0], 1)),  # concatenate vector of 1's with shape [batch_size]\n",
        "            ], dim=1),\n",
        "            \"past_key_values\": past_key_values,\n",
        "        }\n",
        "\n",
        "        next_tokens = tokenizer.batch_decode(next_token_ids)\n",
        "        for i, token in enumerate(next_tokens):\n",
        "            generated_tokens[i].append(token)\n",
        "    return [\"\".join(tokens) for tokens in generated_tokens]"
      ],
      "metadata": {
        "id": "ZPlZE6Ryu9a-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the requests to be processed**"
      ],
      "metadata": {
        "id": "Xtk4tIA_vFwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# seed the random number generator so our results are deterministic\n",
        "random.seed(42)\n",
        "\n",
        "# constants\n",
        "queue_size = 32\n",
        "batch_size = 8\n",
        "\n",
        "# requests waiting to be processed\n",
        "# requests are tuples (prompt, max_tokens)\n",
        "request_queue = [\n",
        "    (prompts[0], 100 if i % batch_size == 0 else 10)\n",
        "    for i in range(queue_size)\n",
        "]"
      ],
      "metadata": {
        "id": "VBl6EVa_u9X2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "request_queue[:8]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ab2G8KymvGbu",
        "outputId": "92cbace0-996f-4311-b982-5506e933f743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The quick brown fox jumped over the', 100),\n",
              " ('The quick brown fox jumped over the', 10),\n",
              " ('The quick brown fox jumped over the', 10),\n",
              " ('The quick brown fox jumped over the', 10),\n",
              " ('The quick brown fox jumped over the', 10),\n",
              " ('The quick brown fox jumped over the', 10),\n",
              " ('The quick brown fox jumped over the', 10),\n",
              " ('The quick brown fox jumped over the', 10)]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batches = [\n",
        "    request_queue[i:i + batch_size]\n",
        "    for i in range(0, len(request_queue), batch_size)\n",
        "]"
      ],
      "metadata": {
        "id": "ajR2_IeIvGhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(batches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhLbMO9LvGeu",
        "outputId": "89262081-b5de-415b-bccc-a9929837ca14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batches[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrcA1W2ivJsQ",
        "outputId": "a5d9412e-7027-4e6f-c559-9aae046b73f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The quick brown fox jumped over the', 100),\n",
              " ('The quick brown fox jumped over the', 10),\n",
              " ('The quick brown fox jumped over the', 10),\n",
              " ('The quick brown fox jumped over the', 10),\n",
              " ('The quick brown fox jumped over the', 10),\n",
              " ('The quick brown fox jumped over the', 10),\n",
              " ('The quick brown fox jumped over the', 10),\n",
              " ('The quick brown fox jumped over the', 10)]"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Processing batches**"
      ],
      "metadata": {
        "id": "n_dnXqvFvMal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate tokens for all batches and record duration\n",
        "t0 = time.time()\n",
        "with tqdm(total=len(batches), desc=f\"bs={batch_size}\") as pbar:\n",
        "    for i, batch in enumerate(batches):\n",
        "        # to accommodate all the requests with our\n",
        "        # current implementation, we take the max of\n",
        "        # all the tokens to generate among the requests\n",
        "        batch_max_tokens = [b[1] for b in batch]\n",
        "        max_tokens = max(batch_max_tokens)\n",
        "        pbar.set_postfix({'max_tokens': max_tokens})\n",
        "\n",
        "        batch_prompts = [b[0] for b in batch]\n",
        "        inputs = tokenizer(\n",
        "            batch_prompts, padding=True, return_tensors=\"pt\")\n",
        "        generate_batch(inputs, max_tokens=max_tokens)\n",
        "\n",
        "        pbar.update(1)\n",
        "\n",
        "duration_s = time.time() - t0\n",
        "print(\"duration\", duration_s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPTXplYWvJpX",
        "outputId": "bf95b542-0e61-45a7-a34c-33e7043501dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "bs=8: 100%|██████████| 4/4 [00:49<00:00, 12.41s/it, max_tokens=100]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "duration 49.65493988990784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's try continuous batching**\n",
        "\n",
        "- This time, rather than processing each batch to completion, you will use continuous batching to dynamically swap in and out inputs from the queue."
      ],
      "metadata": {
        "id": "ipqeWxw-vPid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# seed the random number generator so our results are deterministic\n",
        "random.seed(42)\n",
        "\n",
        "# constants\n",
        "queue_size = 32\n",
        "batch_size = 8\n",
        "\n",
        "# requests waiting to be processed\n",
        "# this time requests are tuples (prompt, max_tokens)\n",
        "request_queue = [\n",
        "    (prompts[0], 100 if i % batch_size == 0 else 10)\n",
        "    for i in range(queue_size)\n",
        "]\n",
        "\n",
        "t0 = time.time()\n",
        "with tqdm(total=len(request_queue), desc=f\"bs={batch_size}\") as pbar:\n",
        "    # first, let's seed the initial cached_batch\n",
        "    # with the first `batch_size` inputs\n",
        "    # and run the initial prefill step\n",
        "    batch = init_batch(request_queue[:batch_size])\n",
        "    cached_batch = generate_next_token(batch)\n",
        "    request_queue = request_queue[batch_size:]\n",
        "\n",
        "    # continue until both the request queue is\n",
        "    # fully drained and every input\n",
        "    # within the cached_batch has completed generation\n",
        "    while (\n",
        "        len(request_queue) > 0 or\n",
        "        cached_batch[\"input_ids\"].size(0) > 0\n",
        "    ):\n",
        "        batch_capacity = (\n",
        "            batch_size - cached_batch[\"input_ids\"].size(0)\n",
        "        )\n",
        "        if batch_capacity > 0 and len(request_queue) > 0:\n",
        "            # prefill\n",
        "            new_batch = init_batch(request_queue[:batch_capacity])\n",
        "            new_batch = generate_next_token(new_batch)\n",
        "            request_queue = request_queue[batch_capacity:]\n",
        "\n",
        "            # merge\n",
        "            cached_batch = merge_batches(cached_batch, new_batch)\n",
        "\n",
        "        # decode\n",
        "        cached_batch = generate_next_token(cached_batch)\n",
        "\n",
        "        # remove any inputs that have finished generation\n",
        "        cached_batch, removed_indices = filter_batch(cached_batch)\n",
        "        pbar.update(len(removed_indices))\n",
        "\n",
        "duration_s = time.time() - t0\n",
        "print(\"duration\", duration_s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31Qxkb11vJma",
        "outputId": "2832d8e1-5cbf-4d1a-ed7d-07f1f0b46a90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "bs=8: 100%|██████████| 32/32 [00:18<00:00,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "duration 18.821728467941284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantization"
      ],
      "metadata": {
        "id": "MPwF3Y_PV3T0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from transformers.models.gpt2.modeling_gpt2 import GPT2Model"
      ],
      "metadata": {
        "id": "nvJkvP9CV5yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"openai-community/gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "FVkXyultV9YL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_batch_tokens_with_past(model, inputs):\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    last_logits = logits[:, -1, :]\n",
        "    next_token_ids = last_logits.argmax(dim=1)\n",
        "    return next_token_ids, outputs.past_key_values\n",
        "\n",
        "def init_batch(tokenizer, requests):\n",
        "    prompts = [r[0] for r in requests]\n",
        "    inputs = tokenizer(prompts, padding=True, return_tensors=\"pt\")\n",
        "\n",
        "    attention_mask = inputs[\"attention_mask\"]\n",
        "    position_ids = attention_mask.long().cumsum(-1) - 1\n",
        "    position_ids.masked_fill_(attention_mask == 0, 1)\n",
        "\n",
        "    return {\n",
        "        \"position_ids\": position_ids,\n",
        "        \"responses\": copy.copy(prompts),\n",
        "        \"tokens_remaining\": [r[1] for r in requests],\n",
        "        **inputs\n",
        "    }\n",
        "\n",
        "def filter_batch(batch):\n",
        "    # mark all rows with 0 tokens remaining for removal\n",
        "    remove_indices = []\n",
        "    for i, tokens_remaining in enumerate(batch[\"tokens_remaining\"]):\n",
        "        if tokens_remaining <= 0:\n",
        "            remove_indices.append(i)\n",
        "\n",
        "    completed_responses = [\n",
        "        r\n",
        "        for i, r in enumerate(batch[\"responses\"])\n",
        "        if i in remove_indices\n",
        "    ]\n",
        "\n",
        "    # first, define a mask used to subselect the indices to keep\n",
        "    # from each tensor, given the indices to remove\n",
        "    batch_size = batch[\"input_ids\"].size(0)\n",
        "    mask = torch.ones(batch_size, dtype=torch.bool)\n",
        "    mask[remove_indices] = False\n",
        "\n",
        "    # index into the tensors using the mask to remove rows\n",
        "    input_ids = batch[\"input_ids\"][mask]\n",
        "    position_ids = batch[\"position_ids\"][mask]\n",
        "    attention_mask = batch[\"attention_mask\"][mask]\n",
        "    responses = [\n",
        "        r\n",
        "        for i, r in enumerate(batch[\"responses\"])\n",
        "        if i not in remove_indices\n",
        "    ]\n",
        "    tokens_remaining = [\n",
        "        v\n",
        "        for i, v in enumerate(batch[\"tokens_remaining\"])\n",
        "        if i not in remove_indices\n",
        "    ]\n",
        "\n",
        "    past_key_values = batch[\"past_key_values\"]\n",
        "    new_past_key_values = []\n",
        "    for i in range(len(past_key_values)):\n",
        "        k, v = past_key_values[i]\n",
        "        k = k[mask]\n",
        "        v = v[mask]\n",
        "        new_past_key_values.append((k, v))\n",
        "    past_key_values = new_past_key_values\n",
        "\n",
        "    if input_ids.size(0) > 0:\n",
        "        # next, as an optimization to avoid wasting compute cycles on padding tokens,\n",
        "        # we will left truncate the attention_mask and past_key_values to the longest\n",
        "        # remaining sequence length\n",
        "        # we obtain the longest sequence length by looking for the min first non-zero index\n",
        "        # of the attention mask\n",
        "        zero_mask = attention_mask == 0\n",
        "        cumprod = zero_mask.cumprod(dim=1)  # cumprod ensures we stop accumulating when we see a 1\n",
        "        leading_zeros_count = cumprod.sum(dim=1)\n",
        "        min_leading_zeros = torch.min(leading_zeros_count)\n",
        "        truncation_offset = min_leading_zeros.item()\n",
        "\n",
        "        # do the trunction\n",
        "        attention_mask = attention_mask[:, truncation_offset:]\n",
        "        past_key_values = past_key_values\n",
        "        new_past_key_values = []\n",
        "        for i in range(len(past_key_values)):\n",
        "            k, v = past_key_values[i]\n",
        "            k = k[:, :, truncation_offset:, :]\n",
        "            v = v[:, :, truncation_offset:, :]\n",
        "            new_past_key_values.append((k, v))\n",
        "        past_key_values = new_past_key_values\n",
        "\n",
        "    # return the new batch\n",
        "    return {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"position_ids\": position_ids,\n",
        "        \"attention_mask\": attention_mask,\n",
        "        \"past_key_values\": past_key_values,\n",
        "        \"responses\": responses,\n",
        "        \"tokens_remaining\": tokens_remaining,\n",
        "    }, remove_indices, completed_responses\n",
        "\n",
        "def generate_next_token(model, tokenizer, batch):\n",
        "    inputs = copy.copy(batch)\n",
        "    inputs.pop(\"responses\")\n",
        "    inputs.pop(\"tokens_remaining\")\n",
        "\n",
        "    next_token_ids, past_key_values = generate_batch_tokens_with_past(model, inputs)\n",
        "    next_tokens = tokenizer.batch_decode(next_token_ids)\n",
        "    return get_next_inputs(batch, next_token_ids, past_key_values, next_tokens)\n",
        "\n",
        "def generate(model, tokenizer, requests):\n",
        "    # seed the random number generator so our results are deterministic\n",
        "    random.seed(42)\n",
        "\n",
        "    # constants\n",
        "    batch_size = 8\n",
        "    request_queue = copy.copy(requests)\n",
        "\n",
        "    responses = [None] * len(requests)\n",
        "\n",
        "    # and run the initial prefill step\n",
        "    batch = init_batch(tokenizer, request_queue[:batch_size])\n",
        "    cached_batch = generate_next_token(model, tokenizer, batch)\n",
        "    request_queue = request_queue[batch_size:]\n",
        "\n",
        "    # continue until both the request queue is fully drained and every input\n",
        "    # within the cached_batch has completed generation\n",
        "    while len(request_queue) > 0 or cached_batch[\"input_ids\"].size(0) > 0:\n",
        "        batch_capacity = batch_size - cached_batch[\"input_ids\"].size(0)\n",
        "        if batch_capacity > 0 and len(request_queue) > 0:\n",
        "            # prefill\n",
        "            new_batch = init_batch(tokenizer, request_queue[:batch_capacity])\n",
        "            new_batch = generate_next_token(model, tokenizer, new_batch)\n",
        "            request_queue = request_queue[batch_capacity:]\n",
        "\n",
        "            # merge\n",
        "            cached_batch = merge_batches(cached_batch, new_batch)\n",
        "\n",
        "        # decode\n",
        "        cached_batch = generate_next_token(model, tokenizer, cached_batch)\n",
        "\n",
        "        # remove any inputs that have finished generation\n",
        "        cached_batch, removed_indices, completed_responses = filter_batch(cached_batch)\n",
        "\n",
        "        for idx, resp in zip(removed_indices, completed_responses):\n",
        "            responses[idx] = resp\n",
        "\n",
        "    return responses"
      ],
      "metadata": {
        "id": "TKy0xqMRWTYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define PAD Token = EOS Token = 50256\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model.config.pad_token_id = model.config.eos_token_id\n",
        "\n",
        "# pad on the left so we can append new tokens on the right\n",
        "tokenizer.padding_side = \"left\"\n",
        "tokenizer.truncation_side = \"left\""
      ],
      "metadata": {
        "id": "pimqk25XWXdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define a Float 32 type**"
      ],
      "metadata": {
        "id": "DbQxW8YwV5fQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fix dtype post quantization to \"pretend\" to be fp32\n",
        "def get_float32_dtype(self):\n",
        "    return torch.float32\n",
        "GPT2Model.dtype = property(get_float32_dtype)"
      ],
      "metadata": {
        "id": "z-zBXj3NW0gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_memory_footprint()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGrwwir_W0Gp",
        "outputId": "873872d5-454f-4da0-d0e4-730666bece6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "510342192"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define a quantization function**"
      ],
      "metadata": {
        "id": "qTntNIyIW1EH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def quantize(t):\n",
        "    # obtain range of values in the tensor to map between 0 and 255\n",
        "    min_val, max_val = t.min(), t.max()\n",
        "\n",
        "    # determine the \"zero-point\", or value in the tensor to map to 0\n",
        "    scale = (max_val - min_val) / 255\n",
        "    zero_point = min_val\n",
        "\n",
        "    # quantize and clamp to ensure we're in [0, 255]\n",
        "    t_quant = (t - zero_point) / scale\n",
        "    t_quant = torch.clamp(t_quant, min=0, max=255)\n",
        "\n",
        "    # keep track of scale and zero_point for reversing quantization\n",
        "    state = (scale, zero_point)\n",
        "\n",
        "    # cast to uint8 and return\n",
        "    t_quant = t_quant.type(torch.uint8)\n",
        "    return t_quant, state"
      ],
      "metadata": {
        "id": "wSUvIYQqW1X-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = model.transformer.h[0].attn.c_attn.weight.data\n",
        "print(t, t.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eKqI82mW1qs",
        "outputId": "61dc450e-2861-4529-851d-eb5209cf8750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4738, -0.2614, -0.0978,  ...,  0.0513, -0.0584,  0.0250],\n",
            "        [ 0.0874,  0.1473,  0.2387,  ..., -0.0525, -0.0113, -0.0156],\n",
            "        [ 0.0039,  0.0695,  0.3668,  ...,  0.1143,  0.0363, -0.0318],\n",
            "        ...,\n",
            "        [-0.2592, -0.0164,  0.1991,  ...,  0.0095, -0.0516,  0.0319],\n",
            "        [ 0.1517,  0.2170,  0.1043,  ...,  0.0293, -0.0429, -0.0475],\n",
            "        [-0.4100, -0.1924, -0.2400,  ..., -0.0046,  0.0070,  0.0198]]) torch.Size([768, 2304])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_q, state = quantize(t)\n",
        "print(t_q, t_q.min(), t_q.max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwtUYdwQW-d1",
        "outputId": "9223bcd4-1a08-4813-807f-3cf5c57104ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[107, 116, 124,  ..., 130, 125, 129],\n",
            "        [132, 135, 139,  ..., 126, 128, 127],\n",
            "        [128, 131, 145,  ..., 133, 130, 127],\n",
            "        ...,\n",
            "        [116, 127, 137,  ..., 129, 126, 130],\n",
            "        [135, 138, 133,  ..., 129, 126, 126],\n",
            "        [110, 119, 117,  ..., 128, 128, 129]], dtype=torch.uint8) tensor(0, dtype=torch.uint8) tensor(255, dtype=torch.uint8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define a dequantization function**"
      ],
      "metadata": {
        "id": "57V7M14QW_FN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dequantize(t, state):\n",
        "    scale, zero_point = state\n",
        "    return t.to(torch.float32) * scale + zero_point"
      ],
      "metadata": {
        "id": "wg_fxSPlXBMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_rev = dequantize(t_q, state)\n",
        "print(t_rev)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wFjyvA4XCyN",
        "outputId": "6c5e0ed6-7efc-4942-d8ba-50096ca15477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4774, -0.2783, -0.1014,  ...,  0.0313, -0.0793,  0.0092],\n",
            "        [ 0.0755,  0.1419,  0.2303,  ..., -0.0572, -0.0129, -0.0351],\n",
            "        [-0.0129,  0.0534,  0.3630,  ...,  0.0976,  0.0313, -0.0351],\n",
            "        ...,\n",
            "        [-0.2783, -0.0351,  0.1861,  ...,  0.0092, -0.0572,  0.0313],\n",
            "        [ 0.1419,  0.2082,  0.0976,  ...,  0.0092, -0.0572, -0.0572],\n",
            "        [-0.4110, -0.2120, -0.2562,  ..., -0.0129, -0.0129,  0.0092]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.abs(t - t_rev)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_eBIh6EXDnz",
        "outputId": "f1a299ea-9962-475b-9ea3-dc87ddae7b88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0035, 0.0170, 0.0036,  ..., 0.0200, 0.0209, 0.0158],\n",
              "        [0.0119, 0.0055, 0.0084,  ..., 0.0046, 0.0017, 0.0195],\n",
              "        [0.0168, 0.0161, 0.0038,  ..., 0.0167, 0.0050, 0.0032],\n",
              "        ...,\n",
              "        [0.0191, 0.0187, 0.0131,  ..., 0.0004, 0.0056, 0.0006],\n",
              "        [0.0098, 0.0088, 0.0067,  ..., 0.0202, 0.0143, 0.0097],\n",
              "        [0.0010, 0.0196, 0.0162,  ..., 0.0084, 0.0199, 0.0107]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_expected = generate(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    [(\"The quick brown fox jumped over the\", 10)]\n",
        ")[0]\n",
        "response_expected"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "IaYS8d4NXEhT",
        "outputId": "73b69b24-d60f-4c9a-f196-1d37540d8687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The quick brown fox jumped over the fence and ran to the other side of the fence'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's apply the quantization technique to the entire model**"
      ],
      "metadata": {
        "id": "yxqtoruQXHJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def quantize_model(model):\n",
        "    states = {}\n",
        "    for name, param in model.named_parameters():\n",
        "        param.requires_grad = False\n",
        "        param.data, state = quantize(param.data)\n",
        "        states[name] = state\n",
        "    return model, states"
      ],
      "metadata": {
        "id": "Srdig9CgXHwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quant_model, states = quantize_model(model)"
      ],
      "metadata": {
        "id": "G060ZHJtXIKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quant_model.get_memory_footprint()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRTKQdKEXIFH",
        "outputId": "a192bc8b-58df-4ece-9d3f-2e434800108b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "137022768"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def size_in_bytes(t):\n",
        "    return t.numel() * t.element_size()"
      ],
      "metadata": {
        "id": "AUJBKnHvXICP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum([\n",
        "    size_in_bytes(v[0]) + size_in_bytes(v[1])\n",
        "    for v in states.values()\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szk9fDCWXH_h",
        "outputId": "3d5197a1-f4b1-42f7-d697-3abb1fabca5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1184"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dequantize_model(model, states):\n",
        "    for name, param in model.named_parameters():\n",
        "        state = states[name]\n",
        "        param.data = dequantize(param.data, state)\n",
        "    return model"
      ],
      "metadata": {
        "id": "qEiMbBRRXH76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dequant_model = dequantize_model(quant_model, states)"
      ],
      "metadata": {
        "id": "kugDZMfuXODO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dequant_model.get_memory_footprint()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xehRqGaFXOAk",
        "outputId": "676ffb0d-32c3-439a-999d-b8929f207f19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "510342192"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_expected = generate(\n",
        "    dequant_model,\n",
        "    tokenizer,\n",
        "    [(\"The quick brown fox jumped over the\", 10)]\n",
        ")[0]\n",
        "response_expected"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "lRpz2QZUXN90",
        "outputId": "ee08ce38-d9cf-425a-8429-16a6259bb5ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The quick brown fox jumped over the fence.\\n\\nThe fox jumped over the fence'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tuning"
      ],
      "metadata": {
        "id": "s8tRQu9eS9Yv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameter-Efficient Fine-Tuning (PEFT)"
      ],
      "metadata": {
        "id": "-WFpUVghVoad"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **PEFT**: Parameter-Efficient Fine-Tuning of billion-scale models on low-resource hardware. It freezes most parameters of a pre-trained\n",
        "\n"
      ],
      "metadata": {
        "id": "rOPTk5ixVpI5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adapter Tuning\n",
        "\n",
        "Fine-tuning involves copying the weights from a pre-trained network and tuning them on the downstream task (a new set of weights for each task).\n",
        "\n",
        "Multi-task learning requires simultaneous access to all tasks (memory intense).\n",
        "\n",
        "\n",
        "**Adapters** yield \"**parameter-efficient tuning**\" for NLP.\n",
        "It permits training on tasks **sequentially**!\n",
        "\n",
        "Tuning with adapter modules involves adding a small number of new parameters to a model, which are trained on the downstream task.\n",
        "\n",
        "In **adapter-tuning**, the parameters of the original network are **frozen** and therefore may be shared by many tasks."
      ],
      "metadata": {
        "id": "8T4beGTiWInB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AdapterFusion\n",
        "\n",
        "Sequential fine-tuning and multi-task learning are methods aiming to incorporate knowledge from multiple tasks; however, they suffer from **catastrophic forgetting and difficulties in dataset balancing**. To address these shortcomings, AdapterFusion, a new two stage learning algorithm that leverages knowledge from multiple tasks was proposed.\n",
        "\n",
        "Example, if you have 100 dataset, and 100 tasks, after lots of sequential fine-tuning the model might overwrite what it has learned.\n",
        "\n",
        "In this appraoch, each dataset has its own adapters. And there's one AdapterFusion layer for all.\n",
        "\n",
        "![adapterfusion architecture#](https://voicelab.ai/wp-content/uploads/obraz9.png)"
      ],
      "metadata": {
        "id": "p0rZtDfybRt8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Low-Rank Adaptation (LoRA)\n",
        "\n",
        "Goal: Loading a large model into a GPU with lower VRAM and being able to do calculations.\n",
        "\n",
        "\n",
        "\n",
        "> **LoRA**: Low-Rank Adaptation, a random projection to a smaller subspace. Freezes pre-trained model weights and injects trainable rank decomposition matrices inot each layer of Transformer"
      ],
      "metadata": {
        "id": "ssTHZig_CFSb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**LoRA**\n",
        "\n",
        "$$\n",
        "W_0 + \\Delta W = W_o + BA\n",
        "$$\n",
        "\n",
        "Where:\n",
        "- $W_0$ Original untouch model weights\n",
        "- $B$ Low rank matrix, $B \\in R^{dxr}$, $B$ is set to zero\n",
        "- $A$ Low rank matrix, $A \\in R^{rxk}$, $A$ is sampled from Normal Distribution\n",
        "  - rank r << min(d,k)\n",
        "\n",
        "In the Forward Pass:\n",
        "\n",
        "$$\n",
        "h = W_0x+\\Delta Wx = W_0x+ BAx \\\\\n",
        "$$"
      ],
      "metadata": {
        "id": "o0E47CuMTjHx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BA is acheived through SVD compression\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "M &= USV^T \\\\\n",
        "&= (US)V^T \\\\\n",
        "&= LR^T, \\text{ where} \\\\\n",
        "L &= (US), \\text{ and} \\\\\n",
        "R &= V\n",
        "\\end{align*}\n",
        "$$"
      ],
      "metadata": {
        "id": "WNJhQZdPxonl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "def regular_forward_matmul(x, W):\n",
        "  h = x @ W\n",
        "  return h\n",
        "\n",
        "def lora_forward_matmul(x, W, W_A, W_B):\n",
        "  h = x @ W # regular matrix multiplication\n",
        "  h += x @ (W_A @ W_B)*alpha # use scaled LoRA weights\n",
        "  return h\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "9Jmkp6KIDeak"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$BA$ is scaled by $\\frac{\\alpha}{r}$\n",
        "\n",
        "- $r$: The intrinsic dimension, which means to what extent we want to decompose the matrices. Typical numbers range from 1 to 64, and express the amount of compression on the weights.\n",
        "\n",
        "- $\\alpha$: Scaling factor. It controls the amount of change that is added to the original model weights. Using zero will output the original model, and using 1 will output the fully fine-tuned model, and anything larger will be amplifying it's effect."
      ],
      "metadata": {
        "id": "mK6-zqGZERSa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementing LoRA"
      ],
      "metadata": {
        "id": "nUppikWVgfwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "YX7vbJ8wgo2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set the seed so we get the same results from here on for each run\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpP5uEAsgsTH",
        "outputId": "f4e0e400-d1fa-42e3-8b06-4d31755b4256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x78ee5023d790>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create a test Model**"
      ],
      "metadata": {
        "id": "nmtkx277guJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TestModel(torch.nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super().__init__()\n",
        "        self.embedding = torch.nn.Embedding(10, hidden_size)\n",
        "        self.linear = torch.nn.Linear(hidden_size, hidden_size)\n",
        "        self.lm_head = torch.nn.Linear(hidden_size, 10)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        x = self.embedding(input_ids)\n",
        "        x = self.linear(x)\n",
        "        x = self.lm_head(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "kRkhkhKQgvPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set a reasonably large hidden size to illustrate the small fraction of\n",
        "# params needed to be added for LoRA\n",
        "hidden_size = 1024\n",
        "model = TestModel(hidden_size)"
      ],
      "metadata": {
        "id": "z-N3zpNygwJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dummy inputs\n",
        "input_ids = torch.LongTensor([[0, 1, 2, 3, 4, 5, 6, 7]])"
      ],
      "metadata": {
        "id": "B8jhj6_MgxG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# toy example of a detokenizer.\n",
        "# The vocabulary only consists of 10 words (different colors)\n",
        "detokenizer = [\n",
        "    \"red\",\n",
        "    \"orange\",\n",
        "    \"yellow\",\n",
        "    \"green\",\n",
        "    \"blue\",\n",
        "    \"indigo\",\n",
        "    \"violet\",\n",
        "    \"magenta\",\n",
        "    \"marigold\",\n",
        "    \"chartreuse\",\n",
        "]"
      ],
      "metadata": {
        "id": "nSuDXOeXgyOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is the same generation step as we saw in lesson 2 (batching)\n",
        "def generate_token(model, **kwargs):\n",
        "    with torch.no_grad():\n",
        "        logits = model(**kwargs)\n",
        "    last_logits = logits[:, -1, :]\n",
        "    next_token_ids = last_logits.argmax(dim=1)\n",
        "\n",
        "    return [detokenizer[token_id] for token_id in next_token_ids]"
      ],
      "metadata": {
        "id": "YhRXw6iDgz-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate one token\n",
        "next_token = generate_token(model, input_ids=input_ids)[0]\n",
        "next_token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "w6aVMVNVg1Ob",
        "outputId": "6269e4c2-66b7-41c1-956e-797d10ed4c21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'magenta'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dummy input tensor\n",
        "# shape: (batch_size, sequence_length, hidden_size)\n",
        "X = torch.randn(1, 8, 1024)"
      ],
      "metadata": {
        "id": "i2z8curWg19h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's set up the LoRA computation¶**"
      ],
      "metadata": {
        "id": "lkUPJxpQg3g_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LoRA A and B tensors\n",
        "# A has shape (hidden_size, rank)\n",
        "# B has shape (rank, hidden_size)\n",
        "R=2 # hyperparameter rank\n",
        "lora_a = torch.randn(1024, R)\n",
        "lora_b = torch.randn(R, 1024)"
      ],
      "metadata": {
        "id": "c1yOnlIEg4eA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W = model.linear.weight"
      ],
      "metadata": {
        "id": "PWQ1PMiOg5QN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W89PWw9Og6Eq",
        "outputId": "84685e91-613a-45ed-9023-10d27ac9a926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1024, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W2 = lora_a @ lora_b"
      ],
      "metadata": {
        "id": "18dnESJTg67r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBntMY5eg71N",
        "outputId": "96d73225-1ef3-4f9c-e231-f0a15d701a68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1024, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare number of elements of A and B with number of elements of W\n",
        "# W here has shape (hidden_size, hidden_size)\n",
        "lora_numel = lora_a.numel() + lora_b.numel()\n",
        "base_numel = W.numel()\n",
        "print(\"|A+B| / |W|:\", lora_numel / base_numel)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7xenaUHg80E",
        "outputId": "95d9f85d-3c5a-4a4e-a3da-9d13c40a801c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|A+B| / |W|: 0.00390625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's run the LoRA computation"
      ],
      "metadata": {
        "id": "pxAcSa15g_v-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the output of X @ W (the original linear layer)\n",
        "base_output = model.linear(X)\n",
        "\n",
        "# compute the output of X @ A @ B (the added lora adapter)\n",
        "lora_output = X @ lora_a @ lora_b\n",
        "\n",
        "# sum them together\n",
        "total_output = base_output + lora_output\n",
        "\n",
        "# output should have the same shape as the original output:\n",
        "# (batch_size, sequence_length, hidden_size)\n",
        "total_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aWFfCqeg_Yd",
        "outputId": "92d8d13d-feb2-4682-c175-5fcadcd0bfd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LoraLayer(torch.nn.Module):\n",
        "    def __init__(self, base_layer, r):\n",
        "        super().__init__()\n",
        "        self.base_layer = base_layer\n",
        "\n",
        "        d_in, d_out = self.base_layer.weight.shape\n",
        "        self.lora_a = torch.randn(d_in, r)\n",
        "        self.lora_b = torch.randn(r, d_out)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y1 = self.base_layer(x)\n",
        "        y2 = x @ self.lora_a @ self.lora_b\n",
        "        return y1 + y2"
      ],
      "metadata": {
        "id": "pRyFXvE7hDg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wrap the linear layer of our toy model, use rank 2\n",
        "lora_layer = LoraLayer(model.linear, 2)\n",
        "lora_layer(X).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1ivmlz3hFNq",
        "outputId": "89600745-f162-4def-e831-aa27f4c76825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.linear = lora_layer"
      ],
      "metadata": {
        "id": "R0IbG82PhF-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sadii3J6hGuT",
        "outputId": "88353c01-b34f-4a26-ab8b-9cdbf08eeec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TestModel(\n",
              "  (embedding): Embedding(10, 1024)\n",
              "  (linear): LoraLayer(\n",
              "    (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1024, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's try the generate token after adding the LoRA layer**"
      ],
      "metadata": {
        "id": "RRx7_jFthIEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "next_token = generate_token(model, input_ids=input_ids)\n",
        "next_token[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "upfDqShUhJE8",
        "outputId": "7db42739-ab3b-4208-83e7-d050ad718935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'chartreuse'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementing Multi-LoRA"
      ],
      "metadata": {
        "id": "lnFGYyZskYxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "dMHBK7TlkdFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's create a new model**\n",
        "\n",
        "It has a custom helper function for computing the LoRA layer step with multiple LoRAs per batch."
      ],
      "metadata": {
        "id": "OUlrcpNekiQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AbstractMultiLoraModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # hidden_size = 10\n",
        "        # set this so low to ensure we are not\n",
        "        # compute-bound by the linear layer\n",
        "        # this is only an issue when running on CPU,\n",
        "        # for GPUs we can set this much\n",
        "        # higher and still avoid being compute bound\n",
        "        self.embedding = torch.nn.Embedding(10, 10)\n",
        "        self.linear = torch.nn.Linear(10, 10)\n",
        "        self.lm_head = torch.nn.Linear(10, 10)\n",
        "\n",
        "    def linear_lora(\n",
        "        self,\n",
        "        x: torch.Tensor,                 # (batch_size, seq_len, in_features)\n",
        "        loras_a: torch.Tensor,           # (num_loras, in_features, rank)\n",
        "        loras_b: torch.Tensor,           # (num_loras, rank, out_features)\n",
        "        lora_indices: torch.LongTensor,  # (batch_size,)\n",
        "    ) -> torch.Tensor:\n",
        "        # y[i] = x[i] @ loras_a[lora_idx] @ loras_b[lora_idx]\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def forward(self, input_ids, loras_a, loras_b, lora_indices):\n",
        "        x = self.embedding(input_ids)\n",
        "        x = self.linear_lora(x, loras_a, loras_b, lora_indices)\n",
        "        x = self.lm_head(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "y68kAcRdkdCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using a loop**\n",
        "\n",
        "Our first attempt to infer across multiple LoRAs will be straightforward: just loop over every row in the batch and apply the correct LoRA using an index mapping: `batch_index --> lora_index`."
      ],
      "metadata": {
        "id": "wcSpUg9wktW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LoopMultiLoraModel(AbstractMultiLoraModel):\n",
        "    def linear_lora(\n",
        "        self,\n",
        "        x: torch.Tensor,                 # (batch_size, seq_len, in_features)\n",
        "        loras_a: torch.Tensor,           # (num_loras, in_features, lora_rank)\n",
        "        loras_b: torch.Tensor,           # (num_loras, lora_rank, out_features)\n",
        "        lora_indices: torch.LongTensor,  # (batch_size,)\n",
        "    ) -> torch.Tensor:\n",
        "        y = self.linear(x)\n",
        "        for batch_idx, lora_idx in enumerate(lora_indices.numpy()):\n",
        "            lora_a = loras_a[lora_idx]\n",
        "            lora_b = loras_b[lora_idx]\n",
        "            y[batch_idx] += x[batch_idx] @ lora_a @ lora_b\n",
        "        return y"
      ],
      "metadata": {
        "id": "x-3hXibokc_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# toy example of a detokenizer. The vocabular only consists of 10 words (different colors)\n",
        "detokenizer = [\n",
        "    \"red\",\n",
        "    \"orange\",\n",
        "    \"yellow\",\n",
        "    \"green\",\n",
        "    \"blue\",\n",
        "    \"indigo\",\n",
        "    \"violet\",\n",
        "    \"magenta\",\n",
        "    \"marigold\",\n",
        "    \"chartreuse\",\n",
        "]"
      ],
      "metadata": {
        "id": "EEZMjEBLkc8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dummy inputs\n",
        "input_ids = torch.LongTensor([[0, 1, 2, 3, 4, 5, 6, 7]])"
      ],
      "metadata": {
        "id": "fz768s51kc5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8J3WHuJkc2G",
        "outputId": "04a1a9fc-4860-4644-a133-af9aa773f763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x78ee5023d790>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_token(model, **kwargs):\n",
        "    with torch.no_grad():\n",
        "        logits = model(**kwargs)\n",
        "    last_logits = logits[:, -1, :]\n",
        "    next_token_ids = last_logits.argmax(dim=1)\n",
        "\n",
        "    return [detokenizer[token_id] for token_id in next_token_ids]"
      ],
      "metadata": {
        "id": "SHOAkWsmkplD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LoopMultiLoraModel()"
      ],
      "metadata": {
        "id": "YL4_gRDukpi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's try it!**\n",
        "\n",
        "We will try this over a few random LoRAs using a fixed tensor of input_ids. If our multi-LoRA generation process is working as designed, we should see a variety of different outputs generated as we randomly iterate over the LoRAs."
      ],
      "metadata": {
        "id": "Nmlb5Lojkx-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# constants\n",
        "bs = 1\n",
        "num_loras = 64\n",
        "h = 10\n",
        "r = 2\n",
        "\n",
        "# create contiguous blocks for 64 random LoRA weights\n",
        "loras_a = torch.randn(num_loras, h, r)\n",
        "loras_b = torch.randn(num_loras, r, h)\n",
        "\n",
        "for i in range(10):\n",
        "    # randomize the LoRAs each iteration\n",
        "    lora_indices = torch.randint(num_loras, (bs,), dtype=torch.long)\n",
        "    next_token = generate_token(\n",
        "        model,\n",
        "        input_ids=input_ids,\n",
        "        loras_a=loras_a,\n",
        "        loras_b=loras_b,\n",
        "        lora_indices=lora_indices,\n",
        "    )\n",
        "    print(next_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hf3eHH96k0B6",
        "outputId": "44a6b33f-2a64-4334-d5ae-fa50fa9675c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['orange']\n",
            "['red']\n",
            "['chartreuse']\n",
            "['yellow']\n",
            "['marigold']\n",
            "['yellow']\n",
            "['red']\n",
            "['orange']\n",
            "['violet']\n",
            "['red']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's benchmark our multi-LoRA system!**\n",
        "\n",
        "We will measure the average latency to generate a single token as the batch size increases and each element within the batch can have a different LoRA adapter (chosen randomly)."
      ],
      "metadata": {
        "id": "cLfLyCQlk18r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# constants\n",
        "seq_len = 8\n",
        "vocab_size = 10\n",
        "nsamples = 500\n",
        "max_batch_size = 64\n",
        "\n",
        "\n",
        "def benchmark(model):\n",
        "    avg_latencies = []\n",
        "    for bs in range(1, max_batch_size + 1):\n",
        "        latencies = []\n",
        "        for _ in range(nsamples):\n",
        "            # randomize the inputs and LoRA indices\n",
        "            input_ids = torch.randint(\n",
        "                vocab_size, (bs, seq_len), dtype=torch.long)\n",
        "            lora_indices = torch.randint(\n",
        "                num_loras, (bs,), dtype=torch.long)\n",
        "\n",
        "            # measure the end-to-end latency for\n",
        "            # generating a single token\n",
        "            t0 = time.time()\n",
        "            next_token = generate_token(\n",
        "                model,\n",
        "                input_ids=input_ids,\n",
        "                loras_a=loras_a,\n",
        "                loras_b=loras_b,\n",
        "                lora_indices=lora_indices,\n",
        "            )\n",
        "            latencies.append(time.time() - t0)\n",
        "\n",
        "        # average the latency across all the samples\n",
        "        latency_s = sum(latencies) / len(latencies)\n",
        "        avg_latencies.append(latency_s)\n",
        "        print(bs, latency_s)\n",
        "    return avg_latencies"
      ],
      "metadata": {
        "id": "SiTOpE8Fk38C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_latencies_loop = benchmark(model)"
      ],
      "metadata": {
        "id": "IXq8cXM2k35P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's visualize it!**"
      ],
      "metadata": {
        "id": "Px-0gJ9Ek7SU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = list(range(1, max_batch_size + 1))\n",
        "plt.plot(x, avg_latencies_loop, label=\"loop\")\n",
        "\n",
        "plt.xlabel('Batch Size')\n",
        "plt.ylabel('Avg Latency (s)')\n",
        "plt.title('Multi-LoRA latency w.r.t. batch size')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "NCxfb4NEk3eO",
        "outputId": "390b284a-61f0-4e2e-81b2-bf46063c8868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's vectorize the LoRA computation**\n",
        "\n",
        "We will vectorize the LoRA computation by:\n",
        "\n",
        "1. Gather the LoRA weight for each batch into a single tensor using `torch.index_select`.\n",
        "2. Apply LoRA computation once for the entire input tensor."
      ],
      "metadata": {
        "id": "NlTH7jF9k-d2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GatheredMultiLoraModel(AbstractMultiLoraModel):\n",
        "    def linear_lora(\n",
        "        self,\n",
        "        x: torch.Tensor,                 # (batch_size, seq_len, in_features)\n",
        "        loras_a: torch.Tensor,           # (num_loras, in_features, lora_rank)\n",
        "        loras_b: torch.Tensor,           # (num_loras, lora_rank, out_features)\n",
        "        lora_indices: torch.LongTensor,  # (batch_size,)\n",
        "    ) -> torch.Tensor:\n",
        "        y = self.linear(x)\n",
        "\n",
        "        # gather the LoRA weights into a new tensor and apply\n",
        "        lora_a = torch.index_select(loras_a, 0, lora_indices) # (batch_size, in_features, lora_rank)\n",
        "        lora_b = torch.index_select(loras_b, 0, lora_indices) # (batch_size, lora_rank, out_features)\n",
        "        y += x @ lora_a @ lora_b\n",
        "        return y"
      ],
      "metadata": {
        "id": "EwBEM1eJlAni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GatheredMultiLoraModel()"
      ],
      "metadata": {
        "id": "YLQw5tCklCwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_latencies_gathered = benchmark(model)"
      ],
      "metadata": {
        "id": "8usyKGhFlDwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's visualize it!**"
      ],
      "metadata": {
        "id": "9SQDHFqelFU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = list(range(1, max_batch_size + 1))\n",
        "plt.plot(x, avg_latencies_loop, label=\"loop\")\n",
        "plt.plot(x, avg_latencies_gathered, label=\"gathered\")\n",
        "\n",
        "plt.xlabel('Batch Size')\n",
        "plt.ylabel('Avg Latency (s)')\n",
        "plt.title('Multi-LoRA latency w.r.t. batch size')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "AoBfz1OulGQi",
        "outputId": "65d23716-cced-452e-e9d6-9d34a7b2fad2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantization\n",
        "\n",
        "The weights stored in model use 32-bit floating-point numbers.\n",
        "\n",
        "**Quantization** is a technique to reduce the precision of the numbers used in the model. For example, in 4-bit quantization, the weights and activations of the network are compressed from 32-bit floating-point numbers to 4-bit integers."
      ],
      "metadata": {
        "id": "c80BXEChZl2h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4-Bit NormalFloat Quantization\n",
        "\n",
        "A 4-bit integer can range from -8 to 7! How!?\n",
        "\n",
        "1. **Normalization:** The weights of the model are first normalized to have **zero mean** and **unit variance**. This ensures that the weights are **distributed around zero** and fall within a certain range.\n",
        "\n",
        "2. **Quantization:** The normalized weights are then **quantized to 4 bits**. This involves mapping the original high-precision weights to a smaller set of low-precision values. In the case of NF4, the **quantization levels are chosen to be evenly spaced** in the range of the normalized weights.\n",
        "\n",
        "3. **Dequantization:** During the forward pass and backpropagation, the quantized weights are **dequantized back to full precision**. This is done by mapping the 4-bit quantized values back to their original range. The dequantized weights are used in the computations, but they are stored in memory in their 4-bit quantized form.\n"
      ],
      "metadata": {
        "id": "jZARw3V4Z5v3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Note that while the weights are stored as 4-bit integers, they are typically converted back to 32- bit floating-point numbers for the actual computations.\n",
        "\n",
        "**Example**\n",
        "\n",
        "A weight in our NN that is a 32-bit floating-point number, and its value is 0.5678.\n",
        "\n",
        "Let's say our 4-bit integers represent 16 levels evenly spaced between -1 and 1. These levels would be: -1.0, -0.8667, -0.7333, -0.6, -0.4667, -0.3333, -0.2, -0.0667, 0.0667, 0.2, 0.3333, 0.4667, 0.6, 0.7333, 0.8667, 1.0\n",
        "\n",
        "Our original weight value of 0.5678 is closest to 0.6, so we would quantize this weight to 0.6.\n",
        "\n",
        "In our 4-bit representation, let's say 0.6 corresponds to the integer 13. We store the 4-bit integer 13 instead of the 32-bit floating-point number 0.5678.\n",
        "\n",
        "If we use this weight in a computation, we first dequantize it back (0.6) to the floating-point number. The dequantization error is 0.6 -0.5678 = 0.0322 (rem: 1 level spaced out is 0.1333-> 1/4 of a space)"
      ],
      "metadata": {
        "id": "xPrB6Cvibvih"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quantization and Low Rank Adaptors (QLoRA)\n",
        "\n",
        "4-bit Integer Quantization of original 32-bit weights and apply **Parameter Efficient Fine Tuning (PEFT)**, inject LoRA adapters into each layer, in 32-bit precision, and start to **fine-tune the complete Language model** on a specific task, for the quantized configuration to reduce quantization error of the system."
      ],
      "metadata": {
        "id": "gqa83-O9gTE_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Around 1% of all tensor weights are injected LoRa adapter weight tensors, in 32-bit precision\n",
        "\n",
        "If we have a 175B model, we have more than 1 billion injected adapter weights in 32-bit precision.\n",
        "\n",
        "The injected LoRA weight tensors are the only trainable parameters. The rest of the params (the other 99%) are frozen.\n",
        "\n",
        "\n",
        "$$\n",
        "\\begin{matrix}\n",
        "\\ddots & \\vdots & \\vdots & \\vdots & ⋰\\\\\n",
        "\\cdots & 4bit & 4bit & 4bit & \\cdots \\\\\n",
        "\\cdots & 4bit & 32bit & 4bit & \\cdots \\\\\n",
        "\\cdots & 4bit & 4bit & 4bit & \\cdots \\\\\n",
        "⋰ & \\vdots & \\vdots & \\vdots & \\ddots \\\\\n",
        "\\end{matrix} \\\\\n",
        "$$\n",
        "\n",
        "The $32bit$ weight is the LoRA adapter.\n",
        "\n",
        "During computation (forward pass or backward propogation), **dequantization** happens:\n",
        "\n",
        "$$\n",
        "\\begin{matrix}\n",
        "\\ddots & \\vdots & \\vdots & \\vdots & ⋰\\\\\n",
        "\\cdots & 32bit & 32bit & 32bit & \\cdots \\\\\n",
        "\\cdots & 32bit & 32bit & 32bit & \\cdots \\\\\n",
        "\\cdots & 32bit & 32bit & 32bit & \\cdots \\\\\n",
        "⋰ & \\vdots & \\vdots & \\vdots & \\ddots \\\\\n",
        "\\end{matrix} \\\\\n",
        "$$\n",
        "\n",
        "This process is not save in memory, dequantization only happens during computation.\n",
        "\n",
        "After backpropogation, only the LoRA weight is updated ($32bit \\rightarrow {32bit}^*$), and the rest of the weights are restored to the $4bit$ version.\n",
        "\n",
        "$$\n",
        "\\begin{matrix}\n",
        "\\ddots & \\vdots & \\vdots & \\vdots & ⋰\\\\\n",
        "\\cdots & 4bit & 4bit & 4bit & \\cdots \\\\\n",
        "\\cdots & 4bit & {32bit}^* & 4bit & \\cdots \\\\\n",
        "\\cdots & 4bit & 4bit & 4bit & \\cdots \\\\\n",
        "⋰ & \\vdots & \\vdots & \\vdots & \\ddots \\\\\n",
        "\\end{matrix} \\\\\n",
        "$$\n"
      ],
      "metadata": {
        "id": "4dVv5tLng-A7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each dequantized weight, would have a precision error when converted to full-bit size due to the rounding happening at the quantization time.\n",
        "\n",
        "The LoRA weight tensor is not affect by dequantization-error as it never gets quantized.\n",
        "\n",
        "\n",
        "With the QLORA fine-tuning the system (NN) learns the new specific task it is fine-tuned on, given its actual **dequantization error** of every single weight tensor (kept frozen, not updated) of **4-bit precision**."
      ],
      "metadata": {
        "id": "GxJOe1Xnw3L_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The additional low-rank adapters in the QLORA method are in a higher precision format, typically 32-bit floating-point (bflaot16), for a few reasons:\n",
        "\n",
        "- Higher precision allows the model to capture more subtle patterns in the data. This is particularly important for the low-rank adapters, as they are responsible for adapting the pre-trained model to the specific task it is being fine-tuned for.\n",
        "\n",
        "- Training neural networks involves a lot of incremental updates to the weights. Weights in a higher precision format ensures that updates are accurately captured.\n",
        "\n",
        "- While quantizing all weights can save memory, the computational efficiency might not always improve. GPUs are optimized for 32-bit (bfloat16) operations. Computations w/ 32-bit floating-point can be faster than with lower precision."
      ],
      "metadata": {
        "id": "Zp1lrLhSq8Qn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Implementation\n",
        "\n",
        "Run the cells below to setup and install the required libraries. For our experiment we will need `accelerate`, `peft`, `transformers`, `datasets` and TRL to leverage the recent [`SFTTrainer`](https://huggingface.co/docs/trl/main/en/sft_trainer). We will use `bitsandbytes` to [quantize the base model into 4bit](https://huggingface.co/blog/4bit-transformers-bitsandbytes). We will also install `einops` as it is a requirement to load Falcon models."
      ],
      "metadata": {
        "id": "xM44VjYlhpRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# From Artidoro Pagnoni @ https://colab.research.google.com/drive/1BiQiw31DT7-cDp1-0ySXvvhzqomTdI-o?usp=sharing\n",
        "!pip install -q -U trl transformers accelerate git+https://github.com/huggingface/peft.git\n",
        "!pip install -q datasets bitsandbytes einops wandb"
      ],
      "metadata": {
        "id": "f1Qj5VsBho57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset**\n",
        "\n",
        "For our experiment, we will use the Guanaco dataset, which is a clean subset of the OpenAssistant dataset adapted to train general purpose chatbots.\n",
        "\n",
        "The dataset can be found [here](https://huggingface.co/datasets/timdettmers/openassistant-guanaco)"
      ],
      "metadata": {
        "id": "Rnqmq7amRrU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset_name = \"timdettmers/openassistant-guanaco\"\n",
        "dataset = load_dataset(dataset_name, split=\"train\")"
      ],
      "metadata": {
        "id": "ga8ozl2chovb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the model**\n",
        "\n",
        "In this section we will load the [Falcon 7B model](https://huggingface.co/tiiuae/falcon-7b), quantize it in 4bit and attach LoRA adapters on it. Let's get started!"
      ],
      "metadata": {
        "id": "AjB0WAqFSzlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoTokenizer\n",
        "\n",
        "model_name = \"ybelkada/falcon-7b-sharded-bf16\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "model.config.use_cache = False"
      ],
      "metadata": {
        "id": "ZwXZbQ2dSwzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the tokenizer below\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "V2XvYIG1iUge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we will load the configuration file in order to create the LoRA model. According to QLoRA paper, it is important to consider all linear layers in the transformer block for maximum performance. Therefore we will add `dense`, `dense_h_to_4_h` and `dense_4h_to_h` layers in the target modules in addition to the mixed query key value layer."
      ],
      "metadata": {
        "id": "NuAx3zBeUL1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig\n",
        "\n",
        "lora_alpha = 16\n",
        "lora_dropout = 0.1\n",
        "lora_r = 64\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=lora_alpha,\n",
        "    lora_dropout=lora_dropout,\n",
        "    r=lora_r,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=[\n",
        "        \"query_key_value\",\n",
        "        \"dense\",\n",
        "        \"dense_h_to_4h\",\n",
        "        \"dense_4h_to_h\",\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "fKJVx_V8iUdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the trainer**\n",
        "\n",
        "Here we will use the [`SFTTrainer` from TRL library](https://huggingface.co/docs/trl/main/en/sft_trainer) that gives a wrapper around transformers `Trainer` to easily fine-tune models on instruction based datasets using PEFT adapters. Let's first load the training arguments below."
      ],
      "metadata": {
        "id": "aTBJVE4PaJwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "output_dir = \"./results\"\n",
        "per_device_train_batch_size = 4\n",
        "gradient_accumulation_steps = 4\n",
        "optim = \"paged_adamw_32bit\"\n",
        "save_steps = 10\n",
        "logging_steps = 10\n",
        "learning_rate = 2e-4\n",
        "max_grad_norm = 0.3\n",
        "max_steps = 500\n",
        "warmup_ratio = 0.03\n",
        "lr_scheduler_type = \"constant\"\n",
        "\n",
        "training_arguments = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    per_device_train_batch_size=per_device_train_batch_size,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "    optim=optim,\n",
        "    save_steps=save_steps,\n",
        "    logging_steps=logging_steps,\n",
        "    learning_rate=learning_rate,\n",
        "    fp16=True,\n",
        "    max_grad_norm=max_grad_norm,\n",
        "    max_steps=max_steps,\n",
        "    warmup_ratio=warmup_ratio,\n",
        "    group_by_length=True,\n",
        "    lr_scheduler_type=lr_scheduler_type,\n",
        "    gradient_checkpointing=True,\n",
        ")"
      ],
      "metadata": {
        "id": "OCFTvGW6aspE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then finally pass everthing to the trainer"
      ],
      "metadata": {
        "id": "I3t6b2TkcJwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer\n",
        "\n",
        "max_seq_length = 512\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset,\n",
        "    peft_config=peft_config,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        ")"
      ],
      "metadata": {
        "id": "TNeOBgZeTl2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will also pre-process the model by upcasting the layer norms in float 32 for more stable training"
      ],
      "metadata": {
        "id": "GWplqqDjb3sS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, module in trainer.model.named_modules():\n",
        "    if \"norm\" in name:\n",
        "        module = module.to(torch.float32)"
      ],
      "metadata": {
        "id": "7OyIvEx7b1GT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the model**\n",
        "\n",
        "Now let's train the model! Simply call `trainer.train()`"
      ],
      "metadata": {
        "id": "JjvisllacNZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "_kbS7nRxcMt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "During training, the model should converge nicely as follows:\n",
        "\n",
        "![image](https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/images/loss-falcon-7b.png)\n",
        "\n",
        "The `SFTTrainer` also takes care of properly saving only the adapters during training instead of saving the entire model."
      ],
      "metadata": {
        "id": "H5c0ppfasK29"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save and Loading fine-tuned model**"
      ],
      "metadata": {
        "id": "anK0_e51so_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir=\"fine-tuned-model\"\n",
        "\n",
        "model.save_pretrained(output_dir)"
      ],
      "metadata": {
        "id": "u_aHCBhAsuCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from peft import PeftModel, PeftConfig\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "config = PeftConfig.from_pretrained(output_dir)\n",
        "model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, return_dict=True, load_in_8bit=True, device_map='auto')\n",
        "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
        "\n",
        "# Load the Lora model\n",
        "model = PeftModel.from_pretrained(model, peft_model_id)"
      ],
      "metadata": {
        "id": "YlJRqH4QsrNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mixed Precision Training\n",
        "\n",
        "Perform additionally a **mixed precision training** to balance the trade-off between accuracy and speed/memory usage.\n",
        "\n",
        "With all optimization steps and additional training of the model, 4-bit QLoRA performs equivalent to a bfloat16 model."
      ],
      "metadata": {
        "id": "BE6k_bXIzJ6A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8-bit** binary number `11010110` represents the decimal number 214 (max 255)\n",
        "\n",
        "**16-bit integers** can represent values between 0 and 65,535 for unsign int.\n",
        "\n",
        "**float16**: 0 11101 1010000000 is the number 52736 (16-bit binary format, first digit is the sign, the next 5 are the exponents, and the rest are the mantissa bits.).\n",
        "\n",
        "**bfloat16**: one sign bit, eight exponent bits, and seven mantissa bits.\n",
        "\n",
        "> Hardware multiplier scales with the square of the mantissa width\n",
        "\n",
        "\n",
        "The *physical size* of **bfloat16 multiplier**s are **half the size in silicon of a FP16** multiplier, and are **eight times smaller than an float32** multiplier.\n",
        "\n",
        "> Neural networks are more sensitive to the size of the Exponent than the size of the mantissa.\n",
        "\n",
        "To ensure identical behavior **bfloat16** has **the same Exponent size as float32** (both have 8bit exponent size). Google optimized TPUs (also) for bfloat16.\n",
        "\n",
        "Mixed-precision training: **XLA compiler** automatically converts values between float32 and bfloat16. -> PyTorch 2.0, pure in JAX and in TensorFlow2"
      ],
      "metadata": {
        "id": "EAC8yh-TxoBW"
      }
    }
  ]
}